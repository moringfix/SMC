2025-04-16 17:31:59,508 - 【无监督】进入了无监督的设定中, 加载数据集
2025-04-16 17:31:59,508 - data preparation...
2025-04-16 17:32:08,922 - Number of train samples = 1779
2025-04-16 17:32:08,923 - Number of testing samples = 445
2025-04-16 17:32:08,923 - data preparation...
2025-04-16 17:32:11,372 - num_train_examples = 1779
2025-04-16 17:32:11,373 - ============================== Params ==============================
2025-04-16 17:32:11,373 - logger_name: umc_umc_bert-base-uncased_MIntRec_3
2025-04-16 17:32:11,373 - dataset: MIntRec
2025-04-16 17:32:11,373 - multimodal_method: umc
2025-04-16 17:32:11,373 - method: umc
2025-04-16 17:32:11,373 - setting: unsupervised
2025-04-16 17:32:11,373 - text_backbone: bert-base-uncased
2025-04-16 17:32:11,373 - seed: 3
2025-04-16 17:32:11,373 - num_workers: 16
2025-04-16 17:32:11,373 - log_id: umc_umc_bert-base-uncased_MIntRec_3_2025-04-16-17-31-59
2025-04-16 17:32:11,373 - gpu_id: 1
2025-04-16 17:32:11,373 - data_path: /root/autodl-tmp/home/Share/Dataset/LZH
2025-04-16 17:32:11,373 - train: True
2025-04-16 17:32:11,373 - tune: True
2025-04-16 17:32:11,373 - save_model: True
2025-04-16 17:32:11,373 - save_results: True
2025-04-16 17:32:11,373 - log_path: logs
2025-04-16 17:32:11,373 - cache_path: cache
2025-04-16 17:32:11,373 - video_data_path: video_data
2025-04-16 17:32:11,373 - audio_data_path: audio_data
2025-04-16 17:32:11,373 - video_feats_path: swin_feats.pkl
2025-04-16 17:32:11,373 - audio_feats_path: wavlm_feats.pkl
2025-04-16 17:32:11,373 - results_path: results
2025-04-16 17:32:11,373 - output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/SMC/outputs_test2/MIntRec
2025-04-16 17:32:11,373 - model_path: models
2025-04-16 17:32:11,373 - config_file_name: umc_MIntRec
2025-04-16 17:32:11,374 - results_file_name: results_umc.csv
2025-04-16 17:32:11,374 - text_pretrained_model: uncased_L-12_H-768_A-12
2025-04-16 17:32:11,374 - pretrained_bert_model: uncased_L-12_H-768_A-12
2025-04-16 17:32:11,374 - pretrain_batch_size: 128
2025-04-16 17:32:11,374 - train_batch_size: 128
2025-04-16 17:32:11,374 - eval_batch_size: 128
2025-04-16 17:32:11,374 - test_batch_size: 128
2025-04-16 17:32:11,374 - num_pretrain_epochs: 100
2025-04-16 17:32:11,374 - num_train_epochs: 100
2025-04-16 17:32:11,374 - pretrain: [True]
2025-04-16 17:32:11,374 - aligned_method: ctc
2025-04-16 17:32:11,374 - need_aligned: False
2025-04-16 17:32:11,374 - freeze_pretrain_bert_parameters: [True]
2025-04-16 17:32:11,374 - freeze_train_bert_parameters: [True]
2025-04-16 17:32:11,374 - pretrain_temperature: [0.1]
2025-04-16 17:32:11,374 - train_temperature_sup: [0.5]
2025-04-16 17:32:11,374 - train_temperature_unsup: [2]
2025-04-16 17:32:11,374 - activation: tanh
2025-04-16 17:32:11,374 - lr_pre: [3e-05]
2025-04-16 17:32:11,374 - lr: [5e-05]
2025-04-16 17:32:11,374 - delta: [0.05]
2025-04-16 17:32:11,374 - thres: [0.1]
2025-04-16 17:32:11,374 - topk: [5]
2025-04-16 17:32:11,374 - weight_decay: 0.01
2025-04-16 17:32:11,374 - feat_dim: 768
2025-04-16 17:32:11,374 - hidden_size: 768
2025-04-16 17:32:11,374 - grad_clip: -1.0
2025-04-16 17:32:11,374 - warmup_proportion: [0.1]
2025-04-16 17:32:11,374 - hidden_dropout_prob: 0.1
2025-04-16 17:32:11,375 - weight: 1.0
2025-04-16 17:32:11,375 - loss_mode: rdrop
2025-04-16 17:32:11,375 - base_dim: 256
2025-04-16 17:32:11,375 - nheads: 8
2025-04-16 17:32:11,375 - attn_dropout: 0.1
2025-04-16 17:32:11,375 - relu_dropout: 0.1
2025-04-16 17:32:11,375 - embed_dropout: 0.01
2025-04-16 17:32:11,375 - res_dropout: 0.0
2025-04-16 17:32:11,375 - attn_mask: True
2025-04-16 17:32:11,375 - encoder_layers_1: 1
2025-04-16 17:32:11,375 - fusion_act: tanh
2025-04-16 17:32:11,375 - pred_output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/SMC/outputs_test2/MIntRec/umc_umc_MIntRec_bert-base-uncased_3
2025-04-16 17:32:11,375 - model_output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/SMC/outputs_test2/MIntRec/umc_umc_MIntRec_bert-base-uncased_3/models
2025-04-16 17:32:11,375 - text_seq_len: 30
2025-04-16 17:32:11,375 - video_seq_len: 230
2025-04-16 17:32:11,375 - audio_seq_len: 480
2025-04-16 17:32:11,376 - text_feat_dim: 768
2025-04-16 17:32:11,376 - video_feat_dim: 1024
2025-04-16 17:32:11,376 - audio_feat_dim: 768
2025-04-16 17:32:11,376 - num_labels: 20
2025-04-16 17:32:11,376 - num_train_examples: 1779
2025-04-16 17:32:11,376 - ============================== End Params ==============================
2025-04-16 17:32:12,621 - Freeze all parameters but the last layer for efficiency
2025-04-16 17:32:12,660 - Pre-training start...
2025-04-16 17:32:32,350 - ***** Epoch: 1: Eval results *****
2025-04-16 17:32:32,351 -   train_loss = 5.957049165453229
2025-04-16 17:32:54,922 - ***** Epoch: 2: Eval results *****
2025-04-16 17:32:54,922 -   train_loss = 5.953130926404681
2025-04-16 17:33:17,531 - ***** Epoch: 3: Eval results *****
2025-04-16 17:33:17,532 -   train_loss = 5.934126206806728
2025-04-16 17:33:39,766 - ***** Epoch: 4: Eval results *****
2025-04-16 17:33:39,766 -   train_loss = 5.894480773380825
2025-04-16 17:34:04,685 - ***** Epoch: 5: Eval results *****
2025-04-16 17:34:04,686 -   train_loss = 5.786500896726336
2025-04-16 17:34:25,686 - ***** Epoch: 6: Eval results *****
2025-04-16 17:34:25,686 -   train_loss = 5.407231841768537
2025-04-16 17:34:47,679 - ***** Epoch: 7: Eval results *****
2025-04-16 17:34:47,679 -   train_loss = 4.617813723427909
2025-04-16 17:35:10,082 - ***** Epoch: 8: Eval results *****
2025-04-16 17:35:10,083 -   train_loss = 3.864425676209586
2025-04-16 17:35:31,148 - ***** Epoch: 9: Eval results *****
2025-04-16 17:35:31,149 -   train_loss = 3.2503688676016673
2025-04-16 17:35:53,586 - ***** Epoch: 10: Eval results *****
2025-04-16 17:35:53,587 -   train_loss = 2.7532977546964372
2025-04-16 17:36:14,047 - ***** Epoch: 11: Eval results *****
2025-04-16 17:36:14,048 -   train_loss = 2.426272528512137
2025-04-16 17:36:35,664 - ***** Epoch: 12: Eval results *****
2025-04-16 17:36:35,665 -   train_loss = 2.2009078604834422
2025-04-16 17:36:58,516 - ***** Epoch: 13: Eval results *****
2025-04-16 17:36:58,517 -   train_loss = 2.022981192384447
2025-04-16 17:37:24,207 - ***** Epoch: 14: Eval results *****
2025-04-16 17:37:24,208 -   train_loss = 1.913783712046487
2025-04-16 17:37:46,548 - ***** Epoch: 15: Eval results *****
2025-04-16 17:37:46,548 -   train_loss = 1.8261858054569788
2025-04-16 17:38:08,061 - ***** Epoch: 16: Eval results *****
2025-04-16 17:38:08,061 -   train_loss = 1.741072646209172
2025-04-16 17:38:28,704 - ***** Epoch: 17: Eval results *****
2025-04-16 17:38:28,704 -   train_loss = 1.673732510634831
2025-04-16 17:38:48,624 - ***** Epoch: 18: Eval results *****
2025-04-16 17:38:48,625 -   train_loss = 1.6411712595394679
2025-04-16 17:39:10,698 - ***** Epoch: 19: Eval results *****
2025-04-16 17:39:10,698 -   train_loss = 1.5812652707099915
2025-04-16 17:39:30,352 - ***** Epoch: 20: Eval results *****
2025-04-16 17:39:30,353 -   train_loss = 1.5457590648106165
2025-04-16 17:39:50,169 - ***** Epoch: 21: Eval results *****
2025-04-16 17:39:50,169 -   train_loss = 1.5294835482324873
2025-04-16 17:40:09,790 - ***** Epoch: 22: Eval results *****
2025-04-16 17:40:09,790 -   train_loss = 1.4876878942762102
2025-04-16 17:40:29,450 - ***** Epoch: 23: Eval results *****
2025-04-16 17:40:29,451 -   train_loss = 1.473047946180616
2025-04-16 17:40:51,310 - ***** Epoch: 24: Eval results *****
2025-04-16 17:40:51,310 -   train_loss = 1.4492853283882141
2025-04-16 17:41:14,165 - ***** Epoch: 25: Eval results *****
2025-04-16 17:41:14,166 -   train_loss = 1.4111442565917969
2025-04-16 17:41:35,574 - ***** Epoch: 26: Eval results *****
2025-04-16 17:41:35,574 -   train_loss = 1.4022478205817086
2025-04-16 17:41:55,766 - ***** Epoch: 27: Eval results *****
2025-04-16 17:41:55,766 -   train_loss = 1.3989462086132594
2025-04-16 17:42:17,965 - ***** Epoch: 28: Eval results *****
2025-04-16 17:42:17,966 -   train_loss = 1.379797841821398
2025-04-16 17:42:39,753 - ***** Epoch: 29: Eval results *****
2025-04-16 17:42:39,753 -   train_loss = 1.344115470136915
2025-04-16 17:43:01,352 - ***** Epoch: 30: Eval results *****
2025-04-16 17:43:01,352 -   train_loss = 1.335693623338427
2025-04-16 17:43:22,739 - ***** Epoch: 31: Eval results *****
2025-04-16 17:43:22,739 -   train_loss = 1.3330214279038566
2025-04-16 17:43:42,946 - ***** Epoch: 32: Eval results *****
2025-04-16 17:43:42,946 -   train_loss = 1.3075363721166338
2025-04-16 17:44:07,842 - ***** Epoch: 33: Eval results *****
2025-04-16 17:44:07,843 -   train_loss = 1.3036169835499354
2025-04-16 17:44:31,476 - ***** Epoch: 34: Eval results *****
2025-04-16 17:44:31,476 -   train_loss = 1.3021204556737627
2025-04-16 17:44:53,386 - ***** Epoch: 35: Eval results *****
2025-04-16 17:44:53,387 -   train_loss = 1.2963372298649378
2025-04-16 17:45:16,259 - ***** Epoch: 36: Eval results *****
2025-04-16 17:45:16,259 -   train_loss = 1.280416224684034
2025-04-16 17:45:38,835 - ***** Epoch: 37: Eval results *****
2025-04-16 17:45:38,836 -   train_loss = 1.2690643753324236
2025-04-16 17:46:00,397 - ***** Epoch: 38: Eval results *****
2025-04-16 17:46:00,397 -   train_loss = 1.2603785651070731
2025-04-16 17:46:19,394 - ***** Epoch: 39: Eval results *****
2025-04-16 17:46:19,394 -   train_loss = 1.2596165197236198
2025-04-16 17:46:41,602 - ***** Epoch: 40: Eval results *****
2025-04-16 17:46:41,603 -   train_loss = 1.2634307486670358
2025-04-16 17:47:02,897 - ***** Epoch: 41: Eval results *****
2025-04-16 17:47:02,897 -   train_loss = 1.236859244959695
2025-04-16 17:47:27,156 - ***** Epoch: 42: Eval results *****
2025-04-16 17:47:27,156 -   train_loss = 1.2386083517755782
2025-04-16 17:47:48,256 - ***** Epoch: 43: Eval results *****
2025-04-16 17:47:48,256 -   train_loss = 1.226059811455863
2025-04-16 17:48:09,650 - ***** Epoch: 44: Eval results *****
2025-04-16 17:48:09,650 -   train_loss = 1.2233306339808874
2025-04-16 17:48:29,202 - ***** Epoch: 45: Eval results *****
2025-04-16 17:48:29,202 -   train_loss = 1.2295529076031275
2025-04-16 17:48:50,502 - ***** Epoch: 46: Eval results *****
2025-04-16 17:48:50,503 -   train_loss = 1.2185838392802648
2025-04-16 17:49:12,136 - ***** Epoch: 47: Eval results *****
2025-04-16 17:49:12,136 -   train_loss = 1.2099038107054574
2025-04-16 17:49:33,003 - ***** Epoch: 48: Eval results *****
2025-04-16 17:49:33,004 -   train_loss = 1.1988085848944527
2025-04-16 17:49:53,085 - ***** Epoch: 49: Eval results *****
2025-04-16 17:49:53,085 -   train_loss = 1.1912015165601457
2025-04-16 17:50:14,399 - ***** Epoch: 50: Eval results *****
2025-04-16 17:50:14,399 -   train_loss = 1.2087701218468803
2025-04-16 17:50:35,966 - ***** Epoch: 51: Eval results *****
2025-04-16 17:50:35,966 -   train_loss = 1.1927995681762695
2025-04-16 17:50:59,537 - ***** Epoch: 52: Eval results *****
2025-04-16 17:50:59,537 -   train_loss = 1.1898693357195174
2025-04-16 17:51:19,938 - ***** Epoch: 53: Eval results *****
2025-04-16 17:51:19,938 -   train_loss = 1.1830235293933324
2025-04-16 17:51:41,284 - ***** Epoch: 54: Eval results *****
2025-04-16 17:51:41,284 -   train_loss = 1.1884909783090865
2025-04-16 17:52:00,889 - ***** Epoch: 55: Eval results *****
2025-04-16 17:52:00,889 -   train_loss = 1.1803244267191206
2025-04-16 17:52:19,692 - ***** Epoch: 56: Eval results *****
2025-04-16 17:52:19,692 -   train_loss = 1.177817966256823
2025-04-16 17:52:39,574 - ***** Epoch: 57: Eval results *****
2025-04-16 17:52:39,574 -   train_loss = 1.179561299937112
2025-04-16 17:53:00,598 - ***** Epoch: 58: Eval results *****
2025-04-16 17:53:00,599 -   train_loss = 1.1759074585778373
2025-04-16 17:53:21,309 - ***** Epoch: 59: Eval results *****
2025-04-16 17:53:21,309 -   train_loss = 1.1697544966425215
2025-04-16 17:53:43,616 - ***** Epoch: 60: Eval results *****
2025-04-16 17:53:43,617 -   train_loss = 1.1633015871047974
2025-04-16 17:54:05,482 - ***** Epoch: 61: Eval results *****
2025-04-16 17:54:05,482 -   train_loss = 1.1597922784941537
2025-04-16 17:54:29,581 - ***** Epoch: 62: Eval results *****
2025-04-16 17:54:29,581 -   train_loss = 1.1672874774251665
2025-04-16 17:54:53,586 - ***** Epoch: 63: Eval results *****
2025-04-16 17:54:53,586 -   train_loss = 1.1519167167799813
2025-04-16 17:55:14,169 - ***** Epoch: 64: Eval results *****
2025-04-16 17:55:14,169 -   train_loss = 1.1597378253936768
2025-04-16 17:55:35,532 - ***** Epoch: 65: Eval results *****
2025-04-16 17:55:35,532 -   train_loss = 1.1626740608896529
2025-04-16 17:55:57,022 - ***** Epoch: 66: Eval results *****
2025-04-16 17:55:57,022 -   train_loss = 1.1589314086096627
2025-04-16 17:56:17,919 - ***** Epoch: 67: Eval results *****
2025-04-16 17:56:17,919 -   train_loss = 1.151157055582319
2025-04-16 17:56:39,758 - ***** Epoch: 68: Eval results *****
2025-04-16 17:56:39,759 -   train_loss = 1.1644653507641383
2025-04-16 17:57:01,748 - ***** Epoch: 69: Eval results *****
2025-04-16 17:57:01,748 -   train_loss = 1.1557452508381434
2025-04-16 17:57:22,398 - ***** Epoch: 70: Eval results *****
2025-04-16 17:57:22,398 -   train_loss = 1.1587544339043754
2025-04-16 17:57:53,177 - ***** Epoch: 71: Eval results *****
2025-04-16 17:57:53,177 -   train_loss = 1.1496374777385168
2025-04-16 17:58:16,757 - ***** Epoch: 72: Eval results *****
2025-04-16 17:58:16,757 -   train_loss = 1.1372360927718026
2025-04-16 17:58:37,923 - ***** Epoch: 73: Eval results *****
2025-04-16 17:58:37,924 -   train_loss = 1.1394333924565996
2025-04-16 17:58:59,194 - ***** Epoch: 74: Eval results *****
2025-04-16 17:58:59,195 -   train_loss = 1.139816769531795
2025-04-16 17:59:21,120 - ***** Epoch: 75: Eval results *****
2025-04-16 17:59:21,120 -   train_loss = 1.1449484825134277
2025-04-16 17:59:43,850 - ***** Epoch: 76: Eval results *****
2025-04-16 17:59:43,851 -   train_loss = 1.141786209174565
2025-04-16 18:00:04,688 - ***** Epoch: 77: Eval results *****
2025-04-16 18:00:04,689 -   train_loss = 1.1334540503365653
