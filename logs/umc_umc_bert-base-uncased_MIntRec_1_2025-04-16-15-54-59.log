2025-04-16 15:54:59,991 - 【无监督】进入了无监督的设定中, 加载数据集
2025-04-16 15:54:59,991 - data preparation...
2025-04-16 15:55:09,362 - Number of train samples = 1779
2025-04-16 15:55:09,363 - Number of testing samples = 445
2025-04-16 15:55:09,363 - data preparation...
2025-04-16 15:55:11,660 - num_train_examples = 1779
2025-04-16 15:55:11,661 - ============================== Params ==============================
2025-04-16 15:55:11,661 - logger_name: umc_umc_bert-base-uncased_MIntRec_1
2025-04-16 15:55:11,661 - dataset: MIntRec
2025-04-16 15:55:11,661 - multimodal_method: umc
2025-04-16 15:55:11,661 - method: umc
2025-04-16 15:55:11,661 - setting: unsupervised
2025-04-16 15:55:11,661 - text_backbone: bert-base-uncased
2025-04-16 15:55:11,661 - seed: 1
2025-04-16 15:55:11,661 - num_workers: 16
2025-04-16 15:55:11,661 - log_id: umc_umc_bert-base-uncased_MIntRec_1_2025-04-16-15-54-59
2025-04-16 15:55:11,661 - gpu_id: 1
2025-04-16 15:55:11,661 - data_path: /root/autodl-tmp/home/Share/Dataset/LZH
2025-04-16 15:55:11,661 - train: True
2025-04-16 15:55:11,661 - tune: True
2025-04-16 15:55:11,661 - save_model: True
2025-04-16 15:55:11,661 - save_results: True
2025-04-16 15:55:11,661 - log_path: logs
2025-04-16 15:55:11,661 - cache_path: cache
2025-04-16 15:55:11,661 - video_data_path: video_data
2025-04-16 15:55:11,661 - audio_data_path: audio_data
2025-04-16 15:55:11,661 - video_feats_path: swin_feats.pkl
2025-04-16 15:55:11,662 - audio_feats_path: wavlm_feats.pkl
2025-04-16 15:55:11,662 - results_path: results
2025-04-16 15:55:11,662 - output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/SMC/outputs_test2/MIntRec
2025-04-16 15:55:11,662 - model_path: models
2025-04-16 15:55:11,662 - config_file_name: umc_MIntRec
2025-04-16 15:55:11,662 - results_file_name: results_umc.csv
2025-04-16 15:55:11,662 - text_pretrained_model: uncased_L-12_H-768_A-12
2025-04-16 15:55:11,662 - pretrained_bert_model: uncased_L-12_H-768_A-12
2025-04-16 15:55:11,662 - pretrain_batch_size: 128
2025-04-16 15:55:11,662 - train_batch_size: 128
2025-04-16 15:55:11,662 - eval_batch_size: 128
2025-04-16 15:55:11,662 - test_batch_size: 128
2025-04-16 15:55:11,662 - num_pretrain_epochs: 100
2025-04-16 15:55:11,662 - num_train_epochs: 100
2025-04-16 15:55:11,662 - pretrain: [True]
2025-04-16 15:55:11,662 - aligned_method: ctc
2025-04-16 15:55:11,662 - need_aligned: False
2025-04-16 15:55:11,662 - freeze_pretrain_bert_parameters: [True]
2025-04-16 15:55:11,662 - freeze_train_bert_parameters: [True]
2025-04-16 15:55:11,662 - pretrain_temperature: [0.1]
2025-04-16 15:55:11,662 - train_temperature_sup: [0.5]
2025-04-16 15:55:11,662 - train_temperature_unsup: [2]
2025-04-16 15:55:11,662 - activation: tanh
2025-04-16 15:55:11,662 - lr_pre: [3e-05]
2025-04-16 15:55:11,662 - lr: [5e-05]
2025-04-16 15:55:11,662 - delta: [0.05]
2025-04-16 15:55:11,662 - thres: [0.1]
2025-04-16 15:55:11,662 - topk: [5]
2025-04-16 15:55:11,662 - weight_decay: 0.01
2025-04-16 15:55:11,663 - feat_dim: 768
2025-04-16 15:55:11,663 - hidden_size: 768
2025-04-16 15:55:11,663 - grad_clip: -1.0
2025-04-16 15:55:11,663 - warmup_proportion: [0.1]
2025-04-16 15:55:11,663 - hidden_dropout_prob: 0.1
2025-04-16 15:55:11,663 - weight: 1.0
2025-04-16 15:55:11,663 - loss_mode: rdrop
2025-04-16 15:55:11,663 - base_dim: 256
2025-04-16 15:55:11,663 - nheads: 8
2025-04-16 15:55:11,663 - attn_dropout: 0.1
2025-04-16 15:55:11,663 - relu_dropout: 0.1
2025-04-16 15:55:11,663 - embed_dropout: 0.01
2025-04-16 15:55:11,663 - res_dropout: 0.0
2025-04-16 15:55:11,663 - attn_mask: True
2025-04-16 15:55:11,663 - encoder_layers_1: 1
2025-04-16 15:55:11,663 - fusion_act: tanh
2025-04-16 15:55:11,663 - pred_output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/SMC/outputs_test2/MIntRec/umc_umc_MIntRec_bert-base-uncased_1
2025-04-16 15:55:11,664 - model_output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/SMC/outputs_test2/MIntRec/umc_umc_MIntRec_bert-base-uncased_1/models
2025-04-16 15:55:11,664 - text_seq_len: 30
2025-04-16 15:55:11,664 - video_seq_len: 230
2025-04-16 15:55:11,664 - audio_seq_len: 480
2025-04-16 15:55:11,664 - text_feat_dim: 768
2025-04-16 15:55:11,664 - video_feat_dim: 1024
2025-04-16 15:55:11,664 - audio_feat_dim: 768
2025-04-16 15:55:11,664 - num_labels: 20
2025-04-16 15:55:11,664 - num_train_examples: 1779
2025-04-16 15:55:11,664 - ============================== End Params ==============================
2025-04-16 15:55:13,053 - Freeze all parameters but the last layer for efficiency
2025-04-16 15:55:13,092 - Pre-training start...
2025-04-16 15:55:35,009 - ***** Epoch: 1: Eval results *****
2025-04-16 15:55:35,009 -   train_loss = 5.963730709893363
2025-04-16 15:55:57,970 - ***** Epoch: 2: Eval results *****
2025-04-16 15:55:57,970 -   train_loss = 5.95271727016994
2025-04-16 15:56:20,974 - ***** Epoch: 3: Eval results *****
2025-04-16 15:56:20,974 -   train_loss = 5.925801685878208
2025-04-16 15:56:43,098 - ***** Epoch: 4: Eval results *****
2025-04-16 15:56:43,098 -   train_loss = 5.894933836800711
2025-04-16 15:57:08,631 - ***** Epoch: 5: Eval results *****
2025-04-16 15:57:08,631 -   train_loss = 5.806280067988804
2025-04-16 15:57:29,651 - ***** Epoch: 6: Eval results *****
2025-04-16 15:57:29,652 -   train_loss = 5.505420105797904
2025-04-16 15:57:53,467 - ***** Epoch: 7: Eval results *****
2025-04-16 15:57:53,468 -   train_loss = 4.787799392427717
2025-04-16 15:58:16,278 - ***** Epoch: 8: Eval results *****
2025-04-16 15:58:16,278 -   train_loss = 3.9617901188986644
2025-04-16 15:58:37,646 - ***** Epoch: 9: Eval results *****
2025-04-16 15:58:37,647 -   train_loss = 3.3418046917234148
2025-04-16 15:58:58,708 - ***** Epoch: 10: Eval results *****
2025-04-16 15:58:58,708 -   train_loss = 2.8152535813195363
2025-04-16 15:59:20,409 - ***** Epoch: 11: Eval results *****
2025-04-16 15:59:20,409 -   train_loss = 2.4514348677226474
2025-04-16 15:59:42,050 - ***** Epoch: 12: Eval results *****
2025-04-16 15:59:42,051 -   train_loss = 2.1971530403409685
2025-04-16 16:00:03,552 - ***** Epoch: 13: Eval results *****
2025-04-16 16:00:03,552 -   train_loss = 2.0381828205926076
2025-04-16 16:00:27,810 - ***** Epoch: 14: Eval results *****
2025-04-16 16:00:27,810 -   train_loss = 1.9262034552437919
2025-04-16 16:00:50,744 - ***** Epoch: 15: Eval results *****
2025-04-16 16:00:50,745 -   train_loss = 1.8206749217850822
2025-04-16 16:01:11,841 - ***** Epoch: 16: Eval results *****
2025-04-16 16:01:11,841 -   train_loss = 1.7391276870455061
2025-04-16 16:01:34,506 - ***** Epoch: 17: Eval results *****
2025-04-16 16:01:34,507 -   train_loss = 1.6762484482356481
2025-04-16 16:01:56,514 - ***** Epoch: 18: Eval results *****
2025-04-16 16:01:56,514 -   train_loss = 1.6189663410186768
2025-04-16 16:02:17,034 - ***** Epoch: 19: Eval results *****
2025-04-16 16:02:17,034 -   train_loss = 1.58094722032547
2025-04-16 16:02:38,773 - ***** Epoch: 20: Eval results *****
2025-04-16 16:02:38,774 -   train_loss = 1.5582950796399797
2025-04-16 16:03:01,759 - ***** Epoch: 21: Eval results *****
2025-04-16 16:03:01,759 -   train_loss = 1.522051283291408
2025-04-16 16:03:22,857 - ***** Epoch: 22: Eval results *****
2025-04-16 16:03:22,857 -   train_loss = 1.4976452589035034
2025-04-16 16:03:49,613 - ***** Epoch: 23: Eval results *****
2025-04-16 16:03:49,613 -   train_loss = 1.462366989680699
2025-04-16 16:04:12,281 - ***** Epoch: 24: Eval results *****
2025-04-16 16:04:12,281 -   train_loss = 1.4387794051851546
2025-04-16 16:04:35,507 - ***** Epoch: 25: Eval results *****
2025-04-16 16:04:35,508 -   train_loss = 1.4383636542728968
2025-04-16 16:04:57,820 - ***** Epoch: 26: Eval results *****
2025-04-16 16:04:57,821 -   train_loss = 1.4165234395435877
2025-04-16 16:05:20,094 - ***** Epoch: 27: Eval results *****
2025-04-16 16:05:20,094 -   train_loss = 1.3981984853744507
2025-04-16 16:05:41,276 - ***** Epoch: 28: Eval results *****
2025-04-16 16:05:41,276 -   train_loss = 1.3708736726215907
2025-04-16 16:06:03,590 - ***** Epoch: 29: Eval results *****
2025-04-16 16:06:03,591 -   train_loss = 1.3650206582886832
2025-04-16 16:06:26,362 - ***** Epoch: 30: Eval results *****
2025-04-16 16:06:26,362 -   train_loss = 1.3552287902150835
2025-04-16 16:06:49,700 - ***** Epoch: 31: Eval results *****
2025-04-16 16:06:49,700 -   train_loss = 1.328781110899789
2025-04-16 16:07:15,205 - ***** Epoch: 32: Eval results *****
2025-04-16 16:07:15,205 -   train_loss = 1.3264128480638777
2025-04-16 16:07:37,378 - ***** Epoch: 33: Eval results *****
2025-04-16 16:07:37,378 -   train_loss = 1.307023218699864
2025-04-16 16:07:58,365 - ***** Epoch: 34: Eval results *****
2025-04-16 16:07:58,365 -   train_loss = 1.2897475617272514
2025-04-16 16:08:20,364 - ***** Epoch: 35: Eval results *****
2025-04-16 16:08:20,365 -   train_loss = 1.3022339940071106
2025-04-16 16:08:41,648 - ***** Epoch: 36: Eval results *****
2025-04-16 16:08:41,649 -   train_loss = 1.2960752248764038
2025-04-16 16:09:03,716 - ***** Epoch: 37: Eval results *****
2025-04-16 16:09:03,717 -   train_loss = 1.2642323885645186
2025-04-16 16:09:25,145 - ***** Epoch: 38: Eval results *****
2025-04-16 16:09:25,145 -   train_loss = 1.2676366823060172
2025-04-16 16:09:46,606 - ***** Epoch: 39: Eval results *****
2025-04-16 16:09:46,607 -   train_loss = 1.2671581932476588
2025-04-16 16:10:08,366 - ***** Epoch: 40: Eval results *****
2025-04-16 16:10:08,366 -   train_loss = 1.262624876839774
2025-04-16 16:10:30,698 - ***** Epoch: 41: Eval results *****
2025-04-16 16:10:30,698 -   train_loss = 1.2553156444004603
2025-04-16 16:10:54,850 - ***** Epoch: 42: Eval results *****
2025-04-16 16:10:54,850 -   train_loss = 1.2462369459015983
2025-04-16 16:11:15,749 - ***** Epoch: 43: Eval results *****
2025-04-16 16:11:15,749 -   train_loss = 1.240187644958496
2025-04-16 16:11:36,142 - ***** Epoch: 44: Eval results *****
2025-04-16 16:11:36,142 -   train_loss = 1.2254015973636083
2025-04-16 16:11:59,553 - ***** Epoch: 45: Eval results *****
2025-04-16 16:11:59,554 -   train_loss = 1.2235115000179835
2025-04-16 16:12:22,554 - ***** Epoch: 46: Eval results *****
2025-04-16 16:12:22,554 -   train_loss = 1.2185890163694109
2025-04-16 16:12:44,388 - ***** Epoch: 47: Eval results *****
2025-04-16 16:12:44,388 -   train_loss = 1.2151891504015242
2025-04-16 16:13:07,275 - ***** Epoch: 48: Eval results *****
2025-04-16 16:13:07,275 -   train_loss = 1.212614791733878
2025-04-16 16:13:29,545 - ***** Epoch: 49: Eval results *****
2025-04-16 16:13:29,546 -   train_loss = 1.206203622477395
2025-04-16 16:13:51,386 - ***** Epoch: 50: Eval results *****
2025-04-16 16:13:51,387 -   train_loss = 1.2013817599841528
2025-04-16 16:14:15,194 - ***** Epoch: 51: Eval results *****
2025-04-16 16:14:15,195 -   train_loss = 1.191639815058027
2025-04-16 16:14:37,980 - ***** Epoch: 52: Eval results *****
2025-04-16 16:14:37,981 -   train_loss = 1.20064811195646
2025-04-16 16:14:59,776 - ***** Epoch: 53: Eval results *****
2025-04-16 16:14:59,776 -   train_loss = 1.1862693769591195
2025-04-16 16:15:21,498 - ***** Epoch: 54: Eval results *****
2025-04-16 16:15:21,498 -   train_loss = 1.1956207752227783
2025-04-16 16:15:42,061 - ***** Epoch: 55: Eval results *****
2025-04-16 16:15:42,061 -   train_loss = 1.1857260721070426
2025-04-16 16:16:04,726 - ***** Epoch: 56: Eval results *****
2025-04-16 16:16:04,727 -   train_loss = 1.1829244579587663
2025-04-16 16:16:26,321 - ***** Epoch: 57: Eval results *****
2025-04-16 16:16:26,321 -   train_loss = 1.1818377035004752
2025-04-16 16:16:45,619 - ***** Epoch: 58: Eval results *****
2025-04-16 16:16:45,619 -   train_loss = 1.1895879421915327
2025-04-16 16:17:10,616 - ***** Epoch: 59: Eval results *****
2025-04-16 16:17:10,616 -   train_loss = 1.177513369492122
2025-04-16 16:17:32,313 - ***** Epoch: 60: Eval results *****
2025-04-16 16:17:32,314 -   train_loss = 1.1743437222072057
2025-04-16 16:17:52,954 - ***** Epoch: 61: Eval results *****
2025-04-16 16:17:52,955 -   train_loss = 1.1699766942432948
2025-04-16 16:18:13,534 - ***** Epoch: 62: Eval results *****
2025-04-16 16:18:13,535 -   train_loss = 1.1643810187067305
2025-04-16 16:18:37,101 - ***** Epoch: 63: Eval results *****
2025-04-16 16:18:37,101 -   train_loss = 1.1665441479001726
2025-04-16 16:18:59,886 - ***** Epoch: 64: Eval results *****
2025-04-16 16:18:59,886 -   train_loss = 1.1642760293824332
2025-04-16 16:19:22,801 - ***** Epoch: 65: Eval results *****
2025-04-16 16:19:22,801 -   train_loss = 1.1645692586898804
2025-04-16 16:19:44,528 - ***** Epoch: 66: Eval results *****
2025-04-16 16:19:44,528 -   train_loss = 1.1644207324300493
2025-04-16 16:20:06,495 - ***** Epoch: 67: Eval results *****
2025-04-16 16:20:06,495 -   train_loss = 1.15651193686894
2025-04-16 16:20:31,825 - ***** Epoch: 68: Eval results *****
2025-04-16 16:20:31,826 -   train_loss = 1.149542442389897
2025-04-16 16:20:53,710 - ***** Epoch: 69: Eval results *****
2025-04-16 16:20:53,710 -   train_loss = 1.1466066581862313
2025-04-16 16:21:15,934 - ***** Epoch: 70: Eval results *****
2025-04-16 16:21:15,934 -   train_loss = 1.1475192223276411
2025-04-16 16:21:37,981 - ***** Epoch: 71: Eval results *****
2025-04-16 16:21:37,981 -   train_loss = 1.149566113948822
2025-04-16 16:22:00,828 - ***** Epoch: 72: Eval results *****
2025-04-16 16:22:00,828 -   train_loss = 1.1415549772126334
2025-04-16 16:22:22,942 - ***** Epoch: 73: Eval results *****
2025-04-16 16:22:22,943 -   train_loss = 1.1428379331316267
2025-04-16 16:22:43,984 - ***** Epoch: 74: Eval results *****
2025-04-16 16:22:43,985 -   train_loss = 1.139511125428336
2025-04-16 16:23:05,706 - ***** Epoch: 75: Eval results *****
2025-04-16 16:23:05,707 -   train_loss = 1.1407048446791512
2025-04-16 16:23:27,777 - ***** Epoch: 76: Eval results *****
2025-04-16 16:23:27,777 -   train_loss = 1.1493800793375288
2025-04-16 16:23:48,185 - ***** Epoch: 77: Eval results *****
2025-04-16 16:23:48,185 -   train_loss = 1.137962554182325
2025-04-16 16:24:12,262 - ***** Epoch: 78: Eval results *****
2025-04-16 16:24:12,262 -   train_loss = 1.1366891435214452
2025-04-16 16:24:34,532 - ***** Epoch: 79: Eval results *****
2025-04-16 16:24:34,532 -   train_loss = 1.1353387832641602
2025-04-16 16:24:56,461 - ***** Epoch: 80: Eval results *****
2025-04-16 16:24:56,461 -   train_loss = 1.140456165586199
2025-04-16 16:25:17,697 - ***** Epoch: 81: Eval results *****
2025-04-16 16:25:17,698 -   train_loss = 1.1316332476479667
2025-04-16 16:25:40,088 - ***** Epoch: 82: Eval results *****
2025-04-16 16:25:40,088 -   train_loss = 1.135009833744594
2025-04-16 16:26:02,538 - ***** Epoch: 83: Eval results *****
2025-04-16 16:26:02,538 -   train_loss = 1.1265106967517309
2025-04-16 16:26:23,722 - ***** Epoch: 84: Eval results *****
2025-04-16 16:26:23,722 -   train_loss = 1.1301449026380266
2025-04-16 16:26:46,808 - ***** Epoch: 85: Eval results *****
2025-04-16 16:26:46,808 -   train_loss = 1.1446946944509233
2025-04-16 16:27:09,680 - ***** Epoch: 86: Eval results *****
2025-04-16 16:27:09,681 -   train_loss = 1.1360998068537032
2025-04-16 16:27:33,506 - ***** Epoch: 87: Eval results *****
2025-04-16 16:27:33,506 -   train_loss = 1.1354829243251257
2025-04-16 16:27:56,590 - ***** Epoch: 88: Eval results *****
2025-04-16 16:27:56,591 -   train_loss = 1.134540753705161
2025-04-16 16:28:18,072 - ***** Epoch: 89: Eval results *****
2025-04-16 16:28:18,073 -   train_loss = 1.1242119669914246
2025-04-16 16:28:41,768 - ***** Epoch: 90: Eval results *****
2025-04-16 16:28:41,769 -   train_loss = 1.129810324737004
2025-04-16 16:29:03,202 - ***** Epoch: 91: Eval results *****
2025-04-16 16:29:03,202 -   train_loss = 1.136618367263249
2025-04-16 16:29:26,926 - ***** Epoch: 92: Eval results *****
2025-04-16 16:29:26,926 -   train_loss = 1.1357293554714747
2025-04-16 16:29:48,766 - ***** Epoch: 93: Eval results *****
2025-04-16 16:29:48,766 -   train_loss = 1.1366111976759774
2025-04-16 16:30:09,398 - ***** Epoch: 94: Eval results *****
2025-04-16 16:30:09,399 -   train_loss = 1.1308763878686088
2025-04-16 16:30:30,212 - ***** Epoch: 95: Eval results *****
2025-04-16 16:30:30,212 -   train_loss = 1.1286823153495789
2025-04-16 16:30:51,211 - ***** Epoch: 96: Eval results *****
2025-04-16 16:30:51,212 -   train_loss = 1.128765344619751
2025-04-16 16:31:14,614 - ***** Epoch: 97: Eval results *****
2025-04-16 16:31:14,614 -   train_loss = 1.125587821006775
2025-04-16 16:31:34,950 - ***** Epoch: 98: Eval results *****
2025-04-16 16:31:34,950 -   train_loss = 1.131428335394178
2025-04-16 16:31:55,901 - ***** Epoch: 99: Eval results *****
2025-04-16 16:31:55,902 -   train_loss = 1.1274798682757787
2025-04-16 16:32:18,598 - ***** Epoch: 100: Eval results *****
2025-04-16 16:32:18,598 -   train_loss = 1.1283978053501673
2025-04-16 16:32:19,237 - Pre-training finished...
2025-04-16 16:32:19,620 - Freeze all parameters but the last layer for efficiency
2025-04-16 16:32:19,630 - Multimodal Intent Recognition begins...
2025-04-16 16:32:19,630 - Training begins...
2025-04-16 16:32:36,040 - Initializing centroids with K-means++...
2025-04-16 16:32:36,196 - K-means++ used 0.16 s
2025-04-16 16:33:12,847 - K-means used 0.03 s
2025-04-16 16:33:14,582 - ***** Epoch: 1 *****
2025-04-16 16:33:14,583 - Supervised Training Loss: 4.402600
2025-04-16 16:33:14,583 - Unsupervised Training Loss: 5.504070
2025-04-16 16:33:49,021 - K-means used 0.02 s
2025-04-16 16:33:50,174 - ***** Epoch: 2 *****
2025-04-16 16:33:50,175 - Supervised Training Loss: 3.731650
2025-04-16 16:33:50,175 - Unsupervised Training Loss: 5.536230
2025-04-16 16:34:26,996 - K-means used 0.14 s
2025-04-16 16:34:28,808 - ***** Epoch: 3 *****
2025-04-16 16:34:28,809 - Supervised Training Loss: 4.927420
2025-04-16 16:34:28,809 - Unsupervised Training Loss: 5.405300
2025-04-16 16:35:03,224 - K-means used 0.02 s
2025-04-16 16:35:05,182 - ***** Epoch: 4 *****
2025-04-16 16:35:05,182 - Supervised Training Loss: 4.720900
2025-04-16 16:35:05,182 - Unsupervised Training Loss: 5.475120
2025-04-16 16:35:43,518 - K-means used 0.1 s
2025-04-16 16:35:45,414 - ***** Epoch: 5 *****
2025-04-16 16:35:45,415 - Supervised Training Loss: 4.410560
2025-04-16 16:35:45,415 - Unsupervised Training Loss: 5.521460
2025-04-16 16:36:20,337 - K-means used 0.02 s
2025-04-16 16:36:22,172 - ***** Epoch: 6 *****
2025-04-16 16:36:22,173 - Supervised Training Loss: 4.822410
2025-04-16 16:36:22,173 - Unsupervised Training Loss: 5.299880
2025-04-16 16:36:56,698 - K-means used 0.02 s
2025-04-16 16:36:58,744 - ***** Epoch: 7 *****
2025-04-16 16:36:58,744 - Supervised Training Loss: 4.717890
2025-04-16 16:36:58,744 - Unsupervised Training Loss: 5.438220
2025-04-16 16:37:34,922 - K-means used 0.09 s
2025-04-16 16:37:38,644 - ***** Epoch: 8 *****
2025-04-16 16:37:38,644 - Supervised Training Loss: 4.538120
2025-04-16 16:37:38,645 - Unsupervised Training Loss: 5.496360
2025-04-16 16:38:15,113 - K-means used 0.07 s
2025-04-16 16:38:17,230 - ***** Epoch: 9 *****
2025-04-16 16:38:17,231 - Supervised Training Loss: 4.770230
2025-04-16 16:38:17,231 - Unsupervised Training Loss: 5.536670
2025-04-16 16:38:52,210 - K-means used 0.02 s
2025-04-16 16:38:53,961 - ***** Epoch: 10 *****
2025-04-16 16:38:53,961 - Supervised Training Loss: 4.708830
2025-04-16 16:38:53,961 - Unsupervised Training Loss: 5.378100
2025-04-16 16:39:29,814 - K-means used 0.02 s
2025-04-16 16:39:32,161 - ***** Epoch: 11 *****
2025-04-16 16:39:32,161 - Supervised Training Loss: 4.607870
2025-04-16 16:39:32,161 - Unsupervised Training Loss: 5.461480
2025-04-16 16:40:04,331 - K-means used 0.02 s
2025-04-16 16:40:06,009 - ***** Epoch: 12 *****
2025-04-16 16:40:06,009 - Supervised Training Loss: 4.762750
2025-04-16 16:40:06,009 - Unsupervised Training Loss: 5.522460
2025-04-16 16:40:41,197 - K-means used 0.02 s
2025-04-16 16:40:43,150 - ***** Epoch: 13 *****
2025-04-16 16:40:43,150 - Supervised Training Loss: 4.715480
2025-04-16 16:40:43,150 - Unsupervised Training Loss: 5.271820
2025-04-16 16:41:18,848 - K-means used 0.02 s
2025-04-16 16:41:21,301 - ***** Epoch: 14 *****
2025-04-16 16:41:21,301 - Supervised Training Loss: 4.678730
2025-04-16 16:41:21,302 - Unsupervised Training Loss: 5.379300
2025-04-16 16:41:56,630 - K-means used 0.08 s
2025-04-16 16:41:59,425 - ***** Epoch: 15 *****
2025-04-16 16:41:59,425 - Supervised Training Loss: 4.539400
2025-04-16 16:41:59,425 - Unsupervised Training Loss: 5.488970
2025-04-16 16:42:34,131 - K-means used 0.03 s
2025-04-16 16:42:36,603 - ***** Epoch: 16 *****
2025-04-16 16:42:36,603 - Supervised Training Loss: 4.784630
2025-04-16 16:42:36,603 - Unsupervised Training Loss: 4.911120
2025-04-16 16:43:11,701 - K-means used 0.02 s
2025-04-16 16:43:14,007 - ***** Epoch: 17 *****
2025-04-16 16:43:14,007 - Supervised Training Loss: 4.774300
2025-04-16 16:43:14,007 - Unsupervised Training Loss: 5.173190
2025-04-16 16:43:38,478 - Training is finished...
2025-04-16 16:43:38,479 - Testing begins...
2025-04-16 16:43:46,204 - ***** Test results *****
2025-04-16 16:43:46,204 -   ACC = 28.54
2025-04-16 16:43:46,204 -   ARI = 10.81
2025-04-16 16:43:46,204 -   NMI = 36.27
2025-04-16 16:43:46,204 -   fmi = 16.19
2025-04-16 16:43:46,204 - Testing is finished...
2025-04-16 16:43:46,205 - Multimodal intent recognition is finished...
2025-04-16 16:43:46,205 - Results are saved in results/results_umc.csv
