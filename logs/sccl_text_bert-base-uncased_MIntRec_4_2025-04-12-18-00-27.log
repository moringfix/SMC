2025-04-12 18:00:27,162 - ============================== Params ==============================
2025-04-12 18:00:27,162 - logger_name: sccl_text_bert-base-uncased_MIntRec_4
2025-04-12 18:00:27,162 - dataset: MIntRec
2025-04-12 18:00:27,162 - multimodal_method: text
2025-04-12 18:00:27,162 - method: sccl
2025-04-12 18:00:27,162 - text_backbone: bert-base-uncased
2025-04-12 18:00:27,162 - seed: 4
2025-04-12 18:00:27,162 - num_workers: 16
2025-04-12 18:00:27,162 - log_id: sccl_text_bert-base-uncased_MIntRec_4_2025-04-12-18-00-27
2025-04-12 18:00:27,162 - gpu_id: 1
2025-04-12 18:00:27,162 - data_path: /root/autodl-tmp/home/Share/Dataset/LZH
2025-04-12 18:00:27,162 - train: True
2025-04-12 18:00:27,162 - tune: True
2025-04-12 18:00:27,162 - save_model: True
2025-04-12 18:00:27,162 - save_results: True
2025-04-12 18:00:27,162 - log_path: logs
2025-04-12 18:00:27,163 - cache_path: cache
2025-04-12 18:00:27,163 - video_data_path: video_data
2025-04-12 18:00:27,163 - audio_data_path: audio_data
2025-04-12 18:00:27,163 - video_feats_path: video_feats.pkl
2025-04-12 18:00:27,163 - audio_feats_path: audio_feats.pkl
2025-04-12 18:00:27,163 - results_path: results
2025-04-12 18:00:27,163 - output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/UMC/outputs/MIntRec
2025-04-12 18:00:27,163 - model_path: models
2025-04-12 18:00:27,163 - config_file_name: sccl
2025-04-12 18:00:27,163 - results_file_name: results_sccl.csv
2025-04-12 18:00:27,163 - text_pretrained_model: uncased_L-12_H-768_A-12
2025-04-12 18:00:27,163 - text_seq_len: 30
2025-04-12 18:00:27,163 - video_seq_len: 230
2025-04-12 18:00:27,163 - audio_seq_len: 480
2025-04-12 18:00:27,163 - text_feat_dim: 768
2025-04-12 18:00:27,163 - video_feat_dim: 1024
2025-04-12 18:00:27,163 - audio_feat_dim: 768
2025-04-12 18:00:27,164 - num_labels: 20
2025-04-12 18:00:27,164 - num_train_examples: 1779
2025-04-12 18:00:27,164 - pretrained_bert_model: distilbert-base-nli-stsb-mean-tokens
2025-04-12 18:00:27,164 - num_train_epochs: 100
2025-04-12 18:00:27,164 - freeze_train_bert_parameters: True
2025-04-12 18:00:27,164 - hidden_size: 768
2025-04-12 18:00:27,164 - feat_dim: 768
2025-04-12 18:00:27,164 - warmup_proportion: 0.1
2025-04-12 18:00:27,164 - lr: 3e-05
2025-04-12 18:00:27,164 - train_batch_size: 128
2025-04-12 18:00:27,164 - eval_batch_size: 64
2025-04-12 18:00:27,164 - test_batch_size: 64
2025-04-12 18:00:27,164 - weight_decay: 0.01
2025-04-12 18:00:27,164 - temperature: 0.5
2025-04-12 18:00:27,164 - lr_scale: 100
2025-04-12 18:00:27,164 - eta: 10
2025-04-12 18:00:27,164 - alpha: 1.0
2025-04-12 18:00:27,164 - pred_output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/UMC/outputs/MIntRec/sccl_text_MIntRec_bert-base-uncased_4
2025-04-12 18:00:27,164 - model_output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/UMC/outputs/MIntRec/sccl_text_MIntRec_bert-base-uncased_4/models
2025-04-12 18:00:27,164 - ============================== End Params ==============================
2025-04-12 18:00:47,455 - Freeze all parameters but the last layer for efficiency
