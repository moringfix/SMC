2025-04-16 20:24:39,539 - 【无监督】进入了无监督的设定中, 加载数据集
2025-04-16 20:24:39,539 - data preparation...
2025-04-16 20:24:49,068 - Number of train samples = 1779
2025-04-16 20:24:49,069 - Number of testing samples = 445
2025-04-16 20:24:49,069 - data preparation...
2025-04-16 20:24:51,422 - num_train_examples = 1779
2025-04-16 20:24:51,423 - ============================== Params ==============================
2025-04-16 20:24:51,423 - logger_name: umc_umc_bert-base-uncased_MIntRec_3
2025-04-16 20:24:51,423 - dataset: MIntRec
2025-04-16 20:24:51,423 - multimodal_method: umc
2025-04-16 20:24:51,423 - method: umc
2025-04-16 20:24:51,423 - setting: unsupervised
2025-04-16 20:24:51,423 - text_backbone: bert-base-uncased
2025-04-16 20:24:51,423 - seed: 3
2025-04-16 20:24:51,423 - num_workers: 16
2025-04-16 20:24:51,423 - log_id: umc_umc_bert-base-uncased_MIntRec_3_2025-04-16-20-24-39
2025-04-16 20:24:51,423 - gpu_id: 1
2025-04-16 20:24:51,423 - data_path: /root/autodl-tmp/home/Share/Dataset/LZH
2025-04-16 20:24:51,423 - train: True
2025-04-16 20:24:51,423 - tune: True
2025-04-16 20:24:51,424 - save_model: True
2025-04-16 20:24:51,424 - save_results: True
2025-04-16 20:24:51,424 - log_path: logs
2025-04-16 20:24:51,424 - cache_path: cache
2025-04-16 20:24:51,424 - video_data_path: video_data
2025-04-16 20:24:51,424 - audio_data_path: audio_data
2025-04-16 20:24:51,424 - video_feats_path: swin_feats.pkl
2025-04-16 20:24:51,424 - audio_feats_path: wavlm_feats.pkl
2025-04-16 20:24:51,424 - results_path: results
2025-04-16 20:24:51,424 - output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/SMC/outputs_test2/MIntRec
2025-04-16 20:24:51,424 - model_path: models
2025-04-16 20:24:51,424 - config_file_name: umc_MIntRec
2025-04-16 20:24:51,424 - results_file_name: results_umc.csv
2025-04-16 20:24:51,424 - text_pretrained_model: uncased_L-12_H-768_A-12
2025-04-16 20:24:51,424 - pretrained_bert_model: uncased_L-12_H-768_A-12
2025-04-16 20:24:51,424 - pretrain_batch_size: 128
2025-04-16 20:24:51,424 - train_batch_size: 128
2025-04-16 20:24:51,424 - eval_batch_size: 128
2025-04-16 20:24:51,424 - test_batch_size: 128
2025-04-16 20:24:51,424 - num_pretrain_epochs: 100
2025-04-16 20:24:51,424 - num_train_epochs: 100
2025-04-16 20:24:51,424 - pretrain: [True]
2025-04-16 20:24:51,424 - aligned_method: ctc
2025-04-16 20:24:51,424 - need_aligned: False
2025-04-16 20:24:51,424 - freeze_pretrain_bert_parameters: [True]
2025-04-16 20:24:51,424 - freeze_train_bert_parameters: [True]
2025-04-16 20:24:51,424 - pretrain_temperature: [0.1]
2025-04-16 20:24:51,424 - train_temperature_sup: [0.5]
2025-04-16 20:24:51,425 - train_temperature_unsup: [2]
2025-04-16 20:24:51,425 - activation: tanh
2025-04-16 20:24:51,425 - lr_pre: [5e-06]
2025-04-16 20:24:51,425 - lr: [5e-05]
2025-04-16 20:24:51,425 - delta: [0.05]
2025-04-16 20:24:51,425 - thres: [0.1]
2025-04-16 20:24:51,425 - topk: [5]
2025-04-16 20:24:51,425 - weight_decay: 0.01
2025-04-16 20:24:51,425 - feat_dim: 768
2025-04-16 20:24:51,425 - hidden_size: 768
2025-04-16 20:24:51,425 - grad_clip: -1.0
2025-04-16 20:24:51,425 - warmup_proportion: [0.1]
2025-04-16 20:24:51,425 - hidden_dropout_prob: 0.1
2025-04-16 20:24:51,425 - weight: 1.0
2025-04-16 20:24:51,425 - loss_mode: rdrop
2025-04-16 20:24:51,425 - base_dim: 256
2025-04-16 20:24:51,425 - nheads: 8
2025-04-16 20:24:51,425 - attn_dropout: 0.1
2025-04-16 20:24:51,425 - relu_dropout: 0.1
2025-04-16 20:24:51,425 - embed_dropout: 0.01
2025-04-16 20:24:51,425 - res_dropout: 0.0
2025-04-16 20:24:51,425 - attn_mask: True
2025-04-16 20:24:51,425 - encoder_layers_1: 1
2025-04-16 20:24:51,425 - fusion_act: tanh
2025-04-16 20:24:51,425 - pred_output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/SMC/outputs_test2/MIntRec/umc_umc_MIntRec_bert-base-uncased_3
2025-04-16 20:24:51,425 - model_output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/SMC/outputs_test2/MIntRec/umc_umc_MIntRec_bert-base-uncased_3/models
2025-04-16 20:24:51,426 - text_seq_len: 30
2025-04-16 20:24:51,426 - video_seq_len: 230
2025-04-16 20:24:51,426 - audio_seq_len: 480
2025-04-16 20:24:51,426 - text_feat_dim: 768
2025-04-16 20:24:51,426 - video_feat_dim: 1024
2025-04-16 20:24:51,426 - audio_feat_dim: 768
2025-04-16 20:24:51,426 - num_labels: 20
2025-04-16 20:24:51,426 - num_train_examples: 1779
2025-04-16 20:24:51,426 - ============================== End Params ==============================
2025-04-16 20:24:52,737 - Freeze all parameters but the last layer for efficiency
2025-04-16 20:24:52,771 - Pre-training start...
2025-04-16 20:25:13,681 - ***** Epoch: 1: Eval results *****
2025-04-16 20:25:13,682 -   train_loss = 5.958248955862863
2025-04-16 20:25:36,217 - ***** Epoch: 2: Eval results *****
2025-04-16 20:25:36,217 -   train_loss = 5.962451457977295
2025-04-16 20:25:56,543 - ***** Epoch: 3: Eval results *****
2025-04-16 20:25:56,544 -   train_loss = 5.959684610366821
2025-04-16 20:26:18,197 - ***** Epoch: 4: Eval results *****
2025-04-16 20:26:18,197 -   train_loss = 5.9566738946097235
2025-04-16 20:26:39,324 - ***** Epoch: 5: Eval results *****
2025-04-16 20:26:39,324 -   train_loss = 5.952866656439645
2025-04-16 20:27:00,300 - ***** Epoch: 6: Eval results *****
2025-04-16 20:27:00,300 -   train_loss = 5.93950080871582
2025-04-16 20:27:21,538 - ***** Epoch: 7: Eval results *****
2025-04-16 20:27:21,538 -   train_loss = 5.931129251207624
2025-04-16 20:27:46,920 - ***** Epoch: 8: Eval results *****
2025-04-16 20:27:46,920 -   train_loss = 5.917787449700492
2025-04-16 20:28:09,597 - ***** Epoch: 9: Eval results *****
2025-04-16 20:28:09,598 -   train_loss = 5.885487283979144
2025-04-16 20:28:31,567 - ***** Epoch: 10: Eval results *****
2025-04-16 20:28:31,568 -   train_loss = 5.844285522188459
2025-04-16 20:28:54,468 - ***** Epoch: 11: Eval results *****
2025-04-16 20:28:54,468 -   train_loss = 5.776459659848895
2025-04-16 20:29:16,616 - ***** Epoch: 12: Eval results *****
2025-04-16 20:29:16,617 -   train_loss = 5.648239271981375
2025-04-16 20:29:38,439 - ***** Epoch: 13: Eval results *****
2025-04-16 20:29:38,439 -   train_loss = 5.462373495101929
2025-04-16 20:29:59,977 - ***** Epoch: 14: Eval results *****
2025-04-16 20:29:59,977 -   train_loss = 5.175119979040963
2025-04-16 20:30:22,016 - ***** Epoch: 15: Eval results *****
2025-04-16 20:30:22,016 -   train_loss = 4.9016707965305875
2025-04-16 20:30:46,544 - ***** Epoch: 16: Eval results *****
2025-04-16 20:30:46,544 -   train_loss = 4.649607794625418
2025-04-16 20:31:08,707 - ***** Epoch: 17: Eval results *****
2025-04-16 20:31:08,708 -   train_loss = 4.413263389042446
2025-04-16 20:31:30,065 - ***** Epoch: 18: Eval results *****
2025-04-16 20:31:30,065 -   train_loss = 4.2218901600156515
2025-04-16 20:31:50,309 - ***** Epoch: 19: Eval results *****
2025-04-16 20:31:50,310 -   train_loss = 4.052715863500323
2025-04-16 20:32:11,006 - ***** Epoch: 20: Eval results *****
2025-04-16 20:32:11,007 -   train_loss = 3.8938076155526296
2025-04-16 20:32:30,978 - ***** Epoch: 21: Eval results *****
2025-04-16 20:32:30,978 -   train_loss = 3.746760368347168
2025-04-16 20:32:52,376 - ***** Epoch: 22: Eval results *****
2025-04-16 20:32:52,376 -   train_loss = 3.6052470207214355
2025-04-16 20:33:12,716 - ***** Epoch: 23: Eval results *****
2025-04-16 20:33:12,717 -   train_loss = 3.494230559894017
2025-04-16 20:33:34,626 - ***** Epoch: 24: Eval results *****
2025-04-16 20:33:34,626 -   train_loss = 3.3997240236827304
2025-04-16 20:33:56,370 - ***** Epoch: 25: Eval results *****
2025-04-16 20:33:56,370 -   train_loss = 3.2725252423967635
2025-04-16 20:34:20,611 - ***** Epoch: 26: Eval results *****
2025-04-16 20:34:20,612 -   train_loss = 3.1912862913949147
2025-04-16 20:34:43,029 - ***** Epoch: 27: Eval results *****
2025-04-16 20:34:43,030 -   train_loss = 3.131421617099217
2025-04-16 20:35:03,275 - ***** Epoch: 28: Eval results *****
2025-04-16 20:35:03,277 -   train_loss = 3.077788846833365
2025-04-16 20:35:24,536 - ***** Epoch: 29: Eval results *****
2025-04-16 20:35:24,536 -   train_loss = 2.9814965554646085
2025-04-16 20:35:46,041 - ***** Epoch: 30: Eval results *****
2025-04-16 20:35:46,042 -   train_loss = 2.9135765859058926
2025-04-16 20:36:06,727 - ***** Epoch: 31: Eval results *****
2025-04-16 20:36:06,727 -   train_loss = 2.863746557916914
2025-04-16 20:36:27,868 - ***** Epoch: 32: Eval results *****
2025-04-16 20:36:27,868 -   train_loss = 2.8201084988457814
2025-04-16 20:36:49,652 - ***** Epoch: 33: Eval results *****
2025-04-16 20:36:49,652 -   train_loss = 2.731136509350368
2025-04-16 20:37:11,680 - ***** Epoch: 34: Eval results *****
2025-04-16 20:37:11,681 -   train_loss = 2.710580280848912
2025-04-16 20:37:33,698 - ***** Epoch: 35: Eval results *****
2025-04-16 20:37:33,698 -   train_loss = 2.6957194123949324
2025-04-16 20:37:58,991 - ***** Epoch: 36: Eval results *****
2025-04-16 20:37:58,992 -   train_loss = 2.6434245450156078
2025-04-16 20:38:21,129 - ***** Epoch: 37: Eval results *****
2025-04-16 20:38:21,129 -   train_loss = 2.5711665834699358
2025-04-16 20:38:43,127 - ***** Epoch: 38: Eval results *****
2025-04-16 20:38:43,127 -   train_loss = 2.553942561149597
2025-04-16 20:39:04,775 - ***** Epoch: 39: Eval results *****
2025-04-16 20:39:04,776 -   train_loss = 2.5113848447799683
2025-04-16 20:39:25,953 - ***** Epoch: 40: Eval results *****
2025-04-16 20:39:25,954 -   train_loss = 2.49808326789311
2025-04-16 20:39:47,365 - ***** Epoch: 41: Eval results *****
2025-04-16 20:39:47,365 -   train_loss = 2.4500401530947005
2025-04-16 20:40:08,608 - ***** Epoch: 42: Eval results *****
2025-04-16 20:40:08,609 -   train_loss = 2.4310250111988614
2025-04-16 20:40:30,167 - ***** Epoch: 43: Eval results *****
2025-04-16 20:40:30,168 -   train_loss = 2.392469593456813
2025-04-16 20:40:55,550 - ***** Epoch: 44: Eval results *****
2025-04-16 20:40:55,551 -   train_loss = 2.368349926812308
2025-04-16 20:41:17,060 - ***** Epoch: 45: Eval results *****
2025-04-16 20:41:17,060 -   train_loss = 2.373630472591945
2025-04-16 20:41:38,929 - ***** Epoch: 46: Eval results *****
2025-04-16 20:41:38,930 -   train_loss = 2.33672765323094
2025-04-16 20:41:59,457 - ***** Epoch: 47: Eval results *****
2025-04-16 20:41:59,457 -   train_loss = 2.310745324407305
2025-04-16 20:42:19,576 - ***** Epoch: 48: Eval results *****
2025-04-16 20:42:19,576 -   train_loss = 2.2771993024008617
2025-04-16 20:42:41,096 - ***** Epoch: 49: Eval results *****
2025-04-16 20:42:41,096 -   train_loss = 2.27403347832816
2025-04-16 20:43:02,232 - ***** Epoch: 50: Eval results *****
2025-04-16 20:43:02,232 -   train_loss = 2.2553397246769498
2025-04-16 20:43:22,886 - ***** Epoch: 51: Eval results *****
2025-04-16 20:43:22,887 -   train_loss = 2.2293260948998586
2025-04-16 20:43:44,597 - ***** Epoch: 52: Eval results *****
2025-04-16 20:43:44,597 -   train_loss = 2.2296378953116283
2025-04-16 20:44:05,229 - ***** Epoch: 53: Eval results *****
2025-04-16 20:44:05,229 -   train_loss = 2.207096644810268
2025-04-16 20:44:28,131 - ***** Epoch: 54: Eval results *****
2025-04-16 20:44:28,131 -   train_loss = 2.1786001409803117
2025-04-16 20:44:50,280 - ***** Epoch: 55: Eval results *****
2025-04-16 20:44:50,280 -   train_loss = 2.1741783618927
2025-04-16 20:45:12,315 - ***** Epoch: 56: Eval results *****
2025-04-16 20:45:12,316 -   train_loss = 2.152860794748579
2025-04-16 20:45:34,641 - ***** Epoch: 57: Eval results *****
2025-04-16 20:45:34,642 -   train_loss = 2.1466545036860873
2025-04-16 20:45:55,860 - ***** Epoch: 58: Eval results *****
2025-04-16 20:45:55,861 -   train_loss = 2.137218168803624
2025-04-16 20:46:17,089 - ***** Epoch: 59: Eval results *****
2025-04-16 20:46:17,089 -   train_loss = 2.1254115785871233
2025-04-16 20:46:38,753 - ***** Epoch: 60: Eval results *****
2025-04-16 20:46:38,753 -   train_loss = 2.113877058029175
2025-04-16 20:47:00,392 - ***** Epoch: 61: Eval results *****
2025-04-16 20:47:00,392 -   train_loss = 2.1071672439575195
2025-04-16 20:47:21,660 - ***** Epoch: 62: Eval results *****
2025-04-16 20:47:21,661 -   train_loss = 2.10195939881461
2025-04-16 20:47:46,742 - ***** Epoch: 63: Eval results *****
2025-04-16 20:47:46,743 -   train_loss = 2.0719235113688876
2025-04-16 20:48:07,637 - ***** Epoch: 64: Eval results *****
2025-04-16 20:48:07,637 -   train_loss = 2.067604116031102
2025-04-16 20:48:29,182 - ***** Epoch: 65: Eval results *****
2025-04-16 20:48:29,182 -   train_loss = 2.06692441872188
2025-04-16 20:48:49,543 - ***** Epoch: 66: Eval results *****
2025-04-16 20:48:49,544 -   train_loss = 2.068431411470686
2025-04-16 20:49:11,287 - ***** Epoch: 67: Eval results *****
2025-04-16 20:49:11,288 -   train_loss = 2.0620247636522566
2025-04-16 20:49:33,041 - ***** Epoch: 68: Eval results *****
2025-04-16 20:49:33,041 -   train_loss = 2.0484774708747864
2025-04-16 20:49:54,795 - ***** Epoch: 69: Eval results *****
2025-04-16 20:49:54,796 -   train_loss = 2.033646489892687
2025-04-16 20:50:15,608 - ***** Epoch: 70: Eval results *****
2025-04-16 20:50:15,609 -   train_loss = 2.044888232435499
2025-04-16 20:50:36,986 - ***** Epoch: 71: Eval results *****
2025-04-16 20:50:36,987 -   train_loss = 2.021940120628902
2025-04-16 20:50:59,614 - ***** Epoch: 72: Eval results *****
2025-04-16 20:50:59,615 -   train_loss = 2.013839943068368
2025-04-16 20:51:23,136 - ***** Epoch: 73: Eval results *****
2025-04-16 20:51:23,136 -   train_loss = 2.007117816380092
2025-04-16 20:51:44,274 - ***** Epoch: 74: Eval results *****
2025-04-16 20:51:44,274 -   train_loss = 1.9981287462370736
2025-04-16 20:52:04,582 - ***** Epoch: 75: Eval results *****
2025-04-16 20:52:04,582 -   train_loss = 2.0186615586280823
2025-04-16 20:52:25,800 - ***** Epoch: 76: Eval results *****
2025-04-16 20:52:25,801 -   train_loss = 2.001980483531952
2025-04-16 20:52:47,826 - ***** Epoch: 77: Eval results *****
2025-04-16 20:52:47,827 -   train_loss = 1.9785772391727992
2025-04-16 20:53:09,214 - ***** Epoch: 78: Eval results *****
2025-04-16 20:53:09,215 -   train_loss = 1.9821122884750366
2025-04-16 20:53:30,682 - ***** Epoch: 79: Eval results *****
2025-04-16 20:53:30,682 -   train_loss = 1.9866270678383964
2025-04-16 20:53:51,560 - ***** Epoch: 80: Eval results *****
2025-04-16 20:53:51,560 -   train_loss = 1.9944131629807609
2025-04-16 20:54:13,122 - ***** Epoch: 81: Eval results *****
2025-04-16 20:54:13,123 -   train_loss = 1.9755614059312003
2025-04-16 20:54:37,304 - ***** Epoch: 82: Eval results *****
2025-04-16 20:54:37,304 -   train_loss = 1.9521979519299097
2025-04-16 20:54:58,497 - ***** Epoch: 83: Eval results *****
2025-04-16 20:54:58,498 -   train_loss = 1.978450562272753
2025-04-16 20:55:20,209 - ***** Epoch: 84: Eval results *****
2025-04-16 20:55:20,210 -   train_loss = 1.9624028376170568
2025-04-16 20:55:40,389 - ***** Epoch: 85: Eval results *****
2025-04-16 20:55:40,389 -   train_loss = 1.9706261243138994
2025-04-16 20:56:02,504 - ***** Epoch: 86: Eval results *****
2025-04-16 20:56:02,505 -   train_loss = 1.9580806834357125
2025-04-16 20:56:24,633 - ***** Epoch: 87: Eval results *****
2025-04-16 20:56:24,634 -   train_loss = 1.9631571940013341
2025-04-16 20:56:46,067 - ***** Epoch: 88: Eval results *****
2025-04-16 20:56:46,067 -   train_loss = 1.9672720517430986
2025-04-16 20:57:07,008 - ***** Epoch: 89: Eval results *****
2025-04-16 20:57:07,008 -   train_loss = 1.9578697085380554
2025-04-16 20:57:28,287 - ***** Epoch: 90: Eval results *****
2025-04-16 20:57:28,288 -   train_loss = 1.9595997418676103
2025-04-16 20:57:51,990 - ***** Epoch: 91: Eval results *****
2025-04-16 20:57:51,990 -   train_loss = 1.9617112874984741
2025-04-16 20:58:12,444 - ***** Epoch: 92: Eval results *****
2025-04-16 20:58:12,445 -   train_loss = 1.9460738727024622
2025-04-16 20:58:32,804 - ***** Epoch: 93: Eval results *****
2025-04-16 20:58:32,805 -   train_loss = 1.9588145102773393
2025-04-16 20:58:55,213 - ***** Epoch: 94: Eval results *****
2025-04-16 20:58:55,214 -   train_loss = 1.9502066118376595
2025-04-16 20:59:16,405 - ***** Epoch: 95: Eval results *****
2025-04-16 20:59:16,405 -   train_loss = 1.9374033638409205
2025-04-16 20:59:37,619 - ***** Epoch: 96: Eval results *****
2025-04-16 20:59:37,620 -   train_loss = 1.9588729228292192
2025-04-16 20:59:59,146 - ***** Epoch: 97: Eval results *****
2025-04-16 20:59:59,146 -   train_loss = 1.9436241558619909
2025-04-16 21:00:19,541 - ***** Epoch: 98: Eval results *****
2025-04-16 21:00:19,541 -   train_loss = 1.9718952775001526
2025-04-16 21:00:40,622 - ***** Epoch: 99: Eval results *****
2025-04-16 21:00:40,623 -   train_loss = 1.950700887611934
2025-04-16 21:01:02,228 - ***** Epoch: 100: Eval results *****
2025-04-16 21:01:02,228 -   train_loss = 1.9583885669708252
2025-04-16 21:01:02,820 - Pre-training finished...
2025-04-16 21:01:03,178 - Freeze all parameters but the last layer for efficiency
2025-04-16 21:01:03,188 - Multimodal Intent Recognition begins...
2025-04-16 21:01:03,188 - Training begins...
2025-04-16 21:01:20,774 - Initializing centroids with K-means++...
2025-04-16 21:01:20,915 - K-means++ used 0.14 s
2025-04-16 21:01:56,928 - K-means used 0.02 s
2025-04-16 21:01:58,699 - ***** Epoch: 1 *****
2025-04-16 21:01:58,700 - Supervised Training Loss: 4.365050
2025-04-16 21:01:58,700 - Unsupervised Training Loss: 5.567850
2025-04-16 21:02:33,611 - K-means used 0.04 s
2025-04-16 21:02:35,418 - ***** Epoch: 2 *****
2025-04-16 21:02:35,418 - Supervised Training Loss: 4.949980
2025-04-16 21:02:35,418 - Unsupervised Training Loss: 5.584760
2025-04-16 21:03:10,342 - K-means used 0.02 s
2025-04-16 21:03:12,318 - ***** Epoch: 3 *****
2025-04-16 21:03:12,318 - Supervised Training Loss: 4.769500
2025-04-16 21:03:12,318 - Unsupervised Training Loss: 5.438620
2025-04-16 21:03:46,921 - K-means used 0.09 s
2025-04-16 21:03:48,821 - ***** Epoch: 4 *****
2025-04-16 21:03:48,821 - Supervised Training Loss: 4.580700
2025-04-16 21:03:48,821 - Unsupervised Training Loss: 5.500270
2025-04-16 21:04:23,696 - K-means used 0.14 s
2025-04-16 21:04:25,646 - ***** Epoch: 5 *****
2025-04-16 21:04:25,646 - Supervised Training Loss: 4.252140
2025-04-16 21:04:25,646 - Unsupervised Training Loss: 5.540490
2025-04-16 21:04:59,943 - K-means used 0.02 s
2025-04-16 21:05:02,260 - ***** Epoch: 6 *****
2025-04-16 21:05:02,260 - Supervised Training Loss: 4.664450
2025-04-16 21:05:02,260 - Unsupervised Training Loss: 5.347060
2025-04-16 21:05:36,409 - K-means used 0.06 s
2025-04-16 21:05:37,989 - ***** Epoch: 7 *****
2025-04-16 21:05:37,989 - Supervised Training Loss: 4.579760
2025-04-16 21:05:37,989 - Unsupervised Training Loss: 5.450090
2025-04-16 21:06:10,653 - K-means used 0.02 s
2025-04-16 21:06:12,625 - ***** Epoch: 8 *****
2025-04-16 21:06:12,625 - Supervised Training Loss: 4.416040
2025-04-16 21:06:12,625 - Unsupervised Training Loss: 5.507050
2025-04-16 21:06:46,700 - K-means used 0.03 s
2025-04-16 21:06:49,102 - ***** Epoch: 9 *****
2025-04-16 21:06:49,102 - Supervised Training Loss: 4.646360
2025-04-16 21:06:49,102 - Unsupervised Training Loss: 4.941630
2025-04-16 21:07:22,455 - K-means used 0.02 s
2025-04-16 21:07:24,555 - ***** Epoch: 10 *****
2025-04-16 21:07:24,555 - Supervised Training Loss: 4.575360
2025-04-16 21:07:24,555 - Unsupervised Training Loss: 5.391480
2025-04-16 21:08:03,267 - K-means used 0.02 s
2025-04-16 21:08:05,337 - ***** Epoch: 11 *****
2025-04-16 21:08:05,337 - Supervised Training Loss: 4.492940
2025-04-16 21:08:05,337 - Unsupervised Training Loss: 5.468100
2025-04-16 21:08:40,996 - K-means used 0.02 s
2025-04-16 21:08:42,774 - ***** Epoch: 12 *****
2025-04-16 21:08:42,774 - Supervised Training Loss: 4.637920
2025-04-16 21:08:42,774 - Unsupervised Training Loss: 5.535160
2025-04-16 21:09:17,808 - K-means used 0.05 s
2025-04-16 21:09:19,843 - ***** Epoch: 13 *****
2025-04-16 21:09:19,843 - Supervised Training Loss: 4.606100
2025-04-16 21:09:19,843 - Unsupervised Training Loss: 5.265140
2025-04-16 21:09:52,410 - K-means used 0.04 s
2025-04-16 21:09:54,665 - ***** Epoch: 14 *****
2025-04-16 21:09:54,666 - Supervised Training Loss: 4.562170
2025-04-16 21:09:54,666 - Unsupervised Training Loss: 5.396880
2025-04-16 21:10:28,495 - K-means used 0.02 s
2025-04-16 21:10:30,505 - ***** Epoch: 15 *****
2025-04-16 21:10:30,505 - Supervised Training Loss: 4.429540
2025-04-16 21:10:30,505 - Unsupervised Training Loss: 5.498530
2025-04-16 21:11:07,381 - K-means used 0.02 s
2025-04-16 21:11:09,500 - ***** Epoch: 16 *****
2025-04-16 21:11:09,501 - Supervised Training Loss: 4.657780
2025-04-16 21:11:09,501 - Unsupervised Training Loss: 4.957580
2025-04-16 21:11:43,300 - K-means used 0.04 s
2025-04-16 21:11:46,004 - ***** Epoch: 17 *****
2025-04-16 21:11:46,004 - Supervised Training Loss: 4.643970
2025-04-16 21:11:46,005 - Unsupervised Training Loss: 5.190270
2025-04-16 21:12:09,350 - Training is finished...
2025-04-16 21:12:09,350 - Testing begins...
2025-04-16 21:12:17,107 - ***** Test results *****
2025-04-16 21:12:17,107 -   ACC = 39.55
2025-04-16 21:12:17,107 -   ARI = 19.53
2025-04-16 21:12:17,107 -   NMI = 44.61
2025-04-16 21:12:17,108 -   fmi = 24.61
2025-04-16 21:12:17,108 - Testing is finished...
2025-04-16 21:12:17,108 - Multimodal intent recognition is finished...
2025-04-16 21:12:17,108 - Results are saved in results/results_umc.csv
