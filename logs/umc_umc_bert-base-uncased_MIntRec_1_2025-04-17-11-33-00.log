2025-04-17 11:33:00,975 - 【无监督】进入了无监督的设定中, 加载数据集
2025-04-17 11:33:00,975 - data preparation...
2025-04-17 11:33:09,696 - Number of train samples = 1779
2025-04-17 11:33:09,696 - Number of testing samples = 445
2025-04-17 11:33:09,696 - data preparation...
2025-04-17 11:33:11,869 - num_train_examples = 1779
2025-04-17 11:33:11,870 - ============================== Params ==============================
2025-04-17 11:33:11,870 - logger_name: umc_umc_bert-base-uncased_MIntRec_1
2025-04-17 11:33:11,870 - dataset: MIntRec
2025-04-17 11:33:11,870 - multimodal_method: umc
2025-04-17 11:33:11,870 - method: umc
2025-04-17 11:33:11,870 - setting: unsupervised
2025-04-17 11:33:11,870 - text_backbone: bert-base-uncased
2025-04-17 11:33:11,870 - seed: 1
2025-04-17 11:33:11,870 - num_workers: 16
2025-04-17 11:33:11,870 - log_id: umc_umc_bert-base-uncased_MIntRec_1_2025-04-17-11-33-00
2025-04-17 11:33:11,870 - gpu_id: 1
2025-04-17 11:33:11,870 - data_path: /root/autodl-tmp/home/Share/Dataset/LZH
2025-04-17 11:33:11,870 - train: True
2025-04-17 11:33:11,870 - tune: True
2025-04-17 11:33:11,870 - save_model: True
2025-04-17 11:33:11,870 - save_results: True
2025-04-17 11:33:11,870 - log_path: logs
2025-04-17 11:33:11,870 - cache_path: cache
2025-04-17 11:33:11,870 - video_data_path: video_data
2025-04-17 11:33:11,870 - audio_data_path: audio_data
2025-04-17 11:33:11,870 - video_feats_path: swin_feats.pkl
2025-04-17 11:33:11,870 - audio_feats_path: wavlm_feats.pkl
2025-04-17 11:33:11,870 - results_path: results
2025-04-17 11:33:11,870 - output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/SMC/outputs_test2/MIntRec
2025-04-17 11:33:11,870 - model_path: models
2025-04-17 11:33:11,870 - config_file_name: umc_MIntRec
2025-04-17 11:33:11,870 - results_file_name: results_umc_pre.csv
2025-04-17 11:33:11,871 - text_pretrained_model: uncased_L-12_H-768_A-12
2025-04-17 11:33:11,871 - pretrained_bert_model: uncased_L-12_H-768_A-12
2025-04-17 11:33:11,871 - pretrain_batch_size: 128
2025-04-17 11:33:11,871 - train_batch_size: 128
2025-04-17 11:33:11,871 - eval_batch_size: 128
2025-04-17 11:33:11,871 - test_batch_size: 128
2025-04-17 11:33:11,871 - num_pretrain_epochs: 100
2025-04-17 11:33:11,871 - num_train_epochs: 100
2025-04-17 11:33:11,871 - pretrain: [True]
2025-04-17 11:33:11,871 - aligned_method: ctc
2025-04-17 11:33:11,871 - need_aligned: False
2025-04-17 11:33:11,871 - freeze_pretrain_bert_parameters: [True]
2025-04-17 11:33:11,871 - freeze_train_bert_parameters: [True]
2025-04-17 11:33:11,871 - pretrain_temperature: [0.1, 0.2, 0.4, 0.5]
2025-04-17 11:33:11,871 - train_temperature_sup: [0.5]
2025-04-17 11:33:11,872 - train_temperature_unsup: [2]
2025-04-17 11:33:11,872 - activation: tanh
2025-04-17 11:33:11,872 - lr_pre: [1e-05]
2025-04-17 11:33:11,872 - lr: [5e-05]
2025-04-17 11:33:11,872 - delta: [0.05]
2025-04-17 11:33:11,872 - thres: [0.1]
2025-04-17 11:33:11,872 - topk: [5]
2025-04-17 11:33:11,872 - weight_decay: 0.01
2025-04-17 11:33:11,872 - feat_dim: 768
2025-04-17 11:33:11,872 - hidden_size: 768
2025-04-17 11:33:11,872 - grad_clip: -1.0
2025-04-17 11:33:11,872 - warmup_proportion: [0.1]
2025-04-17 11:33:11,872 - hidden_dropout_prob: 0.1
2025-04-17 11:33:11,872 - weight: 1.0
2025-04-17 11:33:11,872 - loss_mode: rdrop
2025-04-17 11:33:11,872 - base_dim: 256
2025-04-17 11:33:11,872 - nheads: 8
2025-04-17 11:33:11,872 - attn_dropout: 0.1
2025-04-17 11:33:11,872 - relu_dropout: 0.1
2025-04-17 11:33:11,872 - embed_dropout: 0.01
2025-04-17 11:33:11,872 - res_dropout: 0.0
2025-04-17 11:33:11,872 - attn_mask: True
2025-04-17 11:33:11,872 - encoder_layers_1: 1
2025-04-17 11:33:11,872 - fusion_act: tanh
2025-04-17 11:33:11,872 - pred_output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/SMC/outputs_test2/MIntRec/umc_umc_MIntRec_bert-base-uncased_1
2025-04-17 11:33:11,872 - model_output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/SMC/outputs_test2/MIntRec/umc_umc_MIntRec_bert-base-uncased_1/models
2025-04-17 11:33:11,872 - text_seq_len: 30
2025-04-17 11:33:11,873 - video_seq_len: 230
2025-04-17 11:33:11,873 - audio_seq_len: 480
2025-04-17 11:33:11,873 - text_feat_dim: 768
2025-04-17 11:33:11,873 - video_feat_dim: 1024
2025-04-17 11:33:11,873 - audio_feat_dim: 768
2025-04-17 11:33:11,873 - num_labels: 20
2025-04-17 11:33:11,873 - num_train_examples: 1779
2025-04-17 11:33:11,873 - ============================== End Params ==============================
2025-04-17 11:33:13,057 - Freeze all parameters but the last layer for efficiency
2025-04-17 11:33:13,096 - Pre-training start...
2025-04-17 11:33:28,941 - ***** Epoch: 1: Eval results *****
2025-04-17 11:33:28,941 -   train_loss = 5.964964287621634
2025-04-17 11:33:45,114 - ***** Epoch: 2: Eval results *****
2025-04-17 11:33:45,115 -   train_loss = 5.96149754524231
2025-04-17 11:34:01,477 - ***** Epoch: 3: Eval results *****
2025-04-17 11:34:01,477 -   train_loss = 5.94726960999625
2025-04-17 11:34:17,852 - ***** Epoch: 4: Eval results *****
2025-04-17 11:34:17,853 -   train_loss = 5.941530125481742
2025-04-17 11:34:34,052 - ***** Epoch: 5: Eval results *****
2025-04-17 11:34:34,052 -   train_loss = 5.92945545060294
2025-04-17 11:34:51,255 - ***** Epoch: 6: Eval results *****
2025-04-17 11:34:51,256 -   train_loss = 5.917366640908377
2025-04-17 11:35:07,277 - ***** Epoch: 7: Eval results *****
2025-04-17 11:35:07,277 -   train_loss = 5.880903244018555
2025-04-17 11:35:23,409 - ***** Epoch: 8: Eval results *****
2025-04-17 11:35:23,409 -   train_loss = 5.812240055629185
2025-04-17 11:35:40,007 - ***** Epoch: 9: Eval results *****
2025-04-17 11:35:40,007 -   train_loss = 5.676036732537406
2025-04-17 11:35:57,247 - ***** Epoch: 10: Eval results *****
2025-04-17 11:35:57,247 -   train_loss = 5.349126441138131
2025-04-17 11:36:14,390 - ***** Epoch: 11: Eval results *****
2025-04-17 11:36:14,391 -   train_loss = 4.828298398426601
2025-04-17 11:36:31,517 - ***** Epoch: 12: Eval results *****
2025-04-17 11:36:31,517 -   train_loss = 4.340165155274527
2025-04-17 11:36:48,833 - ***** Epoch: 13: Eval results *****
2025-04-17 11:36:48,834 -   train_loss = 3.956438899040222
2025-04-17 11:37:06,238 - ***** Epoch: 14: Eval results *****
2025-04-17 11:37:06,238 -   train_loss = 3.634731105395726
2025-04-17 11:37:23,180 - ***** Epoch: 15: Eval results *****
2025-04-17 11:37:23,180 -   train_loss = 3.3911640644073486
2025-04-17 11:37:41,377 - ***** Epoch: 16: Eval results *****
2025-04-17 11:37:41,378 -   train_loss = 3.1630330085754395
2025-04-17 11:37:59,149 - ***** Epoch: 17: Eval results *****
2025-04-17 11:37:59,149 -   train_loss = 2.9751807280949185
2025-04-17 11:38:16,205 - ***** Epoch: 18: Eval results *****
2025-04-17 11:38:16,205 -   train_loss = 2.8211011375699724
2025-04-17 11:38:33,257 - ***** Epoch: 19: Eval results *****
2025-04-17 11:38:33,257 -   train_loss = 2.6949925422668457
2025-04-17 11:38:50,806 - ***** Epoch: 20: Eval results *****
2025-04-17 11:38:50,806 -   train_loss = 2.5832738365445818
2025-04-17 11:39:07,869 - ***** Epoch: 21: Eval results *****
2025-04-17 11:39:07,869 -   train_loss = 2.4861670391900197
2025-04-17 11:39:25,122 - ***** Epoch: 22: Eval results *****
2025-04-17 11:39:25,123 -   train_loss = 2.413903594017029
2025-04-17 11:39:41,904 - ***** Epoch: 23: Eval results *****
2025-04-17 11:39:41,905 -   train_loss = 2.3190376417977467
2025-04-17 11:39:58,468 - ***** Epoch: 24: Eval results *****
2025-04-17 11:39:58,468 -   train_loss = 2.246914267539978
2025-04-17 11:40:15,676 - ***** Epoch: 25: Eval results *****
2025-04-17 11:40:15,676 -   train_loss = 2.20946204662323
2025-04-17 11:40:32,586 - ***** Epoch: 26: Eval results *****
2025-04-17 11:40:32,586 -   train_loss = 2.1430978093828474
2025-04-17 11:40:49,847 - ***** Epoch: 27: Eval results *****
2025-04-17 11:40:49,847 -   train_loss = 2.1003366112709045
2025-04-17 11:41:07,681 - ***** Epoch: 28: Eval results *****
2025-04-17 11:41:07,681 -   train_loss = 2.0465653794152394
2025-04-17 11:41:25,242 - ***** Epoch: 29: Eval results *****
2025-04-17 11:41:25,242 -   train_loss = 2.0068075145993913
2025-04-17 11:41:42,807 - ***** Epoch: 30: Eval results *****
2025-04-17 11:41:42,807 -   train_loss = 1.9869355814797538
2025-04-17 11:42:00,294 - ***** Epoch: 31: Eval results *****
2025-04-17 11:42:00,294 -   train_loss = 1.9482183626719884
2025-04-17 11:42:17,735 - ***** Epoch: 32: Eval results *****
2025-04-17 11:42:17,735 -   train_loss = 1.9141506552696228
2025-04-17 11:42:35,173 - ***** Epoch: 33: Eval results *****
2025-04-17 11:42:35,173 -   train_loss = 1.88675514289311
2025-04-17 11:42:52,660 - ***** Epoch: 34: Eval results *****
2025-04-17 11:42:52,661 -   train_loss = 1.850401759147644
2025-04-17 11:43:09,685 - ***** Epoch: 35: Eval results *****
2025-04-17 11:43:09,685 -   train_loss = 1.8574159741401672
2025-04-17 11:43:26,825 - ***** Epoch: 36: Eval results *****
2025-04-17 11:43:26,825 -   train_loss = 1.8394521730286735
2025-04-17 11:43:43,767 - ***** Epoch: 37: Eval results *****
2025-04-17 11:43:43,768 -   train_loss = 1.798018523624965
2025-04-17 11:44:00,379 - ***** Epoch: 38: Eval results *****
2025-04-17 11:44:00,379 -   train_loss = 1.7876474346433366
2025-04-17 11:44:17,365 - ***** Epoch: 39: Eval results *****
2025-04-17 11:44:17,366 -   train_loss = 1.7720959612301417
2025-04-17 11:44:34,077 - ***** Epoch: 40: Eval results *****
2025-04-17 11:44:34,078 -   train_loss = 1.7693935547556197
2025-04-17 11:44:50,610 - ***** Epoch: 41: Eval results *****
2025-04-17 11:44:50,610 -   train_loss = 1.7538228971617562
2025-04-17 11:45:06,968 - ***** Epoch: 42: Eval results *****
2025-04-17 11:45:06,969 -   train_loss = 1.7299907633236475
2025-04-17 11:45:23,923 - ***** Epoch: 43: Eval results *****
2025-04-17 11:45:23,923 -   train_loss = 1.713258113179888
2025-04-17 11:45:41,414 - ***** Epoch: 44: Eval results *****
2025-04-17 11:45:41,414 -   train_loss = 1.6949633700507027
2025-04-17 11:45:58,552 - ***** Epoch: 45: Eval results *****
2025-04-17 11:45:58,552 -   train_loss = 1.693884321621486
2025-04-17 11:46:15,112 - ***** Epoch: 46: Eval results *****
2025-04-17 11:46:15,112 -   train_loss = 1.6805971605437142
2025-04-17 11:46:30,994 - ***** Epoch: 47: Eval results *****
2025-04-17 11:46:30,994 -   train_loss = 1.668487080505916
2025-04-17 11:46:47,725 - ***** Epoch: 48: Eval results *****
2025-04-17 11:46:47,725 -   train_loss = 1.6693219627652849
2025-04-17 11:47:04,236 - ***** Epoch: 49: Eval results *****
2025-04-17 11:47:04,236 -   train_loss = 1.657657069819314
2025-04-17 11:47:21,005 - ***** Epoch: 50: Eval results *****
2025-04-17 11:47:21,005 -   train_loss = 1.6305692195892334
2025-04-17 11:47:38,291 - ***** Epoch: 51: Eval results *****
2025-04-17 11:47:38,291 -   train_loss = 1.6310107963425773
2025-04-17 11:47:55,521 - ***** Epoch: 52: Eval results *****
2025-04-17 11:47:55,522 -   train_loss = 1.6247991919517517
2025-04-17 11:48:12,689 - ***** Epoch: 53: Eval results *****
2025-04-17 11:48:12,690 -   train_loss = 1.6180203131267004
2025-04-17 11:48:29,898 - ***** Epoch: 54: Eval results *****
2025-04-17 11:48:29,899 -   train_loss = 1.6148853046553475
2025-04-17 11:48:47,039 - ***** Epoch: 55: Eval results *****
2025-04-17 11:48:47,040 -   train_loss = 1.6004841497966222
2025-04-17 11:49:03,802 - ***** Epoch: 56: Eval results *****
2025-04-17 11:49:03,802 -   train_loss = 1.592673225062234
2025-04-17 11:49:20,730 - ***** Epoch: 57: Eval results *****
2025-04-17 11:49:20,731 -   train_loss = 1.58889011825834
2025-04-17 11:49:36,948 - ***** Epoch: 58: Eval results *****
2025-04-17 11:49:36,948 -   train_loss = 1.598649059023176
2025-04-17 11:49:53,568 - ***** Epoch: 59: Eval results *****
2025-04-17 11:49:53,569 -   train_loss = 1.5846464889390128
2025-04-17 11:50:10,112 - ***** Epoch: 60: Eval results *****
2025-04-17 11:50:10,113 -   train_loss = 1.5783674291202001
2025-04-17 11:50:26,885 - ***** Epoch: 61: Eval results *****
2025-04-17 11:50:26,885 -   train_loss = 1.5710765208516801
2025-04-17 11:50:43,537 - ***** Epoch: 62: Eval results *****
2025-04-17 11:50:43,537 -   train_loss = 1.556823968887329
2025-04-17 11:50:59,126 - ***** Epoch: 63: Eval results *****
2025-04-17 11:50:59,126 -   train_loss = 1.5519179105758667
2025-04-17 11:51:15,635 - ***** Epoch: 64: Eval results *****
2025-04-17 11:51:15,635 -   train_loss = 1.5527719344411577
2025-04-17 11:51:32,004 - ***** Epoch: 65: Eval results *****
2025-04-17 11:51:32,005 -   train_loss = 1.550715182508741
2025-04-17 11:51:48,393 - ***** Epoch: 66: Eval results *****
2025-04-17 11:51:48,393 -   train_loss = 1.561518200806209
2025-04-17 11:52:04,712 - ***** Epoch: 67: Eval results *****
2025-04-17 11:52:04,712 -   train_loss = 1.5367391875811987
2025-04-17 11:52:20,955 - ***** Epoch: 68: Eval results *****
2025-04-17 11:52:20,956 -   train_loss = 1.5336472477231706
2025-04-17 11:52:37,224 - ***** Epoch: 69: Eval results *****
2025-04-17 11:52:37,224 -   train_loss = 1.515088038785117
2025-04-17 11:52:53,164 - ***** Epoch: 70: Eval results *****
2025-04-17 11:52:53,164 -   train_loss = 1.5253408210618156
2025-04-17 11:53:09,517 - ***** Epoch: 71: Eval results *****
2025-04-17 11:53:09,517 -   train_loss = 1.5236984831946236
2025-04-17 11:53:25,647 - ***** Epoch: 72: Eval results *****
2025-04-17 11:53:25,648 -   train_loss = 1.52104708978108
2025-04-17 11:53:44,941 - ***** Epoch: 73: Eval results *****
2025-04-17 11:53:44,941 -   train_loss = 1.5166881084442139
2025-04-17 11:54:04,502 - ***** Epoch: 74: Eval results *****
2025-04-17 11:54:04,502 -   train_loss = 1.5097762090819222
2025-04-17 11:54:23,897 - ***** Epoch: 75: Eval results *****
2025-04-17 11:54:23,898 -   train_loss = 1.5166692989213126
2025-04-17 11:54:42,739 - ***** Epoch: 76: Eval results *****
2025-04-17 11:54:42,739 -   train_loss = 1.5163623009409224
2025-04-17 11:55:00,295 - ***** Epoch: 77: Eval results *****
2025-04-17 11:55:00,295 -   train_loss = 1.5085278749465942
2025-04-17 11:55:19,803 - ***** Epoch: 78: Eval results *****
2025-04-17 11:55:19,804 -   train_loss = 1.5043780718530928
2025-04-17 11:55:37,420 - ***** Epoch: 79: Eval results *****
2025-04-17 11:55:37,421 -   train_loss = 1.4980038063866752
2025-04-17 11:55:55,272 - ***** Epoch: 80: Eval results *****
2025-04-17 11:55:55,273 -   train_loss = 1.4982831903866358
2025-04-17 11:56:13,755 - ***** Epoch: 81: Eval results *****
2025-04-17 11:56:13,755 -   train_loss = 1.490225178854806
2025-04-17 11:56:33,299 - ***** Epoch: 82: Eval results *****
2025-04-17 11:56:33,300 -   train_loss = 1.502261119229453
2025-04-17 11:56:51,547 - ***** Epoch: 83: Eval results *****
2025-04-17 11:56:51,547 -   train_loss = 1.4924247946058
2025-04-17 11:57:10,002 - ***** Epoch: 84: Eval results *****
2025-04-17 11:57:10,002 -   train_loss = 1.4856064489909582
2025-04-17 11:57:29,143 - ***** Epoch: 85: Eval results *****
2025-04-17 11:57:29,143 -   train_loss = 1.5124091080256872
2025-04-17 11:57:48,412 - ***** Epoch: 86: Eval results *****
2025-04-17 11:57:48,413 -   train_loss = 1.4966718213898795
2025-04-17 11:58:07,227 - ***** Epoch: 87: Eval results *****
2025-04-17 11:58:07,228 -   train_loss = 1.496261443410601
2025-04-17 11:58:28,282 - ***** Epoch: 88: Eval results *****
2025-04-17 11:58:28,282 -   train_loss = 1.4948980382510595
2025-04-17 11:58:48,547 - ***** Epoch: 89: Eval results *****
2025-04-17 11:58:48,548 -   train_loss = 1.4810127530779158
2025-04-17 11:59:06,777 - ***** Epoch: 90: Eval results *****
2025-04-17 11:59:06,778 -   train_loss = 1.494534237044198
2025-04-17 11:59:23,887 - ***** Epoch: 91: Eval results *****
2025-04-17 11:59:23,888 -   train_loss = 1.5000423703874861
2025-04-17 11:59:40,947 - ***** Epoch: 92: Eval results *****
2025-04-17 11:59:40,947 -   train_loss = 1.4972232665334428
2025-04-17 11:59:57,678 - ***** Epoch: 93: Eval results *****
2025-04-17 11:59:57,678 -   train_loss = 1.495499346937452
2025-04-17 12:00:14,350 - ***** Epoch: 94: Eval results *****
2025-04-17 12:00:14,350 -   train_loss = 1.4857696294784546
2025-04-17 12:00:31,312 - ***** Epoch: 95: Eval results *****
2025-04-17 12:00:31,312 -   train_loss = 1.49121527160917
2025-04-17 12:00:47,435 - ***** Epoch: 96: Eval results *****
2025-04-17 12:00:47,435 -   train_loss = 1.4820755890437536
2025-04-17 12:01:03,945 - ***** Epoch: 97: Eval results *****
2025-04-17 12:01:03,946 -   train_loss = 1.4821973102433341
2025-04-17 12:01:20,174 - ***** Epoch: 98: Eval results *****
2025-04-17 12:01:20,175 -   train_loss = 1.496320971420833
2025-04-17 12:01:36,710 - ***** Epoch: 99: Eval results *****
2025-04-17 12:01:36,710 -   train_loss = 1.4853208746228899
2025-04-17 12:01:52,373 - ***** Epoch: 100: Eval results *****
2025-04-17 12:01:52,373 -   train_loss = 1.4887670619147164
2025-04-17 12:01:54,026 - Pre-training finished...
2025-04-17 12:01:54,379 - Freeze all parameters but the last layer for efficiency
2025-04-17 12:01:54,389 - Multimodal Intent Recognition begins...
2025-04-17 12:01:54,389 - Training begins...
2025-04-17 12:02:10,074 - Initializing centroids with K-means++...
2025-04-17 12:02:10,158 - K-means++ used 0.08 s
2025-04-17 12:02:38,372 - K-means used 0.02 s
2025-04-17 12:02:39,423 - ***** Epoch: 1 *****
2025-04-17 12:02:39,424 - Supervised Training Loss: 4.388480
2025-04-17 12:02:39,424 - Unsupervised Training Loss: 5.531390
2025-04-17 12:03:08,464 - K-means used 0.02 s
2025-04-17 12:03:09,544 - ***** Epoch: 2 *****
2025-04-17 12:03:09,544 - Supervised Training Loss: 3.664560
2025-04-17 12:03:09,544 - Unsupervised Training Loss: 5.559770
2025-04-17 12:03:36,776 - K-means used 0.02 s
2025-04-17 12:03:37,880 - ***** Epoch: 3 *****
2025-04-17 12:03:37,881 - Supervised Training Loss: 4.806610
2025-04-17 12:03:37,881 - Unsupervised Training Loss: 5.421080
2025-04-17 12:04:06,372 - K-means used 0.03 s
2025-04-17 12:04:07,724 - ***** Epoch: 4 *****
2025-04-17 12:04:07,724 - Supervised Training Loss: 4.635480
2025-04-17 12:04:07,724 - Unsupervised Training Loss: 5.487580
2025-04-17 12:04:37,454 - K-means used 0.02 s
2025-04-17 12:04:38,579 - ***** Epoch: 5 *****
2025-04-17 12:04:38,580 - Supervised Training Loss: 4.323090
2025-04-17 12:04:38,580 - Unsupervised Training Loss: 5.529570
2025-04-17 12:05:10,649 - K-means used 0.02 s
2025-04-17 12:05:11,796 - ***** Epoch: 6 *****
2025-04-17 12:05:11,797 - Supervised Training Loss: 4.736740
2025-04-17 12:05:11,797 - Unsupervised Training Loss: 5.326600
2025-04-17 12:05:41,204 - K-means used 0.02 s
2025-04-17 12:05:42,469 - ***** Epoch: 7 *****
2025-04-17 12:05:42,469 - Supervised Training Loss: 4.630270
2025-04-17 12:05:42,470 - Unsupervised Training Loss: 5.447480
2025-04-17 12:06:11,611 - K-means used 0.02 s
2025-04-17 12:06:12,903 - ***** Epoch: 8 *****
2025-04-17 12:06:12,903 - Supervised Training Loss: 4.481310
2025-04-17 12:06:12,904 - Unsupervised Training Loss: 5.504610
2025-04-17 12:06:41,228 - K-means used 0.02 s
2025-04-17 12:06:42,492 - ***** Epoch: 9 *****
2025-04-17 12:06:42,492 - Supervised Training Loss: 4.704650
2025-04-17 12:06:42,493 - Unsupervised Training Loss: 5.545520
2025-04-17 12:07:12,558 - K-means used 0.02 s
2025-04-17 12:07:13,973 - ***** Epoch: 10 *****
2025-04-17 12:07:13,973 - Supervised Training Loss: 4.646610
2025-04-17 12:07:13,973 - Unsupervised Training Loss: 5.378070
2025-04-17 12:07:42,537 - K-means used 0.02 s
2025-04-17 12:07:43,924 - ***** Epoch: 11 *****
2025-04-17 12:07:43,924 - Supervised Training Loss: 4.557030
2025-04-17 12:07:43,924 - Unsupervised Training Loss: 5.466700
2025-04-17 12:08:12,804 - K-means used 0.02 s
2025-04-17 12:08:14,205 - ***** Epoch: 12 *****
2025-04-17 12:08:14,205 - Supervised Training Loss: 4.692050
2025-04-17 12:08:14,205 - Unsupervised Training Loss: 5.532200
2025-04-17 12:08:42,571 - K-means used 0.02 s
2025-04-17 12:08:44,102 - ***** Epoch: 13 *****
2025-04-17 12:08:44,103 - Supervised Training Loss: 4.660840
2025-04-17 12:08:44,103 - Unsupervised Training Loss: 5.265250
2025-04-17 12:09:11,496 - K-means used 0.01 s
2025-04-17 12:09:12,991 - ***** Epoch: 14 *****
2025-04-17 12:09:12,991 - Supervised Training Loss: 4.618020
2025-04-17 12:09:12,992 - Unsupervised Training Loss: 5.391510
2025-04-17 12:09:39,443 - K-means used 0.02 s
2025-04-17 12:09:41,200 - ***** Epoch: 15 *****
2025-04-17 12:09:41,201 - Supervised Training Loss: 4.462160
2025-04-17 12:09:41,201 - Unsupervised Training Loss: 5.495450
2025-04-17 12:10:08,578 - K-means used 0.02 s
2025-04-17 12:10:10,478 - ***** Epoch: 16 *****
2025-04-17 12:10:10,478 - Supervised Training Loss: 4.720010
2025-04-17 12:10:10,478 - Unsupervised Training Loss: 4.937030
2025-04-17 12:10:37,300 - K-means used 0.02 s
2025-04-17 12:10:39,123 - ***** Epoch: 17 *****
2025-04-17 12:10:39,123 - Supervised Training Loss: 4.699920
2025-04-17 12:10:39,124 - Unsupervised Training Loss: 5.174460
2025-04-17 12:10:58,325 - Training is finished...
2025-04-17 12:10:58,326 - Testing begins...
2025-04-17 12:11:04,502 - ***** Test results *****
2025-04-17 12:11:04,503 -   ACC = 41.35
2025-04-17 12:11:04,503 -   ARI = 20.62
2025-04-17 12:11:04,503 -   NMI = 46.89
2025-04-17 12:11:04,503 -   fmi = 25.56
2025-04-17 12:11:04,503 - Testing is finished...
2025-04-17 12:11:04,503 - Multimodal intent recognition is finished...
2025-04-17 12:11:04,503 - Results are saved in results/results_umc_pre.csv
2025-04-17 12:11:05,594 - Freeze all parameters but the last layer for efficiency
2025-04-17 12:11:05,634 - Pre-training start...
2025-04-17 12:11:06,491 - ***** Epoch: 1: Eval results *****
2025-04-17 12:11:06,491 -   train_loss = 5.696507930755615
2025-04-17 12:11:07,341 - ***** Epoch: 2: Eval results *****
2025-04-17 12:11:07,341 -   train_loss = 5.698419094085693
2025-04-17 12:11:08,162 - ***** Epoch: 3: Eval results *****
2025-04-17 12:11:08,162 -   train_loss = 5.710855484008789
2025-04-17 12:11:08,874 - ***** Epoch: 4: Eval results *****
2025-04-17 12:11:08,874 -   train_loss = 5.696438312530518
2025-04-17 12:11:09,739 - ***** Epoch: 5: Eval results *****
2025-04-17 12:11:09,739 -   train_loss = 5.694944858551025
2025-04-17 12:11:10,446 - ***** Epoch: 6: Eval results *****
2025-04-17 12:11:10,447 -   train_loss = 5.7081708908081055
2025-04-17 12:11:11,148 - ***** Epoch: 7: Eval results *****
2025-04-17 12:11:11,148 -   train_loss = 5.696908950805664
2025-04-17 12:11:12,053 - ***** Epoch: 8: Eval results *****
2025-04-17 12:11:12,053 -   train_loss = 5.705265522003174
2025-04-17 12:11:12,873 - ***** Epoch: 9: Eval results *****
2025-04-17 12:11:12,873 -   train_loss = 5.688032150268555
2025-04-17 12:11:13,738 - ***** Epoch: 10: Eval results *****
2025-04-17 12:11:13,738 -   train_loss = 5.69288444519043
2025-04-17 12:11:14,529 - ***** Epoch: 11: Eval results *****
2025-04-17 12:11:14,529 -   train_loss = 5.689913272857666
2025-04-17 12:11:15,384 - ***** Epoch: 12: Eval results *****
2025-04-17 12:11:15,384 -   train_loss = 5.6960296630859375
2025-04-17 12:11:16,204 - ***** Epoch: 13: Eval results *****
2025-04-17 12:11:16,204 -   train_loss = 5.690990447998047
2025-04-17 12:11:17,039 - ***** Epoch: 14: Eval results *****
2025-04-17 12:11:17,039 -   train_loss = 5.685594081878662
2025-04-17 12:11:17,851 - ***** Epoch: 15: Eval results *****
2025-04-17 12:11:17,851 -   train_loss = 5.684240818023682
2025-04-17 12:11:18,554 - ***** Epoch: 16: Eval results *****
2025-04-17 12:11:18,555 -   train_loss = 5.688841819763184
2025-04-17 12:11:19,389 - ***** Epoch: 17: Eval results *****
2025-04-17 12:11:19,389 -   train_loss = 5.694008827209473
2025-04-17 12:11:20,258 - ***** Epoch: 18: Eval results *****
2025-04-17 12:11:20,259 -   train_loss = 5.671796798706055
2025-04-17 12:11:21,070 - ***** Epoch: 19: Eval results *****
2025-04-17 12:11:21,070 -   train_loss = 5.68233585357666
2025-04-17 12:11:21,922 - ***** Epoch: 20: Eval results *****
2025-04-17 12:11:21,923 -   train_loss = 5.696654319763184
2025-04-17 12:11:22,736 - ***** Epoch: 21: Eval results *****
2025-04-17 12:11:22,736 -   train_loss = 5.68079137802124
2025-04-17 12:11:23,432 - ***** Epoch: 22: Eval results *****
2025-04-17 12:11:23,432 -   train_loss = 5.6797194480896
2025-04-17 12:11:24,123 - ***** Epoch: 23: Eval results *****
2025-04-17 12:11:24,123 -   train_loss = 5.682372570037842
2025-04-17 12:11:24,826 - ***** Epoch: 24: Eval results *****
2025-04-17 12:11:24,827 -   train_loss = 5.66462516784668
2025-04-17 12:11:25,636 - ***** Epoch: 25: Eval results *****
2025-04-17 12:11:25,636 -   train_loss = 5.682086944580078
2025-04-17 12:11:26,329 - ***** Epoch: 26: Eval results *****
2025-04-17 12:11:26,330 -   train_loss = 5.685041427612305
2025-04-17 12:11:27,034 - ***** Epoch: 27: Eval results *****
2025-04-17 12:11:27,035 -   train_loss = 5.668265342712402
2025-04-17 12:11:27,897 - ***** Epoch: 28: Eval results *****
2025-04-17 12:11:27,898 -   train_loss = 5.68411111831665
2025-04-17 12:11:28,739 - ***** Epoch: 29: Eval results *****
2025-04-17 12:11:28,739 -   train_loss = 5.669480800628662
2025-04-17 12:11:29,559 - ***** Epoch: 30: Eval results *****
2025-04-17 12:11:29,559 -   train_loss = 5.665622711181641
2025-04-17 12:11:30,400 - ***** Epoch: 31: Eval results *****
2025-04-17 12:11:30,400 -   train_loss = 5.669809341430664
2025-04-17 12:11:31,220 - ***** Epoch: 32: Eval results *****
2025-04-17 12:11:31,220 -   train_loss = 5.649714946746826
2025-04-17 12:11:32,084 - ***** Epoch: 33: Eval results *****
2025-04-17 12:11:32,084 -   train_loss = 5.651863098144531
2025-04-17 12:11:32,877 - ***** Epoch: 34: Eval results *****
2025-04-17 12:11:32,877 -   train_loss = 5.63922119140625
2025-04-17 12:11:33,584 - ***** Epoch: 35: Eval results *****
2025-04-17 12:11:33,584 -   train_loss = 5.6557536125183105
2025-04-17 12:11:34,284 - ***** Epoch: 36: Eval results *****
2025-04-17 12:11:34,285 -   train_loss = 5.6429548263549805
2025-04-17 12:11:34,978 - ***** Epoch: 37: Eval results *****
2025-04-17 12:11:34,979 -   train_loss = 5.655308723449707
2025-04-17 12:11:35,840 - ***** Epoch: 38: Eval results *****
2025-04-17 12:11:35,841 -   train_loss = 5.651899337768555
2025-04-17 12:11:36,656 - ***** Epoch: 39: Eval results *****
2025-04-17 12:11:36,656 -   train_loss = 5.6284589767456055
2025-04-17 12:11:37,477 - ***** Epoch: 40: Eval results *****
2025-04-17 12:11:37,477 -   train_loss = 5.63465690612793
2025-04-17 12:11:38,325 - ***** Epoch: 41: Eval results *****
2025-04-17 12:11:38,326 -   train_loss = 5.641138076782227
2025-04-17 12:11:39,227 - ***** Epoch: 42: Eval results *****
2025-04-17 12:11:39,227 -   train_loss = 5.639760971069336
2025-04-17 12:11:40,020 - ***** Epoch: 43: Eval results *****
2025-04-17 12:11:40,020 -   train_loss = 5.625327110290527
2025-04-17 12:11:40,710 - ***** Epoch: 44: Eval results *****
2025-04-17 12:11:40,710 -   train_loss = 5.619540214538574
2025-04-17 12:11:41,562 - ***** Epoch: 45: Eval results *****
2025-04-17 12:11:41,562 -   train_loss = 5.6255598068237305
2025-04-17 12:11:42,385 - ***** Epoch: 46: Eval results *****
2025-04-17 12:11:42,385 -   train_loss = 5.604249000549316
2025-04-17 12:11:43,206 - ***** Epoch: 47: Eval results *****
2025-04-17 12:11:43,206 -   train_loss = 5.619410991668701
2025-04-17 12:11:44,033 - ***** Epoch: 48: Eval results *****
2025-04-17 12:11:44,033 -   train_loss = 5.598379611968994
2025-04-17 12:11:44,941 - ***** Epoch: 49: Eval results *****
2025-04-17 12:11:44,941 -   train_loss = 5.608029365539551
2025-04-17 12:11:45,764 - ***** Epoch: 50: Eval results *****
2025-04-17 12:11:45,764 -   train_loss = 5.604520320892334
2025-04-17 12:11:46,566 - ***** Epoch: 51: Eval results *****
2025-04-17 12:11:46,566 -   train_loss = 5.601308345794678
2025-04-17 12:11:47,270 - ***** Epoch: 52: Eval results *****
2025-04-17 12:11:47,271 -   train_loss = 5.570090293884277
2025-04-17 12:11:48,146 - ***** Epoch: 53: Eval results *****
2025-04-17 12:11:48,147 -   train_loss = 5.571793079376221
2025-04-17 12:11:48,982 - ***** Epoch: 54: Eval results *****
2025-04-17 12:11:48,982 -   train_loss = 5.552858829498291
2025-04-17 12:11:49,815 - ***** Epoch: 55: Eval results *****
2025-04-17 12:11:49,816 -   train_loss = 5.560746192932129
2025-04-17 12:11:50,623 - ***** Epoch: 56: Eval results *****
2025-04-17 12:11:50,623 -   train_loss = 5.548285961151123
2025-04-17 12:11:51,314 - ***** Epoch: 57: Eval results *****
2025-04-17 12:11:51,314 -   train_loss = 5.541900157928467
2025-04-17 12:11:52,007 - ***** Epoch: 58: Eval results *****
2025-04-17 12:11:52,007 -   train_loss = 5.557581424713135
2025-04-17 12:11:52,695 - ***** Epoch: 59: Eval results *****
2025-04-17 12:11:52,695 -   train_loss = 5.5103559494018555
2025-04-17 12:11:53,577 - ***** Epoch: 60: Eval results *****
2025-04-17 12:11:53,577 -   train_loss = 5.525322437286377
2025-04-17 12:11:54,382 - ***** Epoch: 61: Eval results *****
2025-04-17 12:11:54,382 -   train_loss = 5.523665904998779
2025-04-17 12:11:55,249 - ***** Epoch: 62: Eval results *****
2025-04-17 12:11:55,250 -   train_loss = 5.49614143371582
2025-04-17 12:11:56,078 - ***** Epoch: 63: Eval results *****
2025-04-17 12:11:56,078 -   train_loss = 5.4972639083862305
2025-04-17 12:11:56,913 - ***** Epoch: 64: Eval results *****
2025-04-17 12:11:56,914 -   train_loss = 5.447319507598877
2025-04-17 12:11:57,721 - ***** Epoch: 65: Eval results *****
2025-04-17 12:11:57,721 -   train_loss = 5.457533836364746
2025-04-17 12:11:58,601 - ***** Epoch: 66: Eval results *****
2025-04-17 12:11:58,601 -   train_loss = 5.460772514343262
2025-04-17 12:11:59,421 - ***** Epoch: 67: Eval results *****
2025-04-17 12:11:59,421 -   train_loss = 5.439506530761719
2025-04-17 12:12:00,229 - ***** Epoch: 68: Eval results *****
2025-04-17 12:12:00,229 -   train_loss = 5.419358730316162
2025-04-17 12:12:00,920 - ***** Epoch: 69: Eval results *****
2025-04-17 12:12:00,921 -   train_loss = 5.412004470825195
2025-04-17 12:12:01,621 - ***** Epoch: 70: Eval results *****
2025-04-17 12:12:01,621 -   train_loss = 5.393576622009277
2025-04-17 12:12:02,340 - ***** Epoch: 71: Eval results *****
2025-04-17 12:12:02,340 -   train_loss = 5.3926682472229
2025-04-17 12:12:03,038 - ***** Epoch: 72: Eval results *****
2025-04-17 12:12:03,038 -   train_loss = 5.354067325592041
2025-04-17 12:12:03,909 - ***** Epoch: 73: Eval results *****
2025-04-17 12:12:03,910 -   train_loss = 5.343283176422119
2025-04-17 12:12:04,737 - ***** Epoch: 74: Eval results *****
2025-04-17 12:12:04,738 -   train_loss = 5.336525917053223
2025-04-17 12:12:05,564 - ***** Epoch: 75: Eval results *****
2025-04-17 12:12:05,564 -   train_loss = 5.331971645355225
2025-04-17 12:12:06,394 - ***** Epoch: 76: Eval results *****
2025-04-17 12:12:06,394 -   train_loss = 5.307300567626953
2025-04-17 12:12:07,229 - ***** Epoch: 77: Eval results *****
2025-04-17 12:12:07,229 -   train_loss = 5.274288177490234
2025-04-17 12:12:08,044 - ***** Epoch: 78: Eval results *****
2025-04-17 12:12:08,044 -   train_loss = 5.303343296051025
2025-04-17 12:12:08,752 - ***** Epoch: 79: Eval results *****
2025-04-17 12:12:08,753 -   train_loss = 5.2625732421875
2025-04-17 12:12:09,459 - ***** Epoch: 80: Eval results *****
2025-04-17 12:12:09,459 -   train_loss = 5.267982482910156
2025-04-17 12:12:10,339 - ***** Epoch: 81: Eval results *****
2025-04-17 12:12:10,339 -   train_loss = 5.239201068878174
2025-04-17 12:12:11,172 - ***** Epoch: 82: Eval results *****
2025-04-17 12:12:11,173 -   train_loss = 5.218841552734375
2025-04-17 12:12:12,001 - ***** Epoch: 83: Eval results *****
2025-04-17 12:12:12,002 -   train_loss = 5.181854248046875
2025-04-17 12:12:12,844 - ***** Epoch: 84: Eval results *****
2025-04-17 12:12:12,845 -   train_loss = 5.212579727172852
2025-04-17 12:12:13,690 - ***** Epoch: 85: Eval results *****
2025-04-17 12:12:13,690 -   train_loss = 5.152875900268555
2025-04-17 12:12:14,529 - ***** Epoch: 86: Eval results *****
2025-04-17 12:12:14,530 -   train_loss = 5.153646945953369
2025-04-17 12:12:15,361 - ***** Epoch: 87: Eval results *****
2025-04-17 12:12:15,361 -   train_loss = 5.196826934814453
2025-04-17 12:12:16,167 - ***** Epoch: 88: Eval results *****
2025-04-17 12:12:16,167 -   train_loss = 5.141531467437744
2025-04-17 12:12:16,893 - ***** Epoch: 89: Eval results *****
2025-04-17 12:12:16,894 -   train_loss = 5.1095685958862305
2025-04-17 12:12:17,749 - ***** Epoch: 90: Eval results *****
2025-04-17 12:12:17,750 -   train_loss = 5.102705001831055
2025-04-17 12:12:18,586 - ***** Epoch: 91: Eval results *****
2025-04-17 12:12:18,587 -   train_loss = 5.095829963684082
2025-04-17 12:12:19,458 - ***** Epoch: 92: Eval results *****
2025-04-17 12:12:19,458 -   train_loss = 5.059642791748047
2025-04-17 12:12:20,299 - ***** Epoch: 93: Eval results *****
2025-04-17 12:12:20,299 -   train_loss = 5.059573650360107
2025-04-17 12:12:21,132 - ***** Epoch: 94: Eval results *****
2025-04-17 12:12:21,132 -   train_loss = 5.009907245635986
2025-04-17 12:12:21,858 - ***** Epoch: 95: Eval results *****
2025-04-17 12:12:21,858 -   train_loss = 5.039392948150635
2025-04-17 12:12:22,726 - ***** Epoch: 96: Eval results *****
2025-04-17 12:12:22,726 -   train_loss = 4.997632026672363
2025-04-17 12:12:23,525 - ***** Epoch: 97: Eval results *****
2025-04-17 12:12:23,525 -   train_loss = 5.004745960235596
2025-04-17 12:12:24,229 - ***** Epoch: 98: Eval results *****
2025-04-17 12:12:24,229 -   train_loss = 4.960608959197998
2025-04-17 12:12:24,919 - ***** Epoch: 99: Eval results *****
2025-04-17 12:12:24,920 -   train_loss = 4.946610450744629
2025-04-17 12:12:25,619 - ***** Epoch: 100: Eval results *****
2025-04-17 12:12:25,619 -   train_loss = 4.943235874176025
2025-04-17 12:12:27,224 - Pre-training finished...
2025-04-17 12:12:27,418 - Freeze all parameters but the last layer for efficiency
2025-04-17 12:12:27,428 - Multimodal Intent Recognition begins...
2025-04-17 12:12:27,428 - Training begins...
2025-04-17 12:12:38,291 - Initializing centroids with K-means++...
2025-04-17 12:12:38,344 - K-means++ used 0.05 s
2025-04-17 12:13:09,991 - K-means used 0.02 s
2025-04-17 12:13:11,078 - ***** Epoch: 1 *****
2025-04-17 12:13:11,078 - Supervised Training Loss: 5.224690
2025-04-17 12:13:11,078 - Unsupervised Training Loss: 5.836460
2025-04-17 12:13:42,820 - K-means used 0.03 s
2025-04-17 12:13:44,063 - ***** Epoch: 2 *****
2025-04-17 12:13:44,063 - Supervised Training Loss: 4.243590
2025-04-17 12:13:44,063 - Unsupervised Training Loss: 5.827910
2025-04-17 12:14:14,869 - K-means used 0.03 s
2025-04-17 12:14:16,164 - ***** Epoch: 3 *****
2025-04-17 12:14:16,165 - Supervised Training Loss: 5.404220
2025-04-17 12:14:16,165 - Unsupervised Training Loss: 5.618680
2025-04-17 12:14:43,078 - K-means used 0.02 s
2025-04-17 12:14:44,436 - ***** Epoch: 4 *****
2025-04-17 12:14:44,436 - Supervised Training Loss: 5.012500
2025-04-17 12:14:44,437 - Unsupervised Training Loss: 5.616880
2025-04-17 12:15:12,550 - K-means used 0.03 s
2025-04-17 12:15:13,902 - ***** Epoch: 5 *****
2025-04-17 12:15:13,903 - Supervised Training Loss: 4.627330
2025-04-17 12:15:13,903 - Unsupervised Training Loss: 5.612750
2025-04-17 12:15:41,716 - K-means used 0.04 s
2025-04-17 12:15:43,019 - ***** Epoch: 6 *****
2025-04-17 12:15:43,020 - Supervised Training Loss: 4.930910
2025-04-17 12:15:43,020 - Unsupervised Training Loss: 5.387620
2025-04-17 12:16:10,458 - K-means used 0.02 s
2025-04-17 12:16:11,775 - ***** Epoch: 7 *****
2025-04-17 12:16:11,775 - Supervised Training Loss: 4.801940
2025-04-17 12:16:11,775 - Unsupervised Training Loss: 5.500320
2025-04-17 12:16:39,156 - K-means used 0.02 s
2025-04-17 12:16:40,517 - ***** Epoch: 8 *****
2025-04-17 12:16:40,517 - Supervised Training Loss: 4.637280
2025-04-17 12:16:40,517 - Unsupervised Training Loss: 5.549320
2025-04-17 12:17:08,082 - K-means used 0.02 s
2025-04-17 12:17:09,649 - ***** Epoch: 9 *****
2025-04-17 12:17:09,650 - Supervised Training Loss: 4.861120
2025-04-17 12:17:09,650 - Unsupervised Training Loss: 5.586010
2025-04-17 12:17:41,078 - K-means used 0.02 s
2025-04-17 12:17:42,626 - ***** Epoch: 10 *****
2025-04-17 12:17:42,626 - Supervised Training Loss: 4.777980
2025-04-17 12:17:42,626 - Unsupervised Training Loss: 5.430120
2025-04-17 12:18:10,073 - K-means used 0.02 s
2025-04-17 12:18:11,660 - ***** Epoch: 11 *****
2025-04-17 12:18:11,661 - Supervised Training Loss: 4.685130
2025-04-17 12:18:11,661 - Unsupervised Training Loss: 5.498500
2025-04-17 12:18:40,476 - K-means used 0.02 s
2025-04-17 12:18:42,407 - ***** Epoch: 12 *****
2025-04-17 12:18:42,407 - Supervised Training Loss: 4.819510
2025-04-17 12:18:42,407 - Unsupervised Training Loss: 5.567830
2025-04-17 12:19:15,115 - K-means used 0.02 s
2025-04-17 12:19:17,067 - ***** Epoch: 13 *****
2025-04-17 12:19:17,067 - Supervised Training Loss: 4.776680
2025-04-17 12:19:17,068 - Unsupervised Training Loss: 5.293660
2025-04-17 12:19:47,111 - K-means used 0.02 s
2025-04-17 12:19:49,067 - ***** Epoch: 14 *****
2025-04-17 12:19:49,068 - Supervised Training Loss: 4.713410
2025-04-17 12:19:49,068 - Unsupervised Training Loss: 5.426340
2025-04-17 12:20:18,491 - K-means used 0.02 s
2025-04-17 12:20:20,552 - ***** Epoch: 15 *****
2025-04-17 12:20:20,552 - Supervised Training Loss: 4.568670
2025-04-17 12:20:20,552 - Unsupervised Training Loss: 5.526400
2025-04-17 12:20:48,115 - K-means used 0.02 s
2025-04-17 12:20:50,100 - ***** Epoch: 16 *****
2025-04-17 12:20:50,100 - Supervised Training Loss: 4.793350
2025-04-17 12:20:50,100 - Unsupervised Training Loss: 4.977750
2025-04-17 12:21:17,719 - K-means used 0.02 s
2025-04-17 12:21:19,733 - ***** Epoch: 17 *****
2025-04-17 12:21:19,733 - Supervised Training Loss: 4.769420
2025-04-17 12:21:19,733 - Unsupervised Training Loss: 5.193270
2025-04-17 12:21:38,533 - Training is finished...
2025-04-17 12:21:38,533 - Testing begins...
2025-04-17 12:21:44,789 - ***** Test results *****
2025-04-17 12:21:44,789 -   ACC = 24.72
2025-04-17 12:21:44,789 -   ARI = 8.2
2025-04-17 12:21:44,789 -   NMI = 30.92
2025-04-17 12:21:44,789 -   fmi = 14.1
2025-04-17 12:21:44,789 - Testing is finished...
2025-04-17 12:21:44,789 - Multimodal intent recognition is finished...
2025-04-17 12:21:44,789 - Results are saved in results/results_umc_pre.csv
2025-04-17 12:21:45,860 - Freeze all parameters but the last layer for efficiency
2025-04-17 12:21:45,900 - Pre-training start...
2025-04-17 12:21:46,741 - ***** Epoch: 1: Eval results *****
2025-04-17 12:21:46,741 -   train_loss = 5.68843936920166
2025-04-17 12:21:47,575 - ***** Epoch: 2: Eval results *****
2025-04-17 12:21:47,575 -   train_loss = 5.678064346313477
2025-04-17 12:21:48,400 - ***** Epoch: 3: Eval results *****
2025-04-17 12:21:48,401 -   train_loss = 5.687437534332275
2025-04-17 12:21:49,229 - ***** Epoch: 4: Eval results *****
2025-04-17 12:21:49,229 -   train_loss = 5.681346416473389
2025-04-17 12:21:50,063 - ***** Epoch: 5: Eval results *****
2025-04-17 12:21:50,063 -   train_loss = 5.682714462280273
2025-04-17 12:21:50,913 - ***** Epoch: 6: Eval results *****
2025-04-17 12:21:50,913 -   train_loss = 5.686593055725098
2025-04-17 12:21:51,745 - ***** Epoch: 7: Eval results *****
2025-04-17 12:21:51,746 -   train_loss = 5.6737380027771
2025-04-17 12:21:52,577 - ***** Epoch: 8: Eval results *****
2025-04-17 12:21:52,578 -   train_loss = 5.68549919128418
2025-04-17 12:21:53,398 - ***** Epoch: 9: Eval results *****
2025-04-17 12:21:53,398 -   train_loss = 5.679826736450195
2025-04-17 12:21:54,218 - ***** Epoch: 10: Eval results *****
2025-04-17 12:21:54,218 -   train_loss = 5.678646087646484
2025-04-17 12:21:55,058 - ***** Epoch: 11: Eval results *****
2025-04-17 12:21:55,058 -   train_loss = 5.673110008239746
2025-04-17 12:21:55,877 - ***** Epoch: 12: Eval results *****
2025-04-17 12:21:55,877 -   train_loss = 5.687910079956055
2025-04-17 12:21:56,680 - ***** Epoch: 13: Eval results *****
2025-04-17 12:21:56,681 -   train_loss = 5.682312965393066
2025-04-17 12:21:57,371 - ***** Epoch: 14: Eval results *****
2025-04-17 12:21:57,371 -   train_loss = 5.679586887359619
2025-04-17 12:21:58,086 - ***** Epoch: 15: Eval results *****
2025-04-17 12:21:58,086 -   train_loss = 5.681197643280029
2025-04-17 12:21:58,921 - ***** Epoch: 16: Eval results *****
2025-04-17 12:21:58,922 -   train_loss = 5.676245212554932
2025-04-17 12:21:59,740 - ***** Epoch: 17: Eval results *****
2025-04-17 12:21:59,740 -   train_loss = 5.6735615730285645
2025-04-17 12:22:00,564 - ***** Epoch: 18: Eval results *****
2025-04-17 12:22:00,564 -   train_loss = 5.681975841522217
2025-04-17 12:22:01,376 - ***** Epoch: 19: Eval results *****
2025-04-17 12:22:01,377 -   train_loss = 5.673614025115967
2025-04-17 12:22:02,067 - ***** Epoch: 20: Eval results *****
2025-04-17 12:22:02,068 -   train_loss = 5.679065704345703
2025-04-17 12:22:02,756 - ***** Epoch: 21: Eval results *****
2025-04-17 12:22:02,756 -   train_loss = 5.672189712524414
2025-04-17 12:22:03,448 - ***** Epoch: 22: Eval results *****
2025-04-17 12:22:03,448 -   train_loss = 5.679236888885498
2025-04-17 12:22:04,149 - ***** Epoch: 23: Eval results *****
2025-04-17 12:22:04,150 -   train_loss = 5.677225589752197
2025-04-17 12:22:04,857 - ***** Epoch: 24: Eval results *****
2025-04-17 12:22:04,857 -   train_loss = 5.668216705322266
2025-04-17 12:22:05,601 - ***** Epoch: 25: Eval results *****
2025-04-17 12:22:05,602 -   train_loss = 5.668820858001709
2025-04-17 12:22:06,294 - ***** Epoch: 26: Eval results *****
2025-04-17 12:22:06,294 -   train_loss = 5.666215896606445
2025-04-17 12:22:07,133 - ***** Epoch: 27: Eval results *****
2025-04-17 12:22:07,134 -   train_loss = 5.660556316375732
2025-04-17 12:22:07,827 - ***** Epoch: 28: Eval results *****
2025-04-17 12:22:07,827 -   train_loss = 5.655025005340576
2025-04-17 12:22:08,505 - ***** Epoch: 29: Eval results *****
2025-04-17 12:22:08,506 -   train_loss = 5.65897798538208
2025-04-17 12:22:09,359 - ***** Epoch: 30: Eval results *****
2025-04-17 12:22:09,359 -   train_loss = 5.656607627868652
2025-04-17 12:22:10,177 - ***** Epoch: 31: Eval results *****
2025-04-17 12:22:10,177 -   train_loss = 5.648708820343018
2025-04-17 12:22:11,006 - ***** Epoch: 32: Eval results *****
2025-04-17 12:22:11,007 -   train_loss = 5.659979820251465
2025-04-17 12:22:11,845 - ***** Epoch: 33: Eval results *****
2025-04-17 12:22:11,845 -   train_loss = 5.650036334991455
2025-04-17 12:22:12,682 - ***** Epoch: 34: Eval results *****
2025-04-17 12:22:12,682 -   train_loss = 5.65492057800293
2025-04-17 12:22:13,514 - ***** Epoch: 35: Eval results *****
2025-04-17 12:22:13,515 -   train_loss = 5.648324489593506
2025-04-17 12:22:14,342 - ***** Epoch: 36: Eval results *****
2025-04-17 12:22:14,343 -   train_loss = 5.64872407913208
2025-04-17 12:22:15,165 - ***** Epoch: 37: Eval results *****
2025-04-17 12:22:15,165 -   train_loss = 5.649906158447266
2025-04-17 12:22:15,968 - ***** Epoch: 38: Eval results *****
2025-04-17 12:22:15,969 -   train_loss = 5.642889976501465
2025-04-17 12:22:16,678 - ***** Epoch: 39: Eval results *****
2025-04-17 12:22:16,679 -   train_loss = 5.6430745124816895
2025-04-17 12:22:17,386 - ***** Epoch: 40: Eval results *****
2025-04-17 12:22:17,387 -   train_loss = 5.633570194244385
2025-04-17 12:22:18,110 - ***** Epoch: 41: Eval results *****
2025-04-17 12:22:18,110 -   train_loss = 5.636049270629883
2025-04-17 12:22:18,846 - ***** Epoch: 42: Eval results *****
2025-04-17 12:22:18,846 -   train_loss = 5.632550239562988
2025-04-17 12:22:19,730 - ***** Epoch: 43: Eval results *****
2025-04-17 12:22:19,731 -   train_loss = 5.624067306518555
2025-04-17 12:22:20,554 - ***** Epoch: 44: Eval results *****
2025-04-17 12:22:20,555 -   train_loss = 5.625374794006348
2025-04-17 12:22:21,261 - ***** Epoch: 45: Eval results *****
2025-04-17 12:22:21,262 -   train_loss = 5.6264495849609375
2025-04-17 12:22:21,967 - ***** Epoch: 46: Eval results *****
2025-04-17 12:22:21,967 -   train_loss = 5.623356819152832
2025-04-17 12:22:22,665 - ***** Epoch: 47: Eval results *****
2025-04-17 12:22:22,665 -   train_loss = 5.603599548339844
2025-04-17 12:22:23,372 - ***** Epoch: 48: Eval results *****
2025-04-17 12:22:23,373 -   train_loss = 5.61464262008667
2025-04-17 12:22:24,250 - ***** Epoch: 49: Eval results *****
2025-04-17 12:22:24,250 -   train_loss = 5.598910331726074
2025-04-17 12:22:25,044 - ***** Epoch: 50: Eval results *****
2025-04-17 12:22:25,044 -   train_loss = 5.607993125915527
2025-04-17 12:22:25,869 - ***** Epoch: 51: Eval results *****
2025-04-17 12:22:25,869 -   train_loss = 5.598948955535889
2025-04-17 12:22:26,700 - ***** Epoch: 52: Eval results *****
2025-04-17 12:22:26,700 -   train_loss = 5.606263637542725
2025-04-17 12:22:27,539 - ***** Epoch: 53: Eval results *****
2025-04-17 12:22:27,540 -   train_loss = 5.572929859161377
2025-04-17 12:22:28,365 - ***** Epoch: 54: Eval results *****
2025-04-17 12:22:28,366 -   train_loss = 5.58926248550415
2025-04-17 12:22:29,185 - ***** Epoch: 55: Eval results *****
2025-04-17 12:22:29,186 -   train_loss = 5.582170009613037
2025-04-17 12:22:29,990 - ***** Epoch: 56: Eval results *****
2025-04-17 12:22:29,990 -   train_loss = 5.561415672302246
2025-04-17 12:22:30,836 - ***** Epoch: 57: Eval results *****
2025-04-17 12:22:30,836 -   train_loss = 5.55824613571167
2025-04-17 12:22:31,653 - ***** Epoch: 58: Eval results *****
2025-04-17 12:22:31,653 -   train_loss = 5.561110019683838
2025-04-17 12:22:32,493 - ***** Epoch: 59: Eval results *****
2025-04-17 12:22:32,493 -   train_loss = 5.542088031768799
2025-04-17 12:22:33,347 - ***** Epoch: 60: Eval results *****
2025-04-17 12:22:33,347 -   train_loss = 5.541555404663086
2025-04-17 12:22:34,209 - ***** Epoch: 61: Eval results *****
2025-04-17 12:22:34,209 -   train_loss = 5.545750141143799
2025-04-17 12:22:35,041 - ***** Epoch: 62: Eval results *****
2025-04-17 12:22:35,041 -   train_loss = 5.512431621551514
2025-04-17 12:22:35,858 - ***** Epoch: 63: Eval results *****
2025-04-17 12:22:35,858 -   train_loss = 5.520529270172119
2025-04-17 12:22:36,729 - ***** Epoch: 64: Eval results *****
2025-04-17 12:22:36,729 -   train_loss = 5.5147294998168945
2025-04-17 12:22:37,553 - ***** Epoch: 65: Eval results *****
2025-04-17 12:22:37,554 -   train_loss = 5.498492240905762
2025-04-17 12:22:38,380 - ***** Epoch: 66: Eval results *****
2025-04-17 12:22:38,380 -   train_loss = 5.5041656494140625
2025-04-17 12:22:39,084 - ***** Epoch: 67: Eval results *****
2025-04-17 12:22:39,084 -   train_loss = 5.482088088989258
2025-04-17 12:22:39,793 - ***** Epoch: 68: Eval results *****
2025-04-17 12:22:39,793 -   train_loss = 5.48715877532959
2025-04-17 12:22:40,634 - ***** Epoch: 69: Eval results *****
2025-04-17 12:22:40,634 -   train_loss = 5.462331295013428
2025-04-17 12:22:41,474 - ***** Epoch: 70: Eval results *****
2025-04-17 12:22:41,474 -   train_loss = 5.446894645690918
2025-04-17 12:22:42,366 - ***** Epoch: 71: Eval results *****
2025-04-17 12:22:42,367 -   train_loss = 5.462691783905029
2025-04-17 12:22:43,197 - ***** Epoch: 72: Eval results *****
2025-04-17 12:22:43,197 -   train_loss = 5.439791679382324
2025-04-17 12:22:44,033 - ***** Epoch: 73: Eval results *****
2025-04-17 12:22:44,033 -   train_loss = 5.424998760223389
2025-04-17 12:22:44,892 - ***** Epoch: 74: Eval results *****
2025-04-17 12:22:44,892 -   train_loss = 5.431346416473389
2025-04-17 12:22:45,589 - ***** Epoch: 75: Eval results *****
2025-04-17 12:22:45,589 -   train_loss = 5.404333591461182
2025-04-17 12:22:46,450 - ***** Epoch: 76: Eval results *****
2025-04-17 12:22:46,450 -   train_loss = 5.408553123474121
2025-04-17 12:22:47,278 - ***** Epoch: 77: Eval results *****
2025-04-17 12:22:47,279 -   train_loss = 5.3914690017700195
2025-04-17 12:22:48,119 - ***** Epoch: 78: Eval results *****
2025-04-17 12:22:48,119 -   train_loss = 5.380039691925049
2025-04-17 12:22:48,927 - ***** Epoch: 79: Eval results *****
2025-04-17 12:22:48,927 -   train_loss = 5.3516364097595215
2025-04-17 12:22:49,761 - ***** Epoch: 80: Eval results *****
2025-04-17 12:22:49,762 -   train_loss = 5.375464916229248
2025-04-17 12:22:50,568 - ***** Epoch: 81: Eval results *****
2025-04-17 12:22:50,568 -   train_loss = 5.363487243652344
2025-04-17 12:22:51,296 - ***** Epoch: 82: Eval results *****
2025-04-17 12:22:51,297 -   train_loss = 5.337900161743164
2025-04-17 12:22:52,145 - ***** Epoch: 83: Eval results *****
2025-04-17 12:22:52,145 -   train_loss = 5.330726146697998
2025-04-17 12:22:52,975 - ***** Epoch: 84: Eval results *****
2025-04-17 12:22:52,975 -   train_loss = 5.340025901794434
2025-04-17 12:22:53,789 - ***** Epoch: 85: Eval results *****
2025-04-17 12:22:53,789 -   train_loss = 5.318681716918945
2025-04-17 12:22:54,511 - ***** Epoch: 86: Eval results *****
2025-04-17 12:22:54,512 -   train_loss = 5.314453125
2025-04-17 12:22:55,274 - ***** Epoch: 87: Eval results *****
2025-04-17 12:22:55,275 -   train_loss = 5.308139801025391
2025-04-17 12:22:55,965 - ***** Epoch: 88: Eval results *****
2025-04-17 12:22:55,965 -   train_loss = 5.29318904876709
2025-04-17 12:22:56,709 - ***** Epoch: 89: Eval results *****
2025-04-17 12:22:56,709 -   train_loss = 5.294720649719238
2025-04-17 12:22:57,535 - ***** Epoch: 90: Eval results *****
2025-04-17 12:22:57,535 -   train_loss = 5.272887229919434
2025-04-17 12:22:58,425 - ***** Epoch: 91: Eval results *****
2025-04-17 12:22:58,425 -   train_loss = 5.285252094268799
2025-04-17 12:22:59,238 - ***** Epoch: 92: Eval results *****
2025-04-17 12:22:59,238 -   train_loss = 5.2837724685668945
2025-04-17 12:22:59,937 - ***** Epoch: 93: Eval results *****
2025-04-17 12:22:59,937 -   train_loss = 5.231709957122803
2025-04-17 12:23:00,782 - ***** Epoch: 94: Eval results *****
2025-04-17 12:23:00,782 -   train_loss = 5.235637664794922
2025-04-17 12:23:01,650 - ***** Epoch: 95: Eval results *****
2025-04-17 12:23:01,650 -   train_loss = 5.2103166580200195
2025-04-17 12:23:02,468 - ***** Epoch: 96: Eval results *****
2025-04-17 12:23:02,469 -   train_loss = 5.229215145111084
2025-04-17 12:23:03,293 - ***** Epoch: 97: Eval results *****
2025-04-17 12:23:03,293 -   train_loss = 5.210947036743164
2025-04-17 12:23:04,130 - ***** Epoch: 98: Eval results *****
2025-04-17 12:23:04,131 -   train_loss = 5.19492769241333
2025-04-17 12:23:04,930 - ***** Epoch: 99: Eval results *****
2025-04-17 12:23:04,931 -   train_loss = 5.2139668464660645
2025-04-17 12:23:05,738 - ***** Epoch: 100: Eval results *****
2025-04-17 12:23:05,739 -   train_loss = 5.159355640411377
2025-04-17 12:23:07,297 - Pre-training finished...
2025-04-17 12:23:07,491 - Freeze all parameters but the last layer for efficiency
2025-04-17 12:23:07,501 - Multimodal Intent Recognition begins...
2025-04-17 12:23:07,501 - Training begins...
2025-04-17 12:23:17,658 - Initializing centroids with K-means++...
2025-04-17 12:23:17,713 - K-means++ used 0.05 s
2025-04-17 12:23:47,827 - K-means used 0.04 s
2025-04-17 12:23:48,890 - ***** Epoch: 1 *****
2025-04-17 12:23:48,891 - Supervised Training Loss: 5.383460
2025-04-17 12:23:48,891 - Unsupervised Training Loss: 5.808860
2025-04-17 12:24:16,702 - K-means used 0.02 s
2025-04-17 12:24:17,805 - ***** Epoch: 2 *****
2025-04-17 12:24:17,805 - Supervised Training Loss: 4.036610
2025-04-17 12:24:17,805 - Unsupervised Training Loss: 5.803370
2025-04-17 12:24:45,516 - K-means used 0.03 s
2025-04-17 12:24:46,711 - ***** Epoch: 3 *****
2025-04-17 12:24:46,711 - Supervised Training Loss: 5.265420
2025-04-17 12:24:46,711 - Unsupervised Training Loss: 5.570150
2025-04-17 12:25:13,561 - K-means used 0.03 s
2025-04-17 12:25:14,759 - ***** Epoch: 4 *****
2025-04-17 12:25:14,760 - Supervised Training Loss: 4.880430
2025-04-17 12:25:14,760 - Unsupervised Training Loss: 5.568120
2025-04-17 12:25:41,519 - K-means used 0.03 s
2025-04-17 12:25:43,054 - ***** Epoch: 5 *****
2025-04-17 12:25:43,055 - Supervised Training Loss: 4.420930
2025-04-17 12:25:43,055 - Unsupervised Training Loss: 5.588210
2025-04-17 12:26:11,242 - K-means used 0.03 s
2025-04-17 12:26:12,509 - ***** Epoch: 6 *****
2025-04-17 12:26:12,509 - Supervised Training Loss: 4.859740
2025-04-17 12:26:12,509 - Unsupervised Training Loss: 5.356090
2025-04-17 12:26:41,396 - K-means used 0.05 s
2025-04-17 12:26:42,782 - ***** Epoch: 7 *****
2025-04-17 12:26:42,783 - Supervised Training Loss: 4.732830
2025-04-17 12:26:42,783 - Unsupervised Training Loss: 5.475070
2025-04-17 12:27:11,496 - K-means used 0.1 s
2025-04-17 12:27:12,749 - ***** Epoch: 8 *****
2025-04-17 12:27:12,749 - Supervised Training Loss: 4.567100
2025-04-17 12:27:12,749 - Unsupervised Training Loss: 5.529930
2025-04-17 12:27:40,766 - K-means used 0.02 s
2025-04-17 12:27:42,133 - ***** Epoch: 9 *****
2025-04-17 12:27:42,133 - Supervised Training Loss: 4.790120
2025-04-17 12:27:42,133 - Unsupervised Training Loss: 5.566260
2025-04-17 12:28:10,349 - K-means used 0.02 s
2025-04-17 12:28:12,332 - ***** Epoch: 10 *****
2025-04-17 12:28:12,332 - Supervised Training Loss: 4.720900
2025-04-17 12:28:12,332 - Unsupervised Training Loss: 5.408100
2025-04-17 12:28:41,456 - K-means used 0.02 s
2025-04-17 12:28:43,190 - ***** Epoch: 11 *****
2025-04-17 12:28:43,191 - Supervised Training Loss: 4.634880
2025-04-17 12:28:43,191 - Unsupervised Training Loss: 5.490120
2025-04-17 12:29:12,594 - K-means used 0.03 s
2025-04-17 12:29:14,115 - ***** Epoch: 12 *****
2025-04-17 12:29:14,116 - Supervised Training Loss: 4.774850
2025-04-17 12:29:14,116 - Unsupervised Training Loss: 5.552030
2025-04-17 12:29:41,435 - K-means used 0.02 s
2025-04-17 12:29:42,969 - ***** Epoch: 13 *****
2025-04-17 12:29:42,969 - Supervised Training Loss: 4.747160
2025-04-17 12:29:42,969 - Unsupervised Training Loss: 5.290890
2025-04-17 12:30:10,388 - K-means used 0.02 s
2025-04-17 12:30:12,164 - ***** Epoch: 14 *****
2025-04-17 12:30:12,164 - Supervised Training Loss: 4.700070
2025-04-17 12:30:12,164 - Unsupervised Training Loss: 5.401960
2025-04-17 12:30:41,031 - K-means used 0.01 s
2025-04-17 12:30:42,688 - ***** Epoch: 15 *****
2025-04-17 12:30:42,688 - Supervised Training Loss: 4.551770
2025-04-17 12:30:42,688 - Unsupervised Training Loss: 5.507790
2025-04-17 12:31:11,159 - K-means used 0.02 s
2025-04-17 12:31:13,271 - ***** Epoch: 16 *****
2025-04-17 12:31:13,272 - Supervised Training Loss: 4.775190
2025-04-17 12:31:13,272 - Unsupervised Training Loss: 4.971530
2025-04-17 12:31:42,947 - K-means used 0.02 s
2025-04-17 12:31:45,351 - ***** Epoch: 17 *****
2025-04-17 12:31:45,352 - Supervised Training Loss: 4.742760
2025-04-17 12:31:45,352 - Unsupervised Training Loss: 5.186990
2025-04-17 12:32:06,278 - Training is finished...
2025-04-17 12:32:06,279 - Testing begins...
2025-04-17 12:32:13,165 - ***** Test results *****
2025-04-17 12:32:13,165 -   ACC = 28.76
2025-04-17 12:32:13,165 -   ARI = 10.78
2025-04-17 12:32:13,165 -   NMI = 35.43
2025-04-17 12:32:13,165 -   fmi = 16.32
2025-04-17 12:32:13,165 - Testing is finished...
2025-04-17 12:32:13,165 - Multimodal intent recognition is finished...
2025-04-17 12:32:13,165 - Results are saved in results/results_umc_pre.csv
2025-04-17 12:32:14,311 - Freeze all parameters but the last layer for efficiency
2025-04-17 12:32:14,349 - Pre-training start...
2025-04-17 12:32:15,197 - ***** Epoch: 1: Eval results *****
2025-04-17 12:32:15,197 -   train_loss = 5.668908596038818
2025-04-17 12:32:16,024 - ***** Epoch: 2: Eval results *****
2025-04-17 12:32:16,024 -   train_loss = 5.6747541427612305
2025-04-17 12:32:16,825 - ***** Epoch: 3: Eval results *****
2025-04-17 12:32:16,825 -   train_loss = 5.669938564300537
2025-04-17 12:32:17,698 - ***** Epoch: 4: Eval results *****
2025-04-17 12:32:17,698 -   train_loss = 5.675276279449463
2025-04-17 12:32:18,550 - ***** Epoch: 5: Eval results *****
2025-04-17 12:32:18,550 -   train_loss = 5.670127868652344
2025-04-17 12:32:19,385 - ***** Epoch: 6: Eval results *****
2025-04-17 12:32:19,386 -   train_loss = 5.671318531036377
2025-04-17 12:32:20,198 - ***** Epoch: 7: Eval results *****
2025-04-17 12:32:20,199 -   train_loss = 5.6712188720703125
2025-04-17 12:32:20,908 - ***** Epoch: 8: Eval results *****
2025-04-17 12:32:20,909 -   train_loss = 5.668558120727539
2025-04-17 12:32:21,764 - ***** Epoch: 9: Eval results *****
2025-04-17 12:32:21,764 -   train_loss = 5.671740531921387
2025-04-17 12:32:22,604 - ***** Epoch: 10: Eval results *****
2025-04-17 12:32:22,604 -   train_loss = 5.672915458679199
2025-04-17 12:32:23,302 - ***** Epoch: 11: Eval results *****
2025-04-17 12:32:23,302 -   train_loss = 5.669266223907471
2025-04-17 12:32:24,172 - ***** Epoch: 12: Eval results *****
2025-04-17 12:32:24,172 -   train_loss = 5.670348644256592
2025-04-17 12:32:25,008 - ***** Epoch: 13: Eval results *****
2025-04-17 12:32:25,008 -   train_loss = 5.6642022132873535
2025-04-17 12:32:25,829 - ***** Epoch: 14: Eval results *****
2025-04-17 12:32:25,830 -   train_loss = 5.66487455368042
2025-04-17 12:32:26,556 - ***** Epoch: 15: Eval results *****
2025-04-17 12:32:26,557 -   train_loss = 5.6685709953308105
2025-04-17 12:32:27,438 - ***** Epoch: 16: Eval results *****
2025-04-17 12:32:27,438 -   train_loss = 5.6679511070251465
2025-04-17 12:32:28,285 - ***** Epoch: 17: Eval results *****
2025-04-17 12:32:28,285 -   train_loss = 5.664794921875
2025-04-17 12:32:29,117 - ***** Epoch: 18: Eval results *****
2025-04-17 12:32:29,117 -   train_loss = 5.66341495513916
2025-04-17 12:32:29,948 - ***** Epoch: 19: Eval results *****
2025-04-17 12:32:29,949 -   train_loss = 5.667308807373047
2025-04-17 12:32:30,782 - ***** Epoch: 20: Eval results *****
2025-04-17 12:32:30,782 -   train_loss = 5.661367893218994
2025-04-17 12:32:31,625 - ***** Epoch: 21: Eval results *****
2025-04-17 12:32:31,625 -   train_loss = 5.656976222991943
2025-04-17 12:32:32,470 - ***** Epoch: 22: Eval results *****
2025-04-17 12:32:32,470 -   train_loss = 5.655187129974365
2025-04-17 12:32:33,314 - ***** Epoch: 23: Eval results *****
2025-04-17 12:32:33,314 -   train_loss = 5.658908843994141
2025-04-17 12:32:34,146 - ***** Epoch: 24: Eval results *****
2025-04-17 12:32:34,146 -   train_loss = 5.656929969787598
2025-04-17 12:32:34,992 - ***** Epoch: 25: Eval results *****
2025-04-17 12:32:34,993 -   train_loss = 5.654018402099609
2025-04-17 12:32:35,820 - ***** Epoch: 26: Eval results *****
2025-04-17 12:32:35,821 -   train_loss = 5.653346538543701
2025-04-17 12:32:36,645 - ***** Epoch: 27: Eval results *****
2025-04-17 12:32:36,645 -   train_loss = 5.6492414474487305
2025-04-17 12:32:37,481 - ***** Epoch: 28: Eval results *****
2025-04-17 12:32:37,481 -   train_loss = 5.6505231857299805
2025-04-17 12:32:38,281 - ***** Epoch: 29: Eval results *****
2025-04-17 12:32:38,281 -   train_loss = 5.6506428718566895
2025-04-17 12:32:38,985 - ***** Epoch: 30: Eval results *****
2025-04-17 12:32:38,986 -   train_loss = 5.641523361206055
2025-04-17 12:32:39,711 - ***** Epoch: 31: Eval results *****
2025-04-17 12:32:39,712 -   train_loss = 5.637353420257568
2025-04-17 12:32:40,444 - ***** Epoch: 32: Eval results *****
2025-04-17 12:32:40,444 -   train_loss = 5.642851829528809
2025-04-17 12:32:41,285 - ***** Epoch: 33: Eval results *****
2025-04-17 12:32:41,285 -   train_loss = 5.6451873779296875
2025-04-17 12:32:41,977 - ***** Epoch: 34: Eval results *****
2025-04-17 12:32:41,977 -   train_loss = 5.636022090911865
2025-04-17 12:32:42,673 - ***** Epoch: 35: Eval results *****
2025-04-17 12:32:42,673 -   train_loss = 5.63569450378418
2025-04-17 12:32:43,369 - ***** Epoch: 36: Eval results *****
2025-04-17 12:32:43,369 -   train_loss = 5.643639087677002
2025-04-17 12:32:44,213 - ***** Epoch: 37: Eval results *****
2025-04-17 12:32:44,214 -   train_loss = 5.634669780731201
2025-04-17 12:32:44,914 - ***** Epoch: 38: Eval results *****
2025-04-17 12:32:44,915 -   train_loss = 5.621801376342773
2025-04-17 12:32:45,630 - ***** Epoch: 39: Eval results *****
2025-04-17 12:32:45,630 -   train_loss = 5.62551212310791
2025-04-17 12:32:46,334 - ***** Epoch: 40: Eval results *****
2025-04-17 12:32:46,335 -   train_loss = 5.62337064743042
2025-04-17 12:32:47,032 - ***** Epoch: 41: Eval results *****
2025-04-17 12:32:47,033 -   train_loss = 5.621966361999512
2025-04-17 12:32:47,726 - ***** Epoch: 42: Eval results *****
2025-04-17 12:32:47,726 -   train_loss = 5.610127925872803
2025-04-17 12:32:48,423 - ***** Epoch: 43: Eval results *****
2025-04-17 12:32:48,423 -   train_loss = 5.603731632232666
2025-04-17 12:32:49,118 - ***** Epoch: 44: Eval results *****
2025-04-17 12:32:49,118 -   train_loss = 5.612451553344727
2025-04-17 12:32:49,806 - ***** Epoch: 45: Eval results *****
2025-04-17 12:32:49,806 -   train_loss = 5.598226547241211
2025-04-17 12:32:50,494 - ***** Epoch: 46: Eval results *****
2025-04-17 12:32:50,495 -   train_loss = 5.592403411865234
2025-04-17 12:32:51,194 - ***** Epoch: 47: Eval results *****
2025-04-17 12:32:51,194 -   train_loss = 5.584842205047607
2025-04-17 12:32:52,062 - ***** Epoch: 48: Eval results *****
2025-04-17 12:32:52,062 -   train_loss = 5.592772483825684
2025-04-17 12:32:52,853 - ***** Epoch: 49: Eval results *****
2025-04-17 12:32:52,853 -   train_loss = 5.590441703796387
2025-04-17 12:32:53,560 - ***** Epoch: 50: Eval results *****
2025-04-17 12:32:53,560 -   train_loss = 5.5821943283081055
2025-04-17 12:32:54,254 - ***** Epoch: 51: Eval results *****
2025-04-17 12:32:54,254 -   train_loss = 5.570345878601074
2025-04-17 12:32:54,952 - ***** Epoch: 52: Eval results *****
2025-04-17 12:32:54,953 -   train_loss = 5.569978713989258
2025-04-17 12:32:55,655 - ***** Epoch: 53: Eval results *****
2025-04-17 12:32:55,656 -   train_loss = 5.565300464630127
2025-04-17 12:32:56,529 - ***** Epoch: 54: Eval results *****
2025-04-17 12:32:56,529 -   train_loss = 5.569988250732422
2025-04-17 12:32:57,358 - ***** Epoch: 55: Eval results *****
2025-04-17 12:32:57,358 -   train_loss = 5.550588607788086
2025-04-17 12:32:58,161 - ***** Epoch: 56: Eval results *****
2025-04-17 12:32:58,161 -   train_loss = 5.550972938537598
2025-04-17 12:32:58,853 - ***** Epoch: 57: Eval results *****
2025-04-17 12:32:58,854 -   train_loss = 5.543886184692383
2025-04-17 12:32:59,544 - ***** Epoch: 58: Eval results *****
2025-04-17 12:32:59,544 -   train_loss = 5.53324031829834
2025-04-17 12:33:00,228 - ***** Epoch: 59: Eval results *****
2025-04-17 12:33:00,228 -   train_loss = 5.508848667144775
2025-04-17 12:33:00,910 - ***** Epoch: 60: Eval results *****
2025-04-17 12:33:00,910 -   train_loss = 5.515467166900635
2025-04-17 12:33:01,597 - ***** Epoch: 61: Eval results *****
2025-04-17 12:33:01,597 -   train_loss = 5.518980026245117
2025-04-17 12:33:02,297 - ***** Epoch: 62: Eval results *****
2025-04-17 12:33:02,297 -   train_loss = 5.506155490875244
2025-04-17 12:33:02,999 - ***** Epoch: 63: Eval results *****
2025-04-17 12:33:02,999 -   train_loss = 5.4795145988464355
2025-04-17 12:33:03,726 - ***** Epoch: 64: Eval results *****
2025-04-17 12:33:03,726 -   train_loss = 5.482118606567383
2025-04-17 12:33:04,445 - ***** Epoch: 65: Eval results *****
2025-04-17 12:33:04,445 -   train_loss = 5.471767902374268
2025-04-17 12:33:05,149 - ***** Epoch: 66: Eval results *****
2025-04-17 12:33:05,150 -   train_loss = 5.4815192222595215
2025-04-17 12:33:05,848 - ***** Epoch: 67: Eval results *****
2025-04-17 12:33:05,849 -   train_loss = 5.477417945861816
2025-04-17 12:33:06,552 - ***** Epoch: 68: Eval results *****
2025-04-17 12:33:06,552 -   train_loss = 5.4734883308410645
2025-04-17 12:33:07,242 - ***** Epoch: 69: Eval results *****
2025-04-17 12:33:07,242 -   train_loss = 5.4543914794921875
2025-04-17 12:33:07,936 - ***** Epoch: 70: Eval results *****
2025-04-17 12:33:07,937 -   train_loss = 5.455863952636719
2025-04-17 12:33:08,632 - ***** Epoch: 71: Eval results *****
2025-04-17 12:33:08,632 -   train_loss = 5.446334362030029
2025-04-17 12:33:09,496 - ***** Epoch: 72: Eval results *****
2025-04-17 12:33:09,497 -   train_loss = 5.437204837799072
2025-04-17 12:33:10,312 - ***** Epoch: 73: Eval results *****
2025-04-17 12:33:10,312 -   train_loss = 5.413825511932373
2025-04-17 12:33:11,114 - ***** Epoch: 74: Eval results *****
2025-04-17 12:33:11,115 -   train_loss = 5.417523384094238
2025-04-17 12:33:11,953 - ***** Epoch: 75: Eval results *****
2025-04-17 12:33:11,953 -   train_loss = 5.407419681549072
2025-04-17 12:33:12,649 - ***** Epoch: 76: Eval results *****
2025-04-17 12:33:12,650 -   train_loss = 5.4053215980529785
2025-04-17 12:33:13,514 - ***** Epoch: 77: Eval results *****
2025-04-17 12:33:13,515 -   train_loss = 5.3987884521484375
2025-04-17 12:33:14,331 - ***** Epoch: 78: Eval results *****
2025-04-17 12:33:14,332 -   train_loss = 5.3834099769592285
2025-04-17 12:33:15,034 - ***** Epoch: 79: Eval results *****
2025-04-17 12:33:15,034 -   train_loss = 5.379875183105469
2025-04-17 12:33:15,742 - ***** Epoch: 80: Eval results *****
2025-04-17 12:33:15,742 -   train_loss = 5.369325637817383
2025-04-17 12:33:16,438 - ***** Epoch: 81: Eval results *****
2025-04-17 12:33:16,439 -   train_loss = 5.351478576660156
2025-04-17 12:33:17,132 - ***** Epoch: 82: Eval results *****
2025-04-17 12:33:17,132 -   train_loss = 5.343601226806641
2025-04-17 12:33:17,834 - ***** Epoch: 83: Eval results *****
2025-04-17 12:33:17,834 -   train_loss = 5.340723037719727
2025-04-17 12:33:18,538 - ***** Epoch: 84: Eval results *****
2025-04-17 12:33:18,538 -   train_loss = 5.365121841430664
2025-04-17 12:33:19,372 - ***** Epoch: 85: Eval results *****
2025-04-17 12:33:19,373 -   train_loss = 5.325000762939453
2025-04-17 12:33:20,204 - ***** Epoch: 86: Eval results *****
2025-04-17 12:33:20,205 -   train_loss = 5.325738430023193
2025-04-17 12:33:21,067 - ***** Epoch: 87: Eval results *****
2025-04-17 12:33:21,067 -   train_loss = 5.311112880706787
2025-04-17 12:33:21,897 - ***** Epoch: 88: Eval results *****
2025-04-17 12:33:21,897 -   train_loss = 5.292422294616699
2025-04-17 12:33:22,740 - ***** Epoch: 89: Eval results *****
2025-04-17 12:33:22,740 -   train_loss = 5.306870460510254
2025-04-17 12:33:23,443 - ***** Epoch: 90: Eval results *****
2025-04-17 12:33:23,443 -   train_loss = 5.295719146728516
2025-04-17 12:33:24,138 - ***** Epoch: 91: Eval results *****
2025-04-17 12:33:24,138 -   train_loss = 5.27503776550293
2025-04-17 12:33:25,000 - ***** Epoch: 92: Eval results *****
2025-04-17 12:33:25,000 -   train_loss = 5.28312349319458
2025-04-17 12:33:25,836 - ***** Epoch: 93: Eval results *****
2025-04-17 12:33:25,836 -   train_loss = 5.293460369110107
2025-04-17 12:33:26,666 - ***** Epoch: 94: Eval results *****
2025-04-17 12:33:26,666 -   train_loss = 5.269009590148926
2025-04-17 12:33:27,488 - ***** Epoch: 95: Eval results *****
2025-04-17 12:33:27,488 -   train_loss = 5.251882553100586
2025-04-17 12:33:28,185 - ***** Epoch: 96: Eval results *****
2025-04-17 12:33:28,186 -   train_loss = 5.257745742797852
2025-04-17 12:33:29,050 - ***** Epoch: 97: Eval results *****
2025-04-17 12:33:29,050 -   train_loss = 5.230931282043457
2025-04-17 12:33:29,898 - ***** Epoch: 98: Eval results *****
2025-04-17 12:33:29,899 -   train_loss = 5.231293678283691
2025-04-17 12:33:30,713 - ***** Epoch: 99: Eval results *****
2025-04-17 12:33:30,713 -   train_loss = 5.226528167724609
2025-04-17 12:33:31,586 - ***** Epoch: 100: Eval results *****
2025-04-17 12:33:31,586 -   train_loss = 5.221856117248535
2025-04-17 12:33:33,296 - Pre-training finished...
2025-04-17 12:33:33,685 - Freeze all parameters but the last layer for efficiency
2025-04-17 12:33:33,693 - Multimodal Intent Recognition begins...
2025-04-17 12:33:33,693 - Training begins...
2025-04-17 12:33:45,269 - Initializing centroids with K-means++...
2025-04-17 12:33:45,319 - K-means++ used 0.05 s
2025-04-17 12:34:16,515 - K-means used 0.03 s
2025-04-17 12:34:17,557 - ***** Epoch: 1 *****
2025-04-17 12:34:17,557 - Supervised Training Loss: 5.186210
2025-04-17 12:34:17,557 - Unsupervised Training Loss: 5.831730
2025-04-17 12:34:46,755 - K-means used 0.03 s
2025-04-17 12:34:47,838 - ***** Epoch: 2 *****
2025-04-17 12:34:47,838 - Supervised Training Loss: 4.021200
2025-04-17 12:34:47,838 - Unsupervised Training Loss: 5.815720
2025-04-17 12:35:16,599 - K-means used 0.05 s
2025-04-17 12:35:17,926 - ***** Epoch: 3 *****
2025-04-17 12:35:17,926 - Supervised Training Loss: 5.327840
2025-04-17 12:35:17,926 - Unsupervised Training Loss: 5.605700
2025-04-17 12:35:46,242 - K-means used 0.04 s
2025-04-17 12:35:47,350 - ***** Epoch: 4 *****
2025-04-17 12:35:47,350 - Supervised Training Loss: 4.950390
2025-04-17 12:35:47,350 - Unsupervised Training Loss: 5.602190
2025-04-17 12:36:17,085 - K-means used 0.04 s
2025-04-17 12:36:18,350 - ***** Epoch: 5 *****
2025-04-17 12:36:18,350 - Supervised Training Loss: 4.590070
2025-04-17 12:36:18,351 - Unsupervised Training Loss: 5.606120
2025-04-17 12:36:46,330 - K-means used 0.02 s
2025-04-17 12:36:48,085 - ***** Epoch: 6 *****
2025-04-17 12:36:48,085 - Supervised Training Loss: 4.893490
2025-04-17 12:36:48,085 - Unsupervised Training Loss: 5.395210
2025-04-17 12:37:17,119 - K-means used 0.03 s
2025-04-17 12:37:18,521 - ***** Epoch: 7 *****
2025-04-17 12:37:18,521 - Supervised Training Loss: 4.776500
2025-04-17 12:37:18,521 - Unsupervised Training Loss: 5.499790
2025-04-17 12:37:47,535 - K-means used 0.02 s
2025-04-17 12:37:48,942 - ***** Epoch: 8 *****
2025-04-17 12:37:48,942 - Supervised Training Loss: 4.599490
2025-04-17 12:37:48,942 - Unsupervised Training Loss: 5.552770
2025-04-17 12:38:17,841 - K-means used 0.03 s
2025-04-17 12:38:19,222 - ***** Epoch: 9 *****
2025-04-17 12:38:19,222 - Supervised Training Loss: 4.824450
2025-04-17 12:38:19,222 - Unsupervised Training Loss: 5.583890
2025-04-17 12:38:47,143 - K-means used 0.04 s
2025-04-17 12:38:48,538 - ***** Epoch: 10 *****
2025-04-17 12:38:48,538 - Supervised Training Loss: 4.745240
2025-04-17 12:38:48,538 - Unsupervised Training Loss: 5.422360
2025-04-17 12:39:16,808 - K-means used 0.02 s
2025-04-17 12:39:18,272 - ***** Epoch: 11 *****
2025-04-17 12:39:18,272 - Supervised Training Loss: 4.662440
2025-04-17 12:39:18,272 - Unsupervised Training Loss: 5.497940
2025-04-17 12:39:47,643 - K-means used 0.03 s
2025-04-17 12:39:49,207 - ***** Epoch: 12 *****
2025-04-17 12:39:49,208 - Supervised Training Loss: 4.796560
2025-04-17 12:39:49,208 - Unsupervised Training Loss: 5.563480
2025-04-17 12:40:18,169 - K-means used 0.02 s
2025-04-17 12:40:19,899 - ***** Epoch: 13 *****
2025-04-17 12:40:19,900 - Supervised Training Loss: 4.752220
2025-04-17 12:40:19,900 - Unsupervised Training Loss: 5.305610
2025-04-17 12:40:47,235 - K-means used 0.03 s
2025-04-17 12:40:48,934 - ***** Epoch: 14 *****
2025-04-17 12:40:48,934 - Supervised Training Loss: 4.705540
2025-04-17 12:40:48,934 - Unsupervised Training Loss: 5.421520
2025-04-17 12:41:17,821 - K-means used 0.02 s
2025-04-17 12:41:19,523 - ***** Epoch: 15 *****
2025-04-17 12:41:19,523 - Supervised Training Loss: 4.586000
2025-04-17 12:41:19,523 - Unsupervised Training Loss: 5.518990
2025-04-17 12:41:47,976 - K-means used 0.02 s
2025-04-17 12:41:49,860 - ***** Epoch: 16 *****
2025-04-17 12:41:49,860 - Supervised Training Loss: 4.782760
2025-04-17 12:41:49,860 - Unsupervised Training Loss: 4.956980
2025-04-17 12:42:18,596 - K-means used 0.12 s
2025-04-17 12:42:20,436 - ***** Epoch: 17 *****
2025-04-17 12:42:20,436 - Supervised Training Loss: 4.753930
2025-04-17 12:42:20,436 - Unsupervised Training Loss: 5.198590
2025-04-17 12:42:39,899 - Training is finished...
2025-04-17 12:42:39,900 - Testing begins...
2025-04-17 12:42:47,043 - ***** Test results *****
2025-04-17 12:42:47,043 -   ACC = 21.57
2025-04-17 12:42:47,044 -   ARI = 6.87
2025-04-17 12:42:47,044 -   NMI = 28.83
2025-04-17 12:42:47,044 -   fmi = 12.82
2025-04-17 12:42:47,044 - Testing is finished...
2025-04-17 12:42:47,044 - Multimodal intent recognition is finished...
2025-04-17 12:42:47,044 - Results are saved in results/results_umc_pre.csv
