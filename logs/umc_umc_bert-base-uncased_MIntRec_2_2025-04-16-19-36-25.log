2025-04-16 19:36:25,276 - 【无监督】进入了无监督的设定中, 加载数据集
2025-04-16 19:36:25,276 - data preparation...
2025-04-16 19:36:34,681 - Number of train samples = 1779
2025-04-16 19:36:34,681 - Number of testing samples = 445
2025-04-16 19:36:34,681 - data preparation...
2025-04-16 19:36:37,067 - num_train_examples = 1779
2025-04-16 19:36:37,068 - ============================== Params ==============================
2025-04-16 19:36:37,068 - logger_name: umc_umc_bert-base-uncased_MIntRec_2
2025-04-16 19:36:37,068 - dataset: MIntRec
2025-04-16 19:36:37,068 - multimodal_method: umc
2025-04-16 19:36:37,068 - method: umc
2025-04-16 19:36:37,068 - setting: unsupervised
2025-04-16 19:36:37,068 - text_backbone: bert-base-uncased
2025-04-16 19:36:37,068 - seed: 2
2025-04-16 19:36:37,068 - num_workers: 16
2025-04-16 19:36:37,068 - log_id: umc_umc_bert-base-uncased_MIntRec_2_2025-04-16-19-36-25
2025-04-16 19:36:37,068 - gpu_id: 1
2025-04-16 19:36:37,068 - data_path: /root/autodl-tmp/home/Share/Dataset/LZH
2025-04-16 19:36:37,068 - train: True
2025-04-16 19:36:37,068 - tune: True
2025-04-16 19:36:37,068 - save_model: True
2025-04-16 19:36:37,068 - save_results: True
2025-04-16 19:36:37,068 - log_path: logs
2025-04-16 19:36:37,068 - cache_path: cache
2025-04-16 19:36:37,068 - video_data_path: video_data
2025-04-16 19:36:37,068 - audio_data_path: audio_data
2025-04-16 19:36:37,068 - video_feats_path: swin_feats.pkl
2025-04-16 19:36:37,068 - audio_feats_path: wavlm_feats.pkl
2025-04-16 19:36:37,068 - results_path: results
2025-04-16 19:36:37,068 - output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/SMC/outputs_test2/MIntRec
2025-04-16 19:36:37,068 - model_path: models
2025-04-16 19:36:37,068 - config_file_name: umc_MIntRec
2025-04-16 19:36:37,068 - results_file_name: results_umc.csv
2025-04-16 19:36:37,068 - text_pretrained_model: uncased_L-12_H-768_A-12
2025-04-16 19:36:37,069 - pretrained_bert_model: uncased_L-12_H-768_A-12
2025-04-16 19:36:37,069 - pretrain_batch_size: 128
2025-04-16 19:36:37,069 - train_batch_size: 128
2025-04-16 19:36:37,069 - eval_batch_size: 128
2025-04-16 19:36:37,069 - test_batch_size: 128
2025-04-16 19:36:37,069 - num_pretrain_epochs: 100
2025-04-16 19:36:37,069 - num_train_epochs: 100
2025-04-16 19:36:37,069 - pretrain: [True]
2025-04-16 19:36:37,069 - aligned_method: ctc
2025-04-16 19:36:37,069 - need_aligned: False
2025-04-16 19:36:37,069 - freeze_pretrain_bert_parameters: [True]
2025-04-16 19:36:37,069 - freeze_train_bert_parameters: [True]
2025-04-16 19:36:37,069 - pretrain_temperature: [0.1]
2025-04-16 19:36:37,069 - train_temperature_sup: [0.5]
2025-04-16 19:36:37,069 - train_temperature_unsup: [2]
2025-04-16 19:36:37,069 - activation: tanh
2025-04-16 19:36:37,069 - lr_pre: [5e-06]
2025-04-16 19:36:37,069 - lr: [5e-05]
2025-04-16 19:36:37,069 - delta: [0.05]
2025-04-16 19:36:37,069 - thres: [0.1]
2025-04-16 19:36:37,069 - topk: [5]
2025-04-16 19:36:37,069 - weight_decay: 0.01
2025-04-16 19:36:37,069 - feat_dim: 768
2025-04-16 19:36:37,069 - hidden_size: 768
2025-04-16 19:36:37,069 - grad_clip: -1.0
2025-04-16 19:36:37,069 - warmup_proportion: [0.1]
2025-04-16 19:36:37,069 - hidden_dropout_prob: 0.1
2025-04-16 19:36:37,069 - weight: 1.0
2025-04-16 19:36:37,069 - loss_mode: rdrop
2025-04-16 19:36:37,069 - base_dim: 256
2025-04-16 19:36:37,070 - nheads: 8
2025-04-16 19:36:37,070 - attn_dropout: 0.1
2025-04-16 19:36:37,070 - relu_dropout: 0.1
2025-04-16 19:36:37,070 - embed_dropout: 0.01
2025-04-16 19:36:37,070 - res_dropout: 0.0
2025-04-16 19:36:37,070 - attn_mask: True
2025-04-16 19:36:37,070 - encoder_layers_1: 1
2025-04-16 19:36:37,070 - fusion_act: tanh
2025-04-16 19:36:37,070 - pred_output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/SMC/outputs_test2/MIntRec/umc_umc_MIntRec_bert-base-uncased_2
2025-04-16 19:36:37,070 - model_output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/SMC/outputs_test2/MIntRec/umc_umc_MIntRec_bert-base-uncased_2/models
2025-04-16 19:36:37,070 - text_seq_len: 30
2025-04-16 19:36:37,070 - video_seq_len: 230
2025-04-16 19:36:37,070 - audio_seq_len: 480
2025-04-16 19:36:37,070 - text_feat_dim: 768
2025-04-16 19:36:37,070 - video_feat_dim: 1024
2025-04-16 19:36:37,070 - audio_feat_dim: 768
2025-04-16 19:36:37,070 - num_labels: 20
2025-04-16 19:36:37,070 - num_train_examples: 1779
2025-04-16 19:36:37,070 - ============================== End Params ==============================
2025-04-16 19:36:38,283 - Freeze all parameters but the last layer for efficiency
2025-04-16 19:36:38,317 - Pre-training start...
2025-04-16 19:36:58,408 - ***** Epoch: 1: Eval results *****
2025-04-16 19:36:58,408 -   train_loss = 5.960472447531564
2025-04-16 19:37:19,563 - ***** Epoch: 2: Eval results *****
2025-04-16 19:37:19,563 -   train_loss = 5.957665375300816
2025-04-16 19:37:44,892 - ***** Epoch: 3: Eval results *****
2025-04-16 19:37:44,893 -   train_loss = 5.953362941741943
2025-04-16 19:38:06,168 - ***** Epoch: 4: Eval results *****
2025-04-16 19:38:06,169 -   train_loss = 5.9463050365448
2025-04-16 19:38:26,480 - ***** Epoch: 5: Eval results *****
2025-04-16 19:38:26,480 -   train_loss = 5.942861999784197
2025-04-16 19:38:46,417 - ***** Epoch: 6: Eval results *****
2025-04-16 19:38:46,417 -   train_loss = 5.935048137392316
2025-04-16 19:39:07,274 - ***** Epoch: 7: Eval results *****
2025-04-16 19:39:07,274 -   train_loss = 5.923277582441058
2025-04-16 19:39:28,098 - ***** Epoch: 8: Eval results *****
2025-04-16 19:39:28,099 -   train_loss = 5.9078898429870605
2025-04-16 19:39:49,586 - ***** Epoch: 9: Eval results *****
2025-04-16 19:39:49,586 -   train_loss = 5.889720916748047
2025-04-16 19:40:10,674 - ***** Epoch: 10: Eval results *****
2025-04-16 19:40:10,674 -   train_loss = 5.855695860726493
2025-04-16 19:40:31,815 - ***** Epoch: 11: Eval results *****
2025-04-16 19:40:31,816 -   train_loss = 5.78652378490993
2025-04-16 19:40:52,125 - ***** Epoch: 12: Eval results *****
2025-04-16 19:40:52,125 -   train_loss = 5.674649068287441
2025-04-16 19:41:14,867 - ***** Epoch: 13: Eval results *****
2025-04-16 19:41:14,868 -   train_loss = 5.4896895204271585
2025-04-16 19:41:37,491 - ***** Epoch: 14: Eval results *****
2025-04-16 19:41:37,491 -   train_loss = 5.224228995186942
2025-04-16 19:41:59,480 - ***** Epoch: 15: Eval results *****
2025-04-16 19:41:59,480 -   train_loss = 4.924729483468192
2025-04-16 19:42:21,186 - ***** Epoch: 16: Eval results *****
2025-04-16 19:42:21,186 -   train_loss = 4.682312590735299
2025-04-16 19:42:43,844 - ***** Epoch: 17: Eval results *****
2025-04-16 19:42:43,844 -   train_loss = 4.424783502306257
2025-04-16 19:43:06,965 - ***** Epoch: 18: Eval results *****
2025-04-16 19:43:06,965 -   train_loss = 4.21648062978472
2025-04-16 19:43:28,160 - ***** Epoch: 19: Eval results *****
2025-04-16 19:43:28,160 -   train_loss = 4.021022370883396
2025-04-16 19:43:50,682 - ***** Epoch: 20: Eval results *****
2025-04-16 19:43:50,682 -   train_loss = 3.86679060118539
2025-04-16 19:44:12,752 - ***** Epoch: 21: Eval results *****
2025-04-16 19:44:12,752 -   train_loss = 3.6893462112971713
2025-04-16 19:44:38,033 - ***** Epoch: 22: Eval results *****
2025-04-16 19:44:38,034 -   train_loss = 3.562082120350429
2025-04-16 19:45:00,749 - ***** Epoch: 23: Eval results *****
2025-04-16 19:45:00,750 -   train_loss = 3.4697269201278687
2025-04-16 19:45:22,110 - ***** Epoch: 24: Eval results *****
2025-04-16 19:45:22,111 -   train_loss = 3.3496302366256714
2025-04-16 19:45:44,032 - ***** Epoch: 25: Eval results *****
2025-04-16 19:45:44,033 -   train_loss = 3.2526154688426425
2025-04-16 19:46:05,522 - ***** Epoch: 26: Eval results *****
2025-04-16 19:46:05,523 -   train_loss = 3.171050122806004
2025-04-16 19:46:25,446 - ***** Epoch: 27: Eval results *****
2025-04-16 19:46:25,446 -   train_loss = 3.088506511279515
2025-04-16 19:46:45,675 - ***** Epoch: 28: Eval results *****
2025-04-16 19:46:45,675 -   train_loss = 3.0126384666987827
2025-04-16 19:47:08,455 - ***** Epoch: 29: Eval results *****
2025-04-16 19:47:08,455 -   train_loss = 2.9550134113856723
2025-04-16 19:47:33,263 - ***** Epoch: 30: Eval results *****
2025-04-16 19:47:33,263 -   train_loss = 2.911102976117815
2025-04-16 19:47:56,065 - ***** Epoch: 31: Eval results *****
2025-04-16 19:47:56,066 -   train_loss = 2.8281326293945312
2025-04-16 19:48:17,100 - ***** Epoch: 32: Eval results *****
2025-04-16 19:48:17,101 -   train_loss = 2.7873007910592213
2025-04-16 19:48:36,834 - ***** Epoch: 33: Eval results *****
2025-04-16 19:48:36,834 -   train_loss = 2.7330401795251027
2025-04-16 19:48:58,012 - ***** Epoch: 34: Eval results *****
2025-04-16 19:48:58,012 -   train_loss = 2.6920073372977122
2025-04-16 19:49:21,363 - ***** Epoch: 35: Eval results *****
2025-04-16 19:49:21,363 -   train_loss = 2.646432944706508
2025-04-16 19:49:43,064 - ***** Epoch: 36: Eval results *****
2025-04-16 19:49:43,064 -   train_loss = 2.6250275714056834
2025-04-16 19:50:04,649 - ***** Epoch: 37: Eval results *****
2025-04-16 19:50:04,650 -   train_loss = 2.5753355707441057
2025-04-16 19:50:25,194 - ***** Epoch: 38: Eval results *****
2025-04-16 19:50:25,194 -   train_loss = 2.5315412964139665
2025-04-16 19:50:48,512 - ***** Epoch: 39: Eval results *****
2025-04-16 19:50:48,512 -   train_loss = 2.4938268150602068
2025-04-16 19:51:11,391 - ***** Epoch: 40: Eval results *****
2025-04-16 19:51:11,391 -   train_loss = 2.4757284096309116
2025-04-16 19:51:33,965 - ***** Epoch: 41: Eval results *****
2025-04-16 19:51:33,966 -   train_loss = 2.4411772319248746
2025-04-16 19:51:55,818 - ***** Epoch: 42: Eval results *****
2025-04-16 19:51:55,819 -   train_loss = 2.4073509999683926
2025-04-16 19:52:16,157 - ***** Epoch: 43: Eval results *****
2025-04-16 19:52:16,158 -   train_loss = 2.39723425252097
2025-04-16 19:52:37,366 - ***** Epoch: 44: Eval results *****
2025-04-16 19:52:37,366 -   train_loss = 2.3688428231648038
2025-04-16 19:52:59,952 - ***** Epoch: 45: Eval results *****
2025-04-16 19:52:59,952 -   train_loss = 2.340318032673427
2025-04-16 19:53:21,966 - ***** Epoch: 46: Eval results *****
2025-04-16 19:53:21,966 -   train_loss = 2.304501141820635
2025-04-16 19:53:42,310 - ***** Epoch: 47: Eval results *****
2025-04-16 19:53:42,310 -   train_loss = 2.2970074926103865
2025-04-16 19:54:03,206 - ***** Epoch: 48: Eval results *****
2025-04-16 19:54:03,206 -   train_loss = 2.281375425202506
2025-04-16 19:54:27,089 - ***** Epoch: 49: Eval results *****
2025-04-16 19:54:27,090 -   train_loss = 2.2623410395213535
2025-04-16 19:54:47,949 - ***** Epoch: 50: Eval results *****
2025-04-16 19:54:47,950 -   train_loss = 2.2328232867377147
2025-04-16 19:55:09,481 - ***** Epoch: 51: Eval results *****
2025-04-16 19:55:09,481 -   train_loss = 2.234631299972534
2025-04-16 19:55:31,285 - ***** Epoch: 52: Eval results *****
2025-04-16 19:55:31,285 -   train_loss = 2.2161927052906583
2025-04-16 19:55:52,358 - ***** Epoch: 53: Eval results *****
2025-04-16 19:55:52,359 -   train_loss = 2.1821429899760654
2025-04-16 19:56:14,056 - ***** Epoch: 54: Eval results *****
2025-04-16 19:56:14,056 -   train_loss = 2.1698427370616367
2025-04-16 19:56:35,268 - ***** Epoch: 55: Eval results *****
2025-04-16 19:56:35,268 -   train_loss = 2.1440813882010326
2025-04-16 19:56:56,984 - ***** Epoch: 56: Eval results *****
2025-04-16 19:56:56,985 -   train_loss = 2.155594604355948
2025-04-16 19:57:16,771 - ***** Epoch: 57: Eval results *****
2025-04-16 19:57:16,771 -   train_loss = 2.12605311189379
2025-04-16 19:57:41,014 - ***** Epoch: 58: Eval results *****
2025-04-16 19:57:41,014 -   train_loss = 2.120690703392029
2025-04-16 19:58:04,050 - ***** Epoch: 59: Eval results *****
2025-04-16 19:58:04,051 -   train_loss = 2.107618979045323
2025-04-16 19:58:24,842 - ***** Epoch: 60: Eval results *****
2025-04-16 19:58:24,842 -   train_loss = 2.0819439632552013
2025-04-16 19:58:46,523 - ***** Epoch: 61: Eval results *****
2025-04-16 19:58:46,523 -   train_loss = 2.079821058682033
2025-04-16 19:59:08,200 - ***** Epoch: 62: Eval results *****
2025-04-16 19:59:08,200 -   train_loss = 2.092768601008824
2025-04-16 19:59:28,958 - ***** Epoch: 63: Eval results *****
2025-04-16 19:59:28,959 -   train_loss = 2.0757379361561368
2025-04-16 19:59:50,109 - ***** Epoch: 64: Eval results *****
2025-04-16 19:59:50,109 -   train_loss = 2.0730087075914656
2025-04-16 20:00:10,272 - ***** Epoch: 65: Eval results *****
2025-04-16 20:00:10,272 -   train_loss = 2.047907761165074
2025-04-16 20:00:30,565 - ***** Epoch: 66: Eval results *****
2025-04-16 20:00:30,565 -   train_loss = 2.061803902898516
2025-04-16 20:00:49,968 - ***** Epoch: 67: Eval results *****
2025-04-16 20:00:49,968 -   train_loss = 2.0479994671685353
2025-04-16 20:01:13,464 - ***** Epoch: 68: Eval results *****
2025-04-16 20:01:13,464 -   train_loss = 2.0411464997700284
2025-04-16 20:01:34,960 - ***** Epoch: 69: Eval results *****
2025-04-16 20:01:34,961 -   train_loss = 2.034091753619058
2025-04-16 20:01:56,856 - ***** Epoch: 70: Eval results *****
2025-04-16 20:01:56,856 -   train_loss = 2.0381351028169905
2025-04-16 20:02:18,398 - ***** Epoch: 71: Eval results *****
2025-04-16 20:02:18,398 -   train_loss = 2.0137691157204762
2025-04-16 20:02:39,402 - ***** Epoch: 72: Eval results *****
2025-04-16 20:02:39,403 -   train_loss = 2.003820870603834
2025-04-16 20:02:58,808 - ***** Epoch: 73: Eval results *****
2025-04-16 20:02:58,809 -   train_loss = 2.0160652909960066
2025-04-16 20:03:20,073 - ***** Epoch: 74: Eval results *****
2025-04-16 20:03:20,074 -   train_loss = 2.0138971294675554
2025-04-16 20:03:39,738 - ***** Epoch: 75: Eval results *****
2025-04-16 20:03:39,738 -   train_loss = 1.9999159574508667
2025-04-16 20:04:01,265 - ***** Epoch: 76: Eval results *****
2025-04-16 20:04:01,265 -   train_loss = 1.9954732060432434
2025-04-16 20:04:25,258 - ***** Epoch: 77: Eval results *****
2025-04-16 20:04:25,258 -   train_loss = 1.9809682539531164
2025-04-16 20:04:47,189 - ***** Epoch: 78: Eval results *****
2025-04-16 20:04:47,189 -   train_loss = 1.9771834697042192
2025-04-16 20:05:09,652 - ***** Epoch: 79: Eval results *****
2025-04-16 20:05:09,652 -   train_loss = 1.9835203289985657
2025-04-16 20:05:31,090 - ***** Epoch: 80: Eval results *****
2025-04-16 20:05:31,091 -   train_loss = 1.9913218872887748
2025-04-16 20:05:52,638 - ***** Epoch: 81: Eval results *****
2025-04-16 20:05:52,639 -   train_loss = 1.9709776129041399
2025-04-16 20:06:14,772 - ***** Epoch: 82: Eval results *****
2025-04-16 20:06:14,772 -   train_loss = 1.9614349177905492
2025-04-16 20:06:36,122 - ***** Epoch: 83: Eval results *****
2025-04-16 20:06:36,122 -   train_loss = 1.972920494420188
2025-04-16 20:06:58,323 - ***** Epoch: 84: Eval results *****
2025-04-16 20:06:58,323 -   train_loss = 1.9912020223481315
2025-04-16 20:07:23,297 - ***** Epoch: 85: Eval results *****
2025-04-16 20:07:23,297 -   train_loss = 1.9646973269326347
2025-04-16 20:07:45,748 - ***** Epoch: 86: Eval results *****
2025-04-16 20:07:45,748 -   train_loss = 1.9689936552728926
2025-04-16 20:08:06,631 - ***** Epoch: 87: Eval results *****
2025-04-16 20:08:06,631 -   train_loss = 1.9638248511723109
2025-04-16 20:08:26,729 - ***** Epoch: 88: Eval results *****
2025-04-16 20:08:26,729 -   train_loss = 1.9662342752729143
2025-04-16 20:08:47,652 - ***** Epoch: 89: Eval results *****
2025-04-16 20:08:47,652 -   train_loss = 1.9694393617766244
2025-04-16 20:09:07,957 - ***** Epoch: 90: Eval results *****
2025-04-16 20:09:07,958 -   train_loss = 1.9658488460949488
2025-04-16 20:09:31,362 - ***** Epoch: 91: Eval results *****
2025-04-16 20:09:31,362 -   train_loss = 1.9602180549076624
2025-04-16 20:09:54,137 - ***** Epoch: 92: Eval results *****
2025-04-16 20:09:54,137 -   train_loss = 1.9634886809757777
2025-04-16 20:10:16,271 - ***** Epoch: 93: Eval results *****
2025-04-16 20:10:16,271 -   train_loss = 1.974285134247371
2025-04-16 20:10:39,052 - ***** Epoch: 94: Eval results *****
2025-04-16 20:10:39,052 -   train_loss = 1.9703436579023088
2025-04-16 20:11:03,573 - ***** Epoch: 95: Eval results *****
2025-04-16 20:11:03,573 -   train_loss = 1.9607723951339722
2025-04-16 20:11:24,677 - ***** Epoch: 96: Eval results *****
2025-04-16 20:11:24,678 -   train_loss = 1.9694927079336983
2025-04-16 20:11:44,387 - ***** Epoch: 97: Eval results *****
2025-04-16 20:11:44,387 -   train_loss = 1.986294788973672
2025-04-16 20:12:03,981 - ***** Epoch: 98: Eval results *****
2025-04-16 20:12:03,981 -   train_loss = 1.9570960317339217
2025-04-16 20:12:25,820 - ***** Epoch: 99: Eval results *****
2025-04-16 20:12:25,821 -   train_loss = 1.967688832964216
2025-04-16 20:12:46,493 - ***** Epoch: 100: Eval results *****
2025-04-16 20:12:46,493 -   train_loss = 1.9654406820024763
2025-04-16 20:12:48,109 - Pre-training finished...
2025-04-16 20:12:48,474 - Freeze all parameters but the last layer for efficiency
2025-04-16 20:12:48,484 - Multimodal Intent Recognition begins...
2025-04-16 20:12:48,484 - Training begins...
2025-04-16 20:13:06,229 - Initializing centroids with K-means++...
2025-04-16 20:13:06,331 - K-means++ used 0.1 s
2025-04-16 20:13:42,208 - K-means used 0.04 s
2025-04-16 20:13:44,022 - ***** Epoch: 1 *****
2025-04-16 20:13:44,023 - Supervised Training Loss: 4.355320
2025-04-16 20:13:44,024 - Unsupervised Training Loss: 5.566450
2025-04-16 20:14:24,561 - K-means used 0.02 s
2025-04-16 20:14:26,238 - ***** Epoch: 2 *****
2025-04-16 20:14:26,238 - Supervised Training Loss: 4.974110
2025-04-16 20:14:26,239 - Unsupervised Training Loss: 5.582400
2025-04-16 20:15:01,797 - K-means used 0.05 s
2025-04-16 20:15:03,255 - ***** Epoch: 3 *****
2025-04-16 20:15:03,255 - Supervised Training Loss: 4.738540
2025-04-16 20:15:03,255 - Unsupervised Training Loss: 5.434670
2025-04-16 20:15:38,538 - K-means used 0.02 s
2025-04-16 20:15:40,501 - ***** Epoch: 4 *****
2025-04-16 20:15:40,501 - Supervised Training Loss: 4.562060
2025-04-16 20:15:40,501 - Unsupervised Training Loss: 5.493470
2025-04-16 20:16:16,310 - K-means used 0.1 s
2025-04-16 20:16:18,141 - ***** Epoch: 5 *****
2025-04-16 20:16:18,141 - Supervised Training Loss: 4.241740
2025-04-16 20:16:18,141 - Unsupervised Training Loss: 5.535090
2025-04-16 20:16:53,737 - K-means used 0.02 s
2025-04-16 20:16:55,830 - ***** Epoch: 6 *****
2025-04-16 20:16:55,830 - Supervised Training Loss: 4.664150
2025-04-16 20:16:55,830 - Unsupervised Training Loss: 5.323460
2025-04-16 20:17:32,699 - K-means used 0.1 s
2025-04-16 20:17:35,624 - ***** Epoch: 7 *****
2025-04-16 20:17:35,624 - Supervised Training Loss: 4.561560
2025-04-16 20:17:35,624 - Unsupervised Training Loss: 5.447270
2025-04-16 20:18:12,413 - K-means used 0.03 s
2025-04-16 20:18:14,127 - ***** Epoch: 8 *****
2025-04-16 20:18:14,127 - Supervised Training Loss: 4.414900
2025-04-16 20:18:14,127 - Unsupervised Training Loss: 5.504260
2025-04-16 20:18:49,614 - K-means used 0.04 s
2025-04-16 20:18:51,590 - ***** Epoch: 9 *****
2025-04-16 20:18:51,590 - Supervised Training Loss: 4.641660
2025-04-16 20:18:51,590 - Unsupervised Training Loss: 5.547980
2025-04-16 20:19:27,649 - K-means used 0.02 s
2025-04-16 20:19:29,587 - ***** Epoch: 10 *****
2025-04-16 20:19:29,587 - Supervised Training Loss: 4.581540
2025-04-16 20:19:29,587 - Unsupervised Training Loss: 5.390460
2025-04-16 20:20:04,208 - K-means used 0.04 s
2025-04-16 20:20:06,102 - ***** Epoch: 11 *****
2025-04-16 20:20:06,102 - Supervised Training Loss: 4.505230
2025-04-16 20:20:06,102 - Unsupervised Training Loss: 5.464970
2025-04-16 20:20:40,775 - K-means used 0.03 s
2025-04-16 20:20:42,930 - ***** Epoch: 12 *****
2025-04-16 20:20:42,931 - Supervised Training Loss: 4.645120
2025-04-16 20:20:42,931 - Unsupervised Training Loss: 5.534470
2025-04-16 20:21:21,318 - K-means used 0.02 s
2025-04-16 20:21:23,155 - ***** Epoch: 13 *****
2025-04-16 20:21:23,156 - Supervised Training Loss: 4.605680
2025-04-16 20:21:23,156 - Unsupervised Training Loss: 5.265260
2025-04-16 20:21:58,732 - K-means used 0.07 s
2025-04-16 20:22:00,933 - ***** Epoch: 14 *****
2025-04-16 20:22:00,933 - Supervised Training Loss: 4.570850
2025-04-16 20:22:00,933 - Unsupervised Training Loss: 5.386350
2025-04-16 20:22:36,397 - K-means used 0.03 s
2025-04-16 20:22:38,902 - ***** Epoch: 15 *****
2025-04-16 20:22:38,902 - Supervised Training Loss: 4.433970
2025-04-16 20:22:38,902 - Unsupervised Training Loss: 5.494660
2025-04-16 20:23:14,602 - K-means used 0.02 s
2025-04-16 20:23:17,251 - ***** Epoch: 16 *****
2025-04-16 20:23:17,251 - Supervised Training Loss: 4.655650
2025-04-16 20:23:17,251 - Unsupervised Training Loss: 4.968870
2025-04-16 20:23:51,911 - K-means used 0.03 s
2025-04-16 20:23:54,097 - ***** Epoch: 17 *****
2025-04-16 20:23:54,097 - Supervised Training Loss: 4.640080
2025-04-16 20:23:54,097 - Unsupervised Training Loss: 5.168610
2025-04-16 20:24:22,507 - Training is finished...
2025-04-16 20:24:22,508 - Testing begins...
2025-04-16 20:24:30,941 - ***** Test results *****
2025-04-16 20:24:30,941 -   ACC = 38.2
2025-04-16 20:24:30,941 -   ARI = 19.35
2025-04-16 20:24:30,941 -   NMI = 44.38
2025-04-16 20:24:30,942 -   fmi = 24.39
2025-04-16 20:24:30,942 - Testing is finished...
2025-04-16 20:24:30,942 - Multimodal intent recognition is finished...
2025-04-16 20:24:30,942 - Results are saved in results/results_umc.csv
