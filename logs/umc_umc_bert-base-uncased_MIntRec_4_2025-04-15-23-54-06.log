2025-04-15 23:54:06,414 - 进入了无监督的设定中, 加载数据集
2025-04-15 23:54:06,414 - data preparation...
2025-04-15 23:54:15,209 - Number of train samples = 1779
2025-04-15 23:54:15,210 - Number of testing samples = 445
2025-04-15 23:54:15,210 - data preparation...
2025-04-15 23:54:17,434 - num_train_examples = 1779
2025-04-15 23:54:17,434 - ============================== Params ==============================
2025-04-15 23:54:17,434 - logger_name: umc_umc_bert-base-uncased_MIntRec_4
2025-04-15 23:54:17,434 - dataset: MIntRec
2025-04-15 23:54:17,434 - multimodal_method: umc
2025-04-15 23:54:17,434 - method: umc
2025-04-15 23:54:17,434 - setting: unsupervised
2025-04-15 23:54:17,434 - text_backbone: bert-base-uncased
2025-04-15 23:54:17,434 - seed: 4
2025-04-15 23:54:17,435 - num_workers: 16
2025-04-15 23:54:17,435 - log_id: umc_umc_bert-base-uncased_MIntRec_4_2025-04-15-23-54-06
2025-04-15 23:54:17,435 - gpu_id: 1
2025-04-15 23:54:17,435 - data_path: /root/autodl-tmp/home/Share/Dataset/LZH
2025-04-15 23:54:17,435 - train: True
2025-04-15 23:54:17,435 - tune: True
2025-04-15 23:54:17,435 - save_model: True
2025-04-15 23:54:17,435 - save_results: True
2025-04-15 23:54:17,435 - log_path: logs
2025-04-15 23:54:17,435 - cache_path: cache
2025-04-15 23:54:17,435 - video_data_path: video_data
2025-04-15 23:54:17,435 - audio_data_path: audio_data
2025-04-15 23:54:17,435 - video_feats_path: swin_feats.pkl
2025-04-15 23:54:17,435 - audio_feats_path: wavlm_feats.pkl
2025-04-15 23:54:17,436 - results_path: results
2025-04-15 23:54:17,436 - output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/SMC/outputs_test/MIntRec
2025-04-15 23:54:17,436 - model_path: models
2025-04-15 23:54:17,436 - config_file_name: umc_MIntRec
2025-04-15 23:54:17,436 - results_file_name: results_umc.csv
2025-04-15 23:54:17,436 - text_pretrained_model: uncased_L-12_H-768_A-12
2025-04-15 23:54:17,436 - pretrained_bert_model: uncased_L-12_H-768_A-12
2025-04-15 23:54:17,436 - pretrain_batch_size: 128
2025-04-15 23:54:17,436 - train_batch_size: 128
2025-04-15 23:54:17,436 - eval_batch_size: 128
2025-04-15 23:54:17,436 - test_batch_size: 128
2025-04-15 23:54:17,436 - num_pretrain_epochs: 100
2025-04-15 23:54:17,436 - num_train_epochs: 100
2025-04-15 23:54:17,436 - pretrain: [True]
2025-04-15 23:54:17,436 - aligned_method: ctc
2025-04-15 23:54:17,436 - need_aligned: False
2025-04-15 23:54:17,436 - freeze_pretrain_bert_parameters: [True]
2025-04-15 23:54:17,436 - freeze_train_bert_parameters: [True]
2025-04-15 23:54:17,436 - pretrain_temperature: [0.1]
2025-04-15 23:54:17,436 - train_temperature_sup: [0.5, 1, 2, 4, 6, 8]
2025-04-15 23:54:17,436 - train_temperature_unsup: [0.5, 1, 2, 4, 6, 8]
2025-04-15 23:54:17,436 - activation: tanh
2025-04-15 23:54:17,436 - lr_pre: 1e-05
2025-04-15 23:54:17,436 - lr: [0.0001]
2025-04-15 23:54:17,436 - delta: [0.05]
2025-04-15 23:54:17,436 - thres: [0.1]
2025-04-15 23:54:17,436 - topk: [5]
2025-04-15 23:54:17,437 - weight_decay: 0.01
2025-04-15 23:54:17,437 - feat_dim: 768
2025-04-15 23:54:17,437 - hidden_size: 768
2025-04-15 23:54:17,437 - grad_clip: -1.0
2025-04-15 23:54:17,437 - warmup_proportion: 0.5
2025-04-15 23:54:17,437 - hidden_dropout_prob: 0.1
2025-04-15 23:54:17,437 - weight: 1.0
2025-04-15 23:54:17,437 - loss_mode: rdrop
2025-04-15 23:54:17,437 - base_dim: 256
2025-04-15 23:54:17,437 - nheads: 8
2025-04-15 23:54:17,437 - attn_dropout: 0.1
2025-04-15 23:54:17,437 - relu_dropout: 0.1
2025-04-15 23:54:17,437 - embed_dropout: 0.01
2025-04-15 23:54:17,437 - res_dropout: 0.0
2025-04-15 23:54:17,437 - attn_mask: True
2025-04-15 23:54:17,437 - encoder_layers_1: 1
2025-04-15 23:54:17,437 - fusion_act: tanh
2025-04-15 23:54:17,437 - pred_output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/SMC/outputs_test/MIntRec/umc_umc_MIntRec_bert-base-uncased_4
2025-04-15 23:54:17,437 - model_output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/SMC/outputs_test/MIntRec/umc_umc_MIntRec_bert-base-uncased_4/models
2025-04-15 23:54:17,437 - text_seq_len: 30
2025-04-15 23:54:17,437 - video_seq_len: 230
2025-04-15 23:54:17,437 - audio_seq_len: 480
2025-04-15 23:54:17,437 - text_feat_dim: 768
2025-04-15 23:54:17,437 - video_feat_dim: 1024
2025-04-15 23:54:17,437 - audio_feat_dim: 768
2025-04-15 23:54:17,437 - num_train_examples: 1779
2025-04-15 23:54:17,437 - ============================== End Params ==============================
2025-04-15 23:54:18,724 - Freeze all parameters but the last layer for efficiency
2025-04-15 23:54:18,761 - Pre-training start...
2025-04-15 23:54:35,120 - ***** Epoch: 1: Eval results *****
2025-04-15 23:54:35,120 -   train_loss = 5.970648084368024
2025-04-15 23:54:52,188 - ***** Epoch: 2: Eval results *****
2025-04-15 23:54:52,188 -   train_loss = 5.966461079461234
2025-04-15 23:55:09,094 - ***** Epoch: 3: Eval results *****
2025-04-15 23:55:09,094 -   train_loss = 5.965302569525583
2025-04-15 23:55:25,012 - ***** Epoch: 4: Eval results *****
2025-04-15 23:55:25,013 -   train_loss = 5.961013828005109
2025-04-15 23:55:41,741 - ***** Epoch: 5: Eval results *****
2025-04-15 23:55:41,742 -   train_loss = 5.962399448667254
2025-04-15 23:55:58,700 - ***** Epoch: 6: Eval results *****
2025-04-15 23:55:58,700 -   train_loss = 5.964002370834351
2025-04-15 23:56:15,625 - ***** Epoch: 7: Eval results *****
2025-04-15 23:56:15,625 -   train_loss = 5.956438950129917
2025-04-15 23:56:32,490 - ***** Epoch: 8: Eval results *****
2025-04-15 23:56:32,490 -   train_loss = 5.952266080038888
2025-04-15 23:56:49,554 - ***** Epoch: 9: Eval results *****
2025-04-15 23:56:49,554 -   train_loss = 5.946320056915283
2025-04-15 23:57:06,418 - ***** Epoch: 10: Eval results *****
2025-04-15 23:57:06,419 -   train_loss = 5.94390252658299
2025-04-15 23:57:23,355 - ***** Epoch: 11: Eval results *****
2025-04-15 23:57:23,355 -   train_loss = 5.934671810695103
2025-04-15 23:57:40,009 - ***** Epoch: 12: Eval results *****
2025-04-15 23:57:40,009 -   train_loss = 5.9290120261056085
2025-04-15 23:57:56,298 - ***** Epoch: 13: Eval results *****
2025-04-15 23:57:56,298 -   train_loss = 5.922977651868548
2025-04-15 23:58:13,530 - ***** Epoch: 14: Eval results *****
2025-04-15 23:58:13,530 -   train_loss = 5.913618734904698
2025-04-15 23:58:30,102 - ***** Epoch: 15: Eval results *****
2025-04-15 23:58:30,102 -   train_loss = 5.885918855667114
2025-04-15 23:58:47,179 - ***** Epoch: 16: Eval results *****
2025-04-15 23:58:47,179 -   train_loss = 5.866542032786778
2025-04-15 23:59:05,255 - ***** Epoch: 17: Eval results *****
2025-04-15 23:59:05,256 -   train_loss = 5.822826521737235
2025-04-15 23:59:23,993 - ***** Epoch: 18: Eval results *****
2025-04-15 23:59:23,993 -   train_loss = 5.7407021181924005
2025-04-15 23:59:42,847 - ***** Epoch: 19: Eval results *****
2025-04-15 23:59:42,847 -   train_loss = 5.642508677073887
2025-04-16 00:00:02,007 - ***** Epoch: 20: Eval results *****
2025-04-16 00:00:02,008 -   train_loss = 5.472390208925519
2025-04-16 00:00:19,922 - ***** Epoch: 21: Eval results *****
2025-04-16 00:00:19,923 -   train_loss = 5.229619230542864
2025-04-16 00:00:37,359 - ***** Epoch: 22: Eval results *****
2025-04-16 00:00:37,359 -   train_loss = 4.955741507666452
2025-04-16 00:00:54,841 - ***** Epoch: 23: Eval results *****
2025-04-16 00:00:54,841 -   train_loss = 4.683956146240234
2025-04-16 00:01:12,453 - ***** Epoch: 24: Eval results *****
2025-04-16 00:01:12,453 -   train_loss = 4.425085612705776
2025-04-16 00:01:29,690 - ***** Epoch: 25: Eval results *****
2025-04-16 00:01:29,691 -   train_loss = 4.114185895238604
2025-04-16 00:01:46,903 - ***** Epoch: 26: Eval results *****
2025-04-16 00:01:46,903 -   train_loss = 3.8869088206972395
2025-04-16 00:02:04,100 - ***** Epoch: 27: Eval results *****
2025-04-16 00:02:04,101 -   train_loss = 3.6783997331346785
2025-04-16 00:02:21,361 - ***** Epoch: 28: Eval results *****
2025-04-16 00:02:21,362 -   train_loss = 3.4911667619432722
2025-04-16 00:02:38,117 - ***** Epoch: 29: Eval results *****
2025-04-16 00:02:38,117 -   train_loss = 3.3222072465079173
2025-04-16 00:02:54,430 - ***** Epoch: 30: Eval results *****
2025-04-16 00:02:54,431 -   train_loss = 3.1734438283102855
2025-04-16 00:03:11,259 - ***** Epoch: 31: Eval results *****
2025-04-16 00:03:11,259 -   train_loss = 3.0303382192339217
2025-04-16 00:03:27,936 - ***** Epoch: 32: Eval results *****
2025-04-16 00:03:27,937 -   train_loss = 2.9039022752216885
2025-04-16 00:03:44,280 - ***** Epoch: 33: Eval results *****
2025-04-16 00:03:44,280 -   train_loss = 2.7921715804508755
2025-04-16 00:04:00,708 - ***** Epoch: 34: Eval results *****
2025-04-16 00:04:00,709 -   train_loss = 2.6812032801764354
2025-04-16 00:04:17,437 - ***** Epoch: 35: Eval results *****
2025-04-16 00:04:17,437 -   train_loss = 2.577368770326887
2025-04-16 00:04:33,959 - ***** Epoch: 36: Eval results *****
2025-04-16 00:04:33,959 -   train_loss = 2.4790665933064053
2025-04-16 00:04:51,155 - ***** Epoch: 37: Eval results *****
2025-04-16 00:04:51,156 -   train_loss = 2.418008736201695
2025-04-16 00:05:07,831 - ***** Epoch: 38: Eval results *****
2025-04-16 00:05:07,831 -   train_loss = 2.3388369253703525
2025-04-16 00:05:25,018 - ***** Epoch: 39: Eval results *****
2025-04-16 00:05:25,018 -   train_loss = 2.262122597013201
2025-04-16 00:05:41,757 - ***** Epoch: 40: Eval results *****
2025-04-16 00:05:41,757 -   train_loss = 2.2209037031446184
2025-04-16 00:05:59,117 - ***** Epoch: 41: Eval results *****
2025-04-16 00:05:59,118 -   train_loss = 2.167987278529576
2025-04-16 00:06:19,595 - ***** Epoch: 42: Eval results *****
2025-04-16 00:06:19,596 -   train_loss = 2.134170753615243
2025-04-16 00:06:40,854 - ***** Epoch: 43: Eval results *****
2025-04-16 00:06:40,855 -   train_loss = 2.0601467745644704
2025-04-16 00:06:59,345 - ***** Epoch: 44: Eval results *****
2025-04-16 00:06:59,346 -   train_loss = 2.0201016664505005
2025-04-16 00:07:17,230 - ***** Epoch: 45: Eval results *****
2025-04-16 00:07:17,231 -   train_loss = 1.9903226069041662
2025-04-16 00:07:34,730 - ***** Epoch: 46: Eval results *****
2025-04-16 00:07:34,730 -   train_loss = 1.9536106160708837
2025-04-16 00:07:51,950 - ***** Epoch: 47: Eval results *****
2025-04-16 00:07:51,950 -   train_loss = 1.9013313480785914
2025-04-16 00:08:09,080 - ***** Epoch: 48: Eval results *****
2025-04-16 00:08:09,081 -   train_loss = 1.8772331731660026
2025-04-16 00:08:26,049 - ***** Epoch: 49: Eval results *****
2025-04-16 00:08:26,050 -   train_loss = 1.8333850758416312
2025-04-16 00:08:43,046 - ***** Epoch: 50: Eval results *****
2025-04-16 00:08:43,046 -   train_loss = 1.8072478515761239
2025-04-16 00:09:00,032 - ***** Epoch: 51: Eval results *****
2025-04-16 00:09:00,032 -   train_loss = 1.7838449563298906
2025-04-16 00:09:17,093 - ***** Epoch: 52: Eval results *****
2025-04-16 00:09:17,094 -   train_loss = 1.7465388349124364
2025-04-16 00:09:34,414 - ***** Epoch: 53: Eval results *****
2025-04-16 00:09:34,414 -   train_loss = 1.725121293749128
2025-04-16 00:09:51,298 - ***** Epoch: 54: Eval results *****
2025-04-16 00:09:51,298 -   train_loss = 1.711163078035627
2025-04-16 00:10:07,937 - ***** Epoch: 55: Eval results *****
2025-04-16 00:10:07,938 -   train_loss = 1.6726623262677873
2025-04-16 00:10:24,896 - ***** Epoch: 56: Eval results *****
2025-04-16 00:10:24,896 -   train_loss = 1.680017420223781
2025-04-16 00:10:41,957 - ***** Epoch: 57: Eval results *****
2025-04-16 00:10:41,958 -   train_loss = 1.6551468457494463
2025-04-16 00:10:58,454 - ***** Epoch: 58: Eval results *****
2025-04-16 00:10:58,455 -   train_loss = 1.6328698907579695
2025-04-16 00:11:14,994 - ***** Epoch: 59: Eval results *****
2025-04-16 00:11:14,994 -   train_loss = 1.624602837221963
2025-04-16 00:11:31,521 - ***** Epoch: 60: Eval results *****
2025-04-16 00:11:31,521 -   train_loss = 1.61013948065894
2025-04-16 00:11:48,836 - ***** Epoch: 61: Eval results *****
2025-04-16 00:11:48,837 -   train_loss = 1.5860641258103507
2025-04-16 00:12:06,148 - ***** Epoch: 62: Eval results *****
2025-04-16 00:12:06,149 -   train_loss = 1.5950971245765686
2025-04-16 00:12:23,042 - ***** Epoch: 63: Eval results *****
2025-04-16 00:12:23,042 -   train_loss = 1.5782367842538017
2025-04-16 00:12:39,843 - ***** Epoch: 64: Eval results *****
2025-04-16 00:12:39,844 -   train_loss = 1.5496331368173872
2025-04-16 00:12:59,272 - ***** Epoch: 65: Eval results *****
2025-04-16 00:12:59,273 -   train_loss = 1.5445579971585954
2025-04-16 00:13:17,197 - ***** Epoch: 66: Eval results *****
2025-04-16 00:13:17,197 -   train_loss = 1.5389006989342826
2025-04-16 00:13:34,898 - ***** Epoch: 67: Eval results *****
2025-04-16 00:13:34,899 -   train_loss = 1.5336969324520655
2025-04-16 00:13:52,253 - ***** Epoch: 68: Eval results *****
2025-04-16 00:13:52,253 -   train_loss = 1.5168768082346236
2025-04-16 00:14:08,635 - ***** Epoch: 69: Eval results *****
2025-04-16 00:14:08,635 -   train_loss = 1.4933493052210127
2025-04-16 00:14:24,708 - ***** Epoch: 70: Eval results *****
2025-04-16 00:14:24,709 -   train_loss = 1.5009931240762984
2025-04-16 00:14:40,440 - ***** Epoch: 71: Eval results *****
2025-04-16 00:14:40,441 -   train_loss = 1.5056630628449577
2025-04-16 00:14:57,233 - ***** Epoch: 72: Eval results *****
2025-04-16 00:14:57,233 -   train_loss = 1.501506473336901
2025-04-16 00:15:14,506 - ***** Epoch: 73: Eval results *****
2025-04-16 00:15:14,506 -   train_loss = 1.4950505239622933
2025-04-16 00:15:31,869 - ***** Epoch: 74: Eval results *****
2025-04-16 00:15:31,869 -   train_loss = 1.4911161320550101
2025-04-16 00:15:48,988 - ***** Epoch: 75: Eval results *****
2025-04-16 00:15:48,988 -   train_loss = 1.4811289480754308
2025-04-16 00:16:06,396 - ***** Epoch: 76: Eval results *****
2025-04-16 00:16:06,397 -   train_loss = 1.48939448595047
2025-04-16 00:16:23,073 - ***** Epoch: 77: Eval results *****
2025-04-16 00:16:23,073 -   train_loss = 1.4780304431915283
2025-04-16 00:16:39,385 - ***** Epoch: 78: Eval results *****
2025-04-16 00:16:39,385 -   train_loss = 1.480181804725102
2025-04-16 00:16:55,736 - ***** Epoch: 79: Eval results *****
2025-04-16 00:16:55,736 -   train_loss = 1.4671125667435783
2025-04-16 00:17:11,502 - ***** Epoch: 80: Eval results *****
2025-04-16 00:17:11,503 -   train_loss = 1.4607499752725874
2025-04-16 00:17:27,293 - ***** Epoch: 81: Eval results *****
2025-04-16 00:17:27,294 -   train_loss = 1.4580600091389246
2025-04-16 00:17:43,381 - ***** Epoch: 82: Eval results *****
2025-04-16 00:17:43,381 -   train_loss = 1.4527483071599687
2025-04-16 00:17:59,782 - ***** Epoch: 83: Eval results *****
2025-04-16 00:17:59,782 -   train_loss = 1.4581644364765711
2025-04-16 00:18:16,466 - ***** Epoch: 84: Eval results *****
2025-04-16 00:18:16,466 -   train_loss = 1.4521907312529427
2025-04-16 00:18:32,701 - ***** Epoch: 85: Eval results *****
2025-04-16 00:18:32,701 -   train_loss = 1.4468951991626195
2025-04-16 00:18:48,965 - ***** Epoch: 86: Eval results *****
2025-04-16 00:18:48,965 -   train_loss = 1.4407719458852495
2025-04-16 00:19:05,295 - ***** Epoch: 87: Eval results *****
2025-04-16 00:19:05,295 -   train_loss = 1.4412515248571123
2025-04-16 00:19:21,372 - ***** Epoch: 88: Eval results *****
2025-04-16 00:19:21,372 -   train_loss = 1.4458748527935572
2025-04-16 00:19:37,002 - ***** Epoch: 89: Eval results *****
2025-04-16 00:19:37,002 -   train_loss = 1.4527638469423567
2025-04-16 00:19:52,318 - ***** Epoch: 90: Eval results *****
2025-04-16 00:19:52,319 -   train_loss = 1.444801492350442
2025-04-16 00:20:08,775 - ***** Epoch: 91: Eval results *****
2025-04-16 00:20:08,775 -   train_loss = 1.4313005294118608
2025-04-16 00:20:25,503 - ***** Epoch: 92: Eval results *****
2025-04-16 00:20:25,503 -   train_loss = 1.4385235224451338
2025-04-16 00:20:42,576 - ***** Epoch: 93: Eval results *****
2025-04-16 00:20:42,577 -   train_loss = 1.4401353597640991
2025-04-16 00:20:59,733 - ***** Epoch: 94: Eval results *****
2025-04-16 00:20:59,733 -   train_loss = 1.4438101393835885
2025-04-16 00:21:16,770 - ***** Epoch: 95: Eval results *****
2025-04-16 00:21:16,770 -   train_loss = 1.4387265699250358
2025-04-16 00:21:32,764 - ***** Epoch: 96: Eval results *****
2025-04-16 00:21:32,764 -   train_loss = 1.432632429259164
2025-04-16 00:21:49,290 - ***** Epoch: 97: Eval results *****
2025-04-16 00:21:49,290 -   train_loss = 1.4412085158484322
2025-04-16 00:22:05,559 - ***** Epoch: 98: Eval results *****
2025-04-16 00:22:05,559 -   train_loss = 1.442799951348986
2025-04-16 00:22:22,022 - ***** Epoch: 99: Eval results *****
2025-04-16 00:22:22,022 -   train_loss = 1.448082217148372
2025-04-16 00:22:38,289 - ***** Epoch: 100: Eval results *****
2025-04-16 00:22:38,290 -   train_loss = 1.4440207736832755
2025-04-16 00:22:38,872 - Pre-training finished...
