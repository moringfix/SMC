2025-04-11 12:46:29,327 - ============================== Params ==============================
2025-04-11 12:46:29,327 - logger_name: umc_umc_bert-base-uncased_MIntRec_3
2025-04-11 12:46:29,327 - dataset: MIntRec
2025-04-11 12:46:29,327 - multimodal_method: umc
2025-04-11 12:46:29,327 - method: umc
2025-04-11 12:46:29,327 - text_backbone: bert-base-uncased
2025-04-11 12:46:29,328 - seed: 3
2025-04-11 12:46:29,328 - num_workers: 16
2025-04-11 12:46:29,328 - log_id: umc_umc_bert-base-uncased_MIntRec_3_2025-04-11-12-46-29
2025-04-11 12:46:29,328 - gpu_id: 0
2025-04-11 12:46:29,328 - data_path: /root/autodl-tmp/home/Share/Dataset/LZH
2025-04-11 12:46:29,328 - train: True
2025-04-11 12:46:29,328 - tune: True
2025-04-11 12:46:29,328 - save_model: True
2025-04-11 12:46:29,328 - save_results: True
2025-04-11 12:46:29,328 - log_path: logs
2025-04-11 12:46:29,328 - cache_path: cache
2025-04-11 12:46:29,328 - video_data_path: video_data
2025-04-11 12:46:29,328 - audio_data_path: audio_data
2025-04-11 12:46:29,328 - video_feats_path: swin_feats.pkl
2025-04-11 12:46:29,328 - audio_feats_path: wavlm_feats.pkl
2025-04-11 12:46:29,328 - results_path: results
2025-04-11 12:46:29,328 - output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/UMC/outputs/MIntRec
2025-04-11 12:46:29,328 - model_path: models
2025-04-11 12:46:29,328 - config_file_name: umc_MIntRec
2025-04-11 12:46:29,328 - results_file_name: results_umc.csv
2025-04-11 12:46:29,328 - text_pretrained_model: uncased_L-12_H-768_A-12
2025-04-11 12:46:29,328 - text_seq_len: 30
2025-04-11 12:46:29,328 - video_seq_len: 230
2025-04-11 12:46:29,328 - audio_seq_len: 480
2025-04-11 12:46:29,328 - text_feat_dim: 768
2025-04-11 12:46:29,328 - video_feat_dim: 1024
2025-04-11 12:46:29,328 - audio_feat_dim: 768
2025-04-11 12:46:29,328 - num_labels: 20
2025-04-11 12:46:29,328 - num_train_examples: 1779
2025-04-11 12:46:29,329 - pretrained_bert_model: uncased_L-12_H-768_A-12
2025-04-11 12:46:29,329 - pretrain_batch_size: 128
2025-04-11 12:46:29,329 - train_batch_size: 128
2025-04-11 12:46:29,329 - eval_batch_size: 128
2025-04-11 12:46:29,329 - test_batch_size: 128
2025-04-11 12:46:29,329 - num_pretrain_epochs: 100
2025-04-11 12:46:29,329 - num_train_epochs: 100
2025-04-11 12:46:29,329 - pretrain: [True]
2025-04-11 12:46:29,329 - aligned_method: ctc
2025-04-11 12:46:29,329 - need_aligned: False
2025-04-11 12:46:29,329 - freeze_pretrain_bert_parameters: [True]
2025-04-11 12:46:29,329 - freeze_train_bert_parameters: [True]
2025-04-11 12:46:29,329 - pretrain_temperature: [0.2]
2025-04-11 12:46:29,329 - train_temperature_sup: [1.4]
2025-04-11 12:46:29,329 - train_temperature_unsup: [1]
2025-04-11 12:46:29,329 - activation: tanh
2025-04-11 12:46:29,329 - lr_pre: 1e-05
2025-04-11 12:46:29,329 - lr: [0.0003]
2025-04-11 12:46:29,329 - delta: [0.05]
2025-04-11 12:46:29,329 - thres: [0.1]
2025-04-11 12:46:29,329 - topk: [5]
2025-04-11 12:46:29,329 - weight_decay: 0.01
2025-04-11 12:46:29,329 - feat_dim: 768
2025-04-11 12:46:29,329 - hidden_size: 768
2025-04-11 12:46:29,329 - grad_clip: -1.0
2025-04-11 12:46:29,329 - warmup_proportion: 0.5
2025-04-11 12:46:29,329 - hidden_dropout_prob: 0.1
2025-04-11 12:46:29,329 - weight: 1.0
2025-04-11 12:46:29,329 - loss_mode: rdrop
2025-04-11 12:46:29,330 - base_dim: 256
2025-04-11 12:46:29,330 - nheads: 8
2025-04-11 12:46:29,330 - attn_dropout: 0.1
2025-04-11 12:46:29,330 - relu_dropout: 0.1
2025-04-11 12:46:29,330 - embed_dropout: 0.1
2025-04-11 12:46:29,330 - res_dropout: 0.0
2025-04-11 12:46:29,330 - attn_mask: True
2025-04-11 12:46:29,330 - encoder_layers_1: 1
2025-04-11 12:46:29,330 - fusion_act: tanh
2025-04-11 12:46:29,330 - pred_output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/UMC/outputs/MIntRec/umc_umc_MIntRec_bert-base-uncased_3
2025-04-11 12:46:29,330 - model_output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/UMC/outputs/MIntRec/umc_umc_MIntRec_bert-base-uncased_3/models
2025-04-11 12:46:29,330 - ============================== End Params ==============================
2025-04-11 12:46:30,481 - Freeze all parameters but the last layer for efficiency
2025-04-11 12:46:30,514 - Pre-training start...
2025-04-11 12:46:45,741 - ***** Epoch: 1: Eval results *****
2025-04-11 12:46:45,741 -   train_loss = 5.93780745778765
2025-04-11 12:47:00,467 - ***** Epoch: 2: Eval results *****
2025-04-11 12:47:00,468 -   train_loss = 5.939213139670236
2025-04-11 12:47:17,758 - ***** Epoch: 3: Eval results *****
2025-04-11 12:47:17,758 -   train_loss = 5.943105288914272
2025-04-11 12:47:35,712 - ***** Epoch: 4: Eval results *****
2025-04-11 12:47:35,712 -   train_loss = 5.939889771597726
2025-04-11 12:47:52,694 - ***** Epoch: 5: Eval results *****
2025-04-11 12:47:52,694 -   train_loss = 5.942364931106567
2025-04-11 12:48:10,234 - ***** Epoch: 6: Eval results *****
2025-04-11 12:48:10,234 -   train_loss = 5.9402996471949985
2025-04-11 12:48:27,031 - ***** Epoch: 7: Eval results *****
2025-04-11 12:48:27,031 -   train_loss = 5.939898354666574
2025-04-11 12:48:43,351 - ***** Epoch: 8: Eval results *****
2025-04-11 12:48:43,351 -   train_loss = 5.940016542162214
2025-04-11 12:48:59,757 - ***** Epoch: 9: Eval results *****
2025-04-11 12:48:59,757 -   train_loss = 5.93410199029105
2025-04-11 12:49:16,245 - ***** Epoch: 10: Eval results *****
2025-04-11 12:49:16,245 -   train_loss = 5.934543405260358
2025-04-11 12:49:32,156 - ***** Epoch: 11: Eval results *****
2025-04-11 12:49:32,156 -   train_loss = 5.934223549706595
2025-04-11 12:49:48,330 - ***** Epoch: 12: Eval results *****
2025-04-11 12:49:48,331 -   train_loss = 5.925655705588205
2025-04-11 12:50:05,049 - ***** Epoch: 13: Eval results *****
2025-04-11 12:50:05,049 -   train_loss = 5.927046912057059
2025-04-11 12:50:21,439 - ***** Epoch: 14: Eval results *****
2025-04-11 12:50:21,439 -   train_loss = 5.914844615118844
2025-04-11 12:50:37,665 - ***** Epoch: 15: Eval results *****
2025-04-11 12:50:37,665 -   train_loss = 5.904929195131574
2025-04-11 12:50:53,970 - ***** Epoch: 16: Eval results *****
2025-04-11 12:50:53,970 -   train_loss = 5.901663950511387
2025-04-11 12:51:09,669 - ***** Epoch: 17: Eval results *****
2025-04-11 12:51:09,669 -   train_loss = 5.876333100455148
2025-04-11 12:51:26,048 - ***** Epoch: 18: Eval results *****
2025-04-11 12:51:26,049 -   train_loss = 5.845142126083374
2025-04-11 12:51:41,896 - ***** Epoch: 19: Eval results *****
2025-04-11 12:51:41,897 -   train_loss = 5.807328871318272
2025-04-11 12:51:58,126 - ***** Epoch: 20: Eval results *****
2025-04-11 12:51:58,127 -   train_loss = 5.740199940545218
2025-04-11 12:52:14,805 - ***** Epoch: 21: Eval results *****
2025-04-11 12:52:14,805 -   train_loss = 5.626609291349139
2025-04-11 12:52:30,864 - ***** Epoch: 22: Eval results *****
2025-04-11 12:52:30,864 -   train_loss = 5.456859077726092
2025-04-11 12:52:46,579 - ***** Epoch: 23: Eval results *****
2025-04-11 12:52:46,579 -   train_loss = 5.260151624679565
2025-04-11 12:53:02,432 - ***** Epoch: 24: Eval results *****
2025-04-11 12:53:02,433 -   train_loss = 5.074536051068987
2025-04-11 12:53:18,044 - ***** Epoch: 25: Eval results *****
2025-04-11 12:53:18,045 -   train_loss = 4.894688504082816
2025-04-11 12:53:34,025 - ***** Epoch: 26: Eval results *****
2025-04-11 12:53:34,026 -   train_loss = 4.734715257372175
2025-04-11 12:53:51,510 - ***** Epoch: 27: Eval results *****
2025-04-11 12:53:51,510 -   train_loss = 4.612280436924526
2025-04-11 12:54:08,999 - ***** Epoch: 28: Eval results *****
2025-04-11 12:54:08,999 -   train_loss = 4.493528842926025
2025-04-11 12:54:25,991 - ***** Epoch: 29: Eval results *****
2025-04-11 12:54:25,992 -   train_loss = 4.377487148557391
2025-04-11 12:54:42,568 - ***** Epoch: 30: Eval results *****
2025-04-11 12:54:42,569 -   train_loss = 4.258380549294608
2025-04-11 12:54:58,616 - ***** Epoch: 31: Eval results *****
2025-04-11 12:54:58,616 -   train_loss = 4.164058906691415
2025-04-11 12:55:14,072 - ***** Epoch: 32: Eval results *****
2025-04-11 12:55:14,073 -   train_loss = 4.070529086249215
2025-04-11 12:55:29,724 - ***** Epoch: 33: Eval results *****
2025-04-11 12:55:29,725 -   train_loss = 3.968205043247768
2025-04-11 12:55:44,764 - ***** Epoch: 34: Eval results *****
2025-04-11 12:55:44,765 -   train_loss = 3.902783444949559
2025-04-11 12:56:00,627 - ***** Epoch: 35: Eval results *****
2025-04-11 12:56:00,628 -   train_loss = 3.8428641046796526
2025-04-11 12:56:15,932 - ***** Epoch: 36: Eval results *****
2025-04-11 12:56:15,932 -   train_loss = 3.770570363317217
2025-04-11 12:56:31,574 - ***** Epoch: 37: Eval results *****
2025-04-11 12:56:31,574 -   train_loss = 3.6914636066981723
2025-04-11 12:56:46,972 - ***** Epoch: 38: Eval results *****
2025-04-11 12:56:46,973 -   train_loss = 3.6442688022341048
2025-04-11 12:57:02,578 - ***** Epoch: 39: Eval results *****
2025-04-11 12:57:02,578 -   train_loss = 3.6036312580108643
2025-04-11 12:57:21,117 - ***** Epoch: 40: Eval results *****
2025-04-11 12:57:21,118 -   train_loss = 3.562098707471575
2025-04-11 12:57:39,294 - ***** Epoch: 41: Eval results *****
2025-04-11 12:57:39,295 -   train_loss = 3.51145076751709
2025-04-11 12:57:58,277 - ***** Epoch: 42: Eval results *****
2025-04-11 12:57:58,278 -   train_loss = 3.479839869907924
2025-04-11 12:58:16,200 - ***** Epoch: 43: Eval results *****
2025-04-11 12:58:16,200 -   train_loss = 3.4244576351983205
2025-04-11 12:58:33,285 - ***** Epoch: 44: Eval results *****
2025-04-11 12:58:33,285 -   train_loss = 3.392280408314296
2025-04-11 12:58:49,842 - ***** Epoch: 45: Eval results *****
2025-04-11 12:58:49,843 -   train_loss = 3.3635748624801636
2025-04-11 12:59:06,995 - ***** Epoch: 46: Eval results *****
2025-04-11 12:59:06,995 -   train_loss = 3.3199487583977834
2025-04-11 12:59:23,582 - ***** Epoch: 47: Eval results *****
2025-04-11 12:59:23,583 -   train_loss = 3.2940745183399747
2025-04-11 12:59:39,658 - ***** Epoch: 48: Eval results *****
2025-04-11 12:59:39,659 -   train_loss = 3.254611304828099
2025-04-11 12:59:55,704 - ***** Epoch: 49: Eval results *****
2025-04-11 12:59:55,705 -   train_loss = 3.222809604236058
2025-04-11 13:00:11,870 - ***** Epoch: 50: Eval results *****
2025-04-11 13:00:11,871 -   train_loss = 3.2085775647844588
2025-04-11 13:00:28,636 - ***** Epoch: 51: Eval results *****
2025-04-11 13:00:28,637 -   train_loss = 3.1775390931538174
2025-04-11 13:00:45,101 - ***** Epoch: 52: Eval results *****
2025-04-11 13:00:45,102 -   train_loss = 3.168257083211626
2025-04-11 13:01:01,408 - ***** Epoch: 53: Eval results *****
2025-04-11 13:01:01,408 -   train_loss = 3.135911090033395
2025-04-11 13:01:18,342 - ***** Epoch: 54: Eval results *****
2025-04-11 13:01:18,342 -   train_loss = 3.1191659484590804
2025-04-11 13:01:35,394 - ***** Epoch: 55: Eval results *****
2025-04-11 13:01:35,394 -   train_loss = 3.1127937010356357
2025-04-11 13:01:51,889 - ***** Epoch: 56: Eval results *****
2025-04-11 13:01:51,889 -   train_loss = 3.0892701830182756
2025-04-11 13:02:08,514 - ***** Epoch: 57: Eval results *****
2025-04-11 13:02:08,515 -   train_loss = 3.080068622316633
2025-04-11 13:02:24,741 - ***** Epoch: 58: Eval results *****
2025-04-11 13:02:24,741 -   train_loss = 3.069107549531119
2025-04-11 13:02:40,860 - ***** Epoch: 59: Eval results *****
2025-04-11 13:02:40,860 -   train_loss = 3.055029971258981
2025-04-11 13:02:57,742 - ***** Epoch: 60: Eval results *****
2025-04-11 13:02:57,742 -   train_loss = 3.0444293873650685
2025-04-11 13:03:14,964 - ***** Epoch: 61: Eval results *****
2025-04-11 13:03:14,965 -   train_loss = 3.0389347757611955
2025-04-11 13:03:31,519 - ***** Epoch: 62: Eval results *****
2025-04-11 13:03:31,520 -   train_loss = 3.0281723737716675
2025-04-11 13:03:47,713 - ***** Epoch: 63: Eval results *****
2025-04-11 13:03:47,713 -   train_loss = 3.0098237139838084
2025-04-11 13:04:04,054 - ***** Epoch: 64: Eval results *****
2025-04-11 13:04:04,054 -   train_loss = 3.001383696283613
2025-04-11 13:04:21,048 - ***** Epoch: 65: Eval results *****
2025-04-11 13:04:21,049 -   train_loss = 3.0142869097845897
2025-04-11 13:04:38,062 - ***** Epoch: 66: Eval results *****
2025-04-11 13:04:38,062 -   train_loss = 2.999264751161848
2025-04-11 13:04:54,240 - ***** Epoch: 67: Eval results *****
2025-04-11 13:04:54,240 -   train_loss = 2.989941801343645
2025-04-11 13:05:10,369 - ***** Epoch: 68: Eval results *****
2025-04-11 13:05:10,370 -   train_loss = 2.988218511853899
2025-04-11 13:05:27,075 - ***** Epoch: 69: Eval results *****
2025-04-11 13:05:27,076 -   train_loss = 2.9770709105900357
2025-04-11 13:05:44,213 - ***** Epoch: 70: Eval results *****
2025-04-11 13:05:44,214 -   train_loss = 2.9751192161015103
2025-04-11 13:05:59,779 - ***** Epoch: 71: Eval results *****
2025-04-11 13:05:59,780 -   train_loss = 2.9625734772000993
2025-04-11 13:06:15,739 - ***** Epoch: 72: Eval results *****
2025-04-11 13:06:15,739 -   train_loss = 2.9584727627890453
2025-04-11 13:06:31,066 - ***** Epoch: 73: Eval results *****
2025-04-11 13:06:31,066 -   train_loss = 2.950710449899946
2025-04-11 13:06:46,856 - ***** Epoch: 74: Eval results *****
2025-04-11 13:06:46,856 -   train_loss = 2.9473581995282854
2025-04-11 13:07:03,045 - ***** Epoch: 75: Eval results *****
2025-04-11 13:07:03,046 -   train_loss = 2.9602492536817278
2025-04-11 13:07:19,297 - ***** Epoch: 76: Eval results *****
2025-04-11 13:07:19,298 -   train_loss = 2.9502196311950684
2025-04-11 13:07:34,988 - ***** Epoch: 77: Eval results *****
2025-04-11 13:07:34,988 -   train_loss = 2.9246828045163835
2025-04-11 13:07:50,482 - ***** Epoch: 78: Eval results *****
2025-04-11 13:07:50,483 -   train_loss = 2.9334111383983066
2025-04-11 13:08:05,570 - ***** Epoch: 79: Eval results *****
2025-04-11 13:08:05,570 -   train_loss = 2.9347944259643555
2025-04-11 13:08:21,081 - ***** Epoch: 80: Eval results *****
2025-04-11 13:08:21,081 -   train_loss = 2.9331142902374268
2025-04-11 13:08:36,233 - ***** Epoch: 81: Eval results *****
2025-04-11 13:08:36,233 -   train_loss = 2.920053141457694
2025-04-11 13:08:51,134 - ***** Epoch: 82: Eval results *****
2025-04-11 13:08:51,134 -   train_loss = 2.9064704179763794
2025-04-11 13:09:06,353 - ***** Epoch: 83: Eval results *****
2025-04-11 13:09:06,354 -   train_loss = 2.9158216203962053
2025-04-11 13:09:21,698 - ***** Epoch: 84: Eval results *****
2025-04-11 13:09:21,698 -   train_loss = 2.912812113761902
2025-04-11 13:09:37,431 - ***** Epoch: 85: Eval results *****
2025-04-11 13:09:37,432 -   train_loss = 2.9147078139441356
2025-04-11 13:09:52,746 - ***** Epoch: 86: Eval results *****
2025-04-11 13:09:52,746 -   train_loss = 2.911745343889509
2025-04-11 13:10:08,343 - ***** Epoch: 87: Eval results *****
2025-04-11 13:10:08,343 -   train_loss = 2.9123994282313754
2025-04-11 13:10:23,525 - ***** Epoch: 88: Eval results *****
2025-04-11 13:10:23,526 -   train_loss = 2.907144103731428
2025-04-11 13:10:39,050 - ***** Epoch: 89: Eval results *****
2025-04-11 13:10:39,050 -   train_loss = 2.907198122569493
2025-04-11 13:10:54,130 - ***** Epoch: 90: Eval results *****
2025-04-11 13:10:54,130 -   train_loss = 2.9060115473611012
2025-04-11 13:11:09,545 - ***** Epoch: 91: Eval results *****
2025-04-11 13:11:09,545 -   train_loss = 2.9047990015574863
2025-04-11 13:11:24,742 - ***** Epoch: 92: Eval results *****
2025-04-11 13:11:24,742 -   train_loss = 2.895952190671648
2025-04-11 13:11:40,623 - ***** Epoch: 93: Eval results *****
2025-04-11 13:11:40,623 -   train_loss = 2.909797498158046
2025-04-11 13:11:56,373 - ***** Epoch: 94: Eval results *****
2025-04-11 13:11:56,373 -   train_loss = 2.8981896809169223
2025-04-11 13:12:12,376 - ***** Epoch: 95: Eval results *****
2025-04-11 13:12:12,377 -   train_loss = 2.8898405006953647
2025-04-11 13:12:28,603 - ***** Epoch: 96: Eval results *****
2025-04-11 13:12:28,603 -   train_loss = 2.9075123923165456
2025-04-11 13:12:44,776 - ***** Epoch: 97: Eval results *****
2025-04-11 13:12:44,776 -   train_loss = 2.902202316692897
2025-04-11 13:13:01,536 - ***** Epoch: 98: Eval results *****
2025-04-11 13:13:01,536 -   train_loss = 2.9149221181869507
2025-04-11 13:13:17,253 - ***** Epoch: 99: Eval results *****
2025-04-11 13:13:17,253 -   train_loss = 2.899055208478655
2025-04-11 13:13:33,411 - ***** Epoch: 100: Eval results *****
2025-04-11 13:13:33,412 -   train_loss = 2.9017870596476962
2025-04-11 13:13:35,057 - Pre-training finished...
2025-04-11 13:13:35,325 - Freeze all parameters but the last layer for efficiency
2025-04-11 13:13:35,334 - Multimodal Intent Recognition begins...
2025-04-11 13:13:35,335 - Training begins...
2025-04-11 13:13:53,257 - Initializing centroids with K-means++...
2025-04-11 13:13:53,343 - K-means++ used 0.09 s
2025-04-11 13:14:24,701 - K-means used 0.02 s
2025-04-11 13:14:26,153 - ***** Epoch: 1 *****
2025-04-11 13:14:26,153 - Supervised Training Loss: 4.898290
2025-04-11 13:14:26,154 - Unsupervised Training Loss: 5.127410
2025-04-11 13:14:56,520 - K-means used 0.03 s
2025-04-11 13:14:57,875 - ***** Epoch: 2 *****
2025-04-11 13:14:57,876 - Supervised Training Loss: 5.484980
2025-04-11 13:14:57,876 - Unsupervised Training Loss: 5.151850
2025-04-11 13:15:27,768 - K-means used 0.03 s
2025-04-11 13:15:29,188 - ***** Epoch: 3 *****
2025-04-11 13:15:29,188 - Supervised Training Loss: 5.363990
2025-04-11 13:15:29,188 - Unsupervised Training Loss: 4.999770
2025-04-11 13:16:00,431 - K-means used 0.02 s
2025-04-11 13:16:02,046 - ***** Epoch: 4 *****
2025-04-11 13:16:02,046 - Supervised Training Loss: 5.226820
2025-04-11 13:16:02,047 - Unsupervised Training Loss: 5.081170
2025-04-11 13:16:32,376 - K-means used 0.02 s
2025-04-11 13:16:33,871 - ***** Epoch: 5 *****
2025-04-11 13:16:33,872 - Supervised Training Loss: 4.955850
2025-04-11 13:16:33,872 - Unsupervised Training Loss: 5.121120
2025-04-11 13:17:03,656 - K-means used 0.02 s
2025-04-11 13:17:05,208 - ***** Epoch: 6 *****
2025-04-11 13:17:05,208 - Supervised Training Loss: 5.341420
2025-04-11 13:17:05,209 - Unsupervised Training Loss: 4.902150
2025-04-11 13:17:35,000 - K-means used 0.02 s
2025-04-11 13:17:36,638 - ***** Epoch: 7 *****
2025-04-11 13:17:36,638 - Supervised Training Loss: 5.259000
2025-04-11 13:17:36,638 - Unsupervised Training Loss: 5.025070
2025-04-11 13:18:07,154 - K-means used 0.02 s
2025-04-11 13:18:08,730 - ***** Epoch: 8 *****
2025-04-11 13:18:08,730 - Supervised Training Loss: 5.107850
2025-04-11 13:18:08,730 - Unsupervised Training Loss: 5.076990
2025-04-11 13:18:38,812 - K-means used 0.02 s
2025-04-11 13:18:40,463 - ***** Epoch: 9 *****
2025-04-11 13:18:40,463 - Supervised Training Loss: 5.329610
2025-04-11 13:18:40,463 - Unsupervised Training Loss: 5.107440
2025-04-11 13:19:09,996 - K-means used 0.06 s
2025-04-11 13:19:11,606 - ***** Epoch: 10 *****
2025-04-11 13:19:11,607 - Supervised Training Loss: 5.262600
2025-04-11 13:19:11,607 - Unsupervised Training Loss: 4.956260
2025-04-11 13:19:41,414 - K-means used 0.02 s
2025-04-11 13:19:43,242 - ***** Epoch: 11 *****
2025-04-11 13:19:43,242 - Supervised Training Loss: 5.190130
2025-04-11 13:19:43,242 - Unsupervised Training Loss: 5.019090
2025-04-11 13:20:14,698 - K-means used 0.15 s
2025-04-11 13:20:16,536 - ***** Epoch: 12 *****
2025-04-11 13:20:16,537 - Supervised Training Loss: 5.320760
2025-04-11 13:20:16,537 - Unsupervised Training Loss: 5.087220
2025-04-11 13:20:46,472 - K-means used 0.02 s
2025-04-11 13:20:48,324 - ***** Epoch: 13 *****
2025-04-11 13:20:48,324 - Supervised Training Loss: 5.280560
2025-04-11 13:20:48,325 - Unsupervised Training Loss: 4.808250
2025-04-11 13:21:17,216 - K-means used 0.02 s
2025-04-11 13:21:19,110 - ***** Epoch: 14 *****
2025-04-11 13:21:19,110 - Supervised Training Loss: 5.229680
2025-04-11 13:21:19,110 - Unsupervised Training Loss: 4.948220
2025-04-11 13:21:46,962 - K-means used 0.02 s
2025-04-11 13:21:48,909 - ***** Epoch: 15 *****
2025-04-11 13:21:48,909 - Supervised Training Loss: 5.091570
2025-04-11 13:21:48,909 - Unsupervised Training Loss: 5.043300
2025-04-11 13:22:18,596 - K-means used 0.08 s
2025-04-11 13:22:20,768 - ***** Epoch: 16 *****
2025-04-11 13:22:20,768 - Supervised Training Loss: 5.296120
2025-04-11 13:22:20,768 - Unsupervised Training Loss: 4.508530
2025-04-11 13:22:50,716 - K-means used 0.02 s
2025-04-11 13:22:52,898 - ***** Epoch: 17 *****
2025-04-11 13:22:52,899 - Supervised Training Loss: 5.263460
2025-04-11 13:22:52,899 - Unsupervised Training Loss: 4.727230
2025-04-11 13:23:11,801 - Training is finished...
2025-04-11 13:23:11,801 - Testing begins...
2025-04-11 13:23:19,859 - ***** Test results *****
2025-04-11 13:23:19,860 -   ACC = 38.2
2025-04-11 13:23:19,860 -   ARI = 19.63
2025-04-11 13:23:19,860 -   NMI = 43.7
2025-04-11 13:23:19,860 -   fmi = 24.7
2025-04-11 13:23:19,860 - Testing is finished...
2025-04-11 13:23:19,860 - Multimodal intent recognition is finished...
2025-04-11 13:23:19,860 - Results are saved in results/results_umc.csv
