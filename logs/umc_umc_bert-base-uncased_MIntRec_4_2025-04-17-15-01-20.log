2025-04-17 15:01:21,002 - 【无监督】进入了无监督的设定中, 加载数据集
2025-04-17 15:01:21,002 - data preparation...
2025-04-17 15:01:30,040 - Number of train samples = 1779
2025-04-17 15:01:30,041 - Number of testing samples = 445
2025-04-17 15:01:30,041 - data preparation...
2025-04-17 15:01:32,388 - num_train_examples = 1779
2025-04-17 15:01:32,388 - ============================== Params ==============================
2025-04-17 15:01:32,388 - logger_name: umc_umc_bert-base-uncased_MIntRec_4
2025-04-17 15:01:32,388 - dataset: MIntRec
2025-04-17 15:01:32,388 - multimodal_method: umc
2025-04-17 15:01:32,388 - method: umc
2025-04-17 15:01:32,388 - setting: unsupervised
2025-04-17 15:01:32,388 - merge_dev: False
2025-04-17 15:01:32,388 - text_backbone: bert-base-uncased
2025-04-17 15:01:32,388 - seed: 4
2025-04-17 15:01:32,388 - num_workers: 16
2025-04-17 15:01:32,388 - log_id: umc_umc_bert-base-uncased_MIntRec_4_2025-04-17-15-01-20
2025-04-17 15:01:32,389 - gpu_id: 1
2025-04-17 15:01:32,389 - data_path: /root/autodl-tmp/home/Share/Dataset/LZH
2025-04-17 15:01:32,389 - train: True
2025-04-17 15:01:32,389 - tune: True
2025-04-17 15:01:32,389 - save_model: True
2025-04-17 15:01:32,389 - save_results: True
2025-04-17 15:01:32,389 - log_path: logs
2025-04-17 15:01:32,389 - cache_path: cache
2025-04-17 15:01:32,389 - video_data_path: video_data
2025-04-17 15:01:32,389 - audio_data_path: audio_data
2025-04-17 15:01:32,389 - video_feats_path: swin_feats.pkl
2025-04-17 15:01:32,389 - audio_feats_path: wavlm_feats.pkl
2025-04-17 15:01:32,389 - results_path: results
2025-04-17 15:01:32,389 - output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/SMC/outputs_test2/MIntRec
2025-04-17 15:01:32,389 - model_path: models
2025-04-17 15:01:32,389 - config_file_name: umc_MIntRec
2025-04-17 15:01:32,389 - results_file_name: results_umc_pre.csv
2025-04-17 15:01:32,389 - text_pretrained_model: uncased_L-12_H-768_A-12
2025-04-17 15:01:32,389 - pretrained_bert_model: uncased_L-12_H-768_A-12
2025-04-17 15:01:32,389 - pretrain_batch_size: 128
2025-04-17 15:01:32,389 - train_batch_size: 128
2025-04-17 15:01:32,389 - eval_batch_size: 128
2025-04-17 15:01:32,389 - test_batch_size: 128
2025-04-17 15:01:32,389 - num_pretrain_epochs: 100
2025-04-17 15:01:32,389 - num_train_epochs: 100
2025-04-17 15:01:32,389 - pretrain: [True]
2025-04-17 15:01:32,389 - aligned_method: ctc
2025-04-17 15:01:32,389 - need_aligned: False
2025-04-17 15:01:32,389 - freeze_pretrain_bert_parameters: [True]
2025-04-17 15:01:32,390 - freeze_train_bert_parameters: [True]
2025-04-17 15:01:32,390 - pretrain_temperature: [0.1, 0.2, 0.4, 0.5]
2025-04-17 15:01:32,390 - train_temperature_sup: [0.5]
2025-04-17 15:01:32,390 - train_temperature_unsup: [2]
2025-04-17 15:01:32,390 - activation: tanh
2025-04-17 15:01:32,390 - lr_pre: [1e-05]
2025-04-17 15:01:32,390 - lr: [5e-05]
2025-04-17 15:01:32,390 - delta: [0.05]
2025-04-17 15:01:32,390 - thres: [0.1]
2025-04-17 15:01:32,390 - topk: [5]
2025-04-17 15:01:32,390 - weight_decay: 0.01
2025-04-17 15:01:32,390 - feat_dim: 768
2025-04-17 15:01:32,390 - hidden_size: 768
2025-04-17 15:01:32,390 - grad_clip: -1.0
2025-04-17 15:01:32,390 - warmup_proportion: [0.1]
2025-04-17 15:01:32,390 - hidden_dropout_prob: 0.1
2025-04-17 15:01:32,390 - weight: 1.0
2025-04-17 15:01:32,390 - loss_mode: rdrop
2025-04-17 15:01:32,390 - base_dim: 256
2025-04-17 15:01:32,390 - nheads: 8
2025-04-17 15:01:32,390 - attn_dropout: 0.1
2025-04-17 15:01:32,390 - relu_dropout: 0.1
2025-04-17 15:01:32,390 - embed_dropout: 0.01
2025-04-17 15:01:32,390 - res_dropout: 0.0
2025-04-17 15:01:32,390 - attn_mask: True
2025-04-17 15:01:32,390 - encoder_layers_1: 1
2025-04-17 15:01:32,390 - fusion_act: tanh
2025-04-17 15:01:32,390 - pred_output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/SMC/outputs_test2/MIntRec/umc_umc_MIntRec_bert-base-uncased_4
2025-04-17 15:01:32,391 - model_output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/SMC/outputs_test2/MIntRec/umc_umc_MIntRec_bert-base-uncased_4/models
2025-04-17 15:01:32,391 - text_seq_len: 30
2025-04-17 15:01:32,391 - video_seq_len: 230
2025-04-17 15:01:32,391 - audio_seq_len: 480
2025-04-17 15:01:32,391 - text_feat_dim: 768
2025-04-17 15:01:32,391 - video_feat_dim: 1024
2025-04-17 15:01:32,391 - audio_feat_dim: 768
2025-04-17 15:01:32,391 - num_labels: 20
2025-04-17 15:01:32,391 - num_train_examples: 1779
2025-04-17 15:01:32,391 - ============================== End Params ==============================
2025-04-17 15:01:33,608 - Freeze all parameters but the last layer for efficiency
2025-04-17 15:01:33,643 - Pre-training start...
2025-04-17 15:01:50,123 - ***** Epoch: 1: Eval results *****
2025-04-17 15:01:50,124 -   train_loss = 5.97023606300354
2025-04-17 15:02:06,707 - ***** Epoch: 2: Eval results *****
2025-04-17 15:02:06,708 -   train_loss = 5.96319876398359
2025-04-17 15:02:23,541 - ***** Epoch: 3: Eval results *****
2025-04-17 15:02:23,542 -   train_loss = 5.957141126905169
2025-04-17 15:02:40,578 - ***** Epoch: 4: Eval results *****
2025-04-17 15:02:40,578 -   train_loss = 5.946335111345563
2025-04-17 15:02:57,744 - ***** Epoch: 5: Eval results *****
2025-04-17 15:02:57,744 -   train_loss = 5.939557109560285
2025-04-17 15:03:15,004 - ***** Epoch: 6: Eval results *****
2025-04-17 15:03:15,004 -   train_loss = 5.928317853382656
2025-04-17 15:03:32,029 - ***** Epoch: 7: Eval results *****
2025-04-17 15:03:32,029 -   train_loss = 5.8969558988298685
2025-04-17 15:03:49,832 - ***** Epoch: 8: Eval results *****
2025-04-17 15:03:49,832 -   train_loss = 5.843202590942383
2025-04-17 15:04:07,849 - ***** Epoch: 9: Eval results *****
2025-04-17 15:04:07,849 -   train_loss = 5.694854157311576
2025-04-17 15:04:25,457 - ***** Epoch: 10: Eval results *****
2025-04-17 15:04:25,458 -   train_loss = 5.352509873253958
2025-04-17 15:04:42,415 - ***** Epoch: 11: Eval results *****
2025-04-17 15:04:42,415 -   train_loss = 4.855827944619315
2025-04-17 15:05:00,342 - ***** Epoch: 12: Eval results *****
2025-04-17 15:05:00,342 -   train_loss = 4.358715670449393
2025-04-17 15:05:17,397 - ***** Epoch: 13: Eval results *****
2025-04-17 15:05:17,398 -   train_loss = 3.9141299554279874
2025-04-17 15:05:34,856 - ***** Epoch: 14: Eval results *****
2025-04-17 15:05:34,857 -   train_loss = 3.5818171160561696
2025-04-17 15:05:52,158 - ***** Epoch: 15: Eval results *****
2025-04-17 15:05:52,158 -   train_loss = 3.288998450551714
2025-04-17 15:06:09,881 - ***** Epoch: 16: Eval results *****
2025-04-17 15:06:09,881 -   train_loss = 3.0880981513432095
2025-04-17 15:06:26,856 - ***** Epoch: 17: Eval results *****
2025-04-17 15:06:26,857 -   train_loss = 2.9239410161972046
2025-04-17 15:06:44,122 - ***** Epoch: 18: Eval results *****
2025-04-17 15:06:44,123 -   train_loss = 2.745460799762181
2025-04-17 15:07:01,516 - ***** Epoch: 19: Eval results *****
2025-04-17 15:07:01,516 -   train_loss = 2.6422981364386424
2025-04-17 15:07:18,449 - ***** Epoch: 20: Eval results *****
2025-04-17 15:07:18,449 -   train_loss = 2.5311153786523
2025-04-17 15:07:35,611 - ***** Epoch: 21: Eval results *****
2025-04-17 15:07:35,611 -   train_loss = 2.4329413856778825
2025-04-17 15:07:52,863 - ***** Epoch: 22: Eval results *****
2025-04-17 15:07:52,864 -   train_loss = 2.345497897693089
2025-04-17 15:08:10,516 - ***** Epoch: 23: Eval results *****
2025-04-17 15:08:10,516 -   train_loss = 2.2885283402034213
2025-04-17 15:08:29,594 - ***** Epoch: 24: Eval results *****
2025-04-17 15:08:29,594 -   train_loss = 2.223018833569118
2025-04-17 15:08:48,054 - ***** Epoch: 25: Eval results *****
2025-04-17 15:08:48,054 -   train_loss = 2.152667965207781
2025-04-17 15:09:07,117 - ***** Epoch: 26: Eval results *****
2025-04-17 15:09:07,117 -   train_loss = 2.1216451014791216
2025-04-17 15:09:25,275 - ***** Epoch: 27: Eval results *****
2025-04-17 15:09:25,275 -   train_loss = 2.086548924446106
2025-04-17 15:09:42,888 - ***** Epoch: 28: Eval results *****
2025-04-17 15:09:42,888 -   train_loss = 2.034404924937657
2025-04-17 15:10:00,568 - ***** Epoch: 29: Eval results *****
2025-04-17 15:10:00,568 -   train_loss = 2.012808544295175
2025-04-17 15:10:18,177 - ***** Epoch: 30: Eval results *****
2025-04-17 15:10:18,177 -   train_loss = 1.969639309814998
2025-04-17 15:10:35,761 - ***** Epoch: 31: Eval results *****
2025-04-17 15:10:35,761 -   train_loss = 1.93486716066088
2025-04-17 15:10:53,116 - ***** Epoch: 32: Eval results *****
2025-04-17 15:10:53,116 -   train_loss = 1.9178935204233443
2025-04-17 15:11:10,062 - ***** Epoch: 33: Eval results *****
2025-04-17 15:11:10,062 -   train_loss = 1.8958913428442818
2025-04-17 15:11:27,241 - ***** Epoch: 34: Eval results *****
2025-04-17 15:11:27,241 -   train_loss = 1.8632436650139945
2025-04-17 15:11:44,366 - ***** Epoch: 35: Eval results *****
2025-04-17 15:11:44,366 -   train_loss = 1.838563663618905
2025-04-17 15:12:01,399 - ***** Epoch: 36: Eval results *****
2025-04-17 15:12:01,400 -   train_loss = 1.8138832790510995
2025-04-17 15:12:18,570 - ***** Epoch: 37: Eval results *****
2025-04-17 15:12:18,570 -   train_loss = 1.7962791408811296
2025-04-17 15:12:35,414 - ***** Epoch: 38: Eval results *****
2025-04-17 15:12:35,414 -   train_loss = 1.7760122162955148
2025-04-17 15:12:51,848 - ***** Epoch: 39: Eval results *****
2025-04-17 15:12:51,848 -   train_loss = 1.747906310217721
2025-04-17 15:13:08,482 - ***** Epoch: 40: Eval results *****
2025-04-17 15:13:08,483 -   train_loss = 1.7455715366772242
2025-04-17 15:13:24,929 - ***** Epoch: 41: Eval results *****
2025-04-17 15:13:24,930 -   train_loss = 1.7294217092650277
2025-04-17 15:13:41,963 - ***** Epoch: 42: Eval results *****
2025-04-17 15:13:41,964 -   train_loss = 1.7296924931662423
2025-04-17 15:13:58,803 - ***** Epoch: 43: Eval results *****
2025-04-17 15:13:58,804 -   train_loss = 1.6925259828567505
2025-04-17 15:14:15,612 - ***** Epoch: 44: Eval results *****
2025-04-17 15:14:15,612 -   train_loss = 1.6850253599030631
2025-04-17 15:14:32,544 - ***** Epoch: 45: Eval results *****
2025-04-17 15:14:32,544 -   train_loss = 1.6825048071997506
2025-04-17 15:14:49,856 - ***** Epoch: 46: Eval results *****
2025-04-17 15:14:49,856 -   train_loss = 1.6718259709221976
2025-04-17 15:15:06,913 - ***** Epoch: 47: Eval results *****
2025-04-17 15:15:06,913 -   train_loss = 1.6486830796514238
2025-04-17 15:15:24,238 - ***** Epoch: 48: Eval results *****
2025-04-17 15:15:24,238 -   train_loss = 1.6389068450246538
2025-04-17 15:15:40,867 - ***** Epoch: 49: Eval results *****
2025-04-17 15:15:40,868 -   train_loss = 1.624547302722931
2025-04-17 15:15:58,180 - ***** Epoch: 50: Eval results *****
2025-04-17 15:15:58,180 -   train_loss = 1.619175808770316
2025-04-17 15:16:14,820 - ***** Epoch: 51: Eval results *****
2025-04-17 15:16:14,821 -   train_loss = 1.6109808002199446
2025-04-17 15:16:31,294 - ***** Epoch: 52: Eval results *****
2025-04-17 15:16:31,294 -   train_loss = 1.5910064663205827
2025-04-17 15:16:47,884 - ***** Epoch: 53: Eval results *****
2025-04-17 15:16:47,884 -   train_loss = 1.5865020411355155
2025-04-17 15:17:04,868 - ***** Epoch: 54: Eval results *****
2025-04-17 15:17:04,868 -   train_loss = 1.5883907420294625
2025-04-17 15:17:22,010 - ***** Epoch: 55: Eval results *****
2025-04-17 15:17:22,011 -   train_loss = 1.5653846604483468
2025-04-17 15:17:39,179 - ***** Epoch: 56: Eval results *****
2025-04-17 15:17:39,180 -   train_loss = 1.5831958566393172
2025-04-17 15:17:56,358 - ***** Epoch: 57: Eval results *****
2025-04-17 15:17:56,359 -   train_loss = 1.566810863358634
2025-04-17 15:18:13,488 - ***** Epoch: 58: Eval results *****
2025-04-17 15:18:13,489 -   train_loss = 1.554495666708265
2025-04-17 15:18:30,432 - ***** Epoch: 59: Eval results *****
2025-04-17 15:18:30,432 -   train_loss = 1.5545457260949271
2025-04-17 15:18:47,006 - ***** Epoch: 60: Eval results *****
2025-04-17 15:18:47,006 -   train_loss = 1.549096703529358
2025-04-17 15:19:04,275 - ***** Epoch: 61: Eval results *****
2025-04-17 15:19:04,275 -   train_loss = 1.5334391849381583
2025-04-17 15:19:21,981 - ***** Epoch: 62: Eval results *****
2025-04-17 15:19:21,981 -   train_loss = 1.5486982890537806
2025-04-17 15:19:39,453 - ***** Epoch: 63: Eval results *****
2025-04-17 15:19:39,453 -   train_loss = 1.53785126549857
2025-04-17 15:19:56,184 - ***** Epoch: 64: Eval results *****
2025-04-17 15:19:56,185 -   train_loss = 1.5166710700307573
2025-04-17 15:20:13,470 - ***** Epoch: 65: Eval results *****
2025-04-17 15:20:13,471 -   train_loss = 1.5134581327438354
2025-04-17 15:20:31,181 - ***** Epoch: 66: Eval results *****
2025-04-17 15:20:31,182 -   train_loss = 1.5130893758365087
2025-04-17 15:20:48,496 - ***** Epoch: 67: Eval results *****
2025-04-17 15:20:48,496 -   train_loss = 1.5124109642846244
2025-04-17 15:21:05,491 - ***** Epoch: 68: Eval results *****
2025-04-17 15:21:05,492 -   train_loss = 1.5020282013075692
2025-04-17 15:21:23,156 - ***** Epoch: 69: Eval results *****
2025-04-17 15:21:23,157 -   train_loss = 1.4797927396638053
2025-04-17 15:21:40,037 - ***** Epoch: 70: Eval results *****
2025-04-17 15:21:40,037 -   train_loss = 1.4904590589659554
2025-04-17 15:21:57,413 - ***** Epoch: 71: Eval results *****
2025-04-17 15:21:57,414 -   train_loss = 1.496425884110587
2025-04-17 15:22:14,061 - ***** Epoch: 72: Eval results *****
2025-04-17 15:22:14,061 -   train_loss = 1.497824490070343
2025-04-17 15:22:31,114 - ***** Epoch: 73: Eval results *****
2025-04-17 15:22:31,114 -   train_loss = 1.4915749856403895
2025-04-17 15:22:47,979 - ***** Epoch: 74: Eval results *****
2025-04-17 15:22:47,980 -   train_loss = 1.4932321054594857
2025-04-17 15:23:04,478 - ***** Epoch: 75: Eval results *****
2025-04-17 15:23:04,478 -   train_loss = 1.4809982095445906
2025-04-17 15:23:21,370 - ***** Epoch: 76: Eval results *****
2025-04-17 15:23:21,370 -   train_loss = 1.495314461844308
2025-04-17 15:23:38,296 - ***** Epoch: 77: Eval results *****
2025-04-17 15:23:38,296 -   train_loss = 1.4872479438781738
2025-04-17 15:23:57,572 - ***** Epoch: 78: Eval results *****
2025-04-17 15:23:57,573 -   train_loss = 1.4882095200674874
2025-04-17 15:24:16,148 - ***** Epoch: 79: Eval results *****
2025-04-17 15:24:16,149 -   train_loss = 1.4770933730261666
2025-04-17 15:24:35,068 - ***** Epoch: 80: Eval results *****
2025-04-17 15:24:35,069 -   train_loss = 1.4753099594797408
2025-04-17 15:24:52,991 - ***** Epoch: 81: Eval results *****
2025-04-17 15:24:52,992 -   train_loss = 1.471421412059239
2025-04-17 15:25:09,632 - ***** Epoch: 82: Eval results *****
2025-04-17 15:25:09,632 -   train_loss = 1.4682052390916007
2025-04-17 15:25:26,424 - ***** Epoch: 83: Eval results *****
2025-04-17 15:25:26,424 -   train_loss = 1.4721749424934387
2025-04-17 15:25:42,508 - ***** Epoch: 84: Eval results *****
2025-04-17 15:25:42,508 -   train_loss = 1.466243633202144
2025-04-17 15:25:58,829 - ***** Epoch: 85: Eval results *****
2025-04-17 15:25:58,829 -   train_loss = 1.464392295905522
2025-04-17 15:26:15,739 - ***** Epoch: 86: Eval results *****
2025-04-17 15:26:15,739 -   train_loss = 1.4598699467522758
2025-04-17 15:26:32,590 - ***** Epoch: 87: Eval results *****
2025-04-17 15:26:32,591 -   train_loss = 1.4576066136360168
2025-04-17 15:26:49,265 - ***** Epoch: 88: Eval results *****
2025-04-17 15:26:49,265 -   train_loss = 1.4675025854791914
2025-04-17 15:27:06,291 - ***** Epoch: 89: Eval results *****
2025-04-17 15:27:06,291 -   train_loss = 1.4717186093330383
2025-04-17 15:27:22,882 - ***** Epoch: 90: Eval results *****
2025-04-17 15:27:22,883 -   train_loss = 1.4630244203976221
2025-04-17 15:27:39,672 - ***** Epoch: 91: Eval results *****
2025-04-17 15:27:39,672 -   train_loss = 1.4513428040913172
2025-04-17 15:27:56,432 - ***** Epoch: 92: Eval results *****
2025-04-17 15:27:56,432 -   train_loss = 1.4588987997600011
2025-04-17 15:28:13,346 - ***** Epoch: 93: Eval results *****
2025-04-17 15:28:13,347 -   train_loss = 1.4609301430838448
2025-04-17 15:28:30,493 - ***** Epoch: 94: Eval results *****
2025-04-17 15:28:30,493 -   train_loss = 1.4636505331311906
2025-04-17 15:28:47,383 - ***** Epoch: 95: Eval results *****
2025-04-17 15:28:47,383 -   train_loss = 1.46044203213283
2025-04-17 15:29:04,842 - ***** Epoch: 96: Eval results *****
2025-04-17 15:29:04,842 -   train_loss = 1.4530653868402754
2025-04-17 15:29:22,353 - ***** Epoch: 97: Eval results *****
2025-04-17 15:29:22,353 -   train_loss = 1.4613551923206873
2025-04-17 15:29:39,577 - ***** Epoch: 98: Eval results *****
2025-04-17 15:29:39,577 -   train_loss = 1.4624413422175817
2025-04-17 15:29:56,000 - ***** Epoch: 99: Eval results *****
2025-04-17 15:29:56,000 -   train_loss = 1.4647164344787598
2025-04-17 15:30:12,912 - ***** Epoch: 100: Eval results *****
2025-04-17 15:30:12,912 -   train_loss = 1.463797160557338
2025-04-17 15:30:14,563 - Pre-training finished...
2025-04-17 15:30:14,922 - Freeze all parameters but the last layer for efficiency
2025-04-17 15:30:14,932 - Multimodal Intent Recognition begins...
2025-04-17 15:30:14,932 - Training begins...
2025-04-17 15:30:31,061 - Initializing centroids with K-means++...
2025-04-17 15:30:31,156 - K-means++ used 0.09 s
2025-04-17 15:31:01,913 - K-means used 0.03 s
2025-04-17 15:31:03,199 - ***** Epoch: 1 *****
2025-04-17 15:31:03,200 - Supervised Training Loss: 4.339080
2025-04-17 15:31:03,201 - Unsupervised Training Loss: 5.537670
2025-04-17 15:31:32,900 - K-means used 0.03 s
2025-04-17 15:31:33,998 - ***** Epoch: 2 *****
2025-04-17 15:31:33,999 - Supervised Training Loss: 5.011920
2025-04-17 15:31:33,999 - Unsupervised Training Loss: 5.562990
2025-04-17 15:32:03,577 - K-means used 0.02 s
2025-04-17 15:32:04,704 - ***** Epoch: 3 *****
2025-04-17 15:32:04,704 - Supervised Training Loss: 4.817930
2025-04-17 15:32:04,704 - Unsupervised Training Loss: 5.426750
2025-04-17 15:32:34,221 - K-means used 0.02 s
2025-04-17 15:32:35,434 - ***** Epoch: 4 *****
2025-04-17 15:32:35,434 - Supervised Training Loss: 4.633510
2025-04-17 15:32:35,434 - Unsupervised Training Loss: 5.490600
2025-04-17 15:33:03,744 - K-means used 0.02 s
2025-04-17 15:33:05,237 - ***** Epoch: 5 *****
2025-04-17 15:33:05,237 - Supervised Training Loss: 4.326640
2025-04-17 15:33:05,237 - Unsupervised Training Loss: 5.529790
2025-04-17 15:33:33,736 - K-means used 0.02 s
2025-04-17 15:33:34,953 - ***** Epoch: 6 *****
2025-04-17 15:33:34,953 - Supervised Training Loss: 4.717970
2025-04-17 15:33:34,953 - Unsupervised Training Loss: 5.329600
2025-04-17 15:34:03,724 - K-means used 0.02 s
2025-04-17 15:34:04,935 - ***** Epoch: 7 *****
2025-04-17 15:34:04,935 - Supervised Training Loss: 4.616230
2025-04-17 15:34:04,935 - Unsupervised Training Loss: 5.442190
2025-04-17 15:34:33,079 - K-means used 0.02 s
2025-04-17 15:34:34,316 - ***** Epoch: 8 *****
2025-04-17 15:34:34,316 - Supervised Training Loss: 4.465980
2025-04-17 15:34:34,316 - Unsupervised Training Loss: 5.501950
2025-04-17 15:35:03,241 - K-means used 0.02 s
2025-04-17 15:35:04,562 - ***** Epoch: 9 *****
2025-04-17 15:35:04,563 - Supervised Training Loss: 4.687470
2025-04-17 15:35:04,563 - Unsupervised Training Loss: 5.542510
2025-04-17 15:35:33,769 - K-means used 0.02 s
2025-04-17 15:35:35,579 - ***** Epoch: 10 *****
2025-04-17 15:35:35,579 - Supervised Training Loss: 4.618870
2025-04-17 15:35:35,579 - Unsupervised Training Loss: 5.379880
2025-04-17 15:36:06,232 - K-means used 0.02 s
2025-04-17 15:36:07,630 - ***** Epoch: 11 *****
2025-04-17 15:36:07,630 - Supervised Training Loss: 4.541740
2025-04-17 15:36:07,630 - Unsupervised Training Loss: 5.464670
2025-04-17 15:36:37,029 - K-means used 0.02 s
2025-04-17 15:36:38,587 - ***** Epoch: 12 *****
2025-04-17 15:36:38,588 - Supervised Training Loss: 4.680650
2025-04-17 15:36:38,588 - Unsupervised Training Loss: 5.527980
2025-04-17 15:37:07,109 - K-means used 0.02 s
2025-04-17 15:37:08,614 - ***** Epoch: 13 *****
2025-04-17 15:37:08,614 - Supervised Training Loss: 4.638130
2025-04-17 15:37:08,614 - Unsupervised Training Loss: 5.253020
2025-04-17 15:37:37,843 - K-means used 0.03 s
2025-04-17 15:37:39,508 - ***** Epoch: 14 *****
2025-04-17 15:37:39,508 - Supervised Training Loss: 4.588110
2025-04-17 15:37:39,508 - Unsupervised Training Loss: 5.393530
2025-04-17 15:38:07,669 - K-means used 0.02 s
2025-04-17 15:38:09,654 - ***** Epoch: 15 *****
2025-04-17 15:38:09,654 - Supervised Training Loss: 4.482880
2025-04-17 15:38:09,654 - Unsupervised Training Loss: 5.494930
2025-04-17 15:38:39,492 - K-means used 0.02 s
2025-04-17 15:38:41,352 - ***** Epoch: 16 *****
2025-04-17 15:38:41,352 - Supervised Training Loss: 4.687770
2025-04-17 15:38:41,352 - Unsupervised Training Loss: 4.961960
2025-04-17 15:39:10,291 - K-means used 0.02 s
2025-04-17 15:39:12,118 - ***** Epoch: 17 *****
2025-04-17 15:39:12,118 - Supervised Training Loss: 4.673010
2025-04-17 15:39:12,118 - Unsupervised Training Loss: 5.179790
2025-04-17 15:39:30,577 - Training is finished...
2025-04-17 15:39:30,578 - Testing begins...
2025-04-17 15:39:37,530 - ***** Test results *****
2025-04-17 15:39:37,530 -   ACC = 38.43
2025-04-17 15:39:37,530 -   ARI = 19.2
2025-04-17 15:39:37,530 -   NMI = 43.53
2025-04-17 15:39:37,531 -   fmi = 24.19
2025-04-17 15:39:37,531 - Testing is finished...
2025-04-17 15:39:37,531 - Multimodal intent recognition is finished...
2025-04-17 15:39:37,531 - Results are saved in results/results_umc_pre.csv
2025-04-17 15:39:38,536 - Freeze all parameters but the last layer for efficiency
2025-04-17 15:39:38,574 - Pre-training start...
2025-04-17 15:39:39,377 - ***** Epoch: 1: Eval results *****
2025-04-17 15:39:39,377 -   train_loss = 5.652226448059082
2025-04-17 15:39:40,197 - ***** Epoch: 2: Eval results *****
2025-04-17 15:39:40,197 -   train_loss = 5.6523942947387695
2025-04-17 15:39:40,993 - ***** Epoch: 3: Eval results *****
2025-04-17 15:39:40,993 -   train_loss = 5.659887313842773
2025-04-17 15:39:41,828 - ***** Epoch: 4: Eval results *****
2025-04-17 15:39:41,828 -   train_loss = 5.650202751159668
2025-04-17 15:39:42,647 - ***** Epoch: 5: Eval results *****
2025-04-17 15:39:42,647 -   train_loss = 5.6526198387146
2025-04-17 15:39:43,454 - ***** Epoch: 6: Eval results *****
2025-04-17 15:39:43,454 -   train_loss = 5.6710615158081055
2025-04-17 15:39:44,282 - ***** Epoch: 7: Eval results *****
2025-04-17 15:39:44,282 -   train_loss = 5.65602445602417
2025-04-17 15:39:45,103 - ***** Epoch: 8: Eval results *****
2025-04-17 15:39:45,104 -   train_loss = 5.666427135467529
2025-04-17 15:39:45,888 - ***** Epoch: 9: Eval results *****
2025-04-17 15:39:45,888 -   train_loss = 5.657459735870361
2025-04-17 15:39:46,692 - ***** Epoch: 10: Eval results *****
2025-04-17 15:39:46,692 -   train_loss = 5.651672840118408
2025-04-17 15:39:47,406 - ***** Epoch: 11: Eval results *****
2025-04-17 15:39:47,406 -   train_loss = 5.653787612915039
2025-04-17 15:39:48,129 - ***** Epoch: 12: Eval results *****
2025-04-17 15:39:48,129 -   train_loss = 5.659526348114014
2025-04-17 15:39:48,852 - ***** Epoch: 13: Eval results *****
2025-04-17 15:39:48,852 -   train_loss = 5.658702373504639
2025-04-17 15:39:49,652 - ***** Epoch: 14: Eval results *****
2025-04-17 15:39:49,652 -   train_loss = 5.682895183563232
2025-04-17 15:39:50,462 - ***** Epoch: 15: Eval results *****
2025-04-17 15:39:50,462 -   train_loss = 5.684581279754639
2025-04-17 15:39:51,242 - ***** Epoch: 16: Eval results *****
2025-04-17 15:39:51,242 -   train_loss = 5.643721103668213
2025-04-17 15:39:51,940 - ***** Epoch: 17: Eval results *****
2025-04-17 15:39:51,940 -   train_loss = 5.664452075958252
2025-04-17 15:39:52,644 - ***** Epoch: 18: Eval results *****
2025-04-17 15:39:52,644 -   train_loss = 5.643928050994873
2025-04-17 15:39:53,442 - ***** Epoch: 19: Eval results *****
2025-04-17 15:39:53,443 -   train_loss = 5.637171268463135
2025-04-17 15:39:54,164 - ***** Epoch: 20: Eval results *****
2025-04-17 15:39:54,164 -   train_loss = 5.654998779296875
2025-04-17 15:39:54,968 - ***** Epoch: 21: Eval results *****
2025-04-17 15:39:54,968 -   train_loss = 5.653969764709473
2025-04-17 15:39:55,769 - ***** Epoch: 22: Eval results *****
2025-04-17 15:39:55,770 -   train_loss = 5.6392717361450195
2025-04-17 15:39:56,551 - ***** Epoch: 23: Eval results *****
2025-04-17 15:39:56,551 -   train_loss = 5.648330211639404
2025-04-17 15:39:57,359 - ***** Epoch: 24: Eval results *****
2025-04-17 15:39:57,359 -   train_loss = 5.637078762054443
2025-04-17 15:39:58,072 - ***** Epoch: 25: Eval results *****
2025-04-17 15:39:58,072 -   train_loss = 5.6413750648498535
2025-04-17 15:39:58,783 - ***** Epoch: 26: Eval results *****
2025-04-17 15:39:58,783 -   train_loss = 5.646724224090576
2025-04-17 15:39:59,497 - ***** Epoch: 27: Eval results *****
2025-04-17 15:39:59,497 -   train_loss = 5.649015426635742
2025-04-17 15:40:00,213 - ***** Epoch: 28: Eval results *****
2025-04-17 15:40:00,213 -   train_loss = 5.625166893005371
2025-04-17 15:40:00,923 - ***** Epoch: 29: Eval results *****
2025-04-17 15:40:00,924 -   train_loss = 5.643072128295898
2025-04-17 15:40:01,651 - ***** Epoch: 30: Eval results *****
2025-04-17 15:40:01,651 -   train_loss = 5.622555255889893
2025-04-17 15:40:02,370 - ***** Epoch: 31: Eval results *****
2025-04-17 15:40:02,370 -   train_loss = 5.630960941314697
2025-04-17 15:40:03,098 - ***** Epoch: 32: Eval results *****
2025-04-17 15:40:03,098 -   train_loss = 5.611562728881836
2025-04-17 15:40:03,852 - ***** Epoch: 33: Eval results *****
2025-04-17 15:40:03,853 -   train_loss = 5.616786956787109
2025-04-17 15:40:04,597 - ***** Epoch: 34: Eval results *****
2025-04-17 15:40:04,597 -   train_loss = 5.612737655639648
2025-04-17 15:40:05,309 - ***** Epoch: 35: Eval results *****
2025-04-17 15:40:05,310 -   train_loss = 5.6122660636901855
2025-04-17 15:40:06,118 - ***** Epoch: 36: Eval results *****
2025-04-17 15:40:06,118 -   train_loss = 5.608066082000732
2025-04-17 15:40:06,929 - ***** Epoch: 37: Eval results *****
2025-04-17 15:40:06,929 -   train_loss = 5.5929036140441895
2025-04-17 15:40:07,700 - ***** Epoch: 38: Eval results *****
2025-04-17 15:40:07,700 -   train_loss = 5.599288463592529
2025-04-17 15:40:08,401 - ***** Epoch: 39: Eval results *****
2025-04-17 15:40:08,401 -   train_loss = 5.6025190353393555
2025-04-17 15:40:09,105 - ***** Epoch: 40: Eval results *****
2025-04-17 15:40:09,106 -   train_loss = 5.578034400939941
2025-04-17 15:40:09,801 - ***** Epoch: 41: Eval results *****
2025-04-17 15:40:09,801 -   train_loss = 5.592466831207275
