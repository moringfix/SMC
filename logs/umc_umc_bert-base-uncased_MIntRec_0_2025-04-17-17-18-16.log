2025-04-17 17:18:16,623 - 【无监督】进入了无监督的设定中, 加载数据集
2025-04-17 17:18:16,623 - data preparation...
2025-04-17 17:18:25,451 - Number of train samples = 1779
2025-04-17 17:18:25,451 - Number of testing samples = 445
2025-04-17 17:18:25,451 - data preparation...
2025-04-17 17:18:27,609 - num_train_examples = 1779
2025-04-17 17:18:27,609 - ============================== Params ==============================
2025-04-17 17:18:27,609 - logger_name: umc_umc_bert-base-uncased_MIntRec_0
2025-04-17 17:18:27,609 - dataset: MIntRec
2025-04-17 17:18:27,609 - multimodal_method: umc
2025-04-17 17:18:27,609 - method: umc
2025-04-17 17:18:27,609 - setting: unsupervised
2025-04-17 17:18:27,609 - merge_dev: False
2025-04-17 17:18:27,609 - text_backbone: bert-base-uncased
2025-04-17 17:18:27,610 - seed: 0
2025-04-17 17:18:27,610 - num_workers: 16
2025-04-17 17:18:27,610 - log_id: umc_umc_bert-base-uncased_MIntRec_0_2025-04-17-17-18-16
2025-04-17 17:18:27,610 - gpu_id: 1
2025-04-17 17:18:27,610 - data_path: /root/autodl-tmp/home/Share/Dataset/LZH
2025-04-17 17:18:27,610 - train: True
2025-04-17 17:18:27,610 - tune: True
2025-04-17 17:18:27,610 - save_model: True
2025-04-17 17:18:27,610 - save_results: True
2025-04-17 17:18:27,610 - log_path: logs
2025-04-17 17:18:27,610 - cache_path: cache
2025-04-17 17:18:27,610 - video_data_path: video_data
2025-04-17 17:18:27,610 - audio_data_path: audio_data
2025-04-17 17:18:27,610 - video_feats_path: swin_feats.pkl
2025-04-17 17:18:27,610 - audio_feats_path: wavlm_feats.pkl
2025-04-17 17:18:27,610 - results_path: results
2025-04-17 17:18:27,610 - output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/SMC/outputs_test2/MIntRec
2025-04-17 17:18:27,610 - model_path: models
2025-04-17 17:18:27,610 - config_file_name: umc_MIntRec
2025-04-17 17:18:27,610 - results_file_name: results_umc_pre.csv
2025-04-17 17:18:27,610 - text_pretrained_model: uncased_L-12_H-768_A-12
2025-04-17 17:18:27,610 - pretrained_bert_model: uncased_L-12_H-768_A-12
2025-04-17 17:18:27,610 - pretrain_batch_size: 128
2025-04-17 17:18:27,610 - train_batch_size: 128
2025-04-17 17:18:27,610 - eval_batch_size: 128
2025-04-17 17:18:27,610 - test_batch_size: 128
2025-04-17 17:18:27,610 - num_pretrain_epochs: 100
2025-04-17 17:18:27,610 - num_train_epochs: 100
2025-04-17 17:18:27,610 - pretrain: [True]
2025-04-17 17:18:27,611 - aligned_method: ctc
2025-04-17 17:18:27,611 - need_aligned: False
2025-04-17 17:18:27,611 - freeze_pretrain_bert_parameters: [True]
2025-04-17 17:18:27,611 - freeze_train_bert_parameters: [True]
2025-04-17 17:18:27,611 - pretrain_temperature: [0.1]
2025-04-17 17:18:27,611 - train_temperature_sup: [0.5]
2025-04-17 17:18:27,611 - train_temperature_unsup: [2]
2025-04-17 17:18:27,611 - activation: tanh
2025-04-17 17:18:27,611 - lr_pre: [1e-05]
2025-04-17 17:18:27,611 - lr: [5e-05]
2025-04-17 17:18:27,611 - delta: [0.05]
2025-04-17 17:18:27,611 - thres: [0.1]
2025-04-17 17:18:27,611 - topk: [5]
2025-04-17 17:18:27,611 - weight_decay: 0.01
2025-04-17 17:18:27,611 - feat_dim: 768
2025-04-17 17:18:27,611 - hidden_size: 768
2025-04-17 17:18:27,611 - grad_clip: -1.0
2025-04-17 17:18:27,611 - warmup_proportion: [0.1]
2025-04-17 17:18:27,612 - hidden_dropout_prob: 0.1
2025-04-17 17:18:27,612 - weight: 1.0
2025-04-17 17:18:27,612 - loss_mode: rdrop
2025-04-17 17:18:27,612 - base_dim: 256
2025-04-17 17:18:27,612 - nheads: 8
2025-04-17 17:18:27,612 - attn_dropout: 0.1
2025-04-17 17:18:27,612 - relu_dropout: 0.1
2025-04-17 17:18:27,612 - embed_dropout: 0.01
2025-04-17 17:18:27,612 - res_dropout: 0.0
2025-04-17 17:18:27,612 - attn_mask: True
2025-04-17 17:18:27,612 - encoder_layers_1: 1
2025-04-17 17:18:27,612 - fusion_act: tanh
2025-04-17 17:18:27,612 - pred_output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/SMC/outputs_test2/MIntRec/umc_umc_MIntRec_bert-base-uncased_0
2025-04-17 17:18:27,612 - model_output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/SMC/outputs_test2/MIntRec/umc_umc_MIntRec_bert-base-uncased_0/models
2025-04-17 17:18:27,612 - text_seq_len: 30
2025-04-17 17:18:27,612 - video_seq_len: 230
2025-04-17 17:18:27,612 - audio_seq_len: 480
2025-04-17 17:18:27,612 - text_feat_dim: 768
2025-04-17 17:18:27,612 - video_feat_dim: 1024
2025-04-17 17:18:27,612 - audio_feat_dim: 768
2025-04-17 17:18:27,612 - num_labels: 20
2025-04-17 17:18:27,612 - num_train_examples: 1779
2025-04-17 17:18:27,612 - ============================== End Params ==============================
2025-04-17 17:18:28,892 - Freeze all parameters but the last layer for efficiency
2025-04-17 17:18:28,926 - Pre-training start...
2025-04-17 17:18:44,768 - ***** Epoch: 1: Eval results *****
2025-04-17 17:18:44,768 -   train_loss = 5.942015886306763
2025-04-17 17:19:00,982 - ***** Epoch: 2: Eval results *****
2025-04-17 17:19:00,982 -   train_loss = 5.945229564394269
2025-04-17 17:19:17,194 - ***** Epoch: 3: Eval results *****
2025-04-17 17:19:17,195 -   train_loss = 5.92879615511213
2025-04-17 17:19:33,089 - ***** Epoch: 4: Eval results *****
2025-04-17 17:19:33,089 -   train_loss = 5.9206607682364325
2025-04-17 17:19:49,491 - ***** Epoch: 5: Eval results *****
2025-04-17 17:19:49,491 -   train_loss = 5.906202827181135
2025-04-17 17:20:06,327 - ***** Epoch: 6: Eval results *****
2025-04-17 17:20:06,327 -   train_loss = 5.886433192661831
2025-04-17 17:20:23,874 - ***** Epoch: 7: Eval results *****
2025-04-17 17:20:23,874 -   train_loss = 5.843264034816197
2025-04-17 17:20:40,878 - ***** Epoch: 8: Eval results *****
2025-04-17 17:20:40,878 -   train_loss = 5.729844297681536
2025-04-17 17:20:57,917 - ***** Epoch: 9: Eval results *****
2025-04-17 17:20:57,918 -   train_loss = 5.474387202944074
2025-04-17 17:21:14,707 - ***** Epoch: 10: Eval results *****
2025-04-17 17:21:14,708 -   train_loss = 5.01254323550633
2025-04-17 17:21:31,165 - ***** Epoch: 11: Eval results *****
2025-04-17 17:21:31,165 -   train_loss = 4.4921208790370395
2025-04-17 17:21:47,652 - ***** Epoch: 12: Eval results *****
2025-04-17 17:21:47,653 -   train_loss = 4.029951998165676
2025-04-17 17:22:04,313 - ***** Epoch: 13: Eval results *****
2025-04-17 17:22:04,313 -   train_loss = 3.6978036676134383
2025-04-17 17:22:20,924 - ***** Epoch: 14: Eval results *****
2025-04-17 17:22:20,924 -   train_loss = 3.4336907863616943
2025-04-17 17:22:38,218 - ***** Epoch: 15: Eval results *****
2025-04-17 17:22:38,219 -   train_loss = 3.2374097108840942
2025-04-17 17:22:55,091 - ***** Epoch: 16: Eval results *****
2025-04-17 17:22:55,092 -   train_loss = 3.0430590425218855
2025-04-17 17:23:11,612 - ***** Epoch: 17: Eval results *****
2025-04-17 17:23:11,612 -   train_loss = 2.9196456500462125
2025-04-17 17:23:28,229 - ***** Epoch: 18: Eval results *****
2025-04-17 17:23:28,229 -   train_loss = 2.7721584183829173
2025-04-17 17:23:45,520 - ***** Epoch: 19: Eval results *****
2025-04-17 17:23:45,520 -   train_loss = 2.6886506932122365
2025-04-17 17:24:02,324 - ***** Epoch: 20: Eval results *****
2025-04-17 17:24:02,324 -   train_loss = 2.5725657599312917
2025-04-17 17:24:19,536 - ***** Epoch: 21: Eval results *****
2025-04-17 17:24:19,537 -   train_loss = 2.50264733178275
2025-04-17 17:24:37,058 - ***** Epoch: 22: Eval results *****
2025-04-17 17:24:37,058 -   train_loss = 2.4167686189923967
2025-04-17 17:24:54,249 - ***** Epoch: 23: Eval results *****
2025-04-17 17:24:54,250 -   train_loss = 2.368875707898821
2025-04-17 17:25:11,217 - ***** Epoch: 24: Eval results *****
2025-04-17 17:25:11,217 -   train_loss = 2.2922996282577515
2025-04-17 17:25:28,271 - ***** Epoch: 25: Eval results *****
2025-04-17 17:25:28,271 -   train_loss = 2.2429773466927663
2025-04-17 17:25:45,239 - ***** Epoch: 26: Eval results *****
2025-04-17 17:25:45,240 -   train_loss = 2.1962772948401317
2025-04-17 17:26:02,230 - ***** Epoch: 27: Eval results *****
2025-04-17 17:26:02,230 -   train_loss = 2.1515558106558665
2025-04-17 17:26:18,744 - ***** Epoch: 28: Eval results *****
2025-04-17 17:26:18,744 -   train_loss = 2.0950636182512556
2025-04-17 17:26:35,936 - ***** Epoch: 29: Eval results *****
2025-04-17 17:26:35,936 -   train_loss = 2.066980702536447
2025-04-17 17:26:52,810 - ***** Epoch: 30: Eval results *****
2025-04-17 17:26:52,810 -   train_loss = 2.020791241100856
2025-04-17 17:27:09,146 - ***** Epoch: 31: Eval results *****
2025-04-17 17:27:09,146 -   train_loss = 1.99441454240254
2025-04-17 17:27:26,464 - ***** Epoch: 32: Eval results *****
2025-04-17 17:27:26,464 -   train_loss = 1.9698130232947213
2025-04-17 17:27:43,096 - ***** Epoch: 33: Eval results *****
2025-04-17 17:27:43,097 -   train_loss = 1.9324100187846593
2025-04-17 17:27:59,871 - ***** Epoch: 34: Eval results *****
2025-04-17 17:27:59,871 -   train_loss = 1.9100768225533622
2025-04-17 17:28:15,885 - ***** Epoch: 35: Eval results *****
2025-04-17 17:28:15,885 -   train_loss = 1.8967713373047965
2025-04-17 17:28:32,440 - ***** Epoch: 36: Eval results *****
2025-04-17 17:28:32,440 -   train_loss = 1.8680246557508196
2025-04-17 17:28:48,460 - ***** Epoch: 37: Eval results *****
2025-04-17 17:28:48,460 -   train_loss = 1.8296988010406494
2025-04-17 17:29:05,183 - ***** Epoch: 38: Eval results *****
2025-04-17 17:29:05,183 -   train_loss = 1.8052075590406145
2025-04-17 17:29:21,292 - ***** Epoch: 39: Eval results *****
2025-04-17 17:29:21,293 -   train_loss = 1.7976079838616508
2025-04-17 17:29:38,171 - ***** Epoch: 40: Eval results *****
2025-04-17 17:29:38,172 -   train_loss = 1.786383969443185
2025-04-17 17:29:55,178 - ***** Epoch: 41: Eval results *****
2025-04-17 17:29:55,178 -   train_loss = 1.7688069258417403
2025-04-17 17:30:12,402 - ***** Epoch: 42: Eval results *****
2025-04-17 17:30:12,402 -   train_loss = 1.7642564603260584
2025-04-17 17:30:29,813 - ***** Epoch: 43: Eval results *****
2025-04-17 17:30:29,814 -   train_loss = 1.7371773208890642
2025-04-17 17:30:46,336 - ***** Epoch: 44: Eval results *****
2025-04-17 17:30:46,336 -   train_loss = 1.7271380254200526
2025-04-17 17:31:03,246 - ***** Epoch: 45: Eval results *****
2025-04-17 17:31:03,247 -   train_loss = 1.7179391128676278
2025-04-17 17:31:20,653 - ***** Epoch: 46: Eval results *****
2025-04-17 17:31:20,654 -   train_loss = 1.6998693602425712
2025-04-17 17:31:37,607 - ***** Epoch: 47: Eval results *****
2025-04-17 17:31:37,607 -   train_loss = 1.6892382161957877
2025-04-17 17:31:54,500 - ***** Epoch: 48: Eval results *****
2025-04-17 17:31:54,501 -   train_loss = 1.6780373283794947
2025-04-17 17:32:12,038 - ***** Epoch: 49: Eval results *****
2025-04-17 17:32:12,038 -   train_loss = 1.6680383682250977
2025-04-17 17:32:29,810 - ***** Epoch: 50: Eval results *****
2025-04-17 17:32:29,810 -   train_loss = 1.6496956092970712
2025-04-17 17:32:47,397 - ***** Epoch: 51: Eval results *****
2025-04-17 17:32:47,397 -   train_loss = 1.6576870765004839
2025-04-17 17:33:06,028 - ***** Epoch: 52: Eval results *****
2025-04-17 17:33:06,029 -   train_loss = 1.6384485278810774
2025-04-17 17:33:24,037 - ***** Epoch: 53: Eval results *****
2025-04-17 17:33:24,037 -   train_loss = 1.6415157403264726
2025-04-17 17:33:42,331 - ***** Epoch: 54: Eval results *****
2025-04-17 17:33:42,332 -   train_loss = 1.6445366484778268
2025-04-17 17:34:00,876 - ***** Epoch: 55: Eval results *****
2025-04-17 17:34:00,876 -   train_loss = 1.6213800736836024
2025-04-17 17:34:18,740 - ***** Epoch: 56: Eval results *****
2025-04-17 17:34:18,740 -   train_loss = 1.603984270777021
2025-04-17 17:34:35,248 - ***** Epoch: 57: Eval results *****
2025-04-17 17:34:35,248 -   train_loss = 1.5871297035898482
2025-04-17 17:34:52,457 - ***** Epoch: 58: Eval results *****
2025-04-17 17:34:52,457 -   train_loss = 1.6023281897817339
2025-04-17 17:35:11,781 - ***** Epoch: 59: Eval results *****
2025-04-17 17:35:11,782 -   train_loss = 1.5797857557024275
2025-04-17 17:35:30,276 - ***** Epoch: 60: Eval results *****
2025-04-17 17:35:30,276 -   train_loss = 1.5750234127044678
2025-04-17 17:35:48,746 - ***** Epoch: 61: Eval results *****
2025-04-17 17:35:48,746 -   train_loss = 1.576227298804692
2025-04-17 17:36:07,558 - ***** Epoch: 62: Eval results *****
2025-04-17 17:36:07,558 -   train_loss = 1.568065413406917
2025-04-17 17:36:25,490 - ***** Epoch: 63: Eval results *****
2025-04-17 17:36:25,490 -   train_loss = 1.5684285163879395
2025-04-17 17:36:42,822 - ***** Epoch: 64: Eval results *****
2025-04-17 17:36:42,822 -   train_loss = 1.541290785585131
2025-04-17 17:36:58,961 - ***** Epoch: 65: Eval results *****
2025-04-17 17:36:58,961 -   train_loss = 1.5524375523839677
2025-04-17 17:37:15,496 - ***** Epoch: 66: Eval results *****
2025-04-17 17:37:15,496 -   train_loss = 1.543379272733416
2025-04-17 17:37:32,150 - ***** Epoch: 67: Eval results *****
2025-04-17 17:37:32,150 -   train_loss = 1.5251521383013045
2025-04-17 17:37:49,644 - ***** Epoch: 68: Eval results *****
2025-04-17 17:37:49,644 -   train_loss = 1.5283978240830558
2025-04-17 17:38:06,258 - ***** Epoch: 69: Eval results *****
2025-04-17 17:38:06,259 -   train_loss = 1.522790449006217
2025-04-17 17:38:23,071 - ***** Epoch: 70: Eval results *****
2025-04-17 17:38:23,071 -   train_loss = 1.5320047651018416
2025-04-17 17:38:39,621 - ***** Epoch: 71: Eval results *****
2025-04-17 17:38:39,622 -   train_loss = 1.5204978329794747
2025-04-17 17:38:55,785 - ***** Epoch: 72: Eval results *****
2025-04-17 17:38:55,785 -   train_loss = 1.53544420003891
2025-04-17 17:39:12,288 - ***** Epoch: 73: Eval results *****
2025-04-17 17:39:12,288 -   train_loss = 1.526638925075531
2025-04-17 17:39:29,345 - ***** Epoch: 74: Eval results *****
2025-04-17 17:39:29,345 -   train_loss = 1.5217180933271135
2025-04-17 17:39:46,353 - ***** Epoch: 75: Eval results *****
2025-04-17 17:39:46,353 -   train_loss = 1.523929442678179
2025-04-17 17:40:02,353 - ***** Epoch: 76: Eval results *****
2025-04-17 17:40:02,353 -   train_loss = 1.513903898852212
2025-04-17 17:40:19,360 - ***** Epoch: 77: Eval results *****
2025-04-17 17:40:19,360 -   train_loss = 1.498715613569532
2025-04-17 17:40:35,925 - ***** Epoch: 78: Eval results *****
2025-04-17 17:40:35,925 -   train_loss = 1.505569577217102
2025-04-17 17:40:52,992 - ***** Epoch: 79: Eval results *****
2025-04-17 17:40:52,992 -   train_loss = 1.5081029449190413
2025-04-17 17:41:10,260 - ***** Epoch: 80: Eval results *****
2025-04-17 17:41:10,261 -   train_loss = 1.49734285899571
2025-04-17 17:41:27,696 - ***** Epoch: 81: Eval results *****
2025-04-17 17:41:27,696 -   train_loss = 1.5013441613742284
2025-04-17 17:41:45,414 - ***** Epoch: 82: Eval results *****
2025-04-17 17:41:45,414 -   train_loss = 1.4957347852843148
2025-04-17 17:42:02,954 - ***** Epoch: 83: Eval results *****
2025-04-17 17:42:02,954 -   train_loss = 1.5120207411902291
2025-04-17 17:42:20,117 - ***** Epoch: 84: Eval results *****
2025-04-17 17:42:20,117 -   train_loss = 1.493364896093096
2025-04-17 17:42:36,835 - ***** Epoch: 85: Eval results *****
2025-04-17 17:42:36,836 -   train_loss = 1.4965425985200065
2025-04-17 17:42:53,490 - ***** Epoch: 86: Eval results *****
2025-04-17 17:42:53,490 -   train_loss = 1.4934440510613578
2025-04-17 17:43:10,374 - ***** Epoch: 87: Eval results *****
2025-04-17 17:43:10,374 -   train_loss = 1.4893091320991516
2025-04-17 17:43:27,228 - ***** Epoch: 88: Eval results *****
2025-04-17 17:43:27,228 -   train_loss = 1.4877895542553492
2025-04-17 17:43:42,045 - ***** Epoch: 89: Eval results *****
2025-04-17 17:43:42,045 -   train_loss = 1.4808805925505502
2025-04-17 17:43:58,251 - ***** Epoch: 90: Eval results *****
2025-04-17 17:43:58,251 -   train_loss = 1.4965867485318864
2025-04-17 17:44:14,989 - ***** Epoch: 91: Eval results *****
2025-04-17 17:44:14,989 -   train_loss = 1.4823231526783534
2025-04-17 17:44:31,850 - ***** Epoch: 92: Eval results *****
2025-04-17 17:44:31,851 -   train_loss = 1.4853254301207406
2025-04-17 17:44:48,930 - ***** Epoch: 93: Eval results *****
2025-04-17 17:44:48,930 -   train_loss = 1.4868148820740836
2025-04-17 17:45:05,982 - ***** Epoch: 94: Eval results *****
2025-04-17 17:45:05,982 -   train_loss = 1.4881099462509155
2025-04-17 17:45:22,633 - ***** Epoch: 95: Eval results *****
2025-04-17 17:45:22,634 -   train_loss = 1.482932346207755
2025-04-17 17:45:39,103 - ***** Epoch: 96: Eval results *****
2025-04-17 17:45:39,103 -   train_loss = 1.4769306949206762
2025-04-17 17:45:55,354 - ***** Epoch: 97: Eval results *****
2025-04-17 17:45:55,355 -   train_loss = 1.4788521698543005
2025-04-17 17:46:12,538 - ***** Epoch: 98: Eval results *****
2025-04-17 17:46:12,538 -   train_loss = 1.496558862073081
2025-04-17 17:46:32,382 - ***** Epoch: 99: Eval results *****
2025-04-17 17:46:32,382 -   train_loss = 1.4860411201204573
2025-04-17 17:46:50,876 - ***** Epoch: 100: Eval results *****
2025-04-17 17:46:50,876 -   train_loss = 1.488894249711718
2025-04-17 17:46:53,292 - Pre-training finished...
2025-04-17 17:46:53,693 - Freeze all parameters but the last layer for efficiency
2025-04-17 17:46:53,702 - Multimodal Intent Recognition begins...
2025-04-17 17:46:53,702 - Training begins...
2025-04-17 17:47:10,031 - Initializing centroids with K-means++...
2025-04-17 17:47:10,117 - K-means++ used 0.09 s
2025-04-17 17:47:41,884 - K-means used 0.03 s
2025-04-17 17:47:42,927 - ***** Epoch: 1 *****
2025-04-17 17:47:42,928 - Supervised Training Loss: 4.370650
2025-04-17 17:47:42,929 - Unsupervised Training Loss: 5.537960
2025-04-17 17:48:11,311 - K-means used 0.03 s
2025-04-17 17:48:12,390 - ***** Epoch: 2 *****
2025-04-17 17:48:12,390 - Supervised Training Loss: 4.966920
2025-04-17 17:48:12,390 - Unsupervised Training Loss: 5.565050
2025-04-17 17:48:40,366 - K-means used 0.02 s
2025-04-17 17:48:41,477 - ***** Epoch: 3 *****
2025-04-17 17:48:41,477 - Supervised Training Loss: 4.807720
2025-04-17 17:48:41,477 - Unsupervised Training Loss: 5.418870
2025-04-17 17:49:09,813 - K-means used 0.02 s
2025-04-17 17:49:10,952 - ***** Epoch: 4 *****
2025-04-17 17:49:10,952 - Supervised Training Loss: 4.595230
2025-04-17 17:49:10,952 - Unsupervised Training Loss: 5.490500
2025-04-17 17:49:39,568 - K-means used 0.02 s
2025-04-17 17:49:40,773 - ***** Epoch: 5 *****
2025-04-17 17:49:40,773 - Supervised Training Loss: 4.293880
2025-04-17 17:49:40,773 - Unsupervised Training Loss: 5.531470
2025-04-17 17:50:08,666 - K-means used 0.02 s
2025-04-17 17:50:09,895 - ***** Epoch: 6 *****
2025-04-17 17:50:09,895 - Supervised Training Loss: 4.673390
2025-04-17 17:50:09,896 - Unsupervised Training Loss: 5.338940
2025-04-17 17:50:38,360 - K-means used 0.02 s
2025-04-17 17:50:39,640 - ***** Epoch: 7 *****
2025-04-17 17:50:39,640 - Supervised Training Loss: 4.566140
2025-04-17 17:50:39,640 - Unsupervised Training Loss: 5.446630
2025-04-17 17:51:08,038 - K-means used 0.02 s
2025-04-17 17:51:09,274 - ***** Epoch: 8 *****
2025-04-17 17:51:09,275 - Supervised Training Loss: 4.400100
2025-04-17 17:51:09,275 - Unsupervised Training Loss: 5.505740
2025-04-17 17:51:37,837 - K-means used 0.02 s
2025-04-17 17:51:39,139 - ***** Epoch: 9 *****
2025-04-17 17:51:39,139 - Supervised Training Loss: 4.651340
2025-04-17 17:51:39,139 - Unsupervised Training Loss: 5.541290
2025-04-17 17:52:07,317 - K-means used 0.02 s
2025-04-17 17:52:08,758 - ***** Epoch: 10 *****
2025-04-17 17:52:08,758 - Supervised Training Loss: 4.573030
2025-04-17 17:52:08,758 - Unsupervised Training Loss: 5.383810
2025-04-17 17:52:36,300 - K-means used 0.02 s
2025-04-17 17:52:37,706 - ***** Epoch: 11 *****
2025-04-17 17:52:37,706 - Supervised Training Loss: 4.503710
2025-04-17 17:52:37,706 - Unsupervised Training Loss: 5.464370
2025-04-17 17:53:04,771 - K-means used 0.01 s
2025-04-17 17:53:06,357 - ***** Epoch: 12 *****
2025-04-17 17:53:06,358 - Supervised Training Loss: 4.648820
2025-04-17 17:53:06,358 - Unsupervised Training Loss: 5.535350
2025-04-17 17:53:34,497 - K-means used 0.01 s
2025-04-17 17:53:36,009 - ***** Epoch: 13 *****
2025-04-17 17:53:36,009 - Supervised Training Loss: 4.616850
2025-04-17 17:53:36,009 - Unsupervised Training Loss: 5.251880
2025-04-17 17:54:04,379 - K-means used 0.02 s
2025-04-17 17:54:06,065 - ***** Epoch: 14 *****
2025-04-17 17:54:06,065 - Supervised Training Loss: 4.571330
2025-04-17 17:54:06,065 - Unsupervised Training Loss: 5.386930
2025-04-17 17:54:34,862 - K-means used 0.02 s
2025-04-17 17:54:36,568 - ***** Epoch: 15 *****
2025-04-17 17:54:36,569 - Supervised Training Loss: 4.457220
2025-04-17 17:54:36,569 - Unsupervised Training Loss: 5.490700
2025-04-17 17:55:05,532 - K-means used 0.02 s
2025-04-17 17:55:07,329 - ***** Epoch: 16 *****
2025-04-17 17:55:07,329 - Supervised Training Loss: 4.661770
2025-04-17 17:55:07,329 - Unsupervised Training Loss: 4.944100
2025-04-17 17:55:34,500 - K-means used 0.02 s
2025-04-17 17:55:36,406 - ***** Epoch: 17 *****
2025-04-17 17:55:36,406 - Supervised Training Loss: 4.646390
2025-04-17 17:55:36,406 - Unsupervised Training Loss: 5.167520
2025-04-17 17:55:54,839 - Training is finished...
2025-04-17 17:55:54,840 - Testing begins...
2025-04-17 17:56:01,858 - ***** Test results *****
2025-04-17 17:56:01,858 -   ACC = 42.25
2025-04-17 17:56:01,858 -   ARI = 20.77
2025-04-17 17:56:01,858 -   NMI = 45.53
2025-04-17 17:56:01,858 -   fmi = 25.7
2025-04-17 17:56:01,858 - Testing is finished...
2025-04-17 17:56:01,858 - Multimodal intent recognition is finished...
2025-04-17 17:56:01,858 - Results are saved in results/results_umc_pre.csv
