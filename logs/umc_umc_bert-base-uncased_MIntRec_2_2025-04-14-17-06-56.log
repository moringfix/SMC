2025-04-14 17:06:56,733 - ============================== Params ==============================
2025-04-14 17:06:56,733 - logger_name: umc_umc_bert-base-uncased_MIntRec_2
2025-04-14 17:06:56,733 - dataset: MIntRec
2025-04-14 17:06:56,733 - multimodal_method: umc
2025-04-14 17:06:56,733 - method: umc
2025-04-14 17:06:56,733 - text_backbone: bert-base-uncased
2025-04-14 17:06:56,733 - seed: 2
2025-04-14 17:06:56,733 - num_workers: 16
2025-04-14 17:06:56,733 - log_id: umc_umc_bert-base-uncased_MIntRec_2_2025-04-14-17-06-56
2025-04-14 17:06:56,733 - gpu_id: 0
2025-04-14 17:06:56,733 - data_path: /root/autodl-tmp/home/Share/Dataset/LZH
2025-04-14 17:06:56,734 - train: True
2025-04-14 17:06:56,734 - tune: True
2025-04-14 17:06:56,734 - save_model: True
2025-04-14 17:06:56,734 - save_results: True
2025-04-14 17:06:56,734 - log_path: logs
2025-04-14 17:06:56,734 - cache_path: cache
2025-04-14 17:06:56,734 - video_data_path: video_data
2025-04-14 17:06:56,734 - audio_data_path: audio_data
2025-04-14 17:06:56,734 - video_feats_path: swin_feats.pkl
2025-04-14 17:06:56,734 - audio_feats_path: wavlm_feats.pkl
2025-04-14 17:06:56,734 - results_path: results
2025-04-14 17:06:56,734 - output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/UMC/outputs/MIntRec
2025-04-14 17:06:56,734 - model_path: models
2025-04-14 17:06:56,734 - config_file_name: umc_MIntRec
2025-04-14 17:06:56,734 - results_file_name: results_umc.csv
2025-04-14 17:06:56,734 - text_pretrained_model: uncased_L-12_H-768_A-12
2025-04-14 17:06:56,734 - text_seq_len: 30
2025-04-14 17:06:56,734 - video_seq_len: 230
2025-04-14 17:06:56,734 - audio_seq_len: 480
2025-04-14 17:06:56,734 - text_feat_dim: 768
2025-04-14 17:06:56,734 - video_feat_dim: 1024
2025-04-14 17:06:56,734 - audio_feat_dim: 768
2025-04-14 17:06:56,734 - num_labels: 20
2025-04-14 17:06:56,734 - num_train_examples: 1779
2025-04-14 17:06:56,734 - pretrained_bert_model: uncased_L-12_H-768_A-12
2025-04-14 17:06:56,734 - pretrain_batch_size: 128
2025-04-14 17:06:56,734 - train_batch_size: 128
2025-04-14 17:06:56,734 - eval_batch_size: 128
2025-04-14 17:06:56,734 - test_batch_size: 128
2025-04-14 17:06:56,734 - num_pretrain_epochs: 100
2025-04-14 17:06:56,735 - num_train_epochs: 100
2025-04-14 17:06:56,735 - pretrain: [True]
2025-04-14 17:06:56,735 - aligned_method: ctc
2025-04-14 17:06:56,735 - need_aligned: False
2025-04-14 17:06:56,735 - freeze_pretrain_bert_parameters: [True]
2025-04-14 17:06:56,735 - freeze_train_bert_parameters: [True]
2025-04-14 17:06:56,735 - pretrain_temperature: [0.1]
2025-04-14 17:06:56,735 - train_temperature_sup: [7.6]
2025-04-14 17:06:56,735 - train_temperature_unsup: [0.9]
2025-04-14 17:06:56,735 - activation: tanh
2025-04-14 17:06:56,735 - lr_pre: 1e-05
2025-04-14 17:06:56,735 - lr: [0.0003]
2025-04-14 17:06:56,735 - delta: [0.05]
2025-04-14 17:06:56,735 - thres: [0.1]
2025-04-14 17:06:56,735 - topk: [5]
2025-04-14 17:06:56,735 - weight_decay: 0.01
2025-04-14 17:06:56,735 - feat_dim: 768
2025-04-14 17:06:56,735 - hidden_size: 768
2025-04-14 17:06:56,736 - grad_clip: -1.0
2025-04-14 17:06:56,736 - warmup_proportion: 0.5
2025-04-14 17:06:56,736 - hidden_dropout_prob: 0.1
2025-04-14 17:06:56,736 - weight: 1.0
2025-04-14 17:06:56,736 - loss_mode: rdrop
2025-04-14 17:06:56,736 - base_dim: 256
2025-04-14 17:06:56,736 - nheads: 8
2025-04-14 17:06:56,736 - attn_dropout: 0.1
2025-04-14 17:06:56,736 - relu_dropout: 0.1
2025-04-14 17:06:56,736 - embed_dropout: 0.01
2025-04-14 17:06:56,736 - res_dropout: 0.0
2025-04-14 17:06:56,736 - attn_mask: True
2025-04-14 17:06:56,736 - encoder_layers_1: 1
2025-04-14 17:06:56,736 - fusion_act: tanh
2025-04-14 17:06:56,736 - pred_output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/UMC/outputs/MIntRec/umc_umc_MIntRec_bert-base-uncased_2
2025-04-14 17:06:56,736 - model_output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/UMC/outputs/MIntRec/umc_umc_MIntRec_bert-base-uncased_2/models
2025-04-14 17:06:56,736 - ============================== End Params ==============================
2025-04-14 17:06:58,061 - Freeze all parameters but the last layer for efficiency
2025-04-14 17:06:58,098 - Pre-training start...
2025-04-14 17:07:15,281 - ***** Epoch: 1: Eval results *****
2025-04-14 17:07:15,282 -   train_loss = 5.9606238433292935
2025-04-14 17:07:31,881 - ***** Epoch: 2: Eval results *****
2025-04-14 17:07:31,881 -   train_loss = 5.958958762032645
2025-04-14 17:07:48,913 - ***** Epoch: 3: Eval results *****
2025-04-14 17:07:48,913 -   train_loss = 5.956834145954677
2025-04-14 17:08:05,937 - ***** Epoch: 4: Eval results *****
2025-04-14 17:08:05,938 -   train_loss = 5.952617474964687
2025-04-14 17:08:23,095 - ***** Epoch: 5: Eval results *****
2025-04-14 17:08:23,096 -   train_loss = 5.9533233642578125
2025-04-14 17:08:40,525 - ***** Epoch: 6: Eval results *****
2025-04-14 17:08:40,525 -   train_loss = 5.950619799750192
2025-04-14 17:08:57,344 - ***** Epoch: 7: Eval results *****
2025-04-14 17:08:57,344 -   train_loss = 5.945175341197422
2025-04-14 17:09:14,400 - ***** Epoch: 8: Eval results *****
2025-04-14 17:09:14,400 -   train_loss = 5.939927577972412
2025-04-14 17:09:31,300 - ***** Epoch: 9: Eval results *****
2025-04-14 17:09:31,300 -   train_loss = 5.936186211449759
2025-04-14 17:09:47,996 - ***** Epoch: 10: Eval results *****
2025-04-14 17:09:47,997 -   train_loss = 5.930566310882568
2025-04-14 17:10:04,344 - ***** Epoch: 11: Eval results *****
2025-04-14 17:10:04,345 -   train_loss = 5.9166556426457
2025-04-14 17:10:20,684 - ***** Epoch: 12: Eval results *****
2025-04-14 17:10:20,684 -   train_loss = 5.916486978530884
2025-04-14 17:10:36,649 - ***** Epoch: 13: Eval results *****
2025-04-14 17:10:36,649 -   train_loss = 5.901801381792341
2025-04-14 17:10:51,840 - ***** Epoch: 14: Eval results *****
2025-04-14 17:10:51,841 -   train_loss = 5.886326857975551
2025-04-14 17:11:07,537 - ***** Epoch: 15: Eval results *****
2025-04-14 17:11:07,538 -   train_loss = 5.855894769941058
2025-04-14 17:11:23,101 - ***** Epoch: 16: Eval results *****
2025-04-14 17:11:23,101 -   train_loss = 5.8333156790052145
2025-04-14 17:11:39,258 - ***** Epoch: 17: Eval results *****
2025-04-14 17:11:39,259 -   train_loss = 5.779304606573922
2025-04-14 17:11:55,060 - ***** Epoch: 18: Eval results *****
2025-04-14 17:11:55,060 -   train_loss = 5.690906013761248
2025-04-14 17:12:10,877 - ***** Epoch: 19: Eval results *****
2025-04-14 17:12:10,877 -   train_loss = 5.552900893347604
2025-04-14 17:12:27,209 - ***** Epoch: 20: Eval results *****
2025-04-14 17:12:27,209 -   train_loss = 5.339777197156634
2025-04-14 17:12:43,832 - ***** Epoch: 21: Eval results *****
2025-04-14 17:12:43,832 -   train_loss = 5.046753508704049
2025-04-14 17:12:59,917 - ***** Epoch: 22: Eval results *****
2025-04-14 17:12:59,918 -   train_loss = 4.776197297232492
2025-04-14 17:13:15,855 - ***** Epoch: 23: Eval results *****
2025-04-14 17:13:15,855 -   train_loss = 4.5083809580121725
2025-04-14 17:13:32,196 - ***** Epoch: 24: Eval results *****
2025-04-14 17:13:32,196 -   train_loss = 4.2580727849687845
2025-04-14 17:13:48,193 - ***** Epoch: 25: Eval results *****
2025-04-14 17:13:48,193 -   train_loss = 4.025586179324558
2025-04-14 17:14:03,985 - ***** Epoch: 26: Eval results *****
2025-04-14 17:14:03,986 -   train_loss = 3.813383323805673
2025-04-14 17:14:19,877 - ***** Epoch: 27: Eval results *****
2025-04-14 17:14:19,877 -   train_loss = 3.614003436905997
2025-04-14 17:14:36,318 - ***** Epoch: 28: Eval results *****
2025-04-14 17:14:36,318 -   train_loss = 3.4344538961138045
2025-04-14 17:14:51,473 - ***** Epoch: 29: Eval results *****
2025-04-14 17:14:51,473 -   train_loss = 3.284033945628575
2025-04-14 17:15:07,323 - ***** Epoch: 30: Eval results *****
2025-04-14 17:15:07,323 -   train_loss = 3.1570939336504256
2025-04-14 17:15:22,680 - ***** Epoch: 31: Eval results *****
2025-04-14 17:15:22,680 -   train_loss = 2.9998934950147356
2025-04-14 17:15:37,606 - ***** Epoch: 32: Eval results *****
2025-04-14 17:15:37,606 -   train_loss = 2.893157652446202
2025-04-14 17:15:53,101 - ***** Epoch: 33: Eval results *****
2025-04-14 17:15:53,101 -   train_loss = 2.7796852929251537
2025-04-14 17:16:08,753 - ***** Epoch: 34: Eval results *****
2025-04-14 17:16:08,753 -   train_loss = 2.686954515320914
2025-04-14 17:16:24,692 - ***** Epoch: 35: Eval results *****
2025-04-14 17:16:24,693 -   train_loss = 2.5948023114885603
2025-04-14 17:16:40,419 - ***** Epoch: 36: Eval results *****
2025-04-14 17:16:40,420 -   train_loss = 2.5263651268822804
2025-04-14 17:16:57,208 - ***** Epoch: 37: Eval results *****
2025-04-14 17:16:57,208 -   train_loss = 2.436188578605652
2025-04-14 17:17:13,178 - ***** Epoch: 38: Eval results *****
2025-04-14 17:17:13,178 -   train_loss = 2.353552086012704
2025-04-14 17:17:29,359 - ***** Epoch: 39: Eval results *****
2025-04-14 17:17:29,359 -   train_loss = 2.2818842955998013
2025-04-14 17:17:45,182 - ***** Epoch: 40: Eval results *****
2025-04-14 17:17:45,182 -   train_loss = 2.2302630288260326
2025-04-14 17:18:01,364 - ***** Epoch: 41: Eval results *****
2025-04-14 17:18:01,364 -   train_loss = 2.1683950083596364
2025-04-14 17:18:17,265 - ***** Epoch: 42: Eval results *****
2025-04-14 17:18:17,265 -   train_loss = 2.118515236037118
2025-04-14 17:18:33,742 - ***** Epoch: 43: Eval results *****
2025-04-14 17:18:33,742 -   train_loss = 2.083054678780692
2025-04-14 17:18:49,467 - ***** Epoch: 44: Eval results *****
2025-04-14 17:18:49,468 -   train_loss = 2.0359377775873457
2025-04-14 17:19:04,781 - ***** Epoch: 45: Eval results *****
2025-04-14 17:19:04,781 -   train_loss = 1.99053213426045
2025-04-14 17:19:20,891 - ***** Epoch: 46: Eval results *****
2025-04-14 17:19:20,891 -   train_loss = 1.9467548727989197
2025-04-14 17:19:37,381 - ***** Epoch: 47: Eval results *****
2025-04-14 17:19:37,382 -   train_loss = 1.922405753816877
2025-04-14 17:19:53,462 - ***** Epoch: 48: Eval results *****
2025-04-14 17:19:53,462 -   train_loss = 1.8987839477402824
2025-04-14 17:20:09,920 - ***** Epoch: 49: Eval results *****
2025-04-14 17:20:09,921 -   train_loss = 1.8616448215075903
2025-04-14 17:20:25,541 - ***** Epoch: 50: Eval results *****
2025-04-14 17:20:25,542 -   train_loss = 1.8258169037955148
2025-04-14 17:20:41,273 - ***** Epoch: 51: Eval results *****
2025-04-14 17:20:41,273 -   train_loss = 1.8100979243006026
2025-04-14 17:20:57,244 - ***** Epoch: 52: Eval results *****
2025-04-14 17:20:57,245 -   train_loss = 1.7835386310304915
2025-04-14 17:21:14,266 - ***** Epoch: 53: Eval results *****
2025-04-14 17:21:14,267 -   train_loss = 1.7377989036696297
2025-04-14 17:21:31,779 - ***** Epoch: 54: Eval results *****
2025-04-14 17:21:31,779 -   train_loss = 1.7256208232470922
2025-04-14 17:21:48,596 - ***** Epoch: 55: Eval results *****
2025-04-14 17:21:48,597 -   train_loss = 1.6932145271982466
2025-04-14 17:22:05,254 - ***** Epoch: 56: Eval results *****
2025-04-14 17:22:05,254 -   train_loss = 1.6942556415285384
2025-04-14 17:22:21,508 - ***** Epoch: 57: Eval results *****
2025-04-14 17:22:21,508 -   train_loss = 1.666801997593471
2025-04-14 17:22:38,013 - ***** Epoch: 58: Eval results *****
2025-04-14 17:22:38,014 -   train_loss = 1.652653089591435
2025-04-14 17:22:53,654 - ***** Epoch: 59: Eval results *****
2025-04-14 17:22:53,654 -   train_loss = 1.6370477761541093
2025-04-14 17:23:09,241 - ***** Epoch: 60: Eval results *****
2025-04-14 17:23:09,241 -   train_loss = 1.6083134923662459
2025-04-14 17:23:24,382 - ***** Epoch: 61: Eval results *****
2025-04-14 17:23:24,382 -   train_loss = 1.6007348469325475
2025-04-14 17:23:39,666 - ***** Epoch: 62: Eval results *****
2025-04-14 17:23:39,667 -   train_loss = 1.6028303844588143
2025-04-14 17:23:54,574 - ***** Epoch: 63: Eval results *****
2025-04-14 17:23:54,575 -   train_loss = 1.5914484177316939
2025-04-14 17:24:10,467 - ***** Epoch: 64: Eval results *****
2025-04-14 17:24:10,468 -   train_loss = 1.5760979226657323
2025-04-14 17:24:26,315 - ***** Epoch: 65: Eval results *****
2025-04-14 17:24:26,315 -   train_loss = 1.5594738040651595
2025-04-14 17:24:42,448 - ***** Epoch: 66: Eval results *****
2025-04-14 17:24:42,448 -   train_loss = 1.5626112903867448
2025-04-14 17:24:58,026 - ***** Epoch: 67: Eval results *****
2025-04-14 17:24:58,027 -   train_loss = 1.5487346138272966
2025-04-14 17:25:13,177 - ***** Epoch: 68: Eval results *****
2025-04-14 17:25:13,178 -   train_loss = 1.5423594287463598
2025-04-14 17:25:28,896 - ***** Epoch: 69: Eval results *****
2025-04-14 17:25:28,896 -   train_loss = 1.5298511726515633
2025-04-14 17:25:44,730 - ***** Epoch: 70: Eval results *****
2025-04-14 17:25:44,731 -   train_loss = 1.5331180776868547
2025-04-14 17:26:00,935 - ***** Epoch: 71: Eval results *****
2025-04-14 17:26:00,936 -   train_loss = 1.5148788009371077
2025-04-14 17:26:16,269 - ***** Epoch: 72: Eval results *****
2025-04-14 17:26:16,269 -   train_loss = 1.5010193841797965
2025-04-14 17:26:31,403 - ***** Epoch: 73: Eval results *****
2025-04-14 17:26:31,403 -   train_loss = 1.5147102304867335
2025-04-14 17:26:46,725 - ***** Epoch: 74: Eval results *****
2025-04-14 17:26:46,725 -   train_loss = 1.5006787436349052
2025-04-14 17:27:02,121 - ***** Epoch: 75: Eval results *****
2025-04-14 17:27:02,121 -   train_loss = 1.4964990360396249
2025-04-14 17:27:17,156 - ***** Epoch: 76: Eval results *****
2025-04-14 17:27:17,156 -   train_loss = 1.4899564044816154
2025-04-14 17:27:32,370 - ***** Epoch: 77: Eval results *****
2025-04-14 17:27:32,370 -   train_loss = 1.48144165958677
2025-04-14 17:27:48,066 - ***** Epoch: 78: Eval results *****
2025-04-14 17:27:48,067 -   train_loss = 1.4755672216415405
2025-04-14 17:28:03,666 - ***** Epoch: 79: Eval results *****
2025-04-14 17:28:03,666 -   train_loss = 1.4750765987804957
2025-04-14 17:28:18,609 - ***** Epoch: 80: Eval results *****
2025-04-14 17:28:18,609 -   train_loss = 1.478706419467926
2025-04-14 17:28:33,822 - ***** Epoch: 81: Eval results *****
2025-04-14 17:28:33,822 -   train_loss = 1.4703173637390137
2025-04-14 17:28:49,029 - ***** Epoch: 82: Eval results *****
2025-04-14 17:28:49,029 -   train_loss = 1.4631718226841517
2025-04-14 17:29:04,472 - ***** Epoch: 83: Eval results *****
2025-04-14 17:29:04,472 -   train_loss = 1.4661008630480086
2025-04-14 17:29:20,478 - ***** Epoch: 84: Eval results *****
2025-04-14 17:29:20,478 -   train_loss = 1.4795646497181483
2025-04-14 17:29:36,672 - ***** Epoch: 85: Eval results *****
2025-04-14 17:29:36,672 -   train_loss = 1.4639703461102076
2025-04-14 17:29:52,174 - ***** Epoch: 86: Eval results *****
2025-04-14 17:29:52,174 -   train_loss = 1.4561133469854082
2025-04-14 17:30:08,869 - ***** Epoch: 87: Eval results *****
2025-04-14 17:30:08,870 -   train_loss = 1.4628781761441911
2025-04-14 17:30:25,923 - ***** Epoch: 88: Eval results *****
2025-04-14 17:30:25,923 -   train_loss = 1.4585282291684831
2025-04-14 17:30:42,217 - ***** Epoch: 89: Eval results *****
2025-04-14 17:30:42,217 -   train_loss = 1.4578786066600256
2025-04-14 17:30:58,691 - ***** Epoch: 90: Eval results *****
2025-04-14 17:30:58,691 -   train_loss = 1.4574772119522095
2025-04-14 17:31:15,208 - ***** Epoch: 91: Eval results *****
2025-04-14 17:31:15,208 -   train_loss = 1.4529347675187247
2025-04-14 17:31:30,775 - ***** Epoch: 92: Eval results *****
2025-04-14 17:31:30,775 -   train_loss = 1.4586814897400993
2025-04-14 17:31:46,739 - ***** Epoch: 93: Eval results *****
2025-04-14 17:31:46,740 -   train_loss = 1.4654030544417245
2025-04-14 17:32:03,162 - ***** Epoch: 94: Eval results *****
2025-04-14 17:32:03,163 -   train_loss = 1.4597988384110587
2025-04-14 17:32:19,141 - ***** Epoch: 95: Eval results *****
2025-04-14 17:32:19,141 -   train_loss = 1.4522440263203211
2025-04-14 17:32:34,838 - ***** Epoch: 96: Eval results *****
2025-04-14 17:32:34,839 -   train_loss = 1.4680341482162476
2025-04-14 17:32:50,158 - ***** Epoch: 97: Eval results *****
2025-04-14 17:32:50,159 -   train_loss = 1.465115794113704
2025-04-14 17:33:05,480 - ***** Epoch: 98: Eval results *****
2025-04-14 17:33:05,480 -   train_loss = 1.4529715861592973
2025-04-14 17:33:21,770 - ***** Epoch: 99: Eval results *****
2025-04-14 17:33:21,770 -   train_loss = 1.458483738558633
2025-04-14 17:33:37,028 - ***** Epoch: 100: Eval results *****
2025-04-14 17:33:37,029 -   train_loss = 1.4610312921660287
2025-04-14 17:33:38,646 - Pre-training finished...
2025-04-14 17:33:38,891 - Freeze all parameters but the last layer for efficiency
2025-04-14 17:33:38,900 - Multimodal Intent Recognition begins...
2025-04-14 17:33:38,900 - Training begins...
2025-04-14 17:33:55,702 - Initializing centroids with K-means++...
2025-04-14 17:33:55,789 - K-means++ used 0.09 s
2025-04-14 17:34:26,332 - K-means used 0.02 s
2025-04-14 17:34:27,626 - ***** Epoch: 1 *****
2025-04-14 17:34:27,626 - Supervised Training Loss: 5.287390
2025-04-14 17:34:27,628 - Unsupervised Training Loss: 5.078770
2025-04-14 17:34:57,400 - K-means used 0.06 s
2025-04-14 17:34:58,757 - ***** Epoch: 2 *****
2025-04-14 17:34:58,757 - Supervised Training Loss: 4.583290
2025-04-14 17:34:58,757 - Unsupervised Training Loss: 5.096460
2025-04-14 17:35:28,918 - K-means used 0.02 s
2025-04-14 17:35:30,339 - ***** Epoch: 3 *****
2025-04-14 17:35:30,339 - Supervised Training Loss: 5.769120
2025-04-14 17:35:30,340 - Unsupervised Training Loss: 4.935040
2025-04-14 17:36:01,306 - K-means used 0.04 s
2025-04-14 17:36:02,630 - ***** Epoch: 4 *****
2025-04-14 17:36:02,630 - Supervised Training Loss: 5.645650
2025-04-14 17:36:02,630 - Unsupervised Training Loss: 5.012680
2025-04-14 17:36:32,437 - K-means used 0.03 s
2025-04-14 17:36:34,112 - ***** Epoch: 5 *****
2025-04-14 17:36:34,112 - Supervised Training Loss: 5.343790
2025-04-14 17:36:34,112 - Unsupervised Training Loss: 5.046840
2025-04-14 17:37:03,771 - K-means used 0.03 s
2025-04-14 17:37:05,359 - ***** Epoch: 6 *****
2025-04-14 17:37:05,360 - Supervised Training Loss: 5.809060
2025-04-14 17:37:05,360 - Unsupervised Training Loss: 4.830480
2025-04-14 17:37:36,910 - K-means used 0.11 s
2025-04-14 17:37:38,155 - ***** Epoch: 7 *****
2025-04-14 17:37:38,155 - Supervised Training Loss: 5.738510
2025-04-14 17:37:38,156 - Unsupervised Training Loss: 4.960650
2025-04-14 17:38:08,644 - K-means used 0.02 s
2025-04-14 17:38:10,196 - ***** Epoch: 8 *****
2025-04-14 17:38:10,196 - Supervised Training Loss: 5.597820
2025-04-14 17:38:10,196 - Unsupervised Training Loss: 5.005740
2025-04-14 17:38:40,779 - K-means used 0.02 s
2025-04-14 17:38:42,438 - ***** Epoch: 9 *****
2025-04-14 17:38:42,438 - Supervised Training Loss: 5.837460
2025-04-14 17:38:42,438 - Unsupervised Training Loss: 5.046300
2025-04-14 17:39:12,214 - K-means used 0.06 s
2025-04-14 17:39:13,802 - ***** Epoch: 10 *****
2025-04-14 17:39:13,803 - Supervised Training Loss: 5.777330
2025-04-14 17:39:13,803 - Unsupervised Training Loss: 4.891160
2025-04-14 17:39:43,686 - K-means used 0.02 s
2025-04-14 17:39:45,356 - ***** Epoch: 11 *****
2025-04-14 17:39:45,357 - Supervised Training Loss: 5.696850
2025-04-14 17:39:45,357 - Unsupervised Training Loss: 4.977600
2025-04-14 17:40:15,204 - K-means used 0.07 s
2025-04-14 17:40:17,422 - ***** Epoch: 12 *****
2025-04-14 17:40:17,423 - Supervised Training Loss: 5.840440
2025-04-14 17:40:17,423 - Unsupervised Training Loss: 5.024170
2025-04-14 17:40:46,333 - K-means used 0.02 s
2025-04-14 17:40:48,214 - ***** Epoch: 13 *****
2025-04-14 17:40:48,214 - Supervised Training Loss: 5.801220
2025-04-14 17:40:48,214 - Unsupervised Training Loss: 4.741100
2025-04-14 17:41:17,835 - K-means used 0.02 s
2025-04-14 17:41:19,573 - ***** Epoch: 14 *****
2025-04-14 17:41:19,573 - Supervised Training Loss: 5.747910
2025-04-14 17:41:19,573 - Unsupervised Training Loss: 4.868780
2025-04-14 17:41:49,162 - K-means used 0.02 s
2025-04-14 17:41:51,155 - ***** Epoch: 15 *****
2025-04-14 17:41:51,155 - Supervised Training Loss: 5.606740
2025-04-14 17:41:51,155 - Unsupervised Training Loss: 4.958080
2025-04-14 17:42:20,188 - K-means used 0.02 s
2025-04-14 17:42:22,303 - ***** Epoch: 16 *****
2025-04-14 17:42:22,303 - Supervised Training Loss: 5.816840
2025-04-14 17:42:22,303 - Unsupervised Training Loss: 4.403620
2025-04-14 17:42:51,245 - K-means used 0.02 s
2025-04-14 17:42:53,337 - ***** Epoch: 17 *****
2025-04-14 17:42:53,338 - Supervised Training Loss: 5.779070
2025-04-14 17:42:53,338 - Unsupervised Training Loss: 4.638280
2025-04-14 17:43:12,373 - Training is finished...
2025-04-14 17:43:12,373 - Testing begins...
2025-04-14 17:43:19,748 - ***** Test results *****
2025-04-14 17:43:19,749 -   ACC = 40.45
2025-04-14 17:43:19,749 -   ARI = 20.28
2025-04-14 17:43:19,749 -   NMI = 46.75
2025-04-14 17:43:19,749 -   fmi = 25.31
2025-04-14 17:43:19,749 - Testing is finished...
2025-04-14 17:43:19,749 - Multimodal intent recognition is finished...
2025-04-14 17:43:19,749 - Results are saved in results/results_umc.csv
