2025-04-14 17:43:37,987 - ============================== Params ==============================
2025-04-14 17:43:37,987 - logger_name: umc_umc_bert-base-uncased_MIntRec_3
2025-04-14 17:43:37,988 - dataset: MIntRec
2025-04-14 17:43:37,988 - multimodal_method: umc
2025-04-14 17:43:37,988 - method: umc
2025-04-14 17:43:37,988 - text_backbone: bert-base-uncased
2025-04-14 17:43:37,988 - seed: 3
2025-04-14 17:43:37,988 - num_workers: 16
2025-04-14 17:43:37,988 - log_id: umc_umc_bert-base-uncased_MIntRec_3_2025-04-14-17-43-37
2025-04-14 17:43:37,988 - gpu_id: 0
2025-04-14 17:43:37,988 - data_path: /root/autodl-tmp/home/Share/Dataset/LZH
2025-04-14 17:43:37,988 - train: True
2025-04-14 17:43:37,988 - tune: True
2025-04-14 17:43:37,988 - save_model: True
2025-04-14 17:43:37,988 - save_results: True
2025-04-14 17:43:37,988 - log_path: logs
2025-04-14 17:43:37,988 - cache_path: cache
2025-04-14 17:43:37,988 - video_data_path: video_data
2025-04-14 17:43:37,988 - audio_data_path: audio_data
2025-04-14 17:43:37,988 - video_feats_path: swin_feats.pkl
2025-04-14 17:43:37,988 - audio_feats_path: wavlm_feats.pkl
2025-04-14 17:43:37,988 - results_path: results
2025-04-14 17:43:37,988 - output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/UMC/outputs/MIntRec
2025-04-14 17:43:37,988 - model_path: models
2025-04-14 17:43:37,988 - config_file_name: umc_MIntRec
2025-04-14 17:43:37,989 - results_file_name: results_umc.csv
2025-04-14 17:43:37,989 - text_pretrained_model: uncased_L-12_H-768_A-12
2025-04-14 17:43:37,989 - text_seq_len: 30
2025-04-14 17:43:37,989 - video_seq_len: 230
2025-04-14 17:43:37,989 - audio_seq_len: 480
2025-04-14 17:43:37,989 - text_feat_dim: 768
2025-04-14 17:43:37,989 - video_feat_dim: 1024
2025-04-14 17:43:37,989 - audio_feat_dim: 768
2025-04-14 17:43:37,989 - num_labels: 20
2025-04-14 17:43:37,989 - num_train_examples: 1779
2025-04-14 17:43:37,989 - pretrained_bert_model: uncased_L-12_H-768_A-12
2025-04-14 17:43:37,989 - pretrain_batch_size: 128
2025-04-14 17:43:37,989 - train_batch_size: 128
2025-04-14 17:43:37,989 - eval_batch_size: 128
2025-04-14 17:43:37,989 - test_batch_size: 128
2025-04-14 17:43:37,989 - num_pretrain_epochs: 100
2025-04-14 17:43:37,989 - num_train_epochs: 100
2025-04-14 17:43:37,989 - pretrain: [True]
2025-04-14 17:43:37,989 - aligned_method: ctc
2025-04-14 17:43:37,989 - need_aligned: False
2025-04-14 17:43:37,989 - freeze_pretrain_bert_parameters: [True]
2025-04-14 17:43:37,989 - freeze_train_bert_parameters: [True]
2025-04-14 17:43:37,989 - pretrain_temperature: [0.1]
2025-04-14 17:43:37,989 - train_temperature_sup: [7.6]
2025-04-14 17:43:37,989 - train_temperature_unsup: [0.9]
2025-04-14 17:43:37,989 - activation: tanh
2025-04-14 17:43:37,989 - lr_pre: 1e-05
2025-04-14 17:43:37,990 - lr: [0.0003]
2025-04-14 17:43:37,990 - delta: [0.05]
2025-04-14 17:43:37,990 - thres: [0.1]
2025-04-14 17:43:37,990 - topk: [5]
2025-04-14 17:43:37,990 - weight_decay: 0.01
2025-04-14 17:43:37,990 - feat_dim: 768
2025-04-14 17:43:37,990 - hidden_size: 768
2025-04-14 17:43:37,990 - grad_clip: -1.0
2025-04-14 17:43:37,990 - warmup_proportion: 0.5
2025-04-14 17:43:37,990 - hidden_dropout_prob: 0.1
2025-04-14 17:43:37,990 - weight: 1.0
2025-04-14 17:43:37,990 - loss_mode: rdrop
2025-04-14 17:43:37,990 - base_dim: 256
2025-04-14 17:43:37,990 - nheads: 8
2025-04-14 17:43:37,990 - attn_dropout: 0.1
2025-04-14 17:43:37,990 - relu_dropout: 0.1
2025-04-14 17:43:37,990 - embed_dropout: 0.01
2025-04-14 17:43:37,990 - res_dropout: 0.0
2025-04-14 17:43:37,990 - attn_mask: True
2025-04-14 17:43:37,990 - encoder_layers_1: 1
2025-04-14 17:43:37,990 - fusion_act: tanh
2025-04-14 17:43:37,990 - pred_output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/UMC/outputs/MIntRec/umc_umc_MIntRec_bert-base-uncased_3
2025-04-14 17:43:37,990 - model_output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/UMC/outputs/MIntRec/umc_umc_MIntRec_bert-base-uncased_3/models
2025-04-14 17:43:37,990 - ============================== End Params ==============================
2025-04-14 17:43:39,055 - Freeze all parameters but the last layer for efficiency
2025-04-14 17:43:39,089 - Pre-training start...
2025-04-14 17:43:54,313 - ***** Epoch: 1: Eval results *****
2025-04-14 17:43:54,313 -   train_loss = 5.958394391196115
2025-04-14 17:44:09,124 - ***** Epoch: 2: Eval results *****
2025-04-14 17:44:09,124 -   train_loss = 5.963605846677508
2025-04-14 17:44:24,365 - ***** Epoch: 3: Eval results *****
2025-04-14 17:44:24,365 -   train_loss = 5.962784835270473
2025-04-14 17:44:39,224 - ***** Epoch: 4: Eval results *****
2025-04-14 17:44:39,224 -   train_loss = 5.963015079498291
2025-04-14 17:44:55,194 - ***** Epoch: 5: Eval results *****
2025-04-14 17:44:55,194 -   train_loss = 5.963409628186907
2025-04-14 17:45:10,987 - ***** Epoch: 6: Eval results *****
2025-04-14 17:45:10,987 -   train_loss = 5.95563496862139
2025-04-14 17:45:26,989 - ***** Epoch: 7: Eval results *****
2025-04-14 17:45:26,989 -   train_loss = 5.9544409683772495
2025-04-14 17:45:42,785 - ***** Epoch: 8: Eval results *****
2025-04-14 17:45:42,785 -   train_loss = 5.953428336552212
2025-04-14 17:45:59,409 - ***** Epoch: 9: Eval results *****
2025-04-14 17:45:59,409 -   train_loss = 5.937513453619821
2025-04-14 17:46:15,339 - ***** Epoch: 10: Eval results *****
2025-04-14 17:46:15,339 -   train_loss = 5.931964090892246
2025-04-14 17:46:31,121 - ***** Epoch: 11: Eval results *****
2025-04-14 17:46:31,121 -   train_loss = 5.929917539869036
2025-04-14 17:46:46,688 - ***** Epoch: 12: Eval results *****
2025-04-14 17:46:46,689 -   train_loss = 5.918503931590489
2025-04-14 17:47:02,517 - ***** Epoch: 13: Eval results *****
2025-04-14 17:47:02,517 -   train_loss = 5.9092628955841064
2025-04-14 17:47:18,672 - ***** Epoch: 14: Eval results *****
2025-04-14 17:47:18,673 -   train_loss = 5.883241755621774
2025-04-14 17:47:34,839 - ***** Epoch: 15: Eval results *****
2025-04-14 17:47:34,839 -   train_loss = 5.855455296380179
2025-04-14 17:47:50,896 - ***** Epoch: 16: Eval results *****
2025-04-14 17:47:50,896 -   train_loss = 5.8266003131866455
2025-04-14 17:48:07,742 - ***** Epoch: 17: Eval results *****
2025-04-14 17:48:07,743 -   train_loss = 5.758595364434378
2025-04-14 17:48:23,441 - ***** Epoch: 18: Eval results *****
2025-04-14 17:48:23,441 -   train_loss = 5.659095219203404
2025-04-14 17:48:39,190 - ***** Epoch: 19: Eval results *****
2025-04-14 17:48:39,190 -   train_loss = 5.514867714473179
2025-04-14 17:48:54,970 - ***** Epoch: 20: Eval results *****
2025-04-14 17:48:54,970 -   train_loss = 5.304683549063546
2025-04-14 17:49:10,312 - ***** Epoch: 21: Eval results *****
2025-04-14 17:49:10,312 -   train_loss = 5.028524535042899
2025-04-14 17:49:26,462 - ***** Epoch: 22: Eval results *****
2025-04-14 17:49:26,462 -   train_loss = 4.743766410010202
2025-04-14 17:49:42,609 - ***** Epoch: 23: Eval results *****
2025-04-14 17:49:42,609 -   train_loss = 4.497014284133911
2025-04-14 17:49:58,399 - ***** Epoch: 24: Eval results *****
2025-04-14 17:49:58,400 -   train_loss = 4.278868300574167
2025-04-14 17:50:14,528 - ***** Epoch: 25: Eval results *****
2025-04-14 17:50:14,528 -   train_loss = 4.040535535131182
2025-04-14 17:50:30,714 - ***** Epoch: 26: Eval results *****
2025-04-14 17:50:30,714 -   train_loss = 3.843787363597325
2025-04-14 17:50:47,293 - ***** Epoch: 27: Eval results *****
2025-04-14 17:50:47,293 -   train_loss = 3.671750068664551
2025-04-14 17:51:03,340 - ***** Epoch: 28: Eval results *****
2025-04-14 17:51:03,340 -   train_loss = 3.511806539126805
2025-04-14 17:51:18,695 - ***** Epoch: 29: Eval results *****
2025-04-14 17:51:18,695 -   train_loss = 3.325914536203657
2025-04-14 17:51:34,150 - ***** Epoch: 30: Eval results *****
2025-04-14 17:51:34,150 -   train_loss = 3.1744313750948225
2025-04-14 17:51:50,152 - ***** Epoch: 31: Eval results *****
2025-04-14 17:51:50,152 -   train_loss = 3.0525875432150706
2025-04-14 17:52:05,631 - ***** Epoch: 32: Eval results *****
2025-04-14 17:52:05,632 -   train_loss = 2.9402808121272495
2025-04-14 17:52:21,326 - ***** Epoch: 33: Eval results *****
2025-04-14 17:52:21,326 -   train_loss = 2.7897267171314786
2025-04-14 17:52:36,617 - ***** Epoch: 34: Eval results *****
2025-04-14 17:52:36,617 -   train_loss = 2.712785039629255
2025-04-14 17:52:52,982 - ***** Epoch: 35: Eval results *****
2025-04-14 17:52:52,982 -   train_loss = 2.6475987945284163
2025-04-14 17:53:08,814 - ***** Epoch: 36: Eval results *****
2025-04-14 17:53:08,814 -   train_loss = 2.5477472884314403
2025-04-14 17:53:24,576 - ***** Epoch: 37: Eval results *****
2025-04-14 17:53:24,577 -   train_loss = 2.4363394805363248
2025-04-14 17:53:40,660 - ***** Epoch: 38: Eval results *****
2025-04-14 17:53:40,660 -   train_loss = 2.380130308015006
2025-04-14 17:53:56,980 - ***** Epoch: 39: Eval results *****
2025-04-14 17:53:56,981 -   train_loss = 2.306690216064453
2025-04-14 17:54:12,577 - ***** Epoch: 40: Eval results *****
2025-04-14 17:54:12,577 -   train_loss = 2.260338510785784
2025-04-14 17:54:28,831 - ***** Epoch: 41: Eval results *****
2025-04-14 17:54:28,831 -   train_loss = 2.1875518219811574
2025-04-14 17:54:44,970 - ***** Epoch: 42: Eval results *****
2025-04-14 17:54:44,970 -   train_loss = 2.142239434378488
2025-04-14 17:55:00,456 - ***** Epoch: 43: Eval results *****
2025-04-14 17:55:00,456 -   train_loss = 2.0754104937825884
2025-04-14 17:55:16,625 - ***** Epoch: 44: Eval results *****
2025-04-14 17:55:16,625 -   train_loss = 2.0342792017119273
2025-04-14 17:55:32,816 - ***** Epoch: 45: Eval results *****
2025-04-14 17:55:32,817 -   train_loss = 2.0134884885379245
2025-04-14 17:55:48,919 - ***** Epoch: 46: Eval results *****
2025-04-14 17:55:48,920 -   train_loss = 1.9587212375232153
2025-04-14 17:56:05,555 - ***** Epoch: 47: Eval results *****
2025-04-14 17:56:05,555 -   train_loss = 1.914073075566973
2025-04-14 17:56:22,128 - ***** Epoch: 48: Eval results *****
2025-04-14 17:56:22,128 -   train_loss = 1.8596136995724268
2025-04-14 17:56:37,494 - ***** Epoch: 49: Eval results *****
2025-04-14 17:56:37,495 -   train_loss = 1.8328484041350228
2025-04-14 17:56:53,059 - ***** Epoch: 50: Eval results *****
2025-04-14 17:56:53,059 -   train_loss = 1.8139105694634574
2025-04-14 17:57:08,033 - ***** Epoch: 51: Eval results *****
2025-04-14 17:57:08,033 -   train_loss = 1.7708241939544678
2025-04-14 17:57:23,481 - ***** Epoch: 52: Eval results *****
2025-04-14 17:57:23,481 -   train_loss = 1.7562080877167838
2025-04-14 17:57:39,198 - ***** Epoch: 53: Eval results *****
2025-04-14 17:57:39,198 -   train_loss = 1.7228997690337045
2025-04-14 17:57:54,549 - ***** Epoch: 54: Eval results *****
2025-04-14 17:57:54,550 -   train_loss = 1.7003247737884521
2025-04-14 17:58:10,673 - ***** Epoch: 55: Eval results *****
2025-04-14 17:58:10,673 -   train_loss = 1.682667417185647
2025-04-14 17:58:25,874 - ***** Epoch: 56: Eval results *****
2025-04-14 17:58:25,874 -   train_loss = 1.6563288399151392
2025-04-14 17:58:41,546 - ***** Epoch: 57: Eval results *****
2025-04-14 17:58:41,546 -   train_loss = 1.6509178962026323
2025-04-14 17:58:56,649 - ***** Epoch: 58: Eval results *****
2025-04-14 17:58:56,650 -   train_loss = 1.6433622070721217
2025-04-14 17:59:12,087 - ***** Epoch: 59: Eval results *****
2025-04-14 17:59:12,087 -   train_loss = 1.625234569822039
2025-04-14 17:59:27,568 - ***** Epoch: 60: Eval results *****
2025-04-14 17:59:27,568 -   train_loss = 1.6025020565305437
2025-04-14 17:59:43,045 - ***** Epoch: 61: Eval results *****
2025-04-14 17:59:43,046 -   train_loss = 1.5896337372916085
2025-04-14 17:59:58,909 - ***** Epoch: 62: Eval results *****
2025-04-14 17:59:58,909 -   train_loss = 1.5893564309392656
2025-04-14 18:00:14,686 - ***** Epoch: 63: Eval results *****
2025-04-14 18:00:14,686 -   train_loss = 1.5579829556601388
2025-04-14 18:00:30,569 - ***** Epoch: 64: Eval results *****
2025-04-14 18:00:30,569 -   train_loss = 1.55862329687391
2025-04-14 18:00:46,618 - ***** Epoch: 65: Eval results *****
2025-04-14 18:00:46,618 -   train_loss = 1.557980171271733
2025-04-14 18:01:02,241 - ***** Epoch: 66: Eval results *****
2025-04-14 18:01:02,241 -   train_loss = 1.5526028871536255
2025-04-14 18:01:17,851 - ***** Epoch: 67: Eval results *****
2025-04-14 18:01:17,852 -   train_loss = 1.5412122351782662
2025-04-14 18:01:34,350 - ***** Epoch: 68: Eval results *****
2025-04-14 18:01:34,351 -   train_loss = 1.5460652794156755
2025-04-14 18:01:50,220 - ***** Epoch: 69: Eval results *****
2025-04-14 18:01:50,220 -   train_loss = 1.523160423551287
2025-04-14 18:02:06,334 - ***** Epoch: 70: Eval results *****
2025-04-14 18:02:06,334 -   train_loss = 1.528994517666953
2025-04-14 18:02:23,273 - ***** Epoch: 71: Eval results *****
2025-04-14 18:02:23,273 -   train_loss = 1.5095447897911072
2025-04-14 18:02:39,859 - ***** Epoch: 72: Eval results *****
2025-04-14 18:02:39,860 -   train_loss = 1.5019689798355103
2025-04-14 18:02:56,669 - ***** Epoch: 73: Eval results *****
2025-04-14 18:02:56,669 -   train_loss = 1.4954066021101815
2025-04-14 18:03:13,565 - ***** Epoch: 74: Eval results *****
2025-04-14 18:03:13,565 -   train_loss = 1.4843975475856237
2025-04-14 18:03:30,574 - ***** Epoch: 75: Eval results *****
2025-04-14 18:03:30,574 -   train_loss = 1.499776039804731
2025-04-14 18:03:47,187 - ***** Epoch: 76: Eval results *****
2025-04-14 18:03:47,187 -   train_loss = 1.4869939599718367
2025-04-14 18:04:03,769 - ***** Epoch: 77: Eval results *****
2025-04-14 18:04:03,769 -   train_loss = 1.468133773122515
2025-04-14 18:04:20,655 - ***** Epoch: 78: Eval results *****
2025-04-14 18:04:20,655 -   train_loss = 1.4733101725578308
2025-04-14 18:04:37,482 - ***** Epoch: 79: Eval results *****
2025-04-14 18:04:37,482 -   train_loss = 1.470147430896759
2025-04-14 18:04:54,173 - ***** Epoch: 80: Eval results *****
2025-04-14 18:04:54,173 -   train_loss = 1.4804044791630335
2025-04-14 18:05:10,470 - ***** Epoch: 81: Eval results *****
2025-04-14 18:05:10,471 -   train_loss = 1.4597301483154297
2025-04-14 18:05:27,268 - ***** Epoch: 82: Eval results *****
2025-04-14 18:05:27,268 -   train_loss = 1.4593450341905867
2025-04-14 18:05:43,431 - ***** Epoch: 83: Eval results *****
2025-04-14 18:05:43,431 -   train_loss = 1.4670886908258711
2025-04-14 18:05:59,329 - ***** Epoch: 84: Eval results *****
2025-04-14 18:05:59,329 -   train_loss = 1.4570799725396293
2025-04-14 18:06:15,207 - ***** Epoch: 85: Eval results *****
2025-04-14 18:06:15,207 -   train_loss = 1.4552770001547677
2025-04-14 18:06:31,454 - ***** Epoch: 86: Eval results *****
2025-04-14 18:06:31,454 -   train_loss = 1.4516822951180595
2025-04-14 18:06:47,889 - ***** Epoch: 87: Eval results *****
2025-04-14 18:06:47,889 -   train_loss = 1.4528398684092931
2025-04-14 18:07:03,603 - ***** Epoch: 88: Eval results *****
2025-04-14 18:07:03,604 -   train_loss = 1.4528947728020805
2025-04-14 18:07:19,417 - ***** Epoch: 89: Eval results *****
2025-04-14 18:07:19,417 -   train_loss = 1.4481311185019357
2025-04-14 18:07:35,061 - ***** Epoch: 90: Eval results *****
2025-04-14 18:07:35,061 -   train_loss = 1.4567870668002538
2025-04-14 18:07:51,298 - ***** Epoch: 91: Eval results *****
2025-04-14 18:07:51,298 -   train_loss = 1.4528983575957162
2025-04-14 18:08:07,779 - ***** Epoch: 92: Eval results *****
2025-04-14 18:08:07,780 -   train_loss = 1.4478634425571986
2025-04-14 18:08:23,836 - ***** Epoch: 93: Eval results *****
2025-04-14 18:08:23,836 -   train_loss = 1.4463383896010262
2025-04-14 18:08:40,311 - ***** Epoch: 94: Eval results *****
2025-04-14 18:08:40,311 -   train_loss = 1.4453147394316537
2025-04-14 18:08:56,129 - ***** Epoch: 95: Eval results *****
2025-04-14 18:08:56,129 -   train_loss = 1.436013204710824
2025-04-14 18:09:12,078 - ***** Epoch: 96: Eval results *****
2025-04-14 18:09:12,078 -   train_loss = 1.4477193781307764
2025-04-14 18:09:28,289 - ***** Epoch: 97: Eval results *****
2025-04-14 18:09:28,290 -   train_loss = 1.4438733628817968
2025-04-14 18:09:44,316 - ***** Epoch: 98: Eval results *****
2025-04-14 18:09:44,316 -   train_loss = 1.4547363775117057
2025-04-14 18:10:00,239 - ***** Epoch: 99: Eval results *****
2025-04-14 18:10:00,240 -   train_loss = 1.4453875507627214
2025-04-14 18:10:16,060 - ***** Epoch: 100: Eval results *****
2025-04-14 18:10:16,060 -   train_loss = 1.447544242654528
2025-04-14 18:10:16,628 - Pre-training finished...
2025-04-14 18:10:16,878 - Freeze all parameters but the last layer for efficiency
2025-04-14 18:10:16,887 - Multimodal Intent Recognition begins...
2025-04-14 18:10:16,887 - Training begins...
2025-04-14 18:10:33,519 - Initializing centroids with K-means++...
2025-04-14 18:10:33,597 - K-means++ used 0.08 s
2025-04-14 18:11:04,872 - K-means used 0.02 s
2025-04-14 18:11:06,117 - ***** Epoch: 1 *****
2025-04-14 18:11:06,118 - Supervised Training Loss: 5.300350
2025-04-14 18:11:06,119 - Unsupervised Training Loss: 5.084330
2025-04-14 18:11:35,620 - K-means used 0.02 s
2025-04-14 18:11:36,957 - ***** Epoch: 2 *****
2025-04-14 18:11:36,957 - Supervised Training Loss: 4.149710
2025-04-14 18:11:36,957 - Unsupervised Training Loss: 5.099850
2025-04-14 18:12:08,056 - K-means used 0.03 s
2025-04-14 18:12:09,495 - ***** Epoch: 3 *****
2025-04-14 18:12:09,496 - Supervised Training Loss: 5.767180
2025-04-14 18:12:09,496 - Unsupervised Training Loss: 4.947510
2025-04-14 18:12:40,173 - K-means used 0.02 s
2025-04-14 18:12:42,128 - ***** Epoch: 4 *****
2025-04-14 18:12:42,128 - Supervised Training Loss: 5.648540
2025-04-14 18:12:42,128 - Unsupervised Training Loss: 5.024550
2025-04-14 18:13:12,604 - K-means used 0.04 s
2025-04-14 18:13:13,898 - ***** Epoch: 5 *****
2025-04-14 18:13:13,899 - Supervised Training Loss: 5.398120
2025-04-14 18:13:13,899 - Unsupervised Training Loss: 5.059670
2025-04-14 18:13:45,723 - K-means used 0.03 s
2025-04-14 18:13:47,130 - ***** Epoch: 6 *****
2025-04-14 18:13:47,130 - Supervised Training Loss: 5.814210
2025-04-14 18:13:47,130 - Unsupervised Training Loss: 4.854480
2025-04-14 18:14:18,080 - K-means used 0.02 s
2025-04-14 18:14:19,539 - ***** Epoch: 7 *****
2025-04-14 18:14:19,539 - Supervised Training Loss: 5.739850
2025-04-14 18:14:19,540 - Unsupervised Training Loss: 4.952550
2025-04-14 18:14:51,201 - K-means used 0.04 s
2025-04-14 18:14:52,798 - ***** Epoch: 8 *****
2025-04-14 18:14:52,799 - Supervised Training Loss: 5.603740
2025-04-14 18:14:52,799 - Unsupervised Training Loss: 4.994490
2025-04-14 18:15:23,977 - K-means used 0.03 s
2025-04-14 18:15:25,513 - ***** Epoch: 9 *****
2025-04-14 18:15:25,514 - Supervised Training Loss: 5.833430
2025-04-14 18:15:25,514 - Unsupervised Training Loss: 5.040380
2025-04-14 18:15:54,840 - K-means used 0.02 s
2025-04-14 18:15:56,620 - ***** Epoch: 10 *****
2025-04-14 18:15:56,620 - Supervised Training Loss: 5.775930
2025-04-14 18:15:56,620 - Unsupervised Training Loss: 4.868330
2025-04-14 18:16:26,816 - K-means used 0.02 s
2025-04-14 18:16:28,497 - ***** Epoch: 11 *****
2025-04-14 18:16:28,497 - Supervised Training Loss: 5.700520
2025-04-14 18:16:28,498 - Unsupervised Training Loss: 4.955660
2025-04-14 18:16:57,943 - K-means used 0.02 s
2025-04-14 18:16:59,595 - ***** Epoch: 12 *****
2025-04-14 18:16:59,596 - Supervised Training Loss: 5.840050
2025-04-14 18:16:59,596 - Unsupervised Training Loss: 5.015240
2025-04-14 18:17:29,791 - K-means used 0.02 s
2025-04-14 18:17:31,610 - ***** Epoch: 13 *****
2025-04-14 18:17:31,610 - Supervised Training Loss: 5.799520
2025-04-14 18:17:31,610 - Unsupervised Training Loss: 4.760650
2025-04-14 18:18:02,108 - K-means used 0.1 s
2025-04-14 18:18:03,904 - ***** Epoch: 14 *****
2025-04-14 18:18:03,904 - Supervised Training Loss: 5.750330
2025-04-14 18:18:03,904 - Unsupervised Training Loss: 4.876490
2025-04-14 18:18:33,713 - K-means used 0.02 s
2025-04-14 18:18:35,555 - ***** Epoch: 15 *****
2025-04-14 18:18:35,555 - Supervised Training Loss: 5.606970
2025-04-14 18:18:35,556 - Unsupervised Training Loss: 4.956520
2025-04-14 18:19:06,899 - K-means used 0.02 s
2025-04-14 18:19:09,106 - ***** Epoch: 16 *****
2025-04-14 18:19:09,107 - Supervised Training Loss: 5.819190
2025-04-14 18:19:09,107 - Unsupervised Training Loss: 4.365650
2025-04-14 18:19:38,786 - K-means used 0.02 s
2025-04-14 18:19:41,330 - ***** Epoch: 17 *****
2025-04-14 18:19:41,330 - Supervised Training Loss: 5.777970
2025-04-14 18:19:41,331 - Unsupervised Training Loss: 4.641260
2025-04-14 18:20:00,341 - Training is finished...
2025-04-14 18:20:00,341 - Testing begins...
2025-04-14 18:20:08,022 - ***** Test results *****
2025-04-14 18:20:08,023 -   ACC = 36.18
2025-04-14 18:20:08,023 -   ARI = 17.15
2025-04-14 18:20:08,023 -   NMI = 43.89
2025-04-14 18:20:08,023 -   fmi = 22.26
2025-04-14 18:20:08,023 - Testing is finished...
2025-04-14 18:20:08,023 - Multimodal intent recognition is finished...
2025-04-14 18:20:08,023 - Results are saved in results/results_umc.csv
