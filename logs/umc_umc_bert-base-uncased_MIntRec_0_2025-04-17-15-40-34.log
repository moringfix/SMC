2025-04-17 15:40:34,164 - 【无监督】进入了无监督的设定中, 加载数据集
2025-04-17 15:40:34,165 - data preparation...
2025-04-17 15:40:43,015 - Number of train samples = 1779
2025-04-17 15:40:43,016 - Number of testing samples = 445
2025-04-17 15:40:43,016 - data preparation...
2025-04-17 15:40:45,168 - num_train_examples = 1779
2025-04-17 15:40:45,169 - ============================== Params ==============================
2025-04-17 15:40:45,169 - logger_name: umc_umc_bert-base-uncased_MIntRec_0
2025-04-17 15:40:45,169 - dataset: MIntRec
2025-04-17 15:40:45,169 - multimodal_method: umc
2025-04-17 15:40:45,169 - method: umc
2025-04-17 15:40:45,169 - setting: unsupervised
2025-04-17 15:40:45,169 - merge_dev: False
2025-04-17 15:40:45,169 - text_backbone: bert-base-uncased
2025-04-17 15:40:45,169 - seed: 0
2025-04-17 15:40:45,169 - num_workers: 16
2025-04-17 15:40:45,169 - log_id: umc_umc_bert-base-uncased_MIntRec_0_2025-04-17-15-40-34
2025-04-17 15:40:45,169 - gpu_id: 1
2025-04-17 15:40:45,169 - data_path: /root/autodl-tmp/home/Share/Dataset/LZH
2025-04-17 15:40:45,169 - train: True
2025-04-17 15:40:45,169 - tune: True
2025-04-17 15:40:45,169 - save_model: True
2025-04-17 15:40:45,169 - save_results: True
2025-04-17 15:40:45,169 - log_path: logs
2025-04-17 15:40:45,169 - cache_path: cache
2025-04-17 15:40:45,169 - video_data_path: video_data
2025-04-17 15:40:45,170 - audio_data_path: audio_data
2025-04-17 15:40:45,170 - video_feats_path: swin_feats.pkl
2025-04-17 15:40:45,170 - audio_feats_path: wavlm_feats.pkl
2025-04-17 15:40:45,170 - results_path: results
2025-04-17 15:40:45,170 - output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/SMC/outputs_test2/MIntRec
2025-04-17 15:40:45,170 - model_path: models
2025-04-17 15:40:45,170 - config_file_name: umc_MIntRec
2025-04-17 15:40:45,170 - results_file_name: results_umc_pre.csv
2025-04-17 15:40:45,170 - text_pretrained_model: uncased_L-12_H-768_A-12
2025-04-17 15:40:45,170 - pretrained_bert_model: uncased_L-12_H-768_A-12
2025-04-17 15:40:45,170 - pretrain_batch_size: 128
2025-04-17 15:40:45,170 - train_batch_size: 128
2025-04-17 15:40:45,170 - eval_batch_size: 128
2025-04-17 15:40:45,170 - test_batch_size: 128
2025-04-17 15:40:45,170 - num_pretrain_epochs: 100
2025-04-17 15:40:45,170 - num_train_epochs: 100
2025-04-17 15:40:45,170 - pretrain: [True]
2025-04-17 15:40:45,170 - aligned_method: ctc
2025-04-17 15:40:45,170 - need_aligned: False
2025-04-17 15:40:45,170 - freeze_pretrain_bert_parameters: [True]
2025-04-17 15:40:45,170 - freeze_train_bert_parameters: [True]
2025-04-17 15:40:45,170 - pretrain_temperature: [0.01, 0.05]
2025-04-17 15:40:45,170 - train_temperature_sup: [0.5]
2025-04-17 15:40:45,170 - train_temperature_unsup: [2]
2025-04-17 15:40:45,170 - activation: tanh
2025-04-17 15:40:45,170 - lr_pre: [1e-05]
2025-04-17 15:40:45,170 - lr: [5e-05]
2025-04-17 15:40:45,171 - delta: [0.05]
2025-04-17 15:40:45,171 - thres: [0.1]
2025-04-17 15:40:45,171 - topk: [5]
2025-04-17 15:40:45,171 - weight_decay: 0.01
2025-04-17 15:40:45,171 - feat_dim: 768
2025-04-17 15:40:45,171 - hidden_size: 768
2025-04-17 15:40:45,171 - grad_clip: -1.0
2025-04-17 15:40:45,171 - warmup_proportion: [0.1]
2025-04-17 15:40:45,171 - hidden_dropout_prob: 0.1
2025-04-17 15:40:45,171 - weight: 1.0
2025-04-17 15:40:45,171 - loss_mode: rdrop
2025-04-17 15:40:45,171 - base_dim: 256
2025-04-17 15:40:45,171 - nheads: 8
2025-04-17 15:40:45,171 - attn_dropout: 0.1
2025-04-17 15:40:45,171 - relu_dropout: 0.1
2025-04-17 15:40:45,171 - embed_dropout: 0.01
2025-04-17 15:40:45,172 - res_dropout: 0.0
2025-04-17 15:40:45,172 - attn_mask: True
2025-04-17 15:40:45,172 - encoder_layers_1: 1
2025-04-17 15:40:45,172 - fusion_act: tanh
2025-04-17 15:40:45,172 - pred_output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/SMC/outputs_test2/MIntRec/umc_umc_MIntRec_bert-base-uncased_0
2025-04-17 15:40:45,172 - model_output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/SMC/outputs_test2/MIntRec/umc_umc_MIntRec_bert-base-uncased_0/models
2025-04-17 15:40:45,172 - text_seq_len: 30
2025-04-17 15:40:45,172 - video_seq_len: 230
2025-04-17 15:40:45,172 - audio_seq_len: 480
2025-04-17 15:40:45,172 - text_feat_dim: 768
2025-04-17 15:40:45,172 - video_feat_dim: 1024
2025-04-17 15:40:45,172 - audio_feat_dim: 768
2025-04-17 15:40:45,172 - num_labels: 20
2025-04-17 15:40:45,172 - num_train_examples: 1779
2025-04-17 15:40:45,172 - ============================== End Params ==============================
2025-04-17 15:40:46,400 - Freeze all parameters but the last layer for efficiency
2025-04-17 15:40:46,433 - Pre-training start...
2025-04-17 15:41:02,125 - ***** Epoch: 1: Eval results *****
2025-04-17 15:41:02,125 -   train_loss = 9.35894877570016
2025-04-17 15:41:17,764 - ***** Epoch: 2: Eval results *****
2025-04-17 15:41:17,764 -   train_loss = 9.27643380846296
2025-04-17 15:41:34,264 - ***** Epoch: 3: Eval results *****
2025-04-17 15:41:34,264 -   train_loss = 8.788529532296318
2025-04-17 15:41:50,842 - ***** Epoch: 4: Eval results *****
2025-04-17 15:41:50,842 -   train_loss = 8.39519899232047
2025-04-17 15:42:08,192 - ***** Epoch: 5: Eval results *****
2025-04-17 15:42:08,192 -   train_loss = 7.956466368266514
2025-04-17 15:42:25,545 - ***** Epoch: 6: Eval results *****
2025-04-17 15:42:25,545 -   train_loss = 7.606769153050014
2025-04-17 15:42:42,905 - ***** Epoch: 7: Eval results *****
2025-04-17 15:42:42,905 -   train_loss = 7.332752364022391
2025-04-17 15:43:00,185 - ***** Epoch: 8: Eval results *****
2025-04-17 15:43:00,186 -   train_loss = 7.030749150684902
2025-04-17 15:43:16,912 - ***** Epoch: 9: Eval results *****
2025-04-17 15:43:16,912 -   train_loss = 6.8576881885528564
2025-04-17 15:43:34,292 - ***** Epoch: 10: Eval results *****
2025-04-17 15:43:34,292 -   train_loss = 6.595989431653704
2025-04-17 15:43:51,424 - ***** Epoch: 11: Eval results *****
2025-04-17 15:43:51,424 -   train_loss = 6.470135859080723
2025-04-17 15:44:09,009 - ***** Epoch: 12: Eval results *****
2025-04-17 15:44:09,009 -   train_loss = 6.244149650846209
2025-04-17 15:44:25,130 - ***** Epoch: 13: Eval results *****
2025-04-17 15:44:25,131 -   train_loss = 6.085652555738177
2025-04-17 15:44:42,188 - ***** Epoch: 14: Eval results *****
2025-04-17 15:44:42,188 -   train_loss = 5.745165382112775
2025-04-17 15:44:59,458 - ***** Epoch: 15: Eval results *****
2025-04-17 15:44:59,458 -   train_loss = 5.391778809683664
2025-04-17 15:45:16,273 - ***** Epoch: 16: Eval results *****
2025-04-17 15:45:16,274 -   train_loss = 4.949851921626499
2025-04-17 15:45:32,931 - ***** Epoch: 17: Eval results *****
2025-04-17 15:45:32,931 -   train_loss = 4.4307034356253485
2025-04-17 15:45:49,494 - ***** Epoch: 18: Eval results *****
2025-04-17 15:45:49,494 -   train_loss = 4.019887328147888
2025-04-17 15:46:06,470 - ***** Epoch: 19: Eval results *****
2025-04-17 15:46:06,470 -   train_loss = 3.6816220453807285
2025-04-17 15:46:23,686 - ***** Epoch: 20: Eval results *****
2025-04-17 15:46:23,686 -   train_loss = 3.3138755219323293
2025-04-17 15:46:40,652 - ***** Epoch: 21: Eval results *****
2025-04-17 15:46:40,653 -   train_loss = 3.056520462036133
2025-04-17 15:46:57,395 - ***** Epoch: 22: Eval results *****
2025-04-17 15:46:57,396 -   train_loss = 2.814871907234192
2025-04-17 15:47:14,251 - ***** Epoch: 23: Eval results *****
2025-04-17 15:47:14,252 -   train_loss = 2.6230911016464233
2025-04-17 15:47:30,586 - ***** Epoch: 24: Eval results *****
2025-04-17 15:47:30,586 -   train_loss = 2.460587212017604
2025-04-17 15:47:47,461 - ***** Epoch: 25: Eval results *****
2025-04-17 15:47:47,461 -   train_loss = 2.3217041322163174
2025-04-17 15:48:04,791 - ***** Epoch: 26: Eval results *****
2025-04-17 15:48:04,792 -   train_loss = 2.1859693016324724
2025-04-17 15:48:24,258 - ***** Epoch: 27: Eval results *****
2025-04-17 15:48:24,258 -   train_loss = 2.1055005363055637
2025-04-17 15:48:42,662 - ***** Epoch: 28: Eval results *****
2025-04-17 15:48:42,662 -   train_loss = 1.9978580985750471
2025-04-17 15:49:01,133 - ***** Epoch: 29: Eval results *****
2025-04-17 15:49:01,133 -   train_loss = 1.916134808744703
2025-04-17 15:49:18,758 - ***** Epoch: 30: Eval results *****
2025-04-17 15:49:18,758 -   train_loss = 1.885126599243709
2025-04-17 15:49:36,188 - ***** Epoch: 31: Eval results *****
2025-04-17 15:49:36,188 -   train_loss = 1.8230220249720983
2025-04-17 15:49:53,630 - ***** Epoch: 32: Eval results *****
2025-04-17 15:49:53,630 -   train_loss = 1.7856393456459045
2025-04-17 15:50:10,842 - ***** Epoch: 33: Eval results *****
2025-04-17 15:50:10,842 -   train_loss = 1.7456206849643163
2025-04-17 15:50:27,726 - ***** Epoch: 34: Eval results *****
2025-04-17 15:50:27,726 -   train_loss = 1.7232705439840044
2025-04-17 15:50:44,338 - ***** Epoch: 35: Eval results *****
2025-04-17 15:50:44,338 -   train_loss = 1.7082551292010717
2025-04-17 15:51:01,562 - ***** Epoch: 36: Eval results *****
2025-04-17 15:51:01,562 -   train_loss = 1.6763242312840052
2025-04-17 15:51:18,570 - ***** Epoch: 37: Eval results *****
2025-04-17 15:51:18,570 -   train_loss = 1.619764072554452
2025-04-17 15:51:35,345 - ***** Epoch: 38: Eval results *****
2025-04-17 15:51:35,345 -   train_loss = 1.5981558561325073
2025-04-17 15:51:52,521 - ***** Epoch: 39: Eval results *****
2025-04-17 15:51:52,521 -   train_loss = 1.5944273216383797
2025-04-17 15:52:09,470 - ***** Epoch: 40: Eval results *****
2025-04-17 15:52:09,470 -   train_loss = 1.5653758559908186
2025-04-17 15:52:26,057 - ***** Epoch: 41: Eval results *****
2025-04-17 15:52:26,057 -   train_loss = 1.5333942004612513
2025-04-17 15:52:42,146 - ***** Epoch: 42: Eval results *****
2025-04-17 15:52:42,146 -   train_loss = 1.5584075025149755
2025-04-17 15:52:58,640 - ***** Epoch: 43: Eval results *****
2025-04-17 15:52:58,640 -   train_loss = 1.5309337632996696
2025-04-17 15:53:15,557 - ***** Epoch: 44: Eval results *****
2025-04-17 15:53:15,557 -   train_loss = 1.5201126081602914
2025-04-17 15:53:32,857 - ***** Epoch: 45: Eval results *****
2025-04-17 15:53:32,857 -   train_loss = 1.4967307959284102
2025-04-17 15:53:50,043 - ***** Epoch: 46: Eval results *****
2025-04-17 15:53:50,044 -   train_loss = 1.473756057875497
2025-04-17 15:54:06,724 - ***** Epoch: 47: Eval results *****
2025-04-17 15:54:06,724 -   train_loss = 1.479923495224544
2025-04-17 15:54:23,430 - ***** Epoch: 48: Eval results *****
2025-04-17 15:54:23,430 -   train_loss = 1.4424126233373369
2025-04-17 15:54:40,210 - ***** Epoch: 49: Eval results *****
2025-04-17 15:54:40,210 -   train_loss = 1.429273213659014
2025-04-17 15:54:57,048 - ***** Epoch: 50: Eval results *****
2025-04-17 15:54:57,048 -   train_loss = 1.4245380674089705
2025-04-17 15:55:13,957 - ***** Epoch: 51: Eval results *****
2025-04-17 15:55:13,957 -   train_loss = 1.4223049879074097
2025-04-17 15:55:30,963 - ***** Epoch: 52: Eval results *****
2025-04-17 15:55:30,964 -   train_loss = 1.4330736568995885
2025-04-17 15:55:48,135 - ***** Epoch: 53: Eval results *****
2025-04-17 15:55:48,135 -   train_loss = 1.398804315498897
2025-04-17 15:56:04,763 - ***** Epoch: 54: Eval results *****
2025-04-17 15:56:04,763 -   train_loss = 1.4219914674758911
2025-04-17 15:56:22,003 - ***** Epoch: 55: Eval results *****
2025-04-17 15:56:22,003 -   train_loss = 1.3947152069636755
2025-04-17 15:56:38,835 - ***** Epoch: 56: Eval results *****
2025-04-17 15:56:38,835 -   train_loss = 1.381931585924966
2025-04-17 15:56:55,884 - ***** Epoch: 57: Eval results *****
2025-04-17 15:56:55,884 -   train_loss = 1.363268596785409
2025-04-17 15:57:12,171 - ***** Epoch: 58: Eval results *****
2025-04-17 15:57:12,171 -   train_loss = 1.3762001310076033
2025-04-17 15:57:28,723 - ***** Epoch: 59: Eval results *****
2025-04-17 15:57:28,723 -   train_loss = 1.3668590017727442
2025-04-17 15:57:45,179 - ***** Epoch: 60: Eval results *****
2025-04-17 15:57:45,180 -   train_loss = 1.366535246372223
2025-04-17 15:58:02,153 - ***** Epoch: 61: Eval results *****
2025-04-17 15:58:02,153 -   train_loss = 1.3396212799208504
2025-04-17 15:58:19,340 - ***** Epoch: 62: Eval results *****
2025-04-17 15:58:19,340 -   train_loss = 1.3537485003471375
2025-04-17 15:58:35,084 - ***** Epoch: 63: Eval results *****
2025-04-17 15:58:35,084 -   train_loss = 1.3513032027653284
2025-04-17 15:58:51,844 - ***** Epoch: 64: Eval results *****
2025-04-17 15:58:51,844 -   train_loss = 1.3265431097575597
2025-04-17 15:59:08,526 - ***** Epoch: 65: Eval results *****
2025-04-17 15:59:08,526 -   train_loss = 1.3355113523347037
2025-04-17 15:59:25,241 - ***** Epoch: 66: Eval results *****
2025-04-17 15:59:25,241 -   train_loss = 1.3269281387329102
2025-04-17 15:59:41,671 - ***** Epoch: 67: Eval results *****
2025-04-17 15:59:41,672 -   train_loss = 1.3289439507893153
2025-04-17 15:59:58,424 - ***** Epoch: 68: Eval results *****
2025-04-17 15:59:58,424 -   train_loss = 1.3145505445344108
2025-04-17 16:00:15,537 - ***** Epoch: 69: Eval results *****
2025-04-17 16:00:15,537 -   train_loss = 1.2954586744308472
2025-04-17 16:00:32,389 - ***** Epoch: 70: Eval results *****
2025-04-17 16:00:32,389 -   train_loss = 1.307165997368949
2025-04-17 16:00:48,991 - ***** Epoch: 71: Eval results *****
2025-04-17 16:00:48,992 -   train_loss = 1.307851595538003
2025-04-17 16:01:05,978 - ***** Epoch: 72: Eval results *****
2025-04-17 16:01:05,978 -   train_loss = 1.3078342080116272
2025-04-17 16:01:23,196 - ***** Epoch: 73: Eval results *****
2025-04-17 16:01:23,196 -   train_loss = 1.3118894270488195
2025-04-17 16:01:41,181 - ***** Epoch: 74: Eval results *****
2025-04-17 16:01:41,182 -   train_loss = 1.3127455966813224
2025-04-17 16:01:59,112 - ***** Epoch: 75: Eval results *****
2025-04-17 16:01:59,113 -   train_loss = 1.3044922522136144
2025-04-17 16:02:17,077 - ***** Epoch: 76: Eval results *****
2025-04-17 16:02:17,077 -   train_loss = 1.2810764823641096
2025-04-17 16:02:34,687 - ***** Epoch: 77: Eval results *****
2025-04-17 16:02:34,687 -   train_loss = 1.2838663629123144
2025-04-17 16:02:52,730 - ***** Epoch: 78: Eval results *****
2025-04-17 16:02:52,731 -   train_loss = 1.282372568334852
2025-04-17 16:03:09,581 - ***** Epoch: 79: Eval results *****
2025-04-17 16:03:09,582 -   train_loss = 1.2850543516022819
2025-04-17 16:03:27,129 - ***** Epoch: 80: Eval results *****
2025-04-17 16:03:27,129 -   train_loss = 1.2762022699628557
2025-04-17 16:03:43,999 - ***** Epoch: 81: Eval results *****
2025-04-17 16:03:44,000 -   train_loss = 1.2977731653622218
2025-04-17 16:04:01,185 - ***** Epoch: 82: Eval results *****
2025-04-17 16:04:01,186 -   train_loss = 1.2734018138476781
2025-04-17 16:04:18,000 - ***** Epoch: 83: Eval results *****
2025-04-17 16:04:18,000 -   train_loss = 1.3144379769052779
2025-04-17 16:04:35,179 - ***** Epoch: 84: Eval results *****
2025-04-17 16:04:35,180 -   train_loss = 1.286664502961295
2025-04-17 16:04:52,224 - ***** Epoch: 85: Eval results *****
2025-04-17 16:04:52,224 -   train_loss = 1.2866576654570443
2025-04-17 16:05:09,234 - ***** Epoch: 86: Eval results *****
2025-04-17 16:05:09,234 -   train_loss = 1.2722310849598475
2025-04-17 16:05:26,570 - ***** Epoch: 87: Eval results *****
2025-04-17 16:05:26,571 -   train_loss = 1.2904156191008431
2025-04-17 16:05:43,880 - ***** Epoch: 88: Eval results *****
2025-04-17 16:05:43,881 -   train_loss = 1.2747933949742998
2025-04-17 16:06:01,340 - ***** Epoch: 89: Eval results *****
2025-04-17 16:06:01,340 -   train_loss = 1.2715655735560827
2025-04-17 16:06:18,709 - ***** Epoch: 90: Eval results *****
2025-04-17 16:06:18,709 -   train_loss = 1.2687983683177404
2025-04-17 16:06:37,233 - ***** Epoch: 91: Eval results *****
2025-04-17 16:06:37,233 -   train_loss = 1.2888742259570531
2025-04-17 16:06:57,652 - ***** Epoch: 92: Eval results *****
2025-04-17 16:06:57,652 -   train_loss = 1.2677186982972282
2025-04-17 16:07:17,842 - ***** Epoch: 93: Eval results *****
2025-04-17 16:07:17,843 -   train_loss = 1.2668306486947196
2025-04-17 16:07:37,771 - ***** Epoch: 94: Eval results *****
2025-04-17 16:07:37,772 -   train_loss = 1.279634416103363
2025-04-17 16:07:57,371 - ***** Epoch: 95: Eval results *****
2025-04-17 16:07:57,371 -   train_loss = 1.268402874469757
2025-04-17 16:08:17,188 - ***** Epoch: 96: Eval results *****
2025-04-17 16:08:17,189 -   train_loss = 1.2821845752852303
2025-04-17 16:08:36,761 - ***** Epoch: 97: Eval results *****
2025-04-17 16:08:36,761 -   train_loss = 1.2526408433914185
2025-04-17 16:08:55,838 - ***** Epoch: 98: Eval results *****
2025-04-17 16:08:55,839 -   train_loss = 1.2713157108851842
2025-04-17 16:09:15,497 - ***** Epoch: 99: Eval results *****
2025-04-17 16:09:15,498 -   train_loss = 1.2557323745318822
2025-04-17 16:09:34,591 - ***** Epoch: 100: Eval results *****
2025-04-17 16:09:34,592 -   train_loss = 1.28048141513552
2025-04-17 16:09:36,454 - Pre-training finished...
2025-04-17 16:09:36,853 - Freeze all parameters but the last layer for efficiency
2025-04-17 16:09:36,865 - Multimodal Intent Recognition begins...
2025-04-17 16:09:36,865 - Training begins...
2025-04-17 16:09:54,460 - Initializing centroids with K-means++...
2025-04-17 16:09:54,605 - K-means++ used 0.14 s
2025-04-17 16:10:28,575 - K-means used 0.04 s
2025-04-17 16:10:30,272 - ***** Epoch: 1 *****
2025-04-17 16:10:30,272 - Supervised Training Loss: 5.074970
2025-04-17 16:10:30,273 - Unsupervised Training Loss: 5.799810
2025-04-17 16:11:05,237 - K-means used 0.05 s
2025-04-17 16:11:07,010 - ***** Epoch: 2 *****
2025-04-17 16:11:07,010 - Supervised Training Loss: 5.506520
2025-04-17 16:11:07,010 - Unsupervised Training Loss: 5.736280
2025-04-17 16:11:40,942 - K-means used 0.05 s
2025-04-17 16:11:42,913 - ***** Epoch: 3 *****
2025-04-17 16:11:42,914 - Supervised Training Loss: 5.037950
2025-04-17 16:11:42,914 - Unsupervised Training Loss: 5.506630
2025-04-17 16:12:16,565 - K-means used 0.03 s
2025-04-17 16:12:17,918 - ***** Epoch: 4 *****
2025-04-17 16:12:17,918 - Supervised Training Loss: 4.698610
2025-04-17 16:12:17,918 - Unsupervised Training Loss: 5.534650
2025-04-17 16:12:52,950 - K-means used 0.04 s
2025-04-17 16:12:54,318 - ***** Epoch: 5 *****
2025-04-17 16:12:54,318 - Supervised Training Loss: 4.333390
2025-04-17 16:12:54,318 - Unsupervised Training Loss: 5.555320
2025-04-17 16:13:29,224 - K-means used 0.03 s
2025-04-17 16:13:30,692 - ***** Epoch: 6 *****
2025-04-17 16:13:30,693 - Supervised Training Loss: 4.711280
2025-04-17 16:13:30,693 - Unsupervised Training Loss: 5.342020
2025-04-17 16:14:05,431 - K-means used 0.04 s
2025-04-17 16:14:06,900 - ***** Epoch: 7 *****
2025-04-17 16:14:06,900 - Supervised Training Loss: 4.613670
2025-04-17 16:14:06,900 - Unsupervised Training Loss: 5.455290
2025-04-17 16:14:38,337 - K-means used 0.02 s
2025-04-17 16:14:39,606 - ***** Epoch: 8 *****
2025-04-17 16:14:39,606 - Supervised Training Loss: 4.433420
2025-04-17 16:14:39,606 - Unsupervised Training Loss: 5.513490
2025-04-17 16:15:09,808 - K-means used 0.02 s
2025-04-17 16:15:11,137 - ***** Epoch: 9 *****
2025-04-17 16:15:11,138 - Supervised Training Loss: 4.684520
2025-04-17 16:15:11,138 - Unsupervised Training Loss: 5.550270
2025-04-17 16:15:41,343 - K-means used 0.03 s
2025-04-17 16:15:42,838 - ***** Epoch: 10 *****
2025-04-17 16:15:42,838 - Supervised Training Loss: 4.613680
2025-04-17 16:15:42,838 - Unsupervised Training Loss: 5.395180
2025-04-17 16:16:15,762 - K-means used 0.03 s
2025-04-17 16:16:17,213 - ***** Epoch: 11 *****
2025-04-17 16:16:17,213 - Supervised Training Loss: 4.538210
2025-04-17 16:16:17,213 - Unsupervised Training Loss: 5.470540
2025-04-17 16:16:46,283 - K-means used 0.02 s
2025-04-17 16:16:47,855 - ***** Epoch: 12 *****
2025-04-17 16:16:47,856 - Supervised Training Loss: 4.675930
2025-04-17 16:16:47,856 - Unsupervised Training Loss: 5.535710
2025-04-17 16:17:17,092 - K-means used 0.02 s
2025-04-17 16:17:18,807 - ***** Epoch: 13 *****
2025-04-17 16:17:18,808 - Supervised Training Loss: 4.641000
2025-04-17 16:17:18,808 - Unsupervised Training Loss: 5.267210
2025-04-17 16:17:52,062 - K-means used 0.02 s
2025-04-17 16:17:54,061 - ***** Epoch: 14 *****
2025-04-17 16:17:54,061 - Supervised Training Loss: 4.591740
2025-04-17 16:17:54,061 - Unsupervised Training Loss: 5.395430
2025-04-17 16:18:24,970 - K-means used 0.02 s
2025-04-17 16:18:26,989 - ***** Epoch: 15 *****
2025-04-17 16:18:26,989 - Supervised Training Loss: 4.472400
2025-04-17 16:18:26,989 - Unsupervised Training Loss: 5.490470
2025-04-17 16:18:58,816 - K-means used 0.02 s
2025-04-17 16:19:00,854 - ***** Epoch: 16 *****
2025-04-17 16:19:00,855 - Supervised Training Loss: 4.684760
2025-04-17 16:19:00,855 - Unsupervised Training Loss: 4.954530
2025-04-17 16:19:30,301 - K-means used 0.02 s
2025-04-17 16:19:32,391 - ***** Epoch: 17 *****
2025-04-17 16:19:32,391 - Supervised Training Loss: 4.667050
2025-04-17 16:19:32,392 - Unsupervised Training Loss: 5.167240
2025-04-17 16:19:52,037 - Training is finished...
2025-04-17 16:19:52,038 - Testing begins...
2025-04-17 16:20:00,229 - ***** Test results *****
2025-04-17 16:20:00,230 -   ACC = 33.03
2025-04-17 16:20:00,230 -   ARI = 15.12
2025-04-17 16:20:00,230 -   NMI = 41.98
2025-04-17 16:20:00,230 -   fmi = 20.38
2025-04-17 16:20:00,230 - Testing is finished...
2025-04-17 16:20:00,230 - Multimodal intent recognition is finished...
2025-04-17 16:20:00,230 - Results are saved in results/results_umc_pre.csv
2025-04-17 16:20:01,306 - Freeze all parameters but the last layer for efficiency
2025-04-17 16:20:01,349 - Pre-training start...
2025-04-17 16:20:02,105 - ***** Epoch: 1: Eval results *****
2025-04-17 16:20:02,106 -   train_loss = 5.823657512664795
2025-04-17 16:20:02,903 - ***** Epoch: 2: Eval results *****
2025-04-17 16:20:02,903 -   train_loss = 5.885112285614014
2025-04-17 16:20:03,691 - ***** Epoch: 3: Eval results *****
2025-04-17 16:20:03,691 -   train_loss = 5.7472100257873535
2025-04-17 16:20:04,470 - ***** Epoch: 4: Eval results *****
2025-04-17 16:20:04,470 -   train_loss = 5.805585861206055
2025-04-17 16:20:05,283 - ***** Epoch: 5: Eval results *****
2025-04-17 16:20:05,283 -   train_loss = 5.791536331176758
2025-04-17 16:20:06,090 - ***** Epoch: 6: Eval results *****
2025-04-17 16:20:06,091 -   train_loss = 5.799524307250977
2025-04-17 16:20:06,920 - ***** Epoch: 7: Eval results *****
2025-04-17 16:20:06,921 -   train_loss = 5.8199543952941895
2025-04-17 16:20:07,703 - ***** Epoch: 8: Eval results *****
2025-04-17 16:20:07,703 -   train_loss = 5.761160373687744
2025-04-17 16:20:08,486 - ***** Epoch: 9: Eval results *****
2025-04-17 16:20:08,486 -   train_loss = 5.786734104156494
2025-04-17 16:20:09,286 - ***** Epoch: 10: Eval results *****
2025-04-17 16:20:09,287 -   train_loss = 5.817480564117432
2025-04-17 16:20:10,077 - ***** Epoch: 11: Eval results *****
2025-04-17 16:20:10,077 -   train_loss = 5.824242115020752
2025-04-17 16:20:10,873 - ***** Epoch: 12: Eval results *****
2025-04-17 16:20:10,873 -   train_loss = 5.753805637359619
2025-04-17 16:20:11,698 - ***** Epoch: 13: Eval results *****
2025-04-17 16:20:11,698 -   train_loss = 5.758243560791016
2025-04-17 16:20:12,496 - ***** Epoch: 14: Eval results *****
2025-04-17 16:20:12,497 -   train_loss = 5.8061089515686035
2025-04-17 16:20:13,342 - ***** Epoch: 15: Eval results *****
2025-04-17 16:20:13,343 -   train_loss = 5.755224704742432
2025-04-17 16:20:14,181 - ***** Epoch: 16: Eval results *****
2025-04-17 16:20:14,181 -   train_loss = 5.742490768432617
2025-04-17 16:20:15,013 - ***** Epoch: 17: Eval results *****
2025-04-17 16:20:15,014 -   train_loss = 5.777987003326416
2025-04-17 16:20:15,905 - ***** Epoch: 18: Eval results *****
2025-04-17 16:20:15,905 -   train_loss = 5.762656211853027
2025-04-17 16:20:16,752 - ***** Epoch: 19: Eval results *****
2025-04-17 16:20:16,753 -   train_loss = 5.785114288330078
2025-04-17 16:20:17,541 - ***** Epoch: 20: Eval results *****
2025-04-17 16:20:17,542 -   train_loss = 5.708564281463623
2025-04-17 16:20:18,266 - ***** Epoch: 21: Eval results *****
2025-04-17 16:20:18,266 -   train_loss = 5.754669189453125
2025-04-17 16:20:19,081 - ***** Epoch: 22: Eval results *****
2025-04-17 16:20:19,082 -   train_loss = 5.754688262939453
2025-04-17 16:20:20,009 - ***** Epoch: 23: Eval results *****
2025-04-17 16:20:20,009 -   train_loss = 5.6992268562316895
2025-04-17 16:20:20,905 - ***** Epoch: 24: Eval results *****
2025-04-17 16:20:20,905 -   train_loss = 5.770853042602539
2025-04-17 16:20:21,669 - ***** Epoch: 25: Eval results *****
2025-04-17 16:20:21,669 -   train_loss = 5.73627233505249
2025-04-17 16:20:22,336 - ***** Epoch: 26: Eval results *****
2025-04-17 16:20:22,336 -   train_loss = 5.72119140625
2025-04-17 16:20:23,174 - ***** Epoch: 27: Eval results *****
2025-04-17 16:20:23,174 -   train_loss = 5.730366230010986
2025-04-17 16:20:23,973 - ***** Epoch: 28: Eval results *****
2025-04-17 16:20:23,973 -   train_loss = 5.739279747009277
2025-04-17 16:20:24,794 - ***** Epoch: 29: Eval results *****
2025-04-17 16:20:24,794 -   train_loss = 5.712916851043701
2025-04-17 16:20:25,578 - ***** Epoch: 30: Eval results *****
2025-04-17 16:20:25,579 -   train_loss = 5.71105432510376
2025-04-17 16:20:26,233 - ***** Epoch: 31: Eval results *****
2025-04-17 16:20:26,233 -   train_loss = 5.684327602386475
2025-04-17 16:20:27,078 - ***** Epoch: 32: Eval results *****
2025-04-17 16:20:27,079 -   train_loss = 5.730025768280029
2025-04-17 16:20:27,876 - ***** Epoch: 33: Eval results *****
2025-04-17 16:20:27,876 -   train_loss = 5.686367034912109
2025-04-17 16:20:28,660 - ***** Epoch: 34: Eval results *****
2025-04-17 16:20:28,661 -   train_loss = 5.7053632736206055
2025-04-17 16:20:29,466 - ***** Epoch: 35: Eval results *****
2025-04-17 16:20:29,466 -   train_loss = 5.694617748260498
2025-04-17 16:20:30,250 - ***** Epoch: 36: Eval results *****
2025-04-17 16:20:30,251 -   train_loss = 5.639256000518799
2025-04-17 16:20:31,038 - ***** Epoch: 37: Eval results *****
2025-04-17 16:20:31,038 -   train_loss = 5.689955234527588
2025-04-17 16:20:31,841 - ***** Epoch: 38: Eval results *****
2025-04-17 16:20:31,841 -   train_loss = 5.648455619812012
2025-04-17 16:20:32,629 - ***** Epoch: 39: Eval results *****
2025-04-17 16:20:32,630 -   train_loss = 5.654710292816162
2025-04-17 16:20:33,404 - ***** Epoch: 40: Eval results *****
2025-04-17 16:20:33,404 -   train_loss = 5.675812721252441
2025-04-17 16:20:34,182 - ***** Epoch: 41: Eval results *****
2025-04-17 16:20:34,182 -   train_loss = 5.6232008934021
2025-04-17 16:20:34,978 - ***** Epoch: 42: Eval results *****
2025-04-17 16:20:34,978 -   train_loss = 5.617104530334473
2025-04-17 16:20:35,758 - ***** Epoch: 43: Eval results *****
2025-04-17 16:20:35,758 -   train_loss = 5.641634464263916
2025-04-17 16:20:36,409 - ***** Epoch: 44: Eval results *****
2025-04-17 16:20:36,409 -   train_loss = 5.586669445037842
2025-04-17 16:20:37,252 - ***** Epoch: 45: Eval results *****
2025-04-17 16:20:37,252 -   train_loss = 5.61081075668335
2025-04-17 16:20:38,051 - ***** Epoch: 46: Eval results *****
2025-04-17 16:20:38,051 -   train_loss = 5.5881757736206055
2025-04-17 16:20:38,849 - ***** Epoch: 47: Eval results *****
2025-04-17 16:20:38,849 -   train_loss = 5.607682704925537
2025-04-17 16:20:39,630 - ***** Epoch: 48: Eval results *****
2025-04-17 16:20:39,630 -   train_loss = 5.623605251312256
2025-04-17 16:20:40,384 - ***** Epoch: 49: Eval results *****
2025-04-17 16:20:40,385 -   train_loss = 5.607202529907227
2025-04-17 16:20:41,031 - ***** Epoch: 50: Eval results *****
2025-04-17 16:20:41,031 -   train_loss = 5.585740566253662
2025-04-17 16:20:41,717 - ***** Epoch: 51: Eval results *****
2025-04-17 16:20:41,718 -   train_loss = 5.608348369598389
2025-04-17 16:20:42,400 - ***** Epoch: 52: Eval results *****
2025-04-17 16:20:42,400 -   train_loss = 5.582693576812744
2025-04-17 16:20:43,053 - ***** Epoch: 53: Eval results *****
2025-04-17 16:20:43,053 -   train_loss = 5.61949348449707
2025-04-17 16:20:43,862 - ***** Epoch: 54: Eval results *****
2025-04-17 16:20:43,863 -   train_loss = 5.53190279006958
2025-04-17 16:20:44,649 - ***** Epoch: 55: Eval results *****
2025-04-17 16:20:44,649 -   train_loss = 5.547484397888184
2025-04-17 16:20:45,434 - ***** Epoch: 56: Eval results *****
2025-04-17 16:20:45,435 -   train_loss = 5.573540687561035
2025-04-17 16:20:46,220 - ***** Epoch: 57: Eval results *****
2025-04-17 16:20:46,220 -   train_loss = 5.554805755615234
2025-04-17 16:20:47,018 - ***** Epoch: 58: Eval results *****
2025-04-17 16:20:47,018 -   train_loss = 5.550930976867676
2025-04-17 16:20:47,788 - ***** Epoch: 59: Eval results *****
2025-04-17 16:20:47,788 -   train_loss = 5.5374040603637695
2025-04-17 16:20:48,453 - ***** Epoch: 60: Eval results *****
2025-04-17 16:20:48,453 -   train_loss = 5.511358261108398
2025-04-17 16:20:49,100 - ***** Epoch: 61: Eval results *****
2025-04-17 16:20:49,101 -   train_loss = 5.522878646850586
2025-04-17 16:20:49,930 - ***** Epoch: 62: Eval results *****
2025-04-17 16:20:49,930 -   train_loss = 5.4776835441589355
2025-04-17 16:20:50,714 - ***** Epoch: 63: Eval results *****
2025-04-17 16:20:50,714 -   train_loss = 5.5219292640686035
2025-04-17 16:20:51,495 - ***** Epoch: 64: Eval results *****
2025-04-17 16:20:51,495 -   train_loss = 5.483576774597168
2025-04-17 16:20:52,253 - ***** Epoch: 65: Eval results *****
2025-04-17 16:20:52,254 -   train_loss = 5.455460071563721
2025-04-17 16:20:52,888 - ***** Epoch: 66: Eval results *****
2025-04-17 16:20:52,889 -   train_loss = 5.462851524353027
2025-04-17 16:20:53,519 - ***** Epoch: 67: Eval results *****
2025-04-17 16:20:53,520 -   train_loss = 5.471529483795166
2025-04-17 16:20:54,327 - ***** Epoch: 68: Eval results *****
2025-04-17 16:20:54,328 -   train_loss = 5.448146343231201
2025-04-17 16:20:55,098 - ***** Epoch: 69: Eval results *****
2025-04-17 16:20:55,098 -   train_loss = 5.3723859786987305
2025-04-17 16:20:55,863 - ***** Epoch: 70: Eval results *****
2025-04-17 16:20:55,864 -   train_loss = 5.428737163543701
2025-04-17 16:20:56,684 - ***** Epoch: 71: Eval results *****
2025-04-17 16:20:56,684 -   train_loss = 5.4051618576049805
2025-04-17 16:20:57,465 - ***** Epoch: 72: Eval results *****
2025-04-17 16:20:57,466 -   train_loss = 5.381279468536377
2025-04-17 16:20:58,247 - ***** Epoch: 73: Eval results *****
2025-04-17 16:20:58,248 -   train_loss = 5.31896448135376
2025-04-17 16:20:59,020 - ***** Epoch: 74: Eval results *****
2025-04-17 16:20:59,020 -   train_loss = 5.2996320724487305
2025-04-17 16:20:59,793 - ***** Epoch: 75: Eval results *****
2025-04-17 16:20:59,793 -   train_loss = 5.287302017211914
2025-04-17 16:21:00,582 - ***** Epoch: 76: Eval results *****
2025-04-17 16:21:00,582 -   train_loss = 5.284562587738037
2025-04-17 16:21:01,395 - ***** Epoch: 77: Eval results *****
2025-04-17 16:21:01,395 -   train_loss = 5.300004005432129
2025-04-17 16:21:02,228 - ***** Epoch: 78: Eval results *****
2025-04-17 16:21:02,229 -   train_loss = 5.223258972167969
2025-04-17 16:21:02,920 - ***** Epoch: 79: Eval results *****
2025-04-17 16:21:02,920 -   train_loss = 5.280882835388184
2025-04-17 16:21:03,581 - ***** Epoch: 80: Eval results *****
2025-04-17 16:21:03,582 -   train_loss = 5.171708583831787
2025-04-17 16:21:04,229 - ***** Epoch: 81: Eval results *****
2025-04-17 16:21:04,229 -   train_loss = 5.216925144195557
2025-04-17 16:21:05,046 - ***** Epoch: 82: Eval results *****
2025-04-17 16:21:05,046 -   train_loss = 5.137200355529785
2025-04-17 16:21:05,814 - ***** Epoch: 83: Eval results *****
2025-04-17 16:21:05,814 -   train_loss = 5.058328151702881
2025-04-17 16:21:06,577 - ***** Epoch: 84: Eval results *****
2025-04-17 16:21:06,577 -   train_loss = 5.127176284790039
2025-04-17 16:21:07,351 - ***** Epoch: 85: Eval results *****
2025-04-17 16:21:07,351 -   train_loss = 4.981012344360352
2025-04-17 16:21:08,136 - ***** Epoch: 86: Eval results *****
2025-04-17 16:21:08,136 -   train_loss = 5.1059088706970215
2025-04-17 16:21:08,937 - ***** Epoch: 87: Eval results *****
2025-04-17 16:21:08,938 -   train_loss = 5.021907806396484
2025-04-17 16:21:09,716 - ***** Epoch: 88: Eval results *****
2025-04-17 16:21:09,717 -   train_loss = 5.014686584472656
2025-04-17 16:21:10,470 - ***** Epoch: 89: Eval results *****
2025-04-17 16:21:10,470 -   train_loss = 4.930964469909668
2025-04-17 16:21:11,290 - ***** Epoch: 90: Eval results *****
2025-04-17 16:21:11,290 -   train_loss = 4.910732269287109
2025-04-17 16:21:12,079 - ***** Epoch: 91: Eval results *****
2025-04-17 16:21:12,079 -   train_loss = 4.871962547302246
2025-04-17 16:21:12,855 - ***** Epoch: 92: Eval results *****
2025-04-17 16:21:12,855 -   train_loss = 4.81933069229126
2025-04-17 16:21:13,627 - ***** Epoch: 93: Eval results *****
2025-04-17 16:21:13,628 -   train_loss = 4.852688312530518
2025-04-17 16:21:14,382 - ***** Epoch: 94: Eval results *****
2025-04-17 16:21:14,383 -   train_loss = 4.759457588195801
2025-04-17 16:21:15,024 - ***** Epoch: 95: Eval results *****
2025-04-17 16:21:15,024 -   train_loss = 4.769085884094238
2025-04-17 16:21:15,659 - ***** Epoch: 96: Eval results *****
2025-04-17 16:21:15,659 -   train_loss = 4.700576305389404
2025-04-17 16:21:16,288 - ***** Epoch: 97: Eval results *****
2025-04-17 16:21:16,288 -   train_loss = 4.640285968780518
2025-04-17 16:21:17,100 - ***** Epoch: 98: Eval results *****
2025-04-17 16:21:17,101 -   train_loss = 4.64229679107666
2025-04-17 16:21:17,884 - ***** Epoch: 99: Eval results *****
2025-04-17 16:21:17,885 -   train_loss = 4.552160739898682
2025-04-17 16:21:18,643 - ***** Epoch: 100: Eval results *****
2025-04-17 16:21:18,643 -   train_loss = 4.605396270751953
2025-04-17 16:21:20,334 - Pre-training finished...
2025-04-17 16:21:20,673 - Freeze all parameters but the last layer for efficiency
2025-04-17 16:21:20,683 - Multimodal Intent Recognition begins...
2025-04-17 16:21:20,683 - Training begins...
2025-04-17 16:21:31,571 - Initializing centroids with K-means++...
2025-04-17 16:21:31,640 - K-means++ used 0.07 s
2025-04-17 16:22:00,813 - K-means used 0.02 s
2025-04-17 16:22:02,418 - ***** Epoch: 1 *****
2025-04-17 16:22:02,419 - Supervised Training Loss: 5.323710
2025-04-17 16:22:02,419 - Unsupervised Training Loss: 5.864020
2025-04-17 16:22:35,177 - K-means used 0.02 s
2025-04-17 16:22:36,414 - ***** Epoch: 2 *****
2025-04-17 16:22:36,414 - Supervised Training Loss: 5.828870
2025-04-17 16:22:36,414 - Unsupervised Training Loss: 5.842100
2025-04-17 16:23:08,021 - K-means used 0.03 s
2025-04-17 16:23:09,222 - ***** Epoch: 3 *****
2025-04-17 16:23:09,222 - Supervised Training Loss: 5.373730
2025-04-17 16:23:09,222 - Unsupervised Training Loss: 5.599190
2025-04-17 16:23:37,591 - K-means used 0.03 s
2025-04-17 16:23:38,797 - ***** Epoch: 4 *****
2025-04-17 16:23:38,797 - Supervised Training Loss: 4.991990
2025-04-17 16:23:38,797 - Unsupervised Training Loss: 5.591000
2025-04-17 16:24:07,947 - K-means used 0.02 s
2025-04-17 16:24:09,200 - ***** Epoch: 5 *****
2025-04-17 16:24:09,201 - Supervised Training Loss: 4.595180
2025-04-17 16:24:09,201 - Unsupervised Training Loss: 5.594400
2025-04-17 16:24:36,913 - K-means used 0.02 s
2025-04-17 16:24:38,341 - ***** Epoch: 6 *****
2025-04-17 16:24:38,341 - Supervised Training Loss: 4.926800
2025-04-17 16:24:38,341 - Unsupervised Training Loss: 5.369690
2025-04-17 16:25:06,842 - K-means used 0.04 s
2025-04-17 16:25:08,088 - ***** Epoch: 7 *****
2025-04-17 16:25:08,088 - Supervised Training Loss: 4.813720
2025-04-17 16:25:08,088 - Unsupervised Training Loss: 5.484680
2025-04-17 16:25:37,156 - K-means used 0.02 s
2025-04-17 16:25:38,394 - ***** Epoch: 8 *****
2025-04-17 16:25:38,394 - Supervised Training Loss: 4.659020
2025-04-17 16:25:38,394 - Unsupervised Training Loss: 5.538220
2025-04-17 16:26:06,798 - K-means used 0.02 s
2025-04-17 16:26:08,396 - ***** Epoch: 9 *****
2025-04-17 16:26:08,396 - Supervised Training Loss: 4.876970
2025-04-17 16:26:08,396 - Unsupervised Training Loss: 5.576320
2025-04-17 16:26:38,404 - K-means used 0.02 s
2025-04-17 16:26:39,802 - ***** Epoch: 10 *****
2025-04-17 16:26:39,803 - Supervised Training Loss: 4.802810
2025-04-17 16:26:39,803 - Unsupervised Training Loss: 5.412310
2025-04-17 16:27:07,289 - K-means used 0.02 s
2025-04-17 16:27:08,674 - ***** Epoch: 11 *****
2025-04-17 16:27:08,674 - Supervised Training Loss: 4.726520
2025-04-17 16:27:08,675 - Unsupervised Training Loss: 5.494360
2025-04-17 16:27:39,747 - K-means used 0.03 s
2025-04-17 16:27:41,210 - ***** Epoch: 12 *****
2025-04-17 16:27:41,210 - Supervised Training Loss: 4.853250
2025-04-17 16:27:41,210 - Unsupervised Training Loss: 5.563630
2025-04-17 16:28:06,868 - K-means used 0.02 s
2025-04-17 16:28:08,402 - ***** Epoch: 13 *****
2025-04-17 16:28:08,403 - Supervised Training Loss: 4.804260
2025-04-17 16:28:08,403 - Unsupervised Training Loss: 5.295910
2025-04-17 16:28:36,630 - K-means used 0.02 s
2025-04-17 16:28:38,266 - ***** Epoch: 14 *****
2025-04-17 16:28:38,266 - Supervised Training Loss: 4.750570
2025-04-17 16:28:38,266 - Unsupervised Training Loss: 5.413840
2025-04-17 16:29:07,765 - K-means used 0.02 s
2025-04-17 16:29:09,433 - ***** Epoch: 15 *****
2025-04-17 16:29:09,434 - Supervised Training Loss: 4.619540
2025-04-17 16:29:09,434 - Unsupervised Training Loss: 5.525650
2025-04-17 16:29:37,696 - K-means used 0.02 s
2025-04-17 16:29:39,456 - ***** Epoch: 16 *****
2025-04-17 16:29:39,457 - Supervised Training Loss: 4.813740
2025-04-17 16:29:39,457 - Unsupervised Training Loss: 4.943500
2025-04-17 16:30:06,354 - K-means used 0.02 s
2025-04-17 16:30:08,232 - ***** Epoch: 17 *****
2025-04-17 16:30:08,232 - Supervised Training Loss: 4.785590
2025-04-17 16:30:08,232 - Unsupervised Training Loss: 5.190980
2025-04-17 16:30:27,860 - Training is finished...
2025-04-17 16:30:27,860 - Testing begins...
2025-04-17 16:30:34,770 - ***** Test results *****
2025-04-17 16:30:34,770 -   ACC = 23.6
2025-04-17 16:30:34,770 -   ARI = 7.84
2025-04-17 16:30:34,770 -   NMI = 31.07
2025-04-17 16:30:34,770 -   fmi = 13.51
2025-04-17 16:30:34,770 - Testing is finished...
2025-04-17 16:30:34,770 - Multimodal intent recognition is finished...
2025-04-17 16:30:34,770 - Results are saved in results/results_umc_pre.csv
