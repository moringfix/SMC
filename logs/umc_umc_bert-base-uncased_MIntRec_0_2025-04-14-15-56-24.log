2025-04-14 15:56:24,608 - ============================== Params ==============================
2025-04-14 15:56:24,608 - logger_name: umc_umc_bert-base-uncased_MIntRec_0
2025-04-14 15:56:24,608 - dataset: MIntRec
2025-04-14 15:56:24,608 - multimodal_method: umc
2025-04-14 15:56:24,608 - method: umc
2025-04-14 15:56:24,608 - text_backbone: bert-base-uncased
2025-04-14 15:56:24,608 - seed: 0
2025-04-14 15:56:24,608 - num_workers: 16
2025-04-14 15:56:24,608 - log_id: umc_umc_bert-base-uncased_MIntRec_0_2025-04-14-15-56-24
2025-04-14 15:56:24,608 - gpu_id: 0
2025-04-14 15:56:24,609 - data_path: /root/autodl-tmp/home/Share/Dataset/LZH
2025-04-14 15:56:24,609 - train: True
2025-04-14 15:56:24,609 - tune: True
2025-04-14 15:56:24,609 - save_model: True
2025-04-14 15:56:24,609 - save_results: True
2025-04-14 15:56:24,609 - log_path: logs
2025-04-14 15:56:24,609 - cache_path: cache
2025-04-14 15:56:24,609 - video_data_path: video_data
2025-04-14 15:56:24,609 - audio_data_path: audio_data
2025-04-14 15:56:24,609 - video_feats_path: swin_feats.pkl
2025-04-14 15:56:24,609 - audio_feats_path: wavlm_feats.pkl
2025-04-14 15:56:24,609 - results_path: results
2025-04-14 15:56:24,609 - output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/UMC/outputs/MIntRec
2025-04-14 15:56:24,609 - model_path: models
2025-04-14 15:56:24,609 - config_file_name: umc_MIntRec
2025-04-14 15:56:24,609 - results_file_name: results_umc.csv
2025-04-14 15:56:24,609 - text_pretrained_model: uncased_L-12_H-768_A-12
2025-04-14 15:56:24,609 - text_seq_len: 30
2025-04-14 15:56:24,609 - video_seq_len: 230
2025-04-14 15:56:24,609 - audio_seq_len: 480
2025-04-14 15:56:24,609 - text_feat_dim: 768
2025-04-14 15:56:24,609 - video_feat_dim: 1024
2025-04-14 15:56:24,609 - audio_feat_dim: 768
2025-04-14 15:56:24,609 - num_labels: 20
2025-04-14 15:56:24,609 - num_train_examples: 1779
2025-04-14 15:56:24,609 - pretrained_bert_model: uncased_L-12_H-768_A-12
2025-04-14 15:56:24,609 - pretrain_batch_size: 128
2025-04-14 15:56:24,609 - train_batch_size: 128
2025-04-14 15:56:24,609 - eval_batch_size: 128
2025-04-14 15:56:24,609 - test_batch_size: 128
2025-04-14 15:56:24,610 - num_pretrain_epochs: 100
2025-04-14 15:56:24,610 - num_train_epochs: 100
2025-04-14 15:56:24,610 - pretrain: [True]
2025-04-14 15:56:24,610 - aligned_method: ctc
2025-04-14 15:56:24,610 - need_aligned: False
2025-04-14 15:56:24,610 - freeze_pretrain_bert_parameters: [True]
2025-04-14 15:56:24,610 - freeze_train_bert_parameters: [True]
2025-04-14 15:56:24,610 - pretrain_temperature: [0.1]
2025-04-14 15:56:24,610 - train_temperature_sup: [7.6]
2025-04-14 15:56:24,610 - train_temperature_unsup: [0.9]
2025-04-14 15:56:24,610 - activation: tanh
2025-04-14 15:56:24,610 - lr_pre: 1e-05
2025-04-14 15:56:24,610 - lr: [0.0003]
2025-04-14 15:56:24,610 - delta: [0.05]
2025-04-14 15:56:24,610 - thres: [0.1]
2025-04-14 15:56:24,610 - topk: [5]
2025-04-14 15:56:24,610 - weight_decay: 0.01
2025-04-14 15:56:24,610 - feat_dim: 768
2025-04-14 15:56:24,610 - hidden_size: 768
2025-04-14 15:56:24,610 - grad_clip: -1.0
2025-04-14 15:56:24,610 - warmup_proportion: 0.5
2025-04-14 15:56:24,610 - hidden_dropout_prob: 0.1
2025-04-14 15:56:24,610 - weight: 1.0
2025-04-14 15:56:24,610 - loss_mode: rdrop
2025-04-14 15:56:24,610 - base_dim: 256
2025-04-14 15:56:24,610 - nheads: 8
2025-04-14 15:56:24,610 - attn_dropout: 0.1
2025-04-14 15:56:24,610 - relu_dropout: 0.1
2025-04-14 15:56:24,610 - embed_dropout: 0.01
2025-04-14 15:56:24,610 - res_dropout: 0.0
2025-04-14 15:56:24,611 - attn_mask: True
2025-04-14 15:56:24,611 - encoder_layers_1: 1
2025-04-14 15:56:24,611 - fusion_act: tanh
2025-04-14 15:56:24,611 - pred_output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/UMC/outputs/MIntRec/umc_umc_MIntRec_bert-base-uncased_0
2025-04-14 15:56:24,611 - model_output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/UMC/outputs/MIntRec/umc_umc_MIntRec_bert-base-uncased_0/models
2025-04-14 15:56:24,611 - ============================== End Params ==============================
2025-04-14 15:56:25,675 - Freeze all parameters but the last layer for efficiency
2025-04-14 15:56:25,709 - Pre-training start...
2025-04-14 15:56:39,500 - ***** Epoch: 1: Eval results *****
2025-04-14 15:56:39,501 -   train_loss = 5.9495507308415005
2025-04-14 15:56:52,874 - ***** Epoch: 2: Eval results *****
2025-04-14 15:56:52,874 -   train_loss = 5.955358266830444
2025-04-14 15:57:07,098 - ***** Epoch: 3: Eval results *****
2025-04-14 15:57:07,098 -   train_loss = 5.943988800048828
2025-04-14 15:57:22,189 - ***** Epoch: 4: Eval results *****
2025-04-14 15:57:22,190 -   train_loss = 5.944168635777065
2025-04-14 15:57:46,967 - ***** Epoch: 5: Eval results *****
2025-04-14 15:57:46,967 -   train_loss = 5.940595729010446
2025-04-14 15:58:04,150 - ***** Epoch: 6: Eval results *****
2025-04-14 15:58:04,151 -   train_loss = 5.940682990210397
2025-04-14 15:58:20,913 - ***** Epoch: 7: Eval results *****
2025-04-14 15:58:20,914 -   train_loss = 5.9418957233428955
2025-04-14 15:58:42,480 - ***** Epoch: 8: Eval results *****
2025-04-14 15:58:42,480 -   train_loss = 5.9308066708700995
2025-04-14 15:59:01,495 - ***** Epoch: 9: Eval results *****
2025-04-14 15:59:01,496 -   train_loss = 5.93429034096854
2025-04-14 15:59:18,884 - ***** Epoch: 10: Eval results *****
2025-04-14 15:59:18,885 -   train_loss = 5.920668704169137
2025-04-14 15:59:35,257 - ***** Epoch: 11: Eval results *****
2025-04-14 15:59:35,257 -   train_loss = 5.918321779796055
2025-04-14 15:59:50,838 - ***** Epoch: 12: Eval results *****
2025-04-14 15:59:50,838 -   train_loss = 5.898892607007708
2025-04-14 16:00:05,782 - ***** Epoch: 13: Eval results *****
2025-04-14 16:00:05,783 -   train_loss = 5.892127922603062
2025-04-14 16:00:21,568 - ***** Epoch: 14: Eval results *****
2025-04-14 16:00:21,568 -   train_loss = 5.8695346627916605
2025-04-14 16:00:37,028 - ***** Epoch: 15: Eval results *****
2025-04-14 16:00:37,028 -   train_loss = 5.848584038870675
2025-04-14 16:00:52,214 - ***** Epoch: 16: Eval results *****
2025-04-14 16:00:52,214 -   train_loss = 5.81001707485744
2025-04-14 16:01:07,037 - ***** Epoch: 17: Eval results *****
2025-04-14 16:01:07,037 -   train_loss = 5.734688179833548
2025-04-14 16:01:21,959 - ***** Epoch: 18: Eval results *****
2025-04-14 16:01:21,959 -   train_loss = 5.622323717389788
2025-04-14 16:01:37,146 - ***** Epoch: 19: Eval results *****
2025-04-14 16:01:37,146 -   train_loss = 5.466900723321097
2025-04-14 16:01:52,155 - ***** Epoch: 20: Eval results *****
2025-04-14 16:01:52,156 -   train_loss = 5.255555221012661
2025-04-14 16:02:07,384 - ***** Epoch: 21: Eval results *****
2025-04-14 16:02:07,385 -   train_loss = 5.041454315185547
2025-04-14 16:02:23,072 - ***** Epoch: 22: Eval results *****
2025-04-14 16:02:23,072 -   train_loss = 4.783291442053659
2025-04-14 16:02:38,325 - ***** Epoch: 23: Eval results *****
2025-04-14 16:02:38,326 -   train_loss = 4.559213263647897
2025-04-14 16:02:53,503 - ***** Epoch: 24: Eval results *****
2025-04-14 16:02:53,504 -   train_loss = 4.31596793447222
2025-04-14 16:03:08,160 - ***** Epoch: 25: Eval results *****
2025-04-14 16:03:08,160 -   train_loss = 4.116786292621067
2025-04-14 16:03:22,930 - ***** Epoch: 26: Eval results *****
2025-04-14 16:03:22,931 -   train_loss = 3.9324608019420078
2025-04-14 16:03:37,787 - ***** Epoch: 27: Eval results *****
2025-04-14 16:03:37,787 -   train_loss = 3.748886159488133
2025-04-14 16:03:52,911 - ***** Epoch: 28: Eval results *****
2025-04-14 16:03:52,911 -   train_loss = 3.5472201108932495
2025-04-14 16:04:08,125 - ***** Epoch: 29: Eval results *****
2025-04-14 16:04:08,125 -   train_loss = 3.391283461025783
2025-04-14 16:04:23,111 - ***** Epoch: 30: Eval results *****
2025-04-14 16:04:23,111 -   train_loss = 3.243634053639003
2025-04-14 16:04:38,184 - ***** Epoch: 31: Eval results *****
2025-04-14 16:04:38,185 -   train_loss = 3.092668890953064
2025-04-14 16:04:53,054 - ***** Epoch: 32: Eval results *****
2025-04-14 16:04:53,054 -   train_loss = 2.9618915149143765
2025-04-14 16:05:07,749 - ***** Epoch: 33: Eval results *****
2025-04-14 16:05:07,750 -   train_loss = 2.831699558666774
2025-04-14 16:05:22,529 - ***** Epoch: 34: Eval results *****
2025-04-14 16:05:22,529 -   train_loss = 2.7434243815285817
2025-04-14 16:05:37,801 - ***** Epoch: 35: Eval results *****
2025-04-14 16:05:37,802 -   train_loss = 2.6528412955147878
2025-04-14 16:05:52,290 - ***** Epoch: 36: Eval results *****
2025-04-14 16:05:52,290 -   train_loss = 2.564497777393886
2025-04-14 16:06:07,520 - ***** Epoch: 37: Eval results *****
2025-04-14 16:06:07,521 -   train_loss = 2.462603007044111
2025-04-14 16:06:22,325 - ***** Epoch: 38: Eval results *****
2025-04-14 16:06:22,325 -   train_loss = 2.385812418801444
2025-04-14 16:06:37,199 - ***** Epoch: 39: Eval results *****
2025-04-14 16:06:37,199 -   train_loss = 2.3337046248572215
2025-04-14 16:06:51,647 - ***** Epoch: 40: Eval results *****
2025-04-14 16:06:51,647 -   train_loss = 2.270782862390791
2025-04-14 16:07:06,717 - ***** Epoch: 41: Eval results *****
2025-04-14 16:07:06,717 -   train_loss = 2.2209890569959367
2025-04-14 16:07:22,078 - ***** Epoch: 42: Eval results *****
2025-04-14 16:07:22,079 -   train_loss = 2.179529002734593
2025-04-14 16:07:36,530 - ***** Epoch: 43: Eval results *****
2025-04-14 16:07:36,530 -   train_loss = 2.1140255076544627
2025-04-14 16:07:51,322 - ***** Epoch: 44: Eval results *****
2025-04-14 16:07:51,322 -   train_loss = 2.069200473172324
2025-04-14 16:08:06,316 - ***** Epoch: 45: Eval results *****
2025-04-14 16:08:06,317 -   train_loss = 2.0328834567751204
2025-04-14 16:08:22,024 - ***** Epoch: 46: Eval results *****
2025-04-14 16:08:22,024 -   train_loss = 1.9813657062394279
2025-04-14 16:08:37,423 - ***** Epoch: 47: Eval results *****
2025-04-14 16:08:37,423 -   train_loss = 1.950800963810512
2025-04-14 16:08:51,974 - ***** Epoch: 48: Eval results *****
2025-04-14 16:08:51,974 -   train_loss = 1.9075575470924377
2025-04-14 16:09:07,032 - ***** Epoch: 49: Eval results *****
2025-04-14 16:09:07,032 -   train_loss = 1.8768897312028068
2025-04-14 16:09:21,697 - ***** Epoch: 50: Eval results *****
2025-04-14 16:09:21,697 -   train_loss = 1.834214985370636
2025-04-14 16:09:36,001 - ***** Epoch: 51: Eval results *****
2025-04-14 16:09:36,002 -   train_loss = 1.8276593855449133
2025-04-14 16:09:50,628 - ***** Epoch: 52: Eval results *****
2025-04-14 16:09:50,629 -   train_loss = 1.787291944026947
2025-04-14 16:10:04,756 - ***** Epoch: 53: Eval results *****
2025-04-14 16:10:04,756 -   train_loss = 1.7758225543158395
2025-04-14 16:10:19,586 - ***** Epoch: 54: Eval results *****
2025-04-14 16:10:19,586 -   train_loss = 1.767319645200457
2025-04-14 16:10:34,352 - ***** Epoch: 55: Eval results *****
2025-04-14 16:10:34,353 -   train_loss = 1.7312930226325989
2025-04-14 16:10:49,068 - ***** Epoch: 56: Eval results *****
2025-04-14 16:10:49,068 -   train_loss = 1.7044147849082947
2025-04-14 16:11:04,609 - ***** Epoch: 57: Eval results *****
2025-04-14 16:11:04,610 -   train_loss = 1.6791687948363168
2025-04-14 16:11:19,811 - ***** Epoch: 58: Eval results *****
2025-04-14 16:11:19,811 -   train_loss = 1.6799958774021693
2025-04-14 16:11:35,453 - ***** Epoch: 59: Eval results *****
2025-04-14 16:11:35,454 -   train_loss = 1.6512435674667358
2025-04-14 16:11:50,212 - ***** Epoch: 60: Eval results *****
2025-04-14 16:11:50,212 -   train_loss = 1.6386903354099818
2025-04-14 16:12:05,068 - ***** Epoch: 61: Eval results *****
2025-04-14 16:12:05,068 -   train_loss = 1.6356177159718104
2025-04-14 16:12:19,352 - ***** Epoch: 62: Eval results *****
2025-04-14 16:12:19,352 -   train_loss = 1.6208768827574593
2025-04-14 16:12:33,686 - ***** Epoch: 63: Eval results *****
2025-04-14 16:12:33,687 -   train_loss = 1.6168820772852217
2025-04-14 16:12:48,328 - ***** Epoch: 64: Eval results *****
2025-04-14 16:12:48,329 -   train_loss = 1.5829995785440718
2025-04-14 16:13:03,124 - ***** Epoch: 65: Eval results *****
2025-04-14 16:13:03,124 -   train_loss = 1.592242649623326
2025-04-14 16:13:17,307 - ***** Epoch: 66: Eval results *****
2025-04-14 16:13:17,308 -   train_loss = 1.5768452286720276
2025-04-14 16:13:31,238 - ***** Epoch: 67: Eval results *****
2025-04-14 16:13:31,238 -   train_loss = 1.5528621673583984
2025-04-14 16:13:45,162 - ***** Epoch: 68: Eval results *****
2025-04-14 16:13:45,162 -   train_loss = 1.5513639450073242
2025-04-14 16:13:59,638 - ***** Epoch: 69: Eval results *****
2025-04-14 16:13:59,639 -   train_loss = 1.5434449400220598
2025-04-14 16:14:13,756 - ***** Epoch: 70: Eval results *****
2025-04-14 16:14:13,756 -   train_loss = 1.551415775503431
2025-04-14 16:14:27,739 - ***** Epoch: 71: Eval results *****
2025-04-14 16:14:27,739 -   train_loss = 1.5383132781301225
2025-04-14 16:14:41,497 - ***** Epoch: 72: Eval results *****
2025-04-14 16:14:41,497 -   train_loss = 1.549813142844609
2025-04-14 16:14:56,069 - ***** Epoch: 73: Eval results *****
2025-04-14 16:14:56,069 -   train_loss = 1.5364599823951721
2025-04-14 16:15:10,540 - ***** Epoch: 74: Eval results *****
2025-04-14 16:15:10,540 -   train_loss = 1.5309514318193709
2025-04-14 16:15:25,884 - ***** Epoch: 75: Eval results *****
2025-04-14 16:15:25,884 -   train_loss = 1.5277042559215002
2025-04-14 16:15:40,476 - ***** Epoch: 76: Eval results *****
2025-04-14 16:15:40,476 -   train_loss = 1.5174924646105086
2025-04-14 16:15:55,022 - ***** Epoch: 77: Eval results *****
2025-04-14 16:15:55,023 -   train_loss = 1.5011286990983146
2025-04-14 16:16:09,456 - ***** Epoch: 78: Eval results *****
2025-04-14 16:16:09,456 -   train_loss = 1.5036937083516801
2025-04-14 16:16:23,718 - ***** Epoch: 79: Eval results *****
2025-04-14 16:16:23,718 -   train_loss = 1.501652215208326
2025-04-14 16:16:38,574 - ***** Epoch: 80: Eval results *****
2025-04-14 16:16:38,574 -   train_loss = 1.4958985107285636
2025-04-14 16:16:52,822 - ***** Epoch: 81: Eval results *****
2025-04-14 16:16:52,822 -   train_loss = 1.4978841032300676
2025-04-14 16:17:07,481 - ***** Epoch: 82: Eval results *****
2025-04-14 16:17:07,481 -   train_loss = 1.4916800601141793
2025-04-14 16:17:21,999 - ***** Epoch: 83: Eval results *****
2025-04-14 16:17:22,000 -   train_loss = 1.5059868693351746
2025-04-14 16:17:36,012 - ***** Epoch: 84: Eval results *****
2025-04-14 16:17:36,012 -   train_loss = 1.4844991735049657
2025-04-14 16:17:50,549 - ***** Epoch: 85: Eval results *****
2025-04-14 16:17:50,549 -   train_loss = 1.4872920768601554
2025-04-14 16:18:04,454 - ***** Epoch: 86: Eval results *****
2025-04-14 16:18:04,454 -   train_loss = 1.4864764894757951
2025-04-14 16:18:17,582 - ***** Epoch: 87: Eval results *****
2025-04-14 16:18:17,583 -   train_loss = 1.4792463268552507
2025-04-14 16:18:29,902 - ***** Epoch: 88: Eval results *****
2025-04-14 16:18:29,903 -   train_loss = 1.4761233414922441
2025-04-14 16:18:42,316 - ***** Epoch: 89: Eval results *****
2025-04-14 16:18:42,316 -   train_loss = 1.4691850117274694
2025-04-14 16:18:54,924 - ***** Epoch: 90: Eval results *****
2025-04-14 16:18:54,925 -   train_loss = 1.4841335245541163
2025-04-14 16:19:07,981 - ***** Epoch: 91: Eval results *****
2025-04-14 16:19:07,981 -   train_loss = 1.4695379904338293
2025-04-14 16:19:21,345 - ***** Epoch: 92: Eval results *****
2025-04-14 16:19:21,346 -   train_loss = 1.4748034392084395
2025-04-14 16:19:33,951 - ***** Epoch: 93: Eval results *****
2025-04-14 16:19:33,952 -   train_loss = 1.4745393565722875
2025-04-14 16:19:46,407 - ***** Epoch: 94: Eval results *****
2025-04-14 16:19:46,407 -   train_loss = 1.4733967695917403
2025-04-14 16:19:59,243 - ***** Epoch: 95: Eval results *****
2025-04-14 16:19:59,244 -   train_loss = 1.4720470990453447
2025-04-14 16:20:11,855 - ***** Epoch: 96: Eval results *****
2025-04-14 16:20:11,856 -   train_loss = 1.4663529736655099
2025-04-14 16:20:24,360 - ***** Epoch: 97: Eval results *****
2025-04-14 16:20:24,361 -   train_loss = 1.4636993663651603
2025-04-14 16:20:37,011 - ***** Epoch: 98: Eval results *****
2025-04-14 16:20:37,011 -   train_loss = 1.4828499470438277
2025-04-14 16:20:49,556 - ***** Epoch: 99: Eval results *****
2025-04-14 16:20:49,557 -   train_loss = 1.4689759271485465
2025-04-14 16:21:02,246 - ***** Epoch: 100: Eval results *****
2025-04-14 16:21:02,247 -   train_loss = 1.4735297390392847
2025-04-14 16:21:03,867 - Pre-training finished...
2025-04-14 16:21:04,137 - Freeze all parameters but the last layer for efficiency
2025-04-14 16:21:04,147 - Multimodal Intent Recognition begins...
2025-04-14 16:21:04,147 - Training begins...
2025-04-14 16:21:23,760 - Initializing centroids with K-means++...
2025-04-14 16:21:23,859 - K-means++ used 0.1 s
2025-04-14 16:21:55,098 - K-means used 0.08 s
2025-04-14 16:21:56,210 - ***** Epoch: 1 *****
2025-04-14 16:21:56,210 - Supervised Training Loss: 5.289080
2025-04-14 16:21:56,211 - Unsupervised Training Loss: 5.089630
2025-04-14 16:22:25,540 - K-means used 0.03 s
2025-04-14 16:22:26,872 - ***** Epoch: 2 *****
2025-04-14 16:22:26,872 - Supervised Training Loss: 4.431090
2025-04-14 16:22:26,872 - Unsupervised Training Loss: 5.102050
2025-04-14 16:22:54,400 - K-means used 0.08 s
2025-04-14 16:22:55,733 - ***** Epoch: 3 *****
2025-04-14 16:22:55,734 - Supervised Training Loss: 5.764110
2025-04-14 16:22:55,734 - Unsupervised Training Loss: 4.947820
2025-04-14 16:23:24,623 - K-means used 0.02 s
2025-04-14 16:23:26,106 - ***** Epoch: 4 *****
2025-04-14 16:23:26,107 - Supervised Training Loss: 5.648660
2025-04-14 16:23:26,107 - Unsupervised Training Loss: 5.024720
2025-04-14 16:23:54,039 - K-means used 0.02 s
2025-04-14 16:23:55,470 - ***** Epoch: 5 *****
2025-04-14 16:23:55,471 - Supervised Training Loss: 5.402330
2025-04-14 16:23:55,471 - Unsupervised Training Loss: 5.053590
2025-04-14 16:24:24,509 - K-means used 0.06 s
2025-04-14 16:24:25,928 - ***** Epoch: 6 *****
2025-04-14 16:24:25,928 - Supervised Training Loss: 5.809770
2025-04-14 16:24:25,928 - Unsupervised Training Loss: 4.862060
2025-04-14 16:24:54,195 - K-means used 0.03 s
2025-04-14 16:24:55,899 - ***** Epoch: 7 *****
2025-04-14 16:24:55,899 - Supervised Training Loss: 5.746940
2025-04-14 16:24:55,899 - Unsupervised Training Loss: 4.972580
2025-04-14 16:25:25,864 - K-means used 0.02 s
2025-04-14 16:25:27,409 - ***** Epoch: 8 *****
2025-04-14 16:25:27,409 - Supervised Training Loss: 5.613110
2025-04-14 16:25:27,409 - Unsupervised Training Loss: 5.034010
2025-04-14 16:25:56,847 - K-means used 0.03 s
2025-04-14 16:25:58,626 - ***** Epoch: 9 *****
2025-04-14 16:25:58,626 - Supervised Training Loss: 5.835190
2025-04-14 16:25:58,626 - Unsupervised Training Loss: 5.064750
2025-04-14 16:26:29,116 - K-means used 0.03 s
2025-04-14 16:26:30,923 - ***** Epoch: 10 *****
2025-04-14 16:26:30,923 - Supervised Training Loss: 5.772620
2025-04-14 16:26:30,924 - Unsupervised Training Loss: 4.904250
2025-04-14 16:27:00,675 - K-means used 0.02 s
2025-04-14 16:27:02,463 - ***** Epoch: 11 *****
2025-04-14 16:27:02,463 - Supervised Training Loss: 5.696890
2025-04-14 16:27:02,464 - Unsupervised Training Loss: 4.948240
2025-04-14 16:27:31,634 - K-means used 0.02 s
2025-04-14 16:27:33,420 - ***** Epoch: 12 *****
2025-04-14 16:27:33,421 - Supervised Training Loss: 5.837910
2025-04-14 16:27:33,421 - Unsupervised Training Loss: 4.997790
2025-04-14 16:28:02,903 - K-means used 0.1 s
2025-04-14 16:28:04,629 - ***** Epoch: 13 *****
2025-04-14 16:28:04,629 - Supervised Training Loss: 5.797000
2025-04-14 16:28:04,630 - Unsupervised Training Loss: 4.740010
2025-04-14 16:28:33,426 - K-means used 0.02 s
2025-04-14 16:28:35,425 - ***** Epoch: 14 *****
2025-04-14 16:28:35,426 - Supervised Training Loss: 5.752800
2025-04-14 16:28:35,426 - Unsupervised Training Loss: 4.843850
2025-04-14 16:29:03,196 - K-means used 0.01 s
2025-04-14 16:29:05,216 - ***** Epoch: 15 *****
2025-04-14 16:29:05,216 - Supervised Training Loss: 5.606310
2025-04-14 16:29:05,216 - Unsupervised Training Loss: 4.946670
2025-04-14 16:29:32,657 - K-means used 0.02 s
2025-04-14 16:29:34,736 - ***** Epoch: 16 *****
2025-04-14 16:29:34,736 - Supervised Training Loss: 5.813610
2025-04-14 16:29:34,736 - Unsupervised Training Loss: 4.438560
2025-04-14 16:30:02,309 - K-means used 0.06 s
2025-04-14 16:30:04,550 - ***** Epoch: 17 *****
2025-04-14 16:30:04,550 - Supervised Training Loss: 5.779500
2025-04-14 16:30:04,550 - Unsupervised Training Loss: 4.625760
2025-04-14 16:30:22,721 - Training is finished...
2025-04-14 16:30:22,721 - Testing begins...
2025-04-14 16:30:31,678 - ***** Test results *****
2025-04-14 16:30:31,679 -   ACC = 37.53
2025-04-14 16:30:31,679 -   ARI = 18.81
2025-04-14 16:30:31,680 -   NMI = 44.89
2025-04-14 16:30:31,680 -   fmi = 23.93
2025-04-14 16:30:31,680 - Testing is finished...
2025-04-14 16:30:31,680 - Multimodal intent recognition is finished...
2025-04-14 16:30:31,680 - Results are saved in results/results_umc.csv
