2025-04-11 12:38:44,473 - ============================== Params ==============================
2025-04-11 12:38:44,474 - logger_name: umc_umc_bert-base-uncased_MELD-DA_3
2025-04-11 12:38:44,474 - dataset: MELD-DA
2025-04-11 12:38:44,474 - multimodal_method: umc
2025-04-11 12:38:44,474 - method: umc
2025-04-11 12:38:44,474 - text_backbone: bert-base-uncased
2025-04-11 12:38:44,474 - seed: 3
2025-04-11 12:38:44,474 - num_workers: 16
2025-04-11 12:38:44,474 - log_id: umc_umc_bert-base-uncased_MELD-DA_3_2025-04-11-12-38-44
2025-04-11 12:38:44,474 - gpu_id: 1
2025-04-11 12:38:44,474 - data_path: /root/autodl-tmp/home/Share/Dataset/LZH
2025-04-11 12:38:44,474 - train: True
2025-04-11 12:38:44,474 - tune: True
2025-04-11 12:38:44,474 - save_model: True
2025-04-11 12:38:44,474 - save_results: True
2025-04-11 12:38:44,474 - log_path: logs
2025-04-11 12:38:44,474 - cache_path: cache
2025-04-11 12:38:44,474 - video_data_path: video_data
2025-04-11 12:38:44,474 - audio_data_path: audio_data
2025-04-11 12:38:44,474 - video_feats_path: swin_feats.pkl
2025-04-11 12:38:44,474 - audio_feats_path: wavlm_feats.pkl
2025-04-11 12:38:44,474 - results_path: results
2025-04-11 12:38:44,474 - output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/UMC/outputs/MELD-DA
2025-04-11 12:38:44,474 - model_path: models
2025-04-11 12:38:44,474 - config_file_name: umc_MELD-DA
2025-04-11 12:38:44,475 - results_file_name: results_umc.csv
2025-04-11 12:38:44,475 - text_pretrained_model: uncased_L-12_H-768_A-12
2025-04-11 12:38:44,475 - text_seq_len: 70
2025-04-11 12:38:44,475 - video_seq_len: 250
2025-04-11 12:38:44,475 - audio_seq_len: 520
2025-04-11 12:38:44,475 - text_feat_dim: 768
2025-04-11 12:38:44,475 - video_feat_dim: 1024
2025-04-11 12:38:44,475 - audio_feat_dim: 768
2025-04-11 12:38:44,475 - num_labels: 12
2025-04-11 12:38:44,475 - num_train_examples: 7990
2025-04-11 12:38:44,475 - pretrained_bert_model: uncased_L-12_H-768_A-12
2025-04-11 12:38:44,475 - pretrain_batch_size: 128
2025-04-11 12:38:44,475 - train_batch_size: 128
2025-04-11 12:38:44,475 - eval_batch_size: 128
2025-04-11 12:38:44,475 - test_batch_size: 128
2025-04-11 12:38:44,475 - num_pretrain_epochs: [100]
2025-04-11 12:38:44,476 - num_train_epochs: [100]
2025-04-11 12:38:44,476 - pretrain: [True]
2025-04-11 12:38:44,476 - aligned_method: ctc
2025-04-11 12:38:44,476 - need_aligned: False
2025-04-11 12:38:44,476 - freeze_pretrain_bert_parameters: True
2025-04-11 12:38:44,476 - freeze_train_bert_parameters: True
2025-04-11 12:38:44,476 - pretrain_temperature: [0.2]
2025-04-11 12:38:44,476 - train_temperature_sup: [20]
2025-04-11 12:38:44,476 - train_temperature_unsup: [20]
2025-04-11 12:38:44,476 - activation: tanh
2025-04-11 12:38:44,476 - lr_pre: [5e-06]
2025-04-11 12:38:44,476 - lr: [0.0002]
2025-04-11 12:38:44,476 - delta: [0.05]
2025-04-11 12:38:44,476 - thres: [0.1]
2025-04-11 12:38:44,476 - topk: [5]
2025-04-11 12:38:44,476 - weight_decay: 0.01
2025-04-11 12:38:44,476 - feat_dim: 768
2025-04-11 12:38:44,476 - hidden_size: 768
2025-04-11 12:38:44,476 - grad_clip: [-1.0]
2025-04-11 12:38:44,476 - warmup_proportion: 0.5
2025-04-11 12:38:44,476 - hidden_dropout_prob: 0.1
2025-04-11 12:38:44,476 - weight: 1.0
2025-04-11 12:38:44,476 - loss_mode: rdrop
2025-04-11 12:38:44,476 - base_dim: [256]
2025-04-11 12:38:44,476 - nheads: 8
2025-04-11 12:38:44,476 - attn_dropout: 0.1
2025-04-11 12:38:44,476 - relu_dropout: 0.1
2025-04-11 12:38:44,476 - embed_dropout: 0.1
2025-04-11 12:38:44,476 - res_dropout: 0.0
2025-04-11 12:38:44,477 - attn_mask: True
2025-04-11 12:38:44,477 - encoder_layers_1: 1
2025-04-11 12:38:44,477 - fusion_act: tanh
2025-04-11 12:38:44,477 - pred_output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/UMC/outputs/MELD-DA/umc_umc_MELD-DA_bert-base-uncased_3
2025-04-11 12:38:44,477 - model_output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/UMC/outputs/MELD-DA/umc_umc_MELD-DA_bert-base-uncased_3/models
2025-04-11 12:38:44,477 - ============================== End Params ==============================
2025-04-11 12:38:45,772 - Freeze all parameters but the last layer for efficiency
2025-04-11 12:38:45,814 - Pre-training start...
2025-04-11 12:40:25,849 - ***** Epoch: 1: Eval results *****
2025-04-11 12:40:25,850 -   train_loss = 5.913269073244125
2025-04-11 12:42:06,461 - ***** Epoch: 2: Eval results *****
2025-04-11 12:42:06,461 -   train_loss = 5.912017148638529
2025-04-11 12:43:45,500 - ***** Epoch: 3: Eval results *****
2025-04-11 12:43:45,500 -   train_loss = 5.910698504675002
2025-04-11 12:45:23,082 - ***** Epoch: 4: Eval results *****
2025-04-11 12:45:23,082 -   train_loss = 5.9081215934147915
2025-04-11 12:46:58,361 - ***** Epoch: 5: Eval results *****
2025-04-11 12:46:58,361 -   train_loss = 5.902470460013737
2025-04-11 12:48:38,732 - ***** Epoch: 6: Eval results *****
2025-04-11 12:48:38,733 -   train_loss = 5.8987560196528355
2025-04-11 12:50:17,839 - ***** Epoch: 7: Eval results *****
2025-04-11 12:50:17,839 -   train_loss = 5.889389393821595
2025-04-11 12:51:58,199 - ***** Epoch: 8: Eval results *****
2025-04-11 12:51:58,199 -   train_loss = 5.879232474735805
2025-04-11 12:53:38,769 - ***** Epoch: 9: Eval results *****
2025-04-11 12:53:38,769 -   train_loss = 5.8533252685789074
2025-04-11 12:55:19,525 - ***** Epoch: 10: Eval results *****
2025-04-11 12:55:19,525 -   train_loss = 5.807526913900224
2025-04-11 12:56:59,004 - ***** Epoch: 11: Eval results *****
2025-04-11 12:56:59,005 -   train_loss = 5.727838463253445
2025-04-11 12:58:39,325 - ***** Epoch: 12: Eval results *****
2025-04-11 12:58:39,325 -   train_loss = 5.602309401073153
2025-04-11 13:00:18,791 - ***** Epoch: 13: Eval results *****
2025-04-11 13:00:18,791 -   train_loss = 5.44945990850055
2025-04-11 13:01:58,750 - ***** Epoch: 14: Eval results *****
2025-04-11 13:01:58,751 -   train_loss = 5.306292458186074
2025-04-11 13:03:39,281 - ***** Epoch: 15: Eval results *****
2025-04-11 13:03:39,281 -   train_loss = 5.179808434985933
2025-04-11 13:05:19,140 - ***** Epoch: 16: Eval results *****
2025-04-11 13:05:19,140 -   train_loss = 5.040032909030006
2025-04-11 13:06:58,739 - ***** Epoch: 17: Eval results *****
2025-04-11 13:06:58,740 -   train_loss = 4.871988796052479
2025-04-11 13:08:37,608 - ***** Epoch: 18: Eval results *****
2025-04-11 13:08:37,608 -   train_loss = 4.684420184483604
2025-04-11 13:10:15,992 - ***** Epoch: 19: Eval results *****
2025-04-11 13:10:15,993 -   train_loss = 4.522499315322391
2025-04-11 13:11:54,917 - ***** Epoch: 20: Eval results *****
2025-04-11 13:11:54,917 -   train_loss = 4.357267069438147
2025-04-11 13:13:35,042 - ***** Epoch: 21: Eval results *****
2025-04-11 13:13:35,042 -   train_loss = 4.209001715221103
2025-04-11 13:15:11,851 - ***** Epoch: 22: Eval results *****
2025-04-11 13:15:11,851 -   train_loss = 4.0734856772044346
2025-04-11 13:16:49,358 - ***** Epoch: 23: Eval results *****
2025-04-11 13:16:49,359 -   train_loss = 3.949559499347021
2025-04-11 13:18:27,370 - ***** Epoch: 24: Eval results *****
2025-04-11 13:18:27,370 -   train_loss = 3.823451201121012
2025-04-11 13:20:04,303 - ***** Epoch: 25: Eval results *****
2025-04-11 13:20:04,303 -   train_loss = 3.710330020813715
2025-04-11 13:21:40,305 - ***** Epoch: 26: Eval results *****
2025-04-11 13:21:40,306 -   train_loss = 3.620368211988419
2025-04-11 13:23:17,076 - ***** Epoch: 27: Eval results *****
2025-04-11 13:23:17,077 -   train_loss = 3.5345709399571494
2025-04-11 13:24:53,506 - ***** Epoch: 28: Eval results *****
2025-04-11 13:24:53,506 -   train_loss = 3.4711506253197077
2025-04-11 13:26:32,420 - ***** Epoch: 29: Eval results *****
2025-04-11 13:26:32,420 -   train_loss = 3.4206994563814193
2025-04-11 13:28:11,662 - ***** Epoch: 30: Eval results *****
2025-04-11 13:28:11,663 -   train_loss = 3.3774432984609453
2025-04-11 13:29:51,793 - ***** Epoch: 31: Eval results *****
2025-04-11 13:29:51,794 -   train_loss = 3.341725084516737
2025-04-11 13:31:31,921 - ***** Epoch: 32: Eval results *****
2025-04-11 13:31:31,921 -   train_loss = 3.300804853439331
2025-04-11 13:33:11,066 - ***** Epoch: 33: Eval results *****
2025-04-11 13:33:11,067 -   train_loss = 3.26485504422869
2025-04-11 13:34:51,149 - ***** Epoch: 34: Eval results *****
2025-04-11 13:34:51,149 -   train_loss = 3.2269768639216347
2025-04-11 13:36:30,605 - ***** Epoch: 35: Eval results *****
2025-04-11 13:36:30,605 -   train_loss = 3.2019619714646113
2025-04-11 13:38:09,404 - ***** Epoch: 36: Eval results *****
2025-04-11 13:38:09,404 -   train_loss = 3.1765573100438194
2025-04-11 13:39:47,981 - ***** Epoch: 37: Eval results *****
2025-04-11 13:39:47,982 -   train_loss = 3.1444023980034723
2025-04-11 13:41:26,413 - ***** Epoch: 38: Eval results *****
2025-04-11 13:41:26,414 -   train_loss = 3.1124804398370167
2025-04-11 13:43:04,407 - ***** Epoch: 39: Eval results *****
2025-04-11 13:43:04,408 -   train_loss = 3.0934937189495755
2025-04-11 13:44:42,546 - ***** Epoch: 40: Eval results *****
2025-04-11 13:44:42,546 -   train_loss = 3.0706301265292697
2025-04-11 13:46:21,740 - ***** Epoch: 41: Eval results *****
2025-04-11 13:46:21,741 -   train_loss = 3.0537187977442666
2025-04-11 13:48:01,683 - ***** Epoch: 42: Eval results *****
2025-04-11 13:48:01,684 -   train_loss = 3.0302380985683866
2025-04-11 13:49:41,806 - ***** Epoch: 43: Eval results *****
2025-04-11 13:49:41,806 -   train_loss = 3.010167666843959
2025-04-11 13:51:19,811 - ***** Epoch: 44: Eval results *****
2025-04-11 13:51:19,811 -   train_loss = 2.9942255587804887
2025-04-11 13:52:57,638 - ***** Epoch: 45: Eval results *****
2025-04-11 13:52:57,638 -   train_loss = 2.9776804787772044
2025-04-11 13:54:34,947 - ***** Epoch: 46: Eval results *****
2025-04-11 13:54:34,947 -   train_loss = 2.961945408866519
2025-04-11 13:56:11,950 - ***** Epoch: 47: Eval results *****
2025-04-11 13:56:11,950 -   train_loss = 2.9480092525482178
2025-04-11 13:57:50,362 - ***** Epoch: 48: Eval results *****
2025-04-11 13:57:50,362 -   train_loss = 2.931030757843502
2025-04-11 13:59:27,729 - ***** Epoch: 49: Eval results *****
2025-04-11 13:59:27,730 -   train_loss = 2.909911893662952
2025-04-11 14:01:06,954 - ***** Epoch: 50: Eval results *****
2025-04-11 14:01:06,954 -   train_loss = 2.898228126858908
2025-04-11 14:02:42,886 - ***** Epoch: 51: Eval results *****
2025-04-11 14:02:42,887 -   train_loss = 2.8802864778609503
2025-04-11 14:04:20,702 - ***** Epoch: 52: Eval results *****
2025-04-11 14:04:20,702 -   train_loss = 2.8694547017415366
2025-04-11 14:05:57,806 - ***** Epoch: 53: Eval results *****
2025-04-11 14:05:57,806 -   train_loss = 2.8599245888846263
2025-04-11 14:07:35,869 - ***** Epoch: 54: Eval results *****
2025-04-11 14:07:35,870 -   train_loss = 2.8460328238351003
2025-04-11 14:09:05,641 - ***** Epoch: 55: Eval results *****
2025-04-11 14:09:05,642 -   train_loss = 2.8266652879260836
2025-04-11 14:10:35,409 - ***** Epoch: 56: Eval results *****
2025-04-11 14:10:35,410 -   train_loss = 2.8192699106912764
2025-04-11 14:12:05,151 - ***** Epoch: 57: Eval results *****
2025-04-11 14:12:05,151 -   train_loss = 2.802924019949777
2025-04-11 14:13:33,992 - ***** Epoch: 58: Eval results *****
2025-04-11 14:13:33,993 -   train_loss = 2.800996712275914
2025-04-11 14:15:03,045 - ***** Epoch: 59: Eval results *****
2025-04-11 14:15:03,046 -   train_loss = 2.7902210061512296
2025-04-11 14:16:31,429 - ***** Epoch: 60: Eval results *****
2025-04-11 14:16:31,430 -   train_loss = 2.7802077664269342
2025-04-11 14:18:00,235 - ***** Epoch: 61: Eval results *****
2025-04-11 14:18:00,236 -   train_loss = 2.775248406425355
2025-04-11 14:19:29,506 - ***** Epoch: 62: Eval results *****
2025-04-11 14:19:29,506 -   train_loss = 2.7629098816523476
2025-04-11 14:20:58,458 - ***** Epoch: 63: Eval results *****
2025-04-11 14:20:58,459 -   train_loss = 2.7553202311197915
2025-04-11 14:22:27,503 - ***** Epoch: 64: Eval results *****
2025-04-11 14:22:27,504 -   train_loss = 2.752799208202059
2025-04-11 14:23:56,808 - ***** Epoch: 65: Eval results *****
2025-04-11 14:23:56,809 -   train_loss = 2.7450461387634277
2025-04-11 14:25:25,589 - ***** Epoch: 66: Eval results *****
2025-04-11 14:25:25,589 -   train_loss = 2.734962887234158
2025-04-11 14:26:54,369 - ***** Epoch: 67: Eval results *****
2025-04-11 14:26:54,369 -   train_loss = 2.72424254341731
2025-04-11 14:28:23,565 - ***** Epoch: 68: Eval results *****
2025-04-11 14:28:23,565 -   train_loss = 2.717637465113685
2025-04-11 14:29:53,306 - ***** Epoch: 69: Eval results *****
2025-04-11 14:29:53,306 -   train_loss = 2.707864534287226
2025-04-11 14:31:23,350 - ***** Epoch: 70: Eval results *****
2025-04-11 14:31:23,350 -   train_loss = 2.703401353624132
2025-04-11 14:32:53,396 - ***** Epoch: 71: Eval results *****
2025-04-11 14:32:53,397 -   train_loss = 2.699736016137259
2025-04-11 14:34:24,214 - ***** Epoch: 72: Eval results *****
2025-04-11 14:34:24,215 -   train_loss = 2.6989152507176475
2025-04-11 14:35:55,515 - ***** Epoch: 73: Eval results *****
2025-04-11 14:35:55,515 -   train_loss = 2.692342591664148
2025-04-11 14:37:26,349 - ***** Epoch: 74: Eval results *****
2025-04-11 14:37:26,350 -   train_loss = 2.683088845676846
2025-04-11 14:38:57,227 - ***** Epoch: 75: Eval results *****
2025-04-11 14:38:57,228 -   train_loss = 2.6850911189639377
2025-04-11 14:40:28,007 - ***** Epoch: 76: Eval results *****
2025-04-11 14:40:28,007 -   train_loss = 2.676437118696788
2025-04-11 14:41:59,228 - ***** Epoch: 77: Eval results *****
2025-04-11 14:41:59,228 -   train_loss = 2.673261082361615
2025-04-11 14:43:30,125 - ***** Epoch: 78: Eval results *****
2025-04-11 14:43:30,126 -   train_loss = 2.6682899868677534
2025-04-11 14:45:01,042 - ***** Epoch: 79: Eval results *****
2025-04-11 14:45:01,042 -   train_loss = 2.65895504421658
2025-04-11 14:46:31,990 - ***** Epoch: 80: Eval results *****
2025-04-11 14:46:31,990 -   train_loss = 2.6648221432216586
2025-04-11 14:48:02,472 - ***** Epoch: 81: Eval results *****
2025-04-11 14:48:02,472 -   train_loss = 2.657724889497908
2025-04-11 14:49:32,611 - ***** Epoch: 82: Eval results *****
2025-04-11 14:49:32,611 -   train_loss = 2.66130206509242
2025-04-11 14:51:03,129 - ***** Epoch: 83: Eval results *****
2025-04-11 14:51:03,130 -   train_loss = 2.654315327841138
2025-04-11 14:52:33,445 - ***** Epoch: 84: Eval results *****
2025-04-11 14:52:33,445 -   train_loss = 2.648819015139625
2025-04-11 14:54:03,079 - ***** Epoch: 85: Eval results *****
2025-04-11 14:54:03,080 -   train_loss = 2.646208958020286
2025-04-11 14:55:33,805 - ***** Epoch: 86: Eval results *****
2025-04-11 14:55:33,806 -   train_loss = 2.6471488929930187
2025-04-11 14:57:04,167 - ***** Epoch: 87: Eval results *****
2025-04-11 14:57:04,168 -   train_loss = 2.6433313895785617
2025-04-11 14:58:35,002 - ***** Epoch: 88: Eval results *****
2025-04-11 14:58:35,003 -   train_loss = 2.641272807878161
2025-04-11 15:00:05,124 - ***** Epoch: 89: Eval results *****
2025-04-11 15:00:05,125 -   train_loss = 2.641554592147706
2025-04-11 15:01:35,809 - ***** Epoch: 90: Eval results *****
2025-04-11 15:01:35,809 -   train_loss = 2.6435942820140292
2025-04-11 15:03:06,329 - ***** Epoch: 91: Eval results *****
2025-04-11 15:03:06,330 -   train_loss = 2.645707160707504
2025-04-11 15:04:37,002 - ***** Epoch: 92: Eval results *****
2025-04-11 15:04:37,002 -   train_loss = 2.6376386388899786
2025-04-11 15:06:07,450 - ***** Epoch: 93: Eval results *****
2025-04-11 15:06:07,450 -   train_loss = 2.632944356827509
2025-04-11 15:07:37,506 - ***** Epoch: 94: Eval results *****
2025-04-11 15:07:37,506 -   train_loss = 2.6357996955750482
2025-04-11 15:09:07,338 - ***** Epoch: 95: Eval results *****
2025-04-11 15:09:07,339 -   train_loss = 2.6340653234057956
2025-04-11 15:10:37,094 - ***** Epoch: 96: Eval results *****
2025-04-11 15:10:37,094 -   train_loss = 2.6354787463233587
2025-04-11 15:12:06,557 - ***** Epoch: 97: Eval results *****
2025-04-11 15:12:06,558 -   train_loss = 2.631969686538454
2025-04-11 15:13:36,693 - ***** Epoch: 98: Eval results *****
2025-04-11 15:13:36,693 -   train_loss = 2.635747056158762
2025-04-11 15:15:06,926 - ***** Epoch: 99: Eval results *****
2025-04-11 15:15:06,926 -   train_loss = 2.633828083674113
2025-04-11 15:16:37,505 - ***** Epoch: 100: Eval results *****
2025-04-11 15:16:37,506 -   train_loss = 2.631780056726365
2025-04-11 15:16:38,032 - Pre-training finished...
2025-04-11 15:16:38,387 - Freeze all parameters but the last layer for efficiency
2025-04-11 15:16:38,397 - Multimodal Intent Recognition begins...
2025-04-11 15:16:38,397 - Training begins...
2025-04-11 15:17:19,528 - Initializing centroids with K-means++...
2025-04-11 15:17:19,754 - K-means++ used 0.22 s
2025-04-11 15:19:34,911 - K-means used 0.13 s
2025-04-11 15:19:38,430 - ***** Epoch: 1 *****
2025-04-11 15:19:38,430 - Supervised Training Loss: 5.692790
2025-04-11 15:19:38,431 - Unsupervised Training Loss: 5.878410
2025-04-11 15:21:48,623 - K-means used 0.07 s
2025-04-11 15:21:52,715 - ***** Epoch: 2 *****
2025-04-11 15:21:52,715 - Supervised Training Loss: 5.801390
2025-04-11 15:21:52,716 - Unsupervised Training Loss: 5.862040
2025-04-11 15:24:01,616 - K-means used 0.2 s
2025-04-11 15:24:08,690 - ***** Epoch: 3 *****
2025-04-11 15:24:08,690 - Supervised Training Loss: 5.845400
2025-04-11 15:24:08,690 - Unsupervised Training Loss: 5.902570
2025-04-11 15:26:25,207 - K-means used 0.09 s
2025-04-11 15:26:31,006 - ***** Epoch: 4 *****
2025-04-11 15:26:31,007 - Supervised Training Loss: 5.868430
2025-04-11 15:26:31,007 - Unsupervised Training Loss: 5.898020
2025-04-11 15:28:47,637 - K-means used 0.21 s
2025-04-11 15:28:57,013 - ***** Epoch: 5 *****
2025-04-11 15:28:57,014 - Supervised Training Loss: 5.880830
2025-04-11 15:28:57,014 - Unsupervised Training Loss: 5.893920
2025-04-11 15:31:24,499 - K-means used 0.12 s
2025-04-11 15:31:36,802 - ***** Epoch: 6 *****
2025-04-11 15:31:36,803 - Supervised Training Loss: 5.890170
2025-04-11 15:31:36,803 - Unsupervised Training Loss: 5.888860
2025-04-11 15:34:25,640 - K-means used 0.14 s
2025-04-11 15:34:38,141 - ***** Epoch: 7 *****
2025-04-11 15:34:38,141 - Supervised Training Loss: 5.897230
2025-04-11 15:34:38,141 - Unsupervised Training Loss: 5.881800
2025-04-11 15:37:30,297 - K-means used 0.22 s
2025-04-11 15:37:48,040 - ***** Epoch: 8 *****
2025-04-11 15:37:48,041 - Supervised Training Loss: 5.792740
2025-04-11 15:37:48,041 - Unsupervised Training Loss: 5.871700
2025-04-11 15:40:30,023 - K-means used 0.11 s
2025-04-11 15:40:52,261 - ***** Epoch: 9 *****
2025-04-11 15:40:52,262 - Supervised Training Loss: 5.848300
2025-04-11 15:40:52,262 - Unsupervised Training Loss: 5.853040
2025-04-11 15:43:30,627 - K-means used 0.13 s
2025-04-11 15:43:50,551 - ***** Epoch: 10 *****
2025-04-11 15:43:50,551 - Supervised Training Loss: 5.863090
2025-04-11 15:43:50,552 - Unsupervised Training Loss: 5.831370
2025-04-11 15:46:07,888 - K-means used 0.05 s
2025-04-11 15:46:25,717 - ***** Epoch: 11 *****
2025-04-11 15:46:25,717 - Supervised Training Loss: 5.876720
2025-04-11 15:46:25,717 - Unsupervised Training Loss: 5.899520
2025-04-11 15:48:50,513 - K-means used 0.1 s
2025-04-11 15:49:10,127 - ***** Epoch: 12 *****
2025-04-11 15:49:10,128 - Supervised Training Loss: 5.884270
2025-04-11 15:49:10,128 - Unsupervised Training Loss: 5.893690
2025-04-11 15:51:23,785 - K-means used 0.06 s
2025-04-11 15:51:45,213 - ***** Epoch: 13 *****
2025-04-11 15:51:45,213 - Supervised Training Loss: 5.889460
2025-04-11 15:51:45,214 - Unsupervised Training Loss: 5.885630
2025-04-11 15:53:56,210 - K-means used 0.11 s
2025-04-11 15:54:33,080 - ***** Epoch: 14 *****
2025-04-11 15:54:33,081 - Supervised Training Loss: 5.894290
2025-04-11 15:54:33,081 - Unsupervised Training Loss: 5.870660
2025-04-11 15:57:04,807 - K-means used 0.16 s
2025-04-11 15:57:49,152 - ***** Epoch: 15 *****
2025-04-11 15:57:49,152 - Supervised Training Loss: 5.897090
2025-04-11 15:57:49,152 - Unsupervised Training Loss: 5.849390
2025-04-11 16:00:50,174 - K-means used 0.09 s
2025-04-11 16:01:40,564 - ***** Epoch: 16 *****
2025-04-11 16:01:40,565 - Supervised Training Loss: 5.802900
2025-04-11 16:01:40,566 - Unsupervised Training Loss: 5.810780
2025-04-11 16:04:08,576 - K-means used 0.05 s
2025-04-11 16:04:36,828 - ***** Epoch: 17 *****
2025-04-11 16:04:36,829 - Supervised Training Loss: 5.865440
2025-04-11 16:04:36,829 - Unsupervised Training Loss: 5.713650
2025-04-11 16:06:17,829 - Training is finished...
2025-04-11 16:06:17,829 - Testing begins...
2025-04-11 16:06:50,239 - ***** Test results *****
2025-04-11 16:06:50,241 -   ACC = 35.69
2025-04-11 16:06:50,241 -   ARI = 23.31
2025-04-11 16:06:50,241 -   NMI = 22.77
2025-04-11 16:06:50,241 -   fmi = 36.71
2025-04-11 16:06:50,241 - Testing is finished...
2025-04-11 16:06:50,241 - Multimodal intent recognition is finished...
2025-04-11 16:06:50,241 - Results are saved in results/results_umc.csv
