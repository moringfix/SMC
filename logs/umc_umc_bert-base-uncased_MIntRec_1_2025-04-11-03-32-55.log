2025-04-11 03:32:55,729 - ============================== Params ==============================
2025-04-11 03:32:55,729 - logger_name: umc_umc_bert-base-uncased_MIntRec_1
2025-04-11 03:32:55,729 - dataset: MIntRec
2025-04-11 03:32:55,729 - multimodal_method: umc
2025-04-11 03:32:55,729 - method: umc
2025-04-11 03:32:55,729 - text_backbone: bert-base-uncased
2025-04-11 03:32:55,729 - seed: 1
2025-04-11 03:32:55,729 - num_workers: 16
2025-04-11 03:32:55,729 - log_id: umc_umc_bert-base-uncased_MIntRec_1_2025-04-11-03-32-55
2025-04-11 03:32:55,729 - gpu_id: 0
2025-04-11 03:32:55,729 - data_path: /root/autodl-tmp/home/Share/Dataset/LZH
2025-04-11 03:32:55,729 - train: True
2025-04-11 03:32:55,729 - tune: True
2025-04-11 03:32:55,730 - save_model: True
2025-04-11 03:32:55,730 - save_results: True
2025-04-11 03:32:55,730 - log_path: logs
2025-04-11 03:32:55,730 - cache_path: cache
2025-04-11 03:32:55,730 - video_data_path: video_data
2025-04-11 03:32:55,730 - audio_data_path: audio_data
2025-04-11 03:32:55,730 - video_feats_path: swin_feats.pkl
2025-04-11 03:32:55,730 - audio_feats_path: wavlm_feats.pkl
2025-04-11 03:32:55,730 - results_path: results
2025-04-11 03:32:55,730 - output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/UMC/outputs/MIntRec
2025-04-11 03:32:55,730 - model_path: models
2025-04-11 03:32:55,730 - config_file_name: umc_MIntRec
2025-04-11 03:32:55,730 - results_file_name: results_umc.csv
2025-04-11 03:32:55,730 - text_pretrained_model: uncased_L-12_H-768_A-12
2025-04-11 03:32:55,730 - text_seq_len: 30
2025-04-11 03:32:55,730 - video_seq_len: 230
2025-04-11 03:32:55,730 - audio_seq_len: 480
2025-04-11 03:32:55,730 - text_feat_dim: 768
2025-04-11 03:32:55,730 - video_feat_dim: 1024
2025-04-11 03:32:55,730 - audio_feat_dim: 768
2025-04-11 03:32:55,731 - num_labels: 20
2025-04-11 03:32:55,731 - num_train_examples: 1779
2025-04-11 03:32:55,731 - pretrained_bert_model: uncased_L-12_H-768_A-12
2025-04-11 03:32:55,731 - pretrain_batch_size: 128
2025-04-11 03:32:55,731 - train_batch_size: 128
2025-04-11 03:32:55,731 - eval_batch_size: 128
2025-04-11 03:32:55,731 - test_batch_size: 128
2025-04-11 03:32:55,731 - num_pretrain_epochs: 100
2025-04-11 03:32:55,731 - num_train_epochs: 100
2025-04-11 03:32:55,731 - pretrain: [True]
2025-04-11 03:32:55,731 - aligned_method: ctc
2025-04-11 03:32:55,731 - need_aligned: False
2025-04-11 03:32:55,731 - freeze_pretrain_bert_parameters: [True]
2025-04-11 03:32:55,732 - freeze_train_bert_parameters: [True]
2025-04-11 03:32:55,732 - pretrain_temperature: [0.2]
2025-04-11 03:32:55,732 - train_temperature_sup: [1.4]
2025-04-11 03:32:55,732 - train_temperature_unsup: [1]
2025-04-11 03:32:55,732 - activation: tanh
2025-04-11 03:32:55,732 - lr_pre: 5e-06
2025-04-11 03:32:55,732 - lr: [0.0003]
2025-04-11 03:32:55,732 - delta: [0.05]
2025-04-11 03:32:55,732 - thres: [0.1]
2025-04-11 03:32:55,732 - topk: [5]
2025-04-11 03:32:55,732 - weight_decay: 0.01
2025-04-11 03:32:55,732 - feat_dim: 768
2025-04-11 03:32:55,732 - hidden_size: 768
2025-04-11 03:32:55,732 - grad_clip: -1.0
2025-04-11 03:32:55,732 - warmup_proportion: 0.5
2025-04-11 03:32:55,732 - hidden_dropout_prob: 0.1
2025-04-11 03:32:55,732 - weight: 1.0
2025-04-11 03:32:55,732 - loss_mode: rdrop
2025-04-11 03:32:55,732 - base_dim: 256
2025-04-11 03:32:55,732 - nheads: 8
2025-04-11 03:32:55,732 - attn_dropout: 0.1
2025-04-11 03:32:55,732 - relu_dropout: 0.1
2025-04-11 03:32:55,732 - embed_dropout: 0.1
2025-04-11 03:32:55,732 - res_dropout: 0.0
2025-04-11 03:32:55,732 - attn_mask: True
2025-04-11 03:32:55,732 - encoder_layers_1: 1
2025-04-11 03:32:55,732 - fusion_act: tanh
2025-04-11 03:32:55,732 - pred_output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/UMC/outputs/MIntRec/umc_umc_MIntRec_bert-base-uncased_1
2025-04-11 03:32:55,733 - model_output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/UMC/outputs/MIntRec/umc_umc_MIntRec_bert-base-uncased_1/models
2025-04-11 03:32:55,733 - ============================== End Params ==============================
2025-04-11 03:32:56,824 - Freeze all parameters but the last layer for efficiency
2025-04-11 03:32:56,858 - Pre-training start...
2025-04-11 03:33:11,848 - ***** Epoch: 1: Eval results *****
2025-04-11 03:33:11,849 -   train_loss = 5.941793203353882
2025-04-11 03:33:25,276 - ***** Epoch: 2: Eval results *****
2025-04-11 03:33:25,276 -   train_loss = 5.943330492292132
2025-04-11 03:33:39,872 - ***** Epoch: 3: Eval results *****
2025-04-11 03:33:39,873 -   train_loss = 5.940353121076312
2025-04-11 03:33:55,025 - ***** Epoch: 4: Eval results *****
2025-04-11 03:33:55,025 -   train_loss = 5.942016635622297
2025-04-11 03:34:10,439 - ***** Epoch: 5: Eval results *****
2025-04-11 03:34:10,439 -   train_loss = 5.945120062146868
2025-04-11 03:34:25,441 - ***** Epoch: 6: Eval results *****
2025-04-11 03:34:25,441 -   train_loss = 5.943916150501797
2025-04-11 03:34:41,376 - ***** Epoch: 7: Eval results *****
2025-04-11 03:34:41,377 -   train_loss = 5.943604128701346
2025-04-11 03:34:57,281 - ***** Epoch: 8: Eval results *****
2025-04-11 03:34:57,281 -   train_loss = 5.938366004398891
2025-04-11 03:35:12,284 - ***** Epoch: 9: Eval results *****
2025-04-11 03:35:12,285 -   train_loss = 5.941239970070975
2025-04-11 03:35:27,570 - ***** Epoch: 10: Eval results *****
2025-04-11 03:35:27,570 -   train_loss = 5.9395768983023505
2025-04-11 03:35:42,970 - ***** Epoch: 11: Eval results *****
2025-04-11 03:35:42,970 -   train_loss = 5.9378088882991245
2025-04-11 03:35:58,866 - ***** Epoch: 12: Eval results *****
2025-04-11 03:35:58,867 -   train_loss = 5.937394176210676
2025-04-11 03:36:14,497 - ***** Epoch: 13: Eval results *****
2025-04-11 03:36:14,498 -   train_loss = 5.936278002602713
2025-04-11 03:36:30,964 - ***** Epoch: 14: Eval results *****
2025-04-11 03:36:30,965 -   train_loss = 5.936078889029367
2025-04-11 03:36:47,118 - ***** Epoch: 15: Eval results *****
2025-04-11 03:36:47,118 -   train_loss = 5.935655627931867
2025-04-11 03:37:02,976 - ***** Epoch: 16: Eval results *****
2025-04-11 03:37:02,976 -   train_loss = 5.928569078445435
2025-04-11 03:37:19,026 - ***** Epoch: 17: Eval results *****
2025-04-11 03:37:19,026 -   train_loss = 5.926501274108887
2025-04-11 03:37:34,989 - ***** Epoch: 18: Eval results *****
2025-04-11 03:37:34,989 -   train_loss = 5.924188545772007
2025-04-11 03:37:50,393 - ***** Epoch: 19: Eval results *****
2025-04-11 03:37:50,394 -   train_loss = 5.925098555428641
2025-04-11 03:38:06,366 - ***** Epoch: 20: Eval results *****
2025-04-11 03:38:06,367 -   train_loss = 5.919574090412685
2025-04-11 03:38:22,529 - ***** Epoch: 21: Eval results *****
2025-04-11 03:38:22,529 -   train_loss = 5.91296683038984
2025-04-11 03:38:38,366 - ***** Epoch: 22: Eval results *****
2025-04-11 03:38:38,366 -   train_loss = 5.909230538776943
2025-04-11 03:38:54,569 - ***** Epoch: 23: Eval results *****
2025-04-11 03:38:54,570 -   train_loss = 5.900466203689575
2025-04-11 03:39:10,515 - ***** Epoch: 24: Eval results *****
2025-04-11 03:39:10,515 -   train_loss = 5.888805253165109
2025-04-11 03:39:25,774 - ***** Epoch: 25: Eval results *****
2025-04-11 03:39:25,774 -   train_loss = 5.87577486038208
2025-04-11 03:39:41,399 - ***** Epoch: 26: Eval results *****
2025-04-11 03:39:41,399 -   train_loss = 5.855708190373012
2025-04-11 03:39:57,016 - ***** Epoch: 27: Eval results *****
2025-04-11 03:39:57,016 -   train_loss = 5.827738591602871
2025-04-11 03:40:12,886 - ***** Epoch: 28: Eval results *****
2025-04-11 03:40:12,887 -   train_loss = 5.7945597512381415
2025-04-11 03:40:28,701 - ***** Epoch: 29: Eval results *****
2025-04-11 03:40:28,702 -   train_loss = 5.737621682030814
2025-04-11 03:40:44,358 - ***** Epoch: 30: Eval results *****
2025-04-11 03:40:44,359 -   train_loss = 5.66811067717416
2025-04-11 03:40:59,950 - ***** Epoch: 31: Eval results *****
2025-04-11 03:40:59,950 -   train_loss = 5.568900959832328
2025-04-11 03:41:15,346 - ***** Epoch: 32: Eval results *****
2025-04-11 03:41:15,346 -   train_loss = 5.438803638730731
2025-04-11 03:41:30,435 - ***** Epoch: 33: Eval results *****
2025-04-11 03:41:30,435 -   train_loss = 5.302306073052542
2025-04-11 03:41:46,134 - ***** Epoch: 34: Eval results *****
2025-04-11 03:41:46,134 -   train_loss = 5.158628225326538
2025-04-11 03:42:01,785 - ***** Epoch: 35: Eval results *****
2025-04-11 03:42:01,785 -   train_loss = 5.040295124053955
2025-04-11 03:42:17,621 - ***** Epoch: 36: Eval results *****
2025-04-11 03:42:17,621 -   train_loss = 4.922524179731097
2025-04-11 03:42:33,273 - ***** Epoch: 37: Eval results *****
2025-04-11 03:42:33,274 -   train_loss = 4.799132210867746
2025-04-11 03:42:48,373 - ***** Epoch: 38: Eval results *****
2025-04-11 03:42:48,373 -   train_loss = 4.672385113579886
2025-04-11 03:43:04,529 - ***** Epoch: 39: Eval results *****
2025-04-11 03:43:04,530 -   train_loss = 4.565621750695365
2025-04-11 03:43:20,671 - ***** Epoch: 40: Eval results *****
2025-04-11 03:43:20,671 -   train_loss = 4.473213502338955
2025-04-11 03:43:36,110 - ***** Epoch: 41: Eval results *****
2025-04-11 03:43:36,110 -   train_loss = 4.380305903298514
2025-04-11 03:43:51,657 - ***** Epoch: 42: Eval results *****
2025-04-11 03:43:51,657 -   train_loss = 4.30491624559675
2025-04-11 03:44:07,858 - ***** Epoch: 43: Eval results *****
2025-04-11 03:44:07,858 -   train_loss = 4.224932670593262
2025-04-11 03:44:24,634 - ***** Epoch: 44: Eval results *****
2025-04-11 03:44:24,635 -   train_loss = 4.155456713267735
2025-04-11 03:44:41,536 - ***** Epoch: 45: Eval results *****
2025-04-11 03:44:41,536 -   train_loss = 4.117396831512451
2025-04-11 03:44:58,172 - ***** Epoch: 46: Eval results *****
2025-04-11 03:44:58,172 -   train_loss = 4.051811831338065
2025-04-11 03:45:15,067 - ***** Epoch: 47: Eval results *****
2025-04-11 03:45:15,067 -   train_loss = 3.997249024254935
2025-04-11 03:45:31,343 - ***** Epoch: 48: Eval results *****
2025-04-11 03:45:31,343 -   train_loss = 3.9442706278392246
2025-04-11 03:45:47,911 - ***** Epoch: 49: Eval results *****
2025-04-11 03:45:47,912 -   train_loss = 3.891256877354213
2025-04-11 03:46:04,270 - ***** Epoch: 50: Eval results *****
2025-04-11 03:46:04,270 -   train_loss = 3.8185534306934903
2025-04-11 03:46:20,376 - ***** Epoch: 51: Eval results *****
2025-04-11 03:46:20,377 -   train_loss = 3.786624380520412
2025-04-11 03:46:36,004 - ***** Epoch: 52: Eval results *****
2025-04-11 03:46:36,004 -   train_loss = 3.7290170192718506
2025-04-11 03:46:51,275 - ***** Epoch: 53: Eval results *****
2025-04-11 03:46:51,276 -   train_loss = 3.7086299998419627
2025-04-11 03:47:06,474 - ***** Epoch: 54: Eval results *****
2025-04-11 03:47:06,474 -   train_loss = 3.670750379562378
2025-04-11 03:47:23,006 - ***** Epoch: 55: Eval results *****
2025-04-11 03:47:23,007 -   train_loss = 3.629887172154018
2025-04-11 03:47:40,186 - ***** Epoch: 56: Eval results *****
2025-04-11 03:47:40,186 -   train_loss = 3.5942713022232056
2025-04-11 03:47:57,083 - ***** Epoch: 57: Eval results *****
2025-04-11 03:47:57,083 -   train_loss = 3.566753659929548
2025-04-11 03:48:14,169 - ***** Epoch: 58: Eval results *****
2025-04-11 03:48:14,169 -   train_loss = 3.5499155521392822
2025-04-11 03:48:30,253 - ***** Epoch: 59: Eval results *****
2025-04-11 03:48:30,254 -   train_loss = 3.529051184654236
2025-04-11 03:48:46,038 - ***** Epoch: 60: Eval results *****
2025-04-11 03:48:46,039 -   train_loss = 3.4997867856706892
2025-04-11 03:49:02,108 - ***** Epoch: 61: Eval results *****
2025-04-11 03:49:02,108 -   train_loss = 3.4866169691085815
2025-04-11 03:49:18,193 - ***** Epoch: 62: Eval results *****
2025-04-11 03:49:18,193 -   train_loss = 3.4684117691857472
2025-04-11 03:49:34,261 - ***** Epoch: 63: Eval results *****
2025-04-11 03:49:34,261 -   train_loss = 3.446504661015102
2025-04-11 03:49:49,675 - ***** Epoch: 64: Eval results *****
2025-04-11 03:49:49,675 -   train_loss = 3.433748245239258
2025-04-11 03:50:05,346 - ***** Epoch: 65: Eval results *****
2025-04-11 03:50:05,347 -   train_loss = 3.42145642212459
2025-04-11 03:50:20,432 - ***** Epoch: 66: Eval results *****
2025-04-11 03:50:20,432 -   train_loss = 3.3958254030772617
2025-04-11 03:50:35,976 - ***** Epoch: 67: Eval results *****
2025-04-11 03:50:35,976 -   train_loss = 3.379720296178545
2025-04-11 03:50:50,888 - ***** Epoch: 68: Eval results *****
2025-04-11 03:50:50,888 -   train_loss = 3.370572260447911
2025-04-11 03:51:06,406 - ***** Epoch: 69: Eval results *****
2025-04-11 03:51:06,407 -   train_loss = 3.3490082877022878
2025-04-11 03:51:21,736 - ***** Epoch: 70: Eval results *****
2025-04-11 03:51:21,737 -   train_loss = 3.3490974732807706
2025-04-11 03:51:36,964 - ***** Epoch: 71: Eval results *****
2025-04-11 03:51:36,965 -   train_loss = 3.3451243298394338
2025-04-11 03:51:51,813 - ***** Epoch: 72: Eval results *****
2025-04-11 03:51:51,813 -   train_loss = 3.3327001673834666
2025-04-11 03:52:09,453 - ***** Epoch: 73: Eval results *****
2025-04-11 03:52:09,453 -   train_loss = 3.3217285871505737
2025-04-11 03:52:28,790 - ***** Epoch: 74: Eval results *****
2025-04-11 03:52:28,791 -   train_loss = 3.32065681048802
2025-04-11 03:52:47,563 - ***** Epoch: 75: Eval results *****
2025-04-11 03:52:47,564 -   train_loss = 3.3141468593052457
2025-04-11 03:53:07,052 - ***** Epoch: 76: Eval results *****
2025-04-11 03:53:07,052 -   train_loss = 3.3017421109335765
2025-04-11 03:53:25,314 - ***** Epoch: 77: Eval results *****
2025-04-11 03:53:25,315 -   train_loss = 3.2917147193636214
2025-04-11 03:53:41,748 - ***** Epoch: 78: Eval results *****
2025-04-11 03:53:41,748 -   train_loss = 3.2920312029974803
2025-04-11 03:53:58,325 - ***** Epoch: 79: Eval results *****
2025-04-11 03:53:58,325 -   train_loss = 3.288293753351484
2025-04-11 03:54:15,452 - ***** Epoch: 80: Eval results *****
2025-04-11 03:54:15,452 -   train_loss = 3.283266680581229
2025-04-11 03:54:32,038 - ***** Epoch: 81: Eval results *****
2025-04-11 03:54:32,038 -   train_loss = 3.268785306385585
2025-04-11 03:54:48,364 - ***** Epoch: 82: Eval results *****
2025-04-11 03:54:48,364 -   train_loss = 3.2812196356909618
2025-04-11 03:55:04,241 - ***** Epoch: 83: Eval results *****
2025-04-11 03:55:04,242 -   train_loss = 3.2707140956606184
2025-04-11 03:55:20,359 - ***** Epoch: 84: Eval results *****
2025-04-11 03:55:20,359 -   train_loss = 3.2567398037229265
2025-04-11 03:55:36,242 - ***** Epoch: 85: Eval results *****
2025-04-11 03:55:36,242 -   train_loss = 3.2763939925602505
2025-04-11 03:55:52,779 - ***** Epoch: 86: Eval results *****
2025-04-11 03:55:52,779 -   train_loss = 3.2603384937558855
2025-04-11 03:56:09,942 - ***** Epoch: 87: Eval results *****
2025-04-11 03:56:09,942 -   train_loss = 3.266019804137094
2025-04-11 03:56:26,332 - ***** Epoch: 88: Eval results *****
2025-04-11 03:56:26,333 -   train_loss = 3.2618737731661116
2025-04-11 03:56:43,497 - ***** Epoch: 89: Eval results *****
2025-04-11 03:56:43,498 -   train_loss = 3.2576690231050764
2025-04-11 03:56:59,907 - ***** Epoch: 90: Eval results *****
2025-04-11 03:56:59,907 -   train_loss = 3.263939448765346
2025-04-11 03:57:16,615 - ***** Epoch: 91: Eval results *****
2025-04-11 03:57:16,616 -   train_loss = 3.266225286892482
2025-04-11 03:57:32,957 - ***** Epoch: 92: Eval results *****
2025-04-11 03:57:32,957 -   train_loss = 3.24674197605678
2025-04-11 03:57:49,140 - ***** Epoch: 93: Eval results *****
2025-04-11 03:57:49,141 -   train_loss = 3.2623991114752635
2025-04-11 03:58:05,478 - ***** Epoch: 94: Eval results *****
2025-04-11 03:58:05,478 -   train_loss = 3.2453326327460155
2025-04-11 03:58:21,561 - ***** Epoch: 95: Eval results *****
2025-04-11 03:58:21,562 -   train_loss = 3.2580127034868513
2025-04-11 03:58:37,473 - ***** Epoch: 96: Eval results *****
2025-04-11 03:58:37,474 -   train_loss = 3.2466209956577847
2025-04-11 03:58:53,054 - ***** Epoch: 97: Eval results *****
2025-04-11 03:58:53,054 -   train_loss = 3.246460574013846
2025-04-11 03:59:09,148 - ***** Epoch: 98: Eval results *****
2025-04-11 03:59:09,148 -   train_loss = 3.2518689802714755
2025-04-11 03:59:25,726 - ***** Epoch: 99: Eval results *****
2025-04-11 03:59:25,726 -   train_loss = 3.2426579168864658
2025-04-11 03:59:42,340 - ***** Epoch: 100: Eval results *****
2025-04-11 03:59:42,341 -   train_loss = 3.26213492665972
2025-04-11 03:59:44,016 - Pre-training finished...
2025-04-11 03:59:44,293 - Freeze all parameters but the last layer for efficiency
2025-04-11 03:59:44,306 - Multimodal Intent Recognition begins...
2025-04-11 03:59:44,306 - Training begins...
2025-04-11 04:00:01,325 - Initializing centroids with K-means++...
2025-04-11 04:00:01,411 - K-means++ used 0.09 s
2025-04-11 04:00:34,796 - K-means used 0.15 s
2025-04-11 04:00:36,226 - ***** Epoch: 1 *****
2025-04-11 04:00:36,226 - Supervised Training Loss: 4.907640
2025-04-11 04:00:36,227 - Unsupervised Training Loss: 5.189310
2025-04-11 04:01:06,707 - K-means used 0.06 s
2025-04-11 04:01:08,065 - ***** Epoch: 2 *****
2025-04-11 04:01:08,065 - Supervised Training Loss: 4.050810
2025-04-11 04:01:08,065 - Unsupervised Training Loss: 5.200630
2025-04-11 04:01:39,489 - K-means used 0.03 s
2025-04-11 04:01:40,972 - ***** Epoch: 3 *****
2025-04-11 04:01:40,972 - Supervised Training Loss: 5.336120
2025-04-11 04:01:40,973 - Unsupervised Training Loss: 5.038300
2025-04-11 04:02:15,717 - K-means used 0.02 s
2025-04-11 04:02:17,237 - ***** Epoch: 4 *****
2025-04-11 04:02:17,238 - Supervised Training Loss: 5.196820
2025-04-11 04:02:17,238 - Unsupervised Training Loss: 5.108060
2025-04-11 04:02:48,305 - K-means used 0.05 s
2025-04-11 04:02:49,861 - ***** Epoch: 5 *****
2025-04-11 04:02:49,861 - Supervised Training Loss: 4.898480
2025-04-11 04:02:49,861 - Unsupervised Training Loss: 5.133690
2025-04-11 04:03:18,215 - K-means used 0.02 s
2025-04-11 04:03:19,688 - ***** Epoch: 6 *****
2025-04-11 04:03:19,688 - Supervised Training Loss: 5.344210
2025-04-11 04:03:19,689 - Unsupervised Training Loss: 4.904640
2025-04-11 04:03:49,122 - K-means used 0.04 s
2025-04-11 04:03:50,530 - ***** Epoch: 7 *****
2025-04-11 04:03:50,530 - Supervised Training Loss: 5.260560
2025-04-11 04:03:50,530 - Unsupervised Training Loss: 5.036010
2025-04-11 04:04:19,388 - K-means used 0.02 s
2025-04-11 04:04:20,952 - ***** Epoch: 8 *****
2025-04-11 04:04:20,952 - Supervised Training Loss: 5.115050
2025-04-11 04:04:20,952 - Unsupervised Training Loss: 5.082340
2025-04-11 04:04:49,097 - K-means used 0.02 s
2025-04-11 04:04:50,714 - ***** Epoch: 9 *****
2025-04-11 04:04:50,714 - Supervised Training Loss: 5.333950
2025-04-11 04:04:50,714 - Unsupervised Training Loss: 5.122760
2025-04-11 04:05:20,488 - K-means used 0.02 s
2025-04-11 04:05:22,245 - ***** Epoch: 10 *****
2025-04-11 04:05:22,246 - Supervised Training Loss: 5.273160
2025-04-11 04:05:22,246 - Unsupervised Training Loss: 4.957980
2025-04-11 04:05:51,340 - K-means used 0.02 s
2025-04-11 04:05:53,024 - ***** Epoch: 11 *****
2025-04-11 04:05:53,024 - Supervised Training Loss: 5.195030
2025-04-11 04:05:53,024 - Unsupervised Training Loss: 5.037070
2025-04-11 04:06:22,534 - K-means used 0.03 s
2025-04-11 04:06:24,251 - ***** Epoch: 12 *****
2025-04-11 04:06:24,251 - Supervised Training Loss: 5.322410
2025-04-11 04:06:24,251 - Unsupervised Training Loss: 5.101480
2025-04-11 04:06:52,680 - K-means used 0.02 s
2025-04-11 04:06:54,428 - ***** Epoch: 13 *****
2025-04-11 04:06:54,428 - Supervised Training Loss: 5.286090
2025-04-11 04:06:54,428 - Unsupervised Training Loss: 4.811310
2025-04-11 04:07:21,732 - K-means used 0.01 s
2025-04-11 04:07:23,814 - ***** Epoch: 14 *****
2025-04-11 04:07:23,814 - Supervised Training Loss: 5.231730
2025-04-11 04:07:23,815 - Unsupervised Training Loss: 4.952330
2025-04-11 04:07:52,121 - K-means used 0.1 s
2025-04-11 04:07:54,145 - ***** Epoch: 15 *****
2025-04-11 04:07:54,145 - Supervised Training Loss: 5.064140
2025-04-11 04:07:54,145 - Unsupervised Training Loss: 5.052420
2025-04-11 04:08:20,877 - K-means used 0.01 s
2025-04-11 04:08:22,882 - ***** Epoch: 16 *****
2025-04-11 04:08:22,882 - Supervised Training Loss: 5.303730
2025-04-11 04:08:22,882 - Unsupervised Training Loss: 4.506040
2025-04-11 04:08:49,846 - K-means used 0.02 s
2025-04-11 04:08:51,902 - ***** Epoch: 17 *****
2025-04-11 04:08:51,902 - Supervised Training Loss: 5.269530
2025-04-11 04:08:51,902 - Unsupervised Training Loss: 4.714460
2025-04-11 04:09:11,120 - Training is finished...
2025-04-11 04:09:11,120 - Testing begins...
2025-04-11 04:09:18,601 - ***** Test results *****
2025-04-11 04:09:18,601 -   ACC = 35.73
2025-04-11 04:09:18,601 -   ARI = 17.32
2025-04-11 04:09:18,602 -   NMI = 39.74
2025-04-11 04:09:18,602 -   fmi = 22.57
2025-04-11 04:09:18,602 - Testing is finished...
2025-04-11 04:09:18,602 - Multimodal intent recognition is finished...
2025-04-11 04:09:18,602 - Results are saved in results/results_umc.csv
