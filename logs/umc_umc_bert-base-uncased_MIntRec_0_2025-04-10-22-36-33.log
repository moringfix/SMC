2025-04-10 22:36:33,380 - ============================== Params ==============================
2025-04-10 22:36:33,381 - logger_name: umc_umc_bert-base-uncased_MIntRec_0
2025-04-10 22:36:33,381 - dataset: MIntRec
2025-04-10 22:36:33,381 - multimodal_method: umc
2025-04-10 22:36:33,381 - method: umc
2025-04-10 22:36:33,381 - text_backbone: bert-base-uncased
2025-04-10 22:36:33,381 - seed: 0
2025-04-10 22:36:33,381 - num_workers: 16
2025-04-10 22:36:33,381 - log_id: umc_umc_bert-base-uncased_MIntRec_0_2025-04-10-22-36-33
2025-04-10 22:36:33,381 - gpu_id: 0
2025-04-10 22:36:33,381 - data_path: /root/autodl-tmp/home/Share/Dataset/LZH
2025-04-10 22:36:33,381 - train: True
2025-04-10 22:36:33,381 - tune: True
2025-04-10 22:36:33,381 - save_model: True
2025-04-10 22:36:33,381 - save_results: True
2025-04-10 22:36:33,381 - log_path: logs
2025-04-10 22:36:33,381 - cache_path: cache
2025-04-10 22:36:33,381 - video_data_path: video_data
2025-04-10 22:36:33,381 - audio_data_path: audio_data
2025-04-10 22:36:33,381 - video_feats_path: swin_feats.pkl
2025-04-10 22:36:33,381 - audio_feats_path: wavlm_feats.pkl
2025-04-10 22:36:33,381 - results_path: results
2025-04-10 22:36:33,381 - output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/UMC/outputs/MIntRec
2025-04-10 22:36:33,381 - model_path: models
2025-04-10 22:36:33,381 - config_file_name: umc_MIntRec
2025-04-10 22:36:33,381 - results_file_name: results_umc.csv
2025-04-10 22:36:33,382 - text_pretrained_model: uncased_L-12_H-768_A-12
2025-04-10 22:36:33,382 - text_seq_len: 30
2025-04-10 22:36:33,382 - video_seq_len: 230
2025-04-10 22:36:33,382 - audio_seq_len: 480
2025-04-10 22:36:33,382 - text_feat_dim: 768
2025-04-10 22:36:33,382 - video_feat_dim: 1024
2025-04-10 22:36:33,382 - audio_feat_dim: 768
2025-04-10 22:36:33,382 - num_labels: 20
2025-04-10 22:36:33,382 - num_train_examples: 1779
2025-04-10 22:36:33,382 - pretrained_bert_model: uncased_L-12_H-768_A-12
2025-04-10 22:36:33,382 - pretrain_batch_size: 128
2025-04-10 22:36:33,382 - train_batch_size: 128
2025-04-10 22:36:33,382 - eval_batch_size: 128
2025-04-10 22:36:33,382 - test_batch_size: 128
2025-04-10 22:36:33,382 - num_pretrain_epochs: 100
2025-04-10 22:36:33,382 - num_train_epochs: 100
2025-04-10 22:36:33,382 - pretrain: [True]
2025-04-10 22:36:33,382 - aligned_method: ctc
2025-04-10 22:36:33,382 - need_aligned: False
2025-04-10 22:36:33,382 - freeze_pretrain_bert_parameters: [True]
2025-04-10 22:36:33,382 - freeze_train_bert_parameters: [True]
2025-04-10 22:36:33,383 - pretrain_temperature: [0.2]
2025-04-10 22:36:33,383 - train_temperature_sup: [1.4]
2025-04-10 22:36:33,383 - train_temperature_unsup: [1]
2025-04-10 22:36:33,383 - activation: tanh
2025-04-10 22:36:33,383 - lr_pre: 2e-05
2025-04-10 22:36:33,383 - lr: [0.0003]
2025-04-10 22:36:33,383 - delta: [0.05]
2025-04-10 22:36:33,383 - thres: [0.1]
2025-04-10 22:36:33,383 - topk: [5]
2025-04-10 22:36:33,383 - weight_decay: 0.01
2025-04-10 22:36:33,383 - feat_dim: 768
2025-04-10 22:36:33,383 - hidden_size: 768
2025-04-10 22:36:33,383 - grad_clip: -1.0
2025-04-10 22:36:33,383 - warmup_proportion: 0.1
2025-04-10 22:36:33,383 - hidden_dropout_prob: 0.1
2025-04-10 22:36:33,383 - weight: 1.0
2025-04-10 22:36:33,384 - loss_mode: rdrop
2025-04-10 22:36:33,384 - base_dim: 256
2025-04-10 22:36:33,384 - nheads: 8
2025-04-10 22:36:33,384 - attn_dropout: 0.1
2025-04-10 22:36:33,384 - relu_dropout: 0.1
2025-04-10 22:36:33,384 - embed_dropout: 0.1
2025-04-10 22:36:33,384 - res_dropout: 0.0
2025-04-10 22:36:33,384 - attn_mask: True
2025-04-10 22:36:33,384 - encoder_layers_1: 1
2025-04-10 22:36:33,384 - fusion_act: tanh
2025-04-10 22:36:33,384 - pred_output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/UMC/outputs/MIntRec/umc_umc_MIntRec_bert-base-uncased_0
2025-04-10 22:36:33,384 - model_output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/UMC/outputs/MIntRec/umc_umc_MIntRec_bert-base-uncased_0/models
2025-04-10 22:36:33,384 - ============================== End Params ==============================
2025-04-10 22:36:34,460 - Freeze all parameters but the last layer for efficiency
2025-04-10 22:36:34,493 - Pre-training start...
2025-04-10 22:36:48,759 - ***** Epoch: 1: Eval results *****
2025-04-10 22:36:48,760 -   train_loss = 5.938369989395142
2025-04-10 22:37:02,435 - ***** Epoch: 2: Eval results *****
2025-04-10 22:37:02,435 -   train_loss = 5.937172821589878
2025-04-10 22:37:15,623 - ***** Epoch: 3: Eval results *****
2025-04-10 22:37:15,623 -   train_loss = 5.931615965706961
2025-04-10 22:37:29,958 - ***** Epoch: 4: Eval results *****
2025-04-10 22:37:29,958 -   train_loss = 5.927084684371948
2025-04-10 22:37:44,837 - ***** Epoch: 5: Eval results *****
2025-04-10 22:37:44,837 -   train_loss = 5.910839421408517
2025-04-10 22:37:59,758 - ***** Epoch: 6: Eval results *****
2025-04-10 22:37:59,758 -   train_loss = 5.885191440582275
2025-04-10 22:38:14,510 - ***** Epoch: 7: Eval results *****
2025-04-10 22:38:14,510 -   train_loss = 5.7869745663234164
2025-04-10 22:38:29,356 - ***** Epoch: 8: Eval results *****
2025-04-10 22:38:29,356 -   train_loss = 5.513078451156616
2025-04-10 22:38:44,050 - ***** Epoch: 9: Eval results *****
2025-04-10 22:38:44,051 -   train_loss = 5.044661998748779
2025-04-10 22:38:58,654 - ***** Epoch: 10: Eval results *****
2025-04-10 22:38:58,654 -   train_loss = 4.582355771745954
2025-04-10 22:39:13,951 - ***** Epoch: 11: Eval results *****
2025-04-10 22:39:13,951 -   train_loss = 4.232972213200161
2025-04-10 22:39:28,838 - ***** Epoch: 12: Eval results *****
2025-04-10 22:39:28,838 -   train_loss = 3.9741884810583934
2025-04-10 22:39:43,753 - ***** Epoch: 13: Eval results *****
2025-04-10 22:39:43,754 -   train_loss = 3.773118359701974
2025-04-10 22:39:58,334 - ***** Epoch: 14: Eval results *****
2025-04-10 22:39:58,334 -   train_loss = 3.610594187464033
2025-04-10 22:40:13,224 - ***** Epoch: 15: Eval results *****
2025-04-10 22:40:13,224 -   train_loss = 3.4917663676398143
2025-04-10 22:40:28,325 - ***** Epoch: 16: Eval results *****
2025-04-10 22:40:28,326 -   train_loss = 3.388807398932321
2025-04-10 22:40:43,314 - ***** Epoch: 17: Eval results *****
2025-04-10 22:40:43,314 -   train_loss = 3.333966476576669
2025-04-10 22:40:58,159 - ***** Epoch: 18: Eval results *****
2025-04-10 22:40:58,159 -   train_loss = 3.2792770862579346
2025-04-10 22:41:13,438 - ***** Epoch: 19: Eval results *****
2025-04-10 22:41:13,438 -   train_loss = 3.244722740990775
2025-04-10 22:41:28,561 - ***** Epoch: 20: Eval results *****
2025-04-10 22:41:28,561 -   train_loss = 3.1968275819505965
2025-04-10 22:41:43,254 - ***** Epoch: 21: Eval results *****
2025-04-10 22:41:43,254 -   train_loss = 3.1681395939418246
2025-04-10 22:41:57,628 - ***** Epoch: 22: Eval results *****
2025-04-10 22:41:57,629 -   train_loss = 3.1358038187026978
2025-04-10 22:42:12,739 - ***** Epoch: 23: Eval results *****
2025-04-10 22:42:12,739 -   train_loss = 3.107098545346941
2025-04-10 22:42:27,358 - ***** Epoch: 24: Eval results *****
2025-04-10 22:42:27,358 -   train_loss = 3.0684227091925487
2025-04-10 22:42:42,262 - ***** Epoch: 25: Eval results *****
2025-04-10 22:42:42,262 -   train_loss = 3.051334261894226
2025-04-10 22:42:56,946 - ***** Epoch: 26: Eval results *****
2025-04-10 22:42:56,946 -   train_loss = 3.027230279786246
2025-04-10 22:43:11,775 - ***** Epoch: 27: Eval results *****
2025-04-10 22:43:11,776 -   train_loss = 3.0187735898154124
2025-04-10 22:43:27,642 - ***** Epoch: 28: Eval results *****
2025-04-10 22:43:27,642 -   train_loss = 2.985887118748256
2025-04-10 22:43:44,320 - ***** Epoch: 29: Eval results *****
2025-04-10 22:43:44,321 -   train_loss = 2.9730291025979176
2025-04-10 22:44:00,798 - ***** Epoch: 30: Eval results *****
2025-04-10 22:44:00,799 -   train_loss = 2.9463283675057546
2025-04-10 22:44:17,212 - ***** Epoch: 31: Eval results *****
2025-04-10 22:44:17,212 -   train_loss = 2.929747428212847
2025-04-10 22:44:33,599 - ***** Epoch: 32: Eval results *****
2025-04-10 22:44:33,600 -   train_loss = 2.923645496368408
2025-04-10 22:44:50,086 - ***** Epoch: 33: Eval results *****
2025-04-10 22:44:50,086 -   train_loss = 2.904875193323408
2025-04-10 22:45:06,239 - ***** Epoch: 34: Eval results *****
2025-04-10 22:45:06,239 -   train_loss = 2.8894005673272267
2025-04-10 22:45:22,212 - ***** Epoch: 35: Eval results *****
2025-04-10 22:45:22,213 -   train_loss = 2.889553887503488
2025-04-10 22:45:38,289 - ***** Epoch: 36: Eval results *****
2025-04-10 22:45:38,289 -   train_loss = 2.858026691845485
2025-04-10 22:45:54,119 - ***** Epoch: 37: Eval results *****
2025-04-10 22:45:54,120 -   train_loss = 2.84201671395983
2025-04-10 22:46:09,180 - ***** Epoch: 38: Eval results *****
2025-04-10 22:46:09,180 -   train_loss = 2.8305706637246266
2025-04-10 22:46:24,621 - ***** Epoch: 39: Eval results *****
2025-04-10 22:46:24,621 -   train_loss = 2.830872212137495
2025-04-10 22:46:40,093 - ***** Epoch: 40: Eval results *****
2025-04-10 22:46:40,094 -   train_loss = 2.820229802812849
2025-04-10 22:46:55,006 - ***** Epoch: 41: Eval results *****
2025-04-10 22:46:55,006 -   train_loss = 2.813401460647583
2025-04-10 22:47:09,556 - ***** Epoch: 42: Eval results *****
2025-04-10 22:47:09,556 -   train_loss = 2.810617055211748
2025-04-10 22:47:23,978 - ***** Epoch: 43: Eval results *****
2025-04-10 22:47:23,978 -   train_loss = 2.791488153593881
2025-04-10 22:47:38,460 - ***** Epoch: 44: Eval results *****
2025-04-10 22:47:38,460 -   train_loss = 2.7886240652629306
2025-04-10 22:47:52,682 - ***** Epoch: 45: Eval results *****
2025-04-10 22:47:52,682 -   train_loss = 2.7831132411956787
2025-04-10 22:48:07,019 - ***** Epoch: 46: Eval results *****
2025-04-10 22:48:07,019 -   train_loss = 2.7711129869733537
2025-04-10 22:48:21,729 - ***** Epoch: 47: Eval results *****
2025-04-10 22:48:21,729 -   train_loss = 2.7657303639820645
2025-04-10 22:48:36,833 - ***** Epoch: 48: Eval results *****
2025-04-10 22:48:36,834 -   train_loss = 2.759146281651088
2025-04-10 22:48:51,524 - ***** Epoch: 49: Eval results *****
2025-04-10 22:48:51,524 -   train_loss = 2.743150387491499
2025-04-10 22:49:06,162 - ***** Epoch: 50: Eval results *****
2025-04-10 22:49:06,162 -   train_loss = 2.7392477818897794
2025-04-10 22:49:20,253 - ***** Epoch: 51: Eval results *****
2025-04-10 22:49:20,253 -   train_loss = 2.751292518207005
2025-04-10 22:49:34,908 - ***** Epoch: 52: Eval results *****
2025-04-10 22:49:34,908 -   train_loss = 2.732565539223807
2025-04-10 22:49:48,905 - ***** Epoch: 53: Eval results *****
2025-04-10 22:49:48,905 -   train_loss = 2.7264172860554288
2025-04-10 22:50:03,619 - ***** Epoch: 54: Eval results *****
2025-04-10 22:50:03,620 -   train_loss = 2.7336704901286533
2025-04-10 22:50:17,669 - ***** Epoch: 55: Eval results *****
2025-04-10 22:50:17,669 -   train_loss = 2.728749769074576
2025-04-10 22:50:31,965 - ***** Epoch: 56: Eval results *****
2025-04-10 22:50:31,966 -   train_loss = 2.711954321180071
2025-04-10 22:50:46,357 - ***** Epoch: 57: Eval results *****
2025-04-10 22:50:46,357 -   train_loss = 2.7110101836068288
2025-04-10 22:51:00,720 - ***** Epoch: 58: Eval results *****
2025-04-10 22:51:00,720 -   train_loss = 2.701969248907907
2025-04-10 22:51:15,024 - ***** Epoch: 59: Eval results *****
2025-04-10 22:51:15,024 -   train_loss = 2.7003055810928345
2025-04-10 22:51:29,437 - ***** Epoch: 60: Eval results *****
2025-04-10 22:51:29,437 -   train_loss = 2.690510834966387
2025-04-10 22:51:44,124 - ***** Epoch: 61: Eval results *****
2025-04-10 22:51:44,124 -   train_loss = 2.6906602723257884
2025-04-10 22:51:58,565 - ***** Epoch: 62: Eval results *****
2025-04-10 22:51:58,565 -   train_loss = 2.6836135046822682
2025-04-10 22:52:13,124 - ***** Epoch: 63: Eval results *****
2025-04-10 22:52:13,124 -   train_loss = 2.6908436843327115
2025-04-10 22:52:27,964 - ***** Epoch: 64: Eval results *****
2025-04-10 22:52:27,964 -   train_loss = 2.6694948502949307
2025-04-10 22:52:42,281 - ***** Epoch: 65: Eval results *****
2025-04-10 22:52:42,281 -   train_loss = 2.676017642021179
2025-04-10 22:52:56,661 - ***** Epoch: 66: Eval results *****
2025-04-10 22:52:56,661 -   train_loss = 2.6760528768811906
2025-04-10 22:53:10,944 - ***** Epoch: 67: Eval results *****
2025-04-10 22:53:10,944 -   train_loss = 2.6579098871776035
2025-04-10 22:53:25,353 - ***** Epoch: 68: Eval results *****
2025-04-10 22:53:25,353 -   train_loss = 2.6642896958759854
2025-04-10 22:53:39,336 - ***** Epoch: 69: Eval results *****
2025-04-10 22:53:39,336 -   train_loss = 2.655852505138942
2025-04-10 22:53:53,470 - ***** Epoch: 70: Eval results *****
2025-04-10 22:53:53,470 -   train_loss = 2.6657282454626903
2025-04-10 22:54:07,685 - ***** Epoch: 71: Eval results *****
2025-04-10 22:54:07,686 -   train_loss = 2.6649221863065446
2025-04-10 22:54:21,686 - ***** Epoch: 72: Eval results *****
2025-04-10 22:54:21,686 -   train_loss = 2.6623952388763428
2025-04-10 22:54:35,530 - ***** Epoch: 73: Eval results *****
2025-04-10 22:54:35,530 -   train_loss = 2.664837292262486
2025-04-10 22:54:49,549 - ***** Epoch: 74: Eval results *****
2025-04-10 22:54:49,550 -   train_loss = 2.6617584569113597
2025-04-10 22:55:03,742 - ***** Epoch: 75: Eval results *****
2025-04-10 22:55:03,742 -   train_loss = 2.664836662156241
2025-04-10 22:55:17,938 - ***** Epoch: 76: Eval results *****
2025-04-10 22:55:17,939 -   train_loss = 2.6476623671395436
2025-04-10 22:55:32,456 - ***** Epoch: 77: Eval results *****
2025-04-10 22:55:32,456 -   train_loss = 2.642677528517587
2025-04-10 22:55:47,190 - ***** Epoch: 78: Eval results *****
2025-04-10 22:55:47,190 -   train_loss = 2.6402431896754672
2025-04-10 22:56:01,843 - ***** Epoch: 79: Eval results *****
2025-04-10 22:56:01,843 -   train_loss = 2.643846767289298
2025-04-10 22:56:16,838 - ***** Epoch: 80: Eval results *****
2025-04-10 22:56:16,838 -   train_loss = 2.6425416128976003
2025-04-10 22:56:31,621 - ***** Epoch: 81: Eval results *****
2025-04-10 22:56:31,621 -   train_loss = 2.6435724837439403
2025-04-10 22:56:46,280 - ***** Epoch: 82: Eval results *****
2025-04-10 22:56:46,280 -   train_loss = 2.640886970928737
2025-04-10 22:57:00,651 - ***** Epoch: 83: Eval results *****
2025-04-10 22:57:00,652 -   train_loss = 2.6530385528291975
2025-04-10 22:57:15,629 - ***** Epoch: 84: Eval results *****
2025-04-10 22:57:15,630 -   train_loss = 2.6379246711730957
2025-04-10 22:57:30,080 - ***** Epoch: 85: Eval results *****
2025-04-10 22:57:30,080 -   train_loss = 2.6386716025216237
2025-04-10 22:57:44,841 - ***** Epoch: 86: Eval results *****
2025-04-10 22:57:44,842 -   train_loss = 2.6378811427525113
2025-04-10 22:57:59,630 - ***** Epoch: 87: Eval results *****
2025-04-10 22:57:59,630 -   train_loss = 2.634073717253549
2025-04-10 22:58:13,953 - ***** Epoch: 88: Eval results *****
2025-04-10 22:58:13,954 -   train_loss = 2.6373197180884227
2025-04-10 22:58:27,938 - ***** Epoch: 89: Eval results *****
2025-04-10 22:58:27,938 -   train_loss = 2.632757919175284
2025-04-10 22:58:42,130 - ***** Epoch: 90: Eval results *****
2025-04-10 22:58:42,130 -   train_loss = 2.6364808763776506
2025-04-10 22:58:56,660 - ***** Epoch: 91: Eval results *****
2025-04-10 22:58:56,661 -   train_loss = 2.6315796204975674
2025-04-10 22:59:11,538 - ***** Epoch: 92: Eval results *****
2025-04-10 22:59:11,538 -   train_loss = 2.629815902028765
2025-04-10 22:59:26,287 - ***** Epoch: 93: Eval results *****
2025-04-10 22:59:26,288 -   train_loss = 2.6351203407560075
2025-04-10 22:59:40,898 - ***** Epoch: 94: Eval results *****
2025-04-10 22:59:40,898 -   train_loss = 2.634196298463004
2025-04-10 22:59:55,199 - ***** Epoch: 95: Eval results *****
2025-04-10 22:59:55,199 -   train_loss = 2.632374269621713
2025-04-10 23:00:09,273 - ***** Epoch: 96: Eval results *****
2025-04-10 23:00:09,274 -   train_loss = 2.6321056400026595
2025-04-10 23:00:23,362 - ***** Epoch: 97: Eval results *****
2025-04-10 23:00:23,362 -   train_loss = 2.635944894381932
2025-04-10 23:00:38,267 - ***** Epoch: 98: Eval results *****
2025-04-10 23:00:38,267 -   train_loss = 2.644279956817627
2025-04-10 23:00:52,907 - ***** Epoch: 99: Eval results *****
2025-04-10 23:00:52,908 -   train_loss = 2.6299379553113664
2025-04-10 23:01:07,218 - ***** Epoch: 100: Eval results *****
2025-04-10 23:01:07,218 -   train_loss = 2.631145102637155
2025-04-10 23:01:08,720 - Pre-training finished...
2025-04-10 23:01:09,008 - Freeze all parameters but the last layer for efficiency
2025-04-10 23:01:09,017 - Multimodal Intent Recognition begins...
2025-04-10 23:01:09,018 - Training begins...
2025-04-10 23:01:26,272 - Initializing centroids with K-means++...
2025-04-10 23:01:26,345 - K-means++ used 0.07 s
2025-04-10 23:02:03,299 - K-means used 0.04 s
2025-04-10 23:02:04,024 - ***** Epoch: 1 *****
2025-04-10 23:02:04,024 - Supervised Training Loss: 4.896830
2025-04-10 23:02:04,024 - Unsupervised Training Loss: 5.090490
2025-04-10 23:02:37,937 - K-means used 0.02 s
2025-04-10 23:02:38,721 - ***** Epoch: 2 *****
2025-04-10 23:02:38,721 - Supervised Training Loss: 4.210330
2025-04-10 23:02:38,721 - Unsupervised Training Loss: 5.127230
2025-04-10 23:03:13,442 - K-means used 0.01 s
2025-04-10 23:03:14,245 - ***** Epoch: 3 *****
2025-04-10 23:03:14,246 - Supervised Training Loss: 5.304690
2025-04-10 23:03:14,246 - Unsupervised Training Loss: 4.971370
2025-04-10 23:03:46,111 - K-means used 0.02 s
2025-04-10 23:03:46,875 - ***** Epoch: 4 *****
2025-04-10 23:03:46,875 - Supervised Training Loss: 5.147090
2025-04-10 23:03:46,875 - Unsupervised Training Loss: 5.040920
2025-04-10 23:04:20,190 - K-means used 0.01 s
2025-04-10 23:04:21,129 - ***** Epoch: 5 *****
2025-04-10 23:04:21,129 - Supervised Training Loss: 4.907470
2025-04-10 23:04:21,130 - Unsupervised Training Loss: 5.072340
2025-04-10 23:04:57,005 - K-means used 0.02 s
2025-04-10 23:04:58,045 - ***** Epoch: 6 *****
2025-04-10 23:04:58,045 - Supervised Training Loss: 5.298480
2025-04-10 23:04:58,045 - Unsupervised Training Loss: 4.870770
2025-04-10 23:05:31,581 - K-means used 0.01 s
2025-04-10 23:05:32,478 - ***** Epoch: 7 *****
2025-04-10 23:05:32,478 - Supervised Training Loss: 5.228290
2025-04-10 23:05:32,478 - Unsupervised Training Loss: 4.989690
2025-04-10 23:06:06,698 - K-means used 0.05 s
2025-04-10 23:06:07,796 - ***** Epoch: 8 *****
2025-04-10 23:06:07,796 - Supervised Training Loss: 5.106990
2025-04-10 23:06:07,796 - Unsupervised Training Loss: 5.041100
2025-04-10 23:06:49,202 - K-means used 0.02 s
2025-04-10 23:06:50,804 - ***** Epoch: 9 *****
2025-04-10 23:06:50,805 - Supervised Training Loss: 5.316680
2025-04-10 23:06:50,805 - Unsupervised Training Loss: 5.079160
2025-04-10 23:07:24,409 - K-means used 0.01 s
2025-04-10 23:07:25,410 - ***** Epoch: 10 *****
2025-04-10 23:07:25,410 - Supervised Training Loss: 5.257790
2025-04-10 23:07:25,410 - Unsupervised Training Loss: 4.921600
2025-04-10 23:07:55,978 - K-means used 0.01 s
2025-04-10 23:07:57,300 - ***** Epoch: 11 *****
2025-04-10 23:07:57,300 - Supervised Training Loss: 5.170560
2025-04-10 23:07:57,300 - Unsupervised Training Loss: 5.016320
2025-04-10 23:08:32,618 - K-means used 0.01 s
2025-04-10 23:08:34,077 - ***** Epoch: 12 *****
2025-04-10 23:08:34,078 - Supervised Training Loss: 5.318940
2025-04-10 23:08:34,078 - Unsupervised Training Loss: 5.073990
2025-04-10 23:09:05,603 - K-means used 0.01 s
2025-04-10 23:09:07,146 - ***** Epoch: 13 *****
2025-04-10 23:09:07,146 - Supervised Training Loss: 5.277900
2025-04-10 23:09:07,146 - Unsupervised Training Loss: 4.812940
2025-04-10 23:09:41,784 - K-means used 0.01 s
2025-04-10 23:09:43,520 - ***** Epoch: 14 *****
2025-04-10 23:09:43,520 - Supervised Training Loss: 5.235200
2025-04-10 23:09:43,521 - Unsupervised Training Loss: 4.927760
2025-04-10 23:10:17,070 - K-means used 0.01 s
2025-04-10 23:10:18,338 - ***** Epoch: 15 *****
2025-04-10 23:10:18,338 - Supervised Training Loss: 5.060700
2025-04-10 23:10:18,338 - Unsupervised Training Loss: 5.051550
2025-04-10 23:10:45,276 - K-means used 0.01 s
2025-04-10 23:10:46,617 - ***** Epoch: 16 *****
2025-04-10 23:10:46,617 - Supervised Training Loss: 5.303530
2025-04-10 23:10:46,617 - Unsupervised Training Loss: 4.491860
2025-04-10 23:11:18,941 - K-means used 0.01 s
2025-04-10 23:11:21,019 - ***** Epoch: 17 *****
2025-04-10 23:11:21,020 - Supervised Training Loss: 5.271940
2025-04-10 23:11:21,020 - Unsupervised Training Loss: 4.713220
2025-04-10 23:11:41,373 - Training is finished...
2025-04-10 23:11:41,373 - Testing begins...
2025-04-10 23:11:52,470 - ***** Test results *****
2025-04-10 23:11:52,470 -   ACC = 39.78
2025-04-10 23:11:52,470 -   ARI = 19.77
2025-04-10 23:11:52,470 -   NMI = 44.7
2025-04-10 23:11:52,470 -   fmi = 24.73
2025-04-10 23:11:52,470 - Testing is finished...
2025-04-10 23:11:52,470 - Multimodal intent recognition is finished...
2025-04-10 23:11:52,470 - Results are saved in results/results_umc.csv
