2025-04-16 01:00:58,976 - 进入了无监督的设定中, 加载数据集
2025-04-16 01:00:58,976 - data preparation...
2025-04-16 01:01:07,361 - Number of train samples = 1779
2025-04-16 01:01:07,362 - Number of testing samples = 445
2025-04-16 01:01:07,362 - data preparation...
2025-04-16 01:01:09,649 - num_train_examples = 1779
2025-04-16 01:01:09,649 - ============================== Params ==============================
2025-04-16 01:01:09,649 - logger_name: umc_umc_bert-base-uncased_MIntRec_2
2025-04-16 01:01:09,649 - dataset: MIntRec
2025-04-16 01:01:09,649 - multimodal_method: umc
2025-04-16 01:01:09,649 - method: umc
2025-04-16 01:01:09,649 - setting: unsupervised
2025-04-16 01:01:09,649 - text_backbone: bert-base-uncased
2025-04-16 01:01:09,649 - seed: 2
2025-04-16 01:01:09,649 - num_workers: 16
2025-04-16 01:01:09,649 - log_id: umc_umc_bert-base-uncased_MIntRec_2_2025-04-16-01-00-58
2025-04-16 01:01:09,650 - gpu_id: 1
2025-04-16 01:01:09,650 - data_path: /root/autodl-tmp/home/Share/Dataset/LZH
2025-04-16 01:01:09,650 - train: True
2025-04-16 01:01:09,650 - tune: True
2025-04-16 01:01:09,650 - save_model: True
2025-04-16 01:01:09,650 - save_results: True
2025-04-16 01:01:09,650 - log_path: logs
2025-04-16 01:01:09,650 - cache_path: cache
2025-04-16 01:01:09,650 - video_data_path: video_data
2025-04-16 01:01:09,650 - audio_data_path: audio_data
2025-04-16 01:01:09,650 - video_feats_path: swin_feats.pkl
2025-04-16 01:01:09,650 - audio_feats_path: wavlm_feats.pkl
2025-04-16 01:01:09,650 - results_path: results
2025-04-16 01:01:09,650 - output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/SMC/outputs_test/MIntRec
2025-04-16 01:01:09,650 - model_path: models
2025-04-16 01:01:09,650 - config_file_name: umc_MIntRec
2025-04-16 01:01:09,650 - results_file_name: results_umc.csv
2025-04-16 01:01:09,650 - text_pretrained_model: uncased_L-12_H-768_A-12
2025-04-16 01:01:09,650 - pretrained_bert_model: uncased_L-12_H-768_A-12
2025-04-16 01:01:09,650 - pretrain_batch_size: 128
2025-04-16 01:01:09,651 - train_batch_size: 128
2025-04-16 01:01:09,651 - eval_batch_size: 128
2025-04-16 01:01:09,651 - test_batch_size: 128
2025-04-16 01:01:09,651 - num_pretrain_epochs: 100
2025-04-16 01:01:09,651 - num_train_epochs: 100
2025-04-16 01:01:09,651 - pretrain: [True]
2025-04-16 01:01:09,651 - aligned_method: ctc
2025-04-16 01:01:09,651 - need_aligned: False
2025-04-16 01:01:09,651 - freeze_pretrain_bert_parameters: [True]
2025-04-16 01:01:09,651 - freeze_train_bert_parameters: [True]
2025-04-16 01:01:09,651 - pretrain_temperature: [0.1]
2025-04-16 01:01:09,651 - train_temperature_sup: [0.5, 1, 2, 4, 6, 8]
2025-04-16 01:01:09,651 - train_temperature_unsup: [0.5, 1, 2, 4, 6, 8]
2025-04-16 01:01:09,651 - activation: tanh
2025-04-16 01:01:09,652 - lr_pre: 1e-05
2025-04-16 01:01:09,652 - lr: [0.0001]
2025-04-16 01:01:09,652 - delta: [0.05]
2025-04-16 01:01:09,652 - thres: [0.1]
2025-04-16 01:01:09,652 - topk: [5]
2025-04-16 01:01:09,652 - weight_decay: 0.01
2025-04-16 01:01:09,652 - feat_dim: 768
2025-04-16 01:01:09,652 - hidden_size: 768
2025-04-16 01:01:09,652 - grad_clip: -1.0
2025-04-16 01:01:09,652 - warmup_proportion: 0.5
2025-04-16 01:01:09,652 - hidden_dropout_prob: 0.1
2025-04-16 01:01:09,652 - weight: 1.0
2025-04-16 01:01:09,652 - loss_mode: rdrop
2025-04-16 01:01:09,652 - base_dim: 256
2025-04-16 01:01:09,652 - nheads: 8
2025-04-16 01:01:09,652 - attn_dropout: 0.1
2025-04-16 01:01:09,652 - relu_dropout: 0.1
2025-04-16 01:01:09,652 - embed_dropout: 0.01
2025-04-16 01:01:09,652 - res_dropout: 0.0
2025-04-16 01:01:09,652 - attn_mask: True
2025-04-16 01:01:09,653 - encoder_layers_1: 1
2025-04-16 01:01:09,653 - fusion_act: tanh
2025-04-16 01:01:09,653 - pred_output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/SMC/outputs_test/MIntRec/umc_umc_MIntRec_bert-base-uncased_2
2025-04-16 01:01:09,653 - model_output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/SMC/outputs_test/MIntRec/umc_umc_MIntRec_bert-base-uncased_2/models
2025-04-16 01:01:09,653 - text_seq_len: 30
2025-04-16 01:01:09,653 - video_seq_len: 230
2025-04-16 01:01:09,653 - audio_seq_len: 480
2025-04-16 01:01:09,653 - text_feat_dim: 768
2025-04-16 01:01:09,653 - video_feat_dim: 1024
2025-04-16 01:01:09,653 - audio_feat_dim: 768
2025-04-16 01:01:09,653 - num_train_examples: 1779
2025-04-16 01:01:09,653 - ============================== End Params ==============================
2025-04-16 01:01:10,828 - Freeze all parameters but the last layer for efficiency
2025-04-16 01:01:10,862 - Pre-training start...
2025-04-16 01:01:26,391 - ***** Epoch: 1: Eval results *****
2025-04-16 01:01:26,392 -   train_loss = 5.9606238433292935
2025-04-16 01:01:42,169 - ***** Epoch: 2: Eval results *****
2025-04-16 01:01:42,170 -   train_loss = 5.958958762032645
2025-04-16 01:01:57,903 - ***** Epoch: 3: Eval results *****
2025-04-16 01:01:57,903 -   train_loss = 5.956834145954677
2025-04-16 01:02:13,352 - ***** Epoch: 4: Eval results *****
2025-04-16 01:02:13,352 -   train_loss = 5.952617474964687
2025-04-16 01:02:29,573 - ***** Epoch: 5: Eval results *****
2025-04-16 01:02:29,573 -   train_loss = 5.9533233642578125
2025-04-16 01:02:46,608 - ***** Epoch: 6: Eval results *****
2025-04-16 01:02:46,609 -   train_loss = 5.950619799750192
2025-04-16 01:03:04,328 - ***** Epoch: 7: Eval results *****
2025-04-16 01:03:04,329 -   train_loss = 5.945175341197422
2025-04-16 01:03:20,905 - ***** Epoch: 8: Eval results *****
2025-04-16 01:03:20,905 -   train_loss = 5.939927577972412
2025-04-16 01:03:38,034 - ***** Epoch: 9: Eval results *****
2025-04-16 01:03:38,034 -   train_loss = 5.936186211449759
2025-04-16 01:03:54,745 - ***** Epoch: 10: Eval results *****
2025-04-16 01:03:54,745 -   train_loss = 5.930566310882568
2025-04-16 01:04:12,042 - ***** Epoch: 11: Eval results *****
2025-04-16 01:04:12,043 -   train_loss = 5.9166556426457
2025-04-16 01:04:28,946 - ***** Epoch: 12: Eval results *****
2025-04-16 01:04:28,946 -   train_loss = 5.916486978530884
2025-04-16 01:04:47,394 - ***** Epoch: 13: Eval results *****
2025-04-16 01:04:47,395 -   train_loss = 5.901801381792341
2025-04-16 01:05:07,561 - ***** Epoch: 14: Eval results *****
2025-04-16 01:05:07,561 -   train_loss = 5.886326857975551
2025-04-16 01:05:26,647 - ***** Epoch: 15: Eval results *****
2025-04-16 01:05:26,648 -   train_loss = 5.855894769941058
2025-04-16 01:05:46,533 - ***** Epoch: 16: Eval results *****
2025-04-16 01:05:46,533 -   train_loss = 5.8333156790052145
2025-04-16 01:06:05,195 - ***** Epoch: 17: Eval results *****
2025-04-16 01:06:05,195 -   train_loss = 5.779304606573922
2025-04-16 01:06:24,062 - ***** Epoch: 18: Eval results *****
2025-04-16 01:06:24,062 -   train_loss = 5.690906013761248
2025-04-16 01:06:42,553 - ***** Epoch: 19: Eval results *****
2025-04-16 01:06:42,553 -   train_loss = 5.552900893347604
2025-04-16 01:07:01,141 - ***** Epoch: 20: Eval results *****
2025-04-16 01:07:01,142 -   train_loss = 5.339777197156634
2025-04-16 01:07:19,116 - ***** Epoch: 21: Eval results *****
2025-04-16 01:07:19,117 -   train_loss = 5.046753508704049
2025-04-16 01:07:37,625 - ***** Epoch: 22: Eval results *****
2025-04-16 01:07:37,626 -   train_loss = 4.776197297232492
2025-04-16 01:07:55,582 - ***** Epoch: 23: Eval results *****
2025-04-16 01:07:55,582 -   train_loss = 4.5083809580121725
2025-04-16 01:08:14,300 - ***** Epoch: 24: Eval results *****
2025-04-16 01:08:14,300 -   train_loss = 4.2580727849687845
2025-04-16 01:08:34,243 - ***** Epoch: 25: Eval results *****
2025-04-16 01:08:34,244 -   train_loss = 4.025586179324558
2025-04-16 01:08:54,358 - ***** Epoch: 26: Eval results *****
2025-04-16 01:08:54,358 -   train_loss = 3.813383323805673
2025-04-16 01:09:13,783 - ***** Epoch: 27: Eval results *****
2025-04-16 01:09:13,784 -   train_loss = 3.614003436905997
2025-04-16 01:09:33,428 - ***** Epoch: 28: Eval results *****
2025-04-16 01:09:33,428 -   train_loss = 3.4344538961138045
2025-04-16 01:09:52,762 - ***** Epoch: 29: Eval results *****
2025-04-16 01:09:52,763 -   train_loss = 3.284033945628575
2025-04-16 01:10:12,213 - ***** Epoch: 30: Eval results *****
2025-04-16 01:10:12,214 -   train_loss = 3.1570939336504256
2025-04-16 01:10:31,373 - ***** Epoch: 31: Eval results *****
2025-04-16 01:10:31,374 -   train_loss = 2.9998934950147356
2025-04-16 01:10:49,834 - ***** Epoch: 32: Eval results *****
2025-04-16 01:10:49,834 -   train_loss = 2.893157652446202
2025-04-16 01:11:08,045 - ***** Epoch: 33: Eval results *****
2025-04-16 01:11:08,045 -   train_loss = 2.7796852929251537
2025-04-16 01:11:27,762 - ***** Epoch: 34: Eval results *****
2025-04-16 01:11:27,762 -   train_loss = 2.686954515320914
2025-04-16 01:11:45,651 - ***** Epoch: 35: Eval results *****
2025-04-16 01:11:45,651 -   train_loss = 2.5948023114885603
2025-04-16 01:12:05,117 - ***** Epoch: 36: Eval results *****
2025-04-16 01:12:05,118 -   train_loss = 2.5263651268822804
2025-04-16 01:12:22,544 - ***** Epoch: 37: Eval results *****
2025-04-16 01:12:22,545 -   train_loss = 2.436188578605652
2025-04-16 01:12:39,433 - ***** Epoch: 38: Eval results *****
2025-04-16 01:12:39,433 -   train_loss = 2.353552086012704
2025-04-16 01:12:56,346 - ***** Epoch: 39: Eval results *****
2025-04-16 01:12:56,347 -   train_loss = 2.2818842955998013
2025-04-16 01:13:14,794 - ***** Epoch: 40: Eval results *****
2025-04-16 01:13:14,794 -   train_loss = 2.2302630288260326
2025-04-16 01:13:32,829 - ***** Epoch: 41: Eval results *****
2025-04-16 01:13:32,829 -   train_loss = 2.1683950083596364
2025-04-16 01:13:49,554 - ***** Epoch: 42: Eval results *****
2025-04-16 01:13:49,554 -   train_loss = 2.118515236037118
2025-04-16 01:14:08,450 - ***** Epoch: 43: Eval results *****
2025-04-16 01:14:08,450 -   train_loss = 2.083054678780692
2025-04-16 01:14:26,565 - ***** Epoch: 44: Eval results *****
2025-04-16 01:14:26,565 -   train_loss = 2.0359377775873457
2025-04-16 01:14:44,354 - ***** Epoch: 45: Eval results *****
2025-04-16 01:14:44,354 -   train_loss = 1.99053213426045
2025-04-16 01:15:02,150 - ***** Epoch: 46: Eval results *****
2025-04-16 01:15:02,151 -   train_loss = 1.9467548727989197
2025-04-16 01:15:19,610 - ***** Epoch: 47: Eval results *****
2025-04-16 01:15:19,610 -   train_loss = 1.922405753816877
2025-04-16 01:15:37,657 - ***** Epoch: 48: Eval results *****
2025-04-16 01:15:37,658 -   train_loss = 1.8987839477402824
2025-04-16 01:15:55,017 - ***** Epoch: 49: Eval results *****
2025-04-16 01:15:55,017 -   train_loss = 1.8616448215075903
2025-04-16 01:16:13,068 - ***** Epoch: 50: Eval results *****
2025-04-16 01:16:13,068 -   train_loss = 1.8258169037955148
2025-04-16 01:16:31,891 - ***** Epoch: 51: Eval results *****
2025-04-16 01:16:31,891 -   train_loss = 1.8100979243006026
2025-04-16 01:16:49,391 - ***** Epoch: 52: Eval results *****
2025-04-16 01:16:49,391 -   train_loss = 1.7835386310304915
2025-04-16 01:17:07,313 - ***** Epoch: 53: Eval results *****
2025-04-16 01:17:07,314 -   train_loss = 1.7377989036696297
2025-04-16 01:17:26,268 - ***** Epoch: 54: Eval results *****
2025-04-16 01:17:26,269 -   train_loss = 1.7256208232470922
2025-04-16 01:17:44,081 - ***** Epoch: 55: Eval results *****
2025-04-16 01:17:44,081 -   train_loss = 1.6932145271982466
2025-04-16 01:18:01,722 - ***** Epoch: 56: Eval results *****
2025-04-16 01:18:01,722 -   train_loss = 1.6942556415285384
2025-04-16 01:18:20,245 - ***** Epoch: 57: Eval results *****
2025-04-16 01:18:20,245 -   train_loss = 1.666801997593471
2025-04-16 01:18:38,867 - ***** Epoch: 58: Eval results *****
2025-04-16 01:18:38,867 -   train_loss = 1.652653089591435
2025-04-16 01:18:56,218 - ***** Epoch: 59: Eval results *****
2025-04-16 01:18:56,218 -   train_loss = 1.6370477761541093
2025-04-16 01:19:14,210 - ***** Epoch: 60: Eval results *****
2025-04-16 01:19:14,210 -   train_loss = 1.6083134923662459
2025-04-16 01:19:31,756 - ***** Epoch: 61: Eval results *****
2025-04-16 01:19:31,757 -   train_loss = 1.6007348469325475
2025-04-16 01:19:50,177 - ***** Epoch: 62: Eval results *****
2025-04-16 01:19:50,177 -   train_loss = 1.6028303844588143
2025-04-16 01:20:07,312 - ***** Epoch: 63: Eval results *****
2025-04-16 01:20:07,312 -   train_loss = 1.5914484177316939
2025-04-16 01:20:24,214 - ***** Epoch: 64: Eval results *****
2025-04-16 01:20:24,214 -   train_loss = 1.5760979226657323
2025-04-16 01:20:42,578 - ***** Epoch: 65: Eval results *****
2025-04-16 01:20:42,579 -   train_loss = 1.5594738040651595
2025-04-16 01:21:01,682 - ***** Epoch: 66: Eval results *****
2025-04-16 01:21:01,683 -   train_loss = 1.5626112903867448
2025-04-16 01:21:20,792 - ***** Epoch: 67: Eval results *****
2025-04-16 01:21:20,792 -   train_loss = 1.5487346138272966
2025-04-16 01:21:40,330 - ***** Epoch: 68: Eval results *****
2025-04-16 01:21:40,331 -   train_loss = 1.5423594287463598
2025-04-16 01:22:00,185 - ***** Epoch: 69: Eval results *****
2025-04-16 01:22:00,185 -   train_loss = 1.5298511726515633
2025-04-16 01:22:19,830 - ***** Epoch: 70: Eval results *****
2025-04-16 01:22:19,830 -   train_loss = 1.5331180776868547
2025-04-16 01:22:37,659 - ***** Epoch: 71: Eval results *****
2025-04-16 01:22:37,659 -   train_loss = 1.5148788009371077
2025-04-16 01:22:55,630 - ***** Epoch: 72: Eval results *****
2025-04-16 01:22:55,630 -   train_loss = 1.5010193841797965
2025-04-16 01:23:13,696 - ***** Epoch: 73: Eval results *****
2025-04-16 01:23:13,696 -   train_loss = 1.5147102304867335
2025-04-16 01:23:32,050 - ***** Epoch: 74: Eval results *****
2025-04-16 01:23:32,051 -   train_loss = 1.5006787436349052
2025-04-16 01:23:50,467 - ***** Epoch: 75: Eval results *****
2025-04-16 01:23:50,467 -   train_loss = 1.4964990360396249
2025-04-16 01:24:07,833 - ***** Epoch: 76: Eval results *****
2025-04-16 01:24:07,833 -   train_loss = 1.4899564044816154
2025-04-16 01:24:26,282 - ***** Epoch: 77: Eval results *****
2025-04-16 01:24:26,282 -   train_loss = 1.48144165958677
2025-04-16 01:24:44,100 - ***** Epoch: 78: Eval results *****
2025-04-16 01:24:44,100 -   train_loss = 1.4755672216415405
2025-04-16 01:25:01,819 - ***** Epoch: 79: Eval results *****
2025-04-16 01:25:01,820 -   train_loss = 1.4750765987804957
2025-04-16 01:25:20,441 - ***** Epoch: 80: Eval results *****
2025-04-16 01:25:20,442 -   train_loss = 1.478706419467926
2025-04-16 01:25:39,234 - ***** Epoch: 81: Eval results *****
2025-04-16 01:25:39,234 -   train_loss = 1.4703173637390137
2025-04-16 01:25:57,125 - ***** Epoch: 82: Eval results *****
2025-04-16 01:25:57,126 -   train_loss = 1.4631718226841517
2025-04-16 01:26:15,265 - ***** Epoch: 83: Eval results *****
2025-04-16 01:26:15,265 -   train_loss = 1.4661008630480086
2025-04-16 01:26:33,316 - ***** Epoch: 84: Eval results *****
2025-04-16 01:26:33,317 -   train_loss = 1.4795646497181483
2025-04-16 01:26:51,453 - ***** Epoch: 85: Eval results *****
2025-04-16 01:26:51,454 -   train_loss = 1.4639703461102076
2025-04-16 01:27:10,052 - ***** Epoch: 86: Eval results *****
2025-04-16 01:27:10,052 -   train_loss = 1.4561133469854082
2025-04-16 01:27:28,810 - ***** Epoch: 87: Eval results *****
2025-04-16 01:27:28,810 -   train_loss = 1.4628781761441911
2025-04-16 01:27:47,877 - ***** Epoch: 88: Eval results *****
2025-04-16 01:27:47,878 -   train_loss = 1.4585282291684831
2025-04-16 01:28:06,675 - ***** Epoch: 89: Eval results *****
2025-04-16 01:28:06,676 -   train_loss = 1.4578786066600256
2025-04-16 01:28:24,097 - ***** Epoch: 90: Eval results *****
2025-04-16 01:28:24,098 -   train_loss = 1.4574772119522095
2025-04-16 01:28:42,139 - ***** Epoch: 91: Eval results *****
2025-04-16 01:28:42,140 -   train_loss = 1.4529347675187247
2025-04-16 01:29:01,033 - ***** Epoch: 92: Eval results *****
2025-04-16 01:29:01,034 -   train_loss = 1.4586814897400993
2025-04-16 01:29:19,788 - ***** Epoch: 93: Eval results *****
2025-04-16 01:29:19,789 -   train_loss = 1.4654030544417245
2025-04-16 01:29:38,022 - ***** Epoch: 94: Eval results *****
2025-04-16 01:29:38,023 -   train_loss = 1.4597988384110587
2025-04-16 01:29:56,428 - ***** Epoch: 95: Eval results *****
2025-04-16 01:29:56,428 -   train_loss = 1.4522440263203211
2025-04-16 01:30:14,547 - ***** Epoch: 96: Eval results *****
2025-04-16 01:30:14,548 -   train_loss = 1.4680341482162476
2025-04-16 01:30:32,618 - ***** Epoch: 97: Eval results *****
2025-04-16 01:30:32,618 -   train_loss = 1.465115794113704
2025-04-16 01:30:50,514 - ***** Epoch: 98: Eval results *****
2025-04-16 01:30:50,515 -   train_loss = 1.4529715861592973
2025-04-16 01:31:07,870 - ***** Epoch: 99: Eval results *****
2025-04-16 01:31:07,870 -   train_loss = 1.458483738558633
2025-04-16 01:31:24,655 - ***** Epoch: 100: Eval results *****
2025-04-16 01:31:24,656 -   train_loss = 1.4610312921660287
2025-04-16 01:31:25,204 - Pre-training finished...
