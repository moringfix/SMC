2025-04-17 17:13:43,656 - 【无监督】进入了无监督的设定中, 加载数据集
2025-04-17 17:13:43,656 - data preparation...
2025-04-17 17:13:52,478 - Number of train samples = 1779
2025-04-17 17:13:52,479 - Number of testing samples = 445
2025-04-17 17:13:52,479 - data preparation...
2025-04-17 17:13:54,787 - num_train_examples = 1779
2025-04-17 17:13:54,787 - ============================== Params ==============================
2025-04-17 17:13:54,788 - logger_name: umc_umc_bert-base-uncased_MIntRec_0
2025-04-17 17:13:54,788 - dataset: MIntRec
2025-04-17 17:13:54,788 - multimodal_method: umc
2025-04-17 17:13:54,788 - method: umc
2025-04-17 17:13:54,788 - setting: unsupervised
2025-04-17 17:13:54,788 - merge_dev: False
2025-04-17 17:13:54,788 - text_backbone: bert-base-uncased
2025-04-17 17:13:54,788 - seed: 0
2025-04-17 17:13:54,788 - num_workers: 16
2025-04-17 17:13:54,788 - log_id: umc_umc_bert-base-uncased_MIntRec_0_2025-04-17-17-13-43
2025-04-17 17:13:54,788 - gpu_id: 1
2025-04-17 17:13:54,788 - data_path: /root/autodl-tmp/home/Share/Dataset/LZH
2025-04-17 17:13:54,788 - train: True
2025-04-17 17:13:54,788 - tune: True
2025-04-17 17:13:54,788 - save_model: True
2025-04-17 17:13:54,788 - save_results: True
2025-04-17 17:13:54,788 - log_path: logs
2025-04-17 17:13:54,788 - cache_path: cache
2025-04-17 17:13:54,788 - video_data_path: video_data
2025-04-17 17:13:54,788 - audio_data_path: audio_data
2025-04-17 17:13:54,788 - video_feats_path: swin_feats.pkl
2025-04-17 17:13:54,788 - audio_feats_path: wavlm_feats.pkl
2025-04-17 17:13:54,788 - results_path: results
2025-04-17 17:13:54,788 - output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/SMC/outputs_test2/MIntRec
2025-04-17 17:13:54,788 - model_path: models
2025-04-17 17:13:54,788 - config_file_name: umc_MIntRec
2025-04-17 17:13:54,788 - results_file_name: results_umc_pre.csv
2025-04-17 17:13:54,789 - text_pretrained_model: uncased_L-12_H-768_A-12
2025-04-17 17:13:54,789 - pretrained_bert_model: uncased_L-12_H-768_A-12
2025-04-17 17:13:54,789 - pretrain_batch_size: 128
2025-04-17 17:13:54,789 - train_batch_size: 128
2025-04-17 17:13:54,789 - eval_batch_size: 128
2025-04-17 17:13:54,789 - test_batch_size: 128
2025-04-17 17:13:54,789 - num_pretrain_epochs: 100
2025-04-17 17:13:54,789 - num_train_epochs: 100
2025-04-17 17:13:54,789 - pretrain: [True]
2025-04-17 17:13:54,789 - aligned_method: ctc
2025-04-17 17:13:54,789 - need_aligned: False
2025-04-17 17:13:54,789 - freeze_pretrain_bert_parameters: [True]
2025-04-17 17:13:54,789 - freeze_train_bert_parameters: [True]
2025-04-17 17:13:54,789 - pretrain_temperature: [0.12]
2025-04-17 17:13:54,789 - train_temperature_sup: [0.5]
2025-04-17 17:13:54,789 - train_temperature_unsup: [2]
2025-04-17 17:13:54,789 - activation: tanh
2025-04-17 17:13:54,789 - lr_pre: [1e-05]
2025-04-17 17:13:54,789 - lr: [5e-05]
2025-04-17 17:13:54,789 - delta: [0.05]
2025-04-17 17:13:54,789 - thres: [0.1]
2025-04-17 17:13:54,789 - topk: [5]
2025-04-17 17:13:54,789 - weight_decay: 0.01
2025-04-17 17:13:54,789 - feat_dim: 768
2025-04-17 17:13:54,789 - hidden_size: 768
2025-04-17 17:13:54,789 - grad_clip: -1.0
2025-04-17 17:13:54,790 - warmup_proportion: [0.1]
2025-04-17 17:13:54,790 - hidden_dropout_prob: 0.1
2025-04-17 17:13:54,790 - weight: 1.0
2025-04-17 17:13:54,790 - loss_mode: rdrop
2025-04-17 17:13:54,790 - base_dim: 256
2025-04-17 17:13:54,790 - nheads: 8
2025-04-17 17:13:54,790 - attn_dropout: 0.1
2025-04-17 17:13:54,790 - relu_dropout: 0.1
2025-04-17 17:13:54,790 - embed_dropout: 0.01
2025-04-17 17:13:54,790 - res_dropout: 0.0
2025-04-17 17:13:54,790 - attn_mask: True
2025-04-17 17:13:54,790 - encoder_layers_1: 1
2025-04-17 17:13:54,790 - fusion_act: tanh
2025-04-17 17:13:54,790 - pred_output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/SMC/outputs_test2/MIntRec/umc_umc_MIntRec_bert-base-uncased_0
2025-04-17 17:13:54,790 - model_output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/SMC/outputs_test2/MIntRec/umc_umc_MIntRec_bert-base-uncased_0/models
2025-04-17 17:13:54,790 - text_seq_len: 30
2025-04-17 17:13:54,790 - video_seq_len: 230
2025-04-17 17:13:54,790 - audio_seq_len: 480
2025-04-17 17:13:54,790 - text_feat_dim: 768
2025-04-17 17:13:54,790 - video_feat_dim: 1024
2025-04-17 17:13:54,790 - audio_feat_dim: 768
2025-04-17 17:13:54,790 - num_labels: 20
2025-04-17 17:13:54,790 - num_train_examples: 1779
2025-04-17 17:13:54,790 - ============================== End Params ==============================
2025-04-17 17:13:56,104 - Freeze all parameters but the last layer for efficiency
2025-04-17 17:13:56,138 - Pre-training start...
2025-04-17 17:14:11,976 - ***** Epoch: 1: Eval results *****
2025-04-17 17:14:11,976 -   train_loss = 5.9402574471064975
2025-04-17 17:14:29,470 - ***** Epoch: 2: Eval results *****
2025-04-17 17:14:29,470 -   train_loss = 5.942788941519601
2025-04-17 17:14:47,105 - ***** Epoch: 3: Eval results *****
2025-04-17 17:14:47,105 -   train_loss = 5.9292020457131525
2025-04-17 17:15:04,510 - ***** Epoch: 4: Eval results *****
2025-04-17 17:15:04,510 -   train_loss = 5.922495126724243
2025-04-17 17:15:22,317 - ***** Epoch: 5: Eval results *****
2025-04-17 17:15:22,317 -   train_loss = 5.909973621368408
2025-04-17 17:15:39,913 - ***** Epoch: 6: Eval results *****
2025-04-17 17:15:39,914 -   train_loss = 5.89323673929487
2025-04-17 17:15:57,237 - ***** Epoch: 7: Eval results *****
2025-04-17 17:15:57,237 -   train_loss = 5.857297829219273
2025-04-17 17:16:14,781 - ***** Epoch: 8: Eval results *****
2025-04-17 17:16:14,781 -   train_loss = 5.763041291918073
2025-04-17 17:16:32,061 - ***** Epoch: 9: Eval results *****
2025-04-17 17:16:32,062 -   train_loss = 5.555539948599679
2025-04-17 17:16:49,675 - ***** Epoch: 10: Eval results *****
2025-04-17 17:16:49,676 -   train_loss = 5.183847325188773
2025-04-17 17:17:07,414 - ***** Epoch: 11: Eval results *****
2025-04-17 17:17:07,414 -   train_loss = 4.754042250769479
2025-04-17 17:17:25,057 - ***** Epoch: 12: Eval results *****
2025-04-17 17:17:25,058 -   train_loss = 4.349936383111136
2025-04-17 17:17:42,676 - ***** Epoch: 13: Eval results *****
2025-04-17 17:17:42,676 -   train_loss = 4.03677613394601
2025-04-17 17:18:00,271 - ***** Epoch: 14: Eval results *****
2025-04-17 17:18:00,271 -   train_loss = 3.772877642086574
