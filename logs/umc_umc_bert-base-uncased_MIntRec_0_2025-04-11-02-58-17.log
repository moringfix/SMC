2025-04-11 02:58:17,095 - ============================== Params ==============================
2025-04-11 02:58:17,095 - logger_name: umc_umc_bert-base-uncased_MIntRec_0
2025-04-11 02:58:17,095 - dataset: MIntRec
2025-04-11 02:58:17,095 - multimodal_method: umc
2025-04-11 02:58:17,095 - method: umc
2025-04-11 02:58:17,095 - text_backbone: bert-base-uncased
2025-04-11 02:58:17,095 - seed: 0
2025-04-11 02:58:17,096 - num_workers: 16
2025-04-11 02:58:17,096 - log_id: umc_umc_bert-base-uncased_MIntRec_0_2025-04-11-02-58-17
2025-04-11 02:58:17,096 - gpu_id: 0
2025-04-11 02:58:17,096 - data_path: /root/autodl-tmp/home/Share/Dataset/LZH
2025-04-11 02:58:17,096 - train: True
2025-04-11 02:58:17,096 - tune: True
2025-04-11 02:58:17,096 - save_model: True
2025-04-11 02:58:17,096 - save_results: True
2025-04-11 02:58:17,096 - log_path: logs
2025-04-11 02:58:17,096 - cache_path: cache
2025-04-11 02:58:17,096 - video_data_path: video_data
2025-04-11 02:58:17,096 - audio_data_path: audio_data
2025-04-11 02:58:17,096 - video_feats_path: swin_feats.pkl
2025-04-11 02:58:17,096 - audio_feats_path: wavlm_feats.pkl
2025-04-11 02:58:17,096 - results_path: results
2025-04-11 02:58:17,096 - output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/UMC/outputs/MIntRec
2025-04-11 02:58:17,096 - model_path: models
2025-04-11 02:58:17,096 - config_file_name: umc_MIntRec
2025-04-11 02:58:17,096 - results_file_name: results_umc.csv
2025-04-11 02:58:17,096 - text_pretrained_model: uncased_L-12_H-768_A-12
2025-04-11 02:58:17,096 - text_seq_len: 30
2025-04-11 02:58:17,096 - video_seq_len: 230
2025-04-11 02:58:17,096 - audio_seq_len: 480
2025-04-11 02:58:17,096 - text_feat_dim: 768
2025-04-11 02:58:17,096 - video_feat_dim: 1024
2025-04-11 02:58:17,096 - audio_feat_dim: 768
2025-04-11 02:58:17,096 - num_labels: 20
2025-04-11 02:58:17,096 - num_train_examples: 1779
2025-04-11 02:58:17,096 - pretrained_bert_model: uncased_L-12_H-768_A-12
2025-04-11 02:58:17,096 - pretrain_batch_size: 128
2025-04-11 02:58:17,097 - train_batch_size: 128
2025-04-11 02:58:17,097 - eval_batch_size: 128
2025-04-11 02:58:17,097 - test_batch_size: 128
2025-04-11 02:58:17,097 - num_pretrain_epochs: 100
2025-04-11 02:58:17,097 - num_train_epochs: 100
2025-04-11 02:58:17,097 - pretrain: [True]
2025-04-11 02:58:17,097 - aligned_method: ctc
2025-04-11 02:58:17,097 - need_aligned: False
2025-04-11 02:58:17,097 - freeze_pretrain_bert_parameters: [True]
2025-04-11 02:58:17,097 - freeze_train_bert_parameters: [True]
2025-04-11 02:58:17,097 - pretrain_temperature: [0.2]
2025-04-11 02:58:17,097 - train_temperature_sup: [1.4]
2025-04-11 02:58:17,097 - train_temperature_unsup: [1]
2025-04-11 02:58:17,097 - activation: tanh
2025-04-11 02:58:17,097 - lr_pre: 5e-06
2025-04-11 02:58:17,097 - lr: [0.0003]
2025-04-11 02:58:17,097 - delta: [0.05]
2025-04-11 02:58:17,097 - thres: [0.1]
2025-04-11 02:58:17,097 - topk: [5]
2025-04-11 02:58:17,097 - weight_decay: 0.01
2025-04-11 02:58:17,097 - feat_dim: 768
2025-04-11 02:58:17,097 - hidden_size: 768
2025-04-11 02:58:17,097 - grad_clip: -1.0
2025-04-11 02:58:17,097 - warmup_proportion: 0.5
2025-04-11 02:58:17,097 - hidden_dropout_prob: 0.1
2025-04-11 02:58:17,097 - weight: 1.0
2025-04-11 02:58:17,097 - loss_mode: rdrop
2025-04-11 02:58:17,097 - base_dim: 256
2025-04-11 02:58:17,097 - nheads: 8
2025-04-11 02:58:17,098 - attn_dropout: 0.1
2025-04-11 02:58:17,098 - relu_dropout: 0.1
2025-04-11 02:58:17,098 - embed_dropout: 0.1
2025-04-11 02:58:17,098 - res_dropout: 0.0
2025-04-11 02:58:17,098 - attn_mask: True
2025-04-11 02:58:17,098 - encoder_layers_1: 1
2025-04-11 02:58:17,098 - fusion_act: tanh
2025-04-11 02:58:17,098 - pred_output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/UMC/outputs/MIntRec/umc_umc_MIntRec_bert-base-uncased_0
2025-04-11 02:58:17,098 - model_output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/UMC/outputs/MIntRec/umc_umc_MIntRec_bert-base-uncased_0/models
2025-04-11 02:58:17,098 - ============================== End Params ==============================
2025-04-11 02:58:18,321 - Freeze all parameters but the last layer for efficiency
2025-04-11 02:58:18,360 - Pre-training start...
2025-04-11 02:58:33,750 - ***** Epoch: 1: Eval results *****
2025-04-11 02:58:33,752 -   train_loss = 5.938602685928345
2025-04-11 02:58:48,872 - ***** Epoch: 2: Eval results *****
2025-04-11 02:58:48,872 -   train_loss = 5.939184120723179
2025-04-11 02:59:03,759 - ***** Epoch: 3: Eval results *****
2025-04-11 02:59:03,759 -   train_loss = 5.937326942171369
2025-04-11 02:59:18,820 - ***** Epoch: 4: Eval results *****
2025-04-11 02:59:18,820 -   train_loss = 5.939189740589687
2025-04-11 02:59:33,280 - ***** Epoch: 5: Eval results *****
2025-04-11 02:59:33,280 -   train_loss = 5.93456768989563
2025-04-11 02:59:47,646 - ***** Epoch: 6: Eval results *****
2025-04-11 02:59:47,646 -   train_loss = 5.939224140984671
2025-04-11 03:00:02,175 - ***** Epoch: 7: Eval results *****
2025-04-11 03:00:02,175 -   train_loss = 5.937442983899798
2025-04-11 03:00:16,724 - ***** Epoch: 8: Eval results *****
2025-04-11 03:00:16,725 -   train_loss = 5.934665713991437
2025-04-11 03:00:31,689 - ***** Epoch: 9: Eval results *****
2025-04-11 03:00:31,690 -   train_loss = 5.937521934509277
2025-04-11 03:00:46,129 - ***** Epoch: 10: Eval results *****
2025-04-11 03:00:46,129 -   train_loss = 5.934695686612811
2025-04-11 03:01:00,158 - ***** Epoch: 11: Eval results *****
2025-04-11 03:01:00,158 -   train_loss = 5.9359400272369385
2025-04-11 03:01:14,083 - ***** Epoch: 12: Eval results *****
2025-04-11 03:01:14,083 -   train_loss = 5.930452278682163
2025-04-11 03:01:28,059 - ***** Epoch: 13: Eval results *****
2025-04-11 03:01:28,059 -   train_loss = 5.930329833711896
2025-04-11 03:01:41,694 - ***** Epoch: 14: Eval results *****
2025-04-11 03:01:41,694 -   train_loss = 5.928925786699567
2025-04-11 03:01:55,474 - ***** Epoch: 15: Eval results *****
2025-04-11 03:01:55,475 -   train_loss = 5.929906913212368
2025-04-11 03:02:09,750 - ***** Epoch: 16: Eval results *****
2025-04-11 03:02:09,751 -   train_loss = 5.925616025924683
2025-04-11 03:02:24,061 - ***** Epoch: 17: Eval results *****
2025-04-11 03:02:24,062 -   train_loss = 5.923224891935076
2025-04-11 03:02:38,978 - ***** Epoch: 18: Eval results *****
2025-04-11 03:02:38,978 -   train_loss = 5.917399644851685
2025-04-11 03:02:56,950 - ***** Epoch: 19: Eval results *****
2025-04-11 03:02:56,951 -   train_loss = 5.916881969996861
2025-04-11 03:03:14,100 - ***** Epoch: 20: Eval results *****
2025-04-11 03:03:14,100 -   train_loss = 5.911725793566022
2025-04-11 03:03:29,630 - ***** Epoch: 21: Eval results *****
2025-04-11 03:03:29,631 -   train_loss = 5.909027542386736
2025-04-11 03:03:43,854 - ***** Epoch: 22: Eval results *****
2025-04-11 03:03:43,855 -   train_loss = 5.901027645383563
2025-04-11 03:03:57,664 - ***** Epoch: 23: Eval results *****
2025-04-11 03:03:57,665 -   train_loss = 5.888685975755964
2025-04-11 03:04:10,794 - ***** Epoch: 24: Eval results *****
2025-04-11 03:04:10,794 -   train_loss = 5.876737628664289
2025-04-11 03:04:24,694 - ***** Epoch: 25: Eval results *****
2025-04-11 03:04:24,694 -   train_loss = 5.859231063297817
2025-04-11 03:04:38,580 - ***** Epoch: 26: Eval results *****
2025-04-11 03:04:38,580 -   train_loss = 5.834101949419294
2025-04-11 03:04:52,232 - ***** Epoch: 27: Eval results *****
2025-04-11 03:04:52,232 -   train_loss = 5.790704829352243
2025-04-11 03:05:05,852 - ***** Epoch: 28: Eval results *****
2025-04-11 03:05:05,852 -   train_loss = 5.740666048867362
2025-04-11 03:05:19,510 - ***** Epoch: 29: Eval results *****
2025-04-11 03:05:19,510 -   train_loss = 5.650965963091169
2025-04-11 03:05:32,679 - ***** Epoch: 30: Eval results *****
2025-04-11 03:05:32,680 -   train_loss = 5.55657993044172
2025-04-11 03:05:45,681 - ***** Epoch: 31: Eval results *****
2025-04-11 03:05:45,682 -   train_loss = 5.426690203802926
2025-04-11 03:05:58,779 - ***** Epoch: 32: Eval results *****
2025-04-11 03:05:58,779 -   train_loss = 5.292576994214739
2025-04-11 03:06:12,562 - ***** Epoch: 33: Eval results *****
2025-04-11 03:06:12,563 -   train_loss = 5.163678441728864
2025-04-11 03:06:27,763 - ***** Epoch: 34: Eval results *****
2025-04-11 03:06:27,764 -   train_loss = 5.045666319983346
2025-04-11 03:06:43,090 - ***** Epoch: 35: Eval results *****
2025-04-11 03:06:43,090 -   train_loss = 4.914295707430158
2025-04-11 03:06:58,585 - ***** Epoch: 36: Eval results *****
2025-04-11 03:06:58,585 -   train_loss = 4.811635051454816
2025-04-11 03:07:14,969 - ***** Epoch: 37: Eval results *****
2025-04-11 03:07:14,970 -   train_loss = 4.684908424104963
2025-04-11 03:07:31,038 - ***** Epoch: 38: Eval results *****
2025-04-11 03:07:31,039 -   train_loss = 4.591740233557565
2025-04-11 03:07:47,010 - ***** Epoch: 39: Eval results *****
2025-04-11 03:07:47,011 -   train_loss = 4.523940733500889
2025-04-11 03:08:02,325 - ***** Epoch: 40: Eval results *****
2025-04-11 03:08:02,326 -   train_loss = 4.440684352602277
2025-04-11 03:08:17,496 - ***** Epoch: 41: Eval results *****
2025-04-11 03:08:17,497 -   train_loss = 4.367914915084839
2025-04-11 03:08:33,018 - ***** Epoch: 42: Eval results *****
2025-04-11 03:08:33,018 -   train_loss = 4.2982445784977505
2025-04-11 03:08:47,956 - ***** Epoch: 43: Eval results *****
2025-04-11 03:08:47,957 -   train_loss = 4.22060523714338
2025-04-11 03:09:03,091 - ***** Epoch: 44: Eval results *****
2025-04-11 03:09:03,092 -   train_loss = 4.159450020108904
2025-04-11 03:09:17,681 - ***** Epoch: 45: Eval results *****
2025-04-11 03:09:17,681 -   train_loss = 4.093494040625436
2025-04-11 03:09:33,481 - ***** Epoch: 46: Eval results *****
2025-04-11 03:09:33,481 -   train_loss = 4.026397858347211
2025-04-11 03:09:49,511 - ***** Epoch: 47: Eval results *****
2025-04-11 03:09:49,511 -   train_loss = 3.9698496716363088
2025-04-11 03:10:04,514 - ***** Epoch: 48: Eval results *****
2025-04-11 03:10:04,514 -   train_loss = 3.9068105901990617
2025-04-11 03:10:19,556 - ***** Epoch: 49: Eval results *****
2025-04-11 03:10:19,556 -   train_loss = 3.8466909442629134
2025-04-11 03:10:33,537 - ***** Epoch: 50: Eval results *****
2025-04-11 03:10:33,538 -   train_loss = 3.7835539749690463
2025-04-11 03:10:47,807 - ***** Epoch: 51: Eval results *****
2025-04-11 03:10:47,808 -   train_loss = 3.7474265098571777
2025-04-11 03:11:02,417 - ***** Epoch: 52: Eval results *****
2025-04-11 03:11:02,417 -   train_loss = 3.6901953560965404
2025-04-11 03:11:16,816 - ***** Epoch: 53: Eval results *****
2025-04-11 03:11:16,816 -   train_loss = 3.664524265698024
2025-04-11 03:11:30,816 - ***** Epoch: 54: Eval results *****
2025-04-11 03:11:30,816 -   train_loss = 3.63210700239454
2025-04-11 03:11:44,976 - ***** Epoch: 55: Eval results *****
2025-04-11 03:11:44,976 -   train_loss = 3.5982449225017
2025-04-11 03:11:59,639 - ***** Epoch: 56: Eval results *****
2025-04-11 03:11:59,639 -   train_loss = 3.567975163459778
2025-04-11 03:12:14,064 - ***** Epoch: 57: Eval results *****
2025-04-11 03:12:14,064 -   train_loss = 3.5361410890306746
2025-04-11 03:12:28,107 - ***** Epoch: 58: Eval results *****
2025-04-11 03:12:28,108 -   train_loss = 3.513167602675302
2025-04-11 03:12:42,014 - ***** Epoch: 59: Eval results *****
2025-04-11 03:12:42,014 -   train_loss = 3.4874345575060164
2025-04-11 03:12:55,841 - ***** Epoch: 60: Eval results *****
2025-04-11 03:12:55,841 -   train_loss = 3.4690817083631242
2025-04-11 03:13:10,021 - ***** Epoch: 61: Eval results *****
2025-04-11 03:13:10,021 -   train_loss = 3.4508738858359203
2025-04-11 03:13:24,418 - ***** Epoch: 62: Eval results *****
2025-04-11 03:13:24,418 -   train_loss = 3.4435283286230907
2025-04-11 03:13:39,477 - ***** Epoch: 63: Eval results *****
2025-04-11 03:13:39,477 -   train_loss = 3.429978234427316
2025-04-11 03:13:54,222 - ***** Epoch: 64: Eval results *****
2025-04-11 03:13:54,222 -   train_loss = 3.397789512361799
2025-04-11 03:14:09,192 - ***** Epoch: 65: Eval results *****
2025-04-11 03:14:09,192 -   train_loss = 3.3990526369639804
2025-04-11 03:14:24,393 - ***** Epoch: 66: Eval results *****
2025-04-11 03:14:24,393 -   train_loss = 3.3777200494493758
2025-04-11 03:14:39,276 - ***** Epoch: 67: Eval results *****
2025-04-11 03:14:39,276 -   train_loss = 3.3554538999285017
2025-04-11 03:14:53,985 - ***** Epoch: 68: Eval results *****
2025-04-11 03:14:53,985 -   train_loss = 3.350895268576486
2025-04-11 03:15:08,987 - ***** Epoch: 69: Eval results *****
2025-04-11 03:15:08,988 -   train_loss = 3.3438134704317366
2025-04-11 03:15:24,288 - ***** Epoch: 70: Eval results *****
2025-04-11 03:15:24,289 -   train_loss = 3.3466955593654086
2025-04-11 03:15:40,178 - ***** Epoch: 71: Eval results *****
2025-04-11 03:15:40,179 -   train_loss = 3.344660861151559
2025-04-11 03:15:55,794 - ***** Epoch: 72: Eval results *****
2025-04-11 03:15:55,794 -   train_loss = 3.3309171199798584
2025-04-11 03:16:11,335 - ***** Epoch: 73: Eval results *****
2025-04-11 03:16:11,336 -   train_loss = 3.3242812837873186
2025-04-11 03:16:26,335 - ***** Epoch: 74: Eval results *****
2025-04-11 03:16:26,335 -   train_loss = 3.317352533340454
2025-04-11 03:16:40,795 - ***** Epoch: 75: Eval results *****
2025-04-11 03:16:40,796 -   train_loss = 3.318174277033125
2025-04-11 03:16:55,730 - ***** Epoch: 76: Eval results *****
2025-04-11 03:16:55,730 -   train_loss = 3.2948563269206455
2025-04-11 03:17:09,973 - ***** Epoch: 77: Eval results *****
2025-04-11 03:17:09,974 -   train_loss = 3.285103644643511
2025-04-11 03:17:24,797 - ***** Epoch: 78: Eval results *****
2025-04-11 03:17:24,797 -   train_loss = 3.2878388336726596
2025-04-11 03:17:38,855 - ***** Epoch: 79: Eval results *****
2025-04-11 03:17:38,855 -   train_loss = 3.2842979771750316
2025-04-11 03:17:53,858 - ***** Epoch: 80: Eval results *****
2025-04-11 03:17:53,858 -   train_loss = 3.278353009905134
2025-04-11 03:18:07,990 - ***** Epoch: 81: Eval results *****
2025-04-11 03:18:07,990 -   train_loss = 3.2710762875420705
2025-04-11 03:18:23,202 - ***** Epoch: 82: Eval results *****
2025-04-11 03:18:23,202 -   train_loss = 3.269394568034581
2025-04-11 03:18:37,568 - ***** Epoch: 83: Eval results *****
2025-04-11 03:18:37,568 -   train_loss = 3.2769948073795865
2025-04-11 03:18:51,969 - ***** Epoch: 84: Eval results *****
2025-04-11 03:18:51,970 -   train_loss = 3.2636313438415527
2025-04-11 03:19:07,544 - ***** Epoch: 85: Eval results *****
2025-04-11 03:19:07,545 -   train_loss = 3.2707871879850114
2025-04-11 03:19:22,189 - ***** Epoch: 86: Eval results *****
2025-04-11 03:19:22,189 -   train_loss = 3.2653057745524814
2025-04-11 03:19:37,567 - ***** Epoch: 87: Eval results *****
2025-04-11 03:19:37,567 -   train_loss = 3.2536890847342357
2025-04-11 03:19:52,816 - ***** Epoch: 88: Eval results *****
2025-04-11 03:19:52,816 -   train_loss = 3.255451491900853
2025-04-11 03:20:08,153 - ***** Epoch: 89: Eval results *****
2025-04-11 03:20:08,153 -   train_loss = 3.25709673336574
2025-04-11 03:20:23,034 - ***** Epoch: 90: Eval results *****
2025-04-11 03:20:23,034 -   train_loss = 3.2552014759608676
2025-04-11 03:20:38,273 - ***** Epoch: 91: Eval results *****
2025-04-11 03:20:38,273 -   train_loss = 3.24813973903656
2025-04-11 03:20:53,222 - ***** Epoch: 92: Eval results *****
2025-04-11 03:20:53,222 -   train_loss = 3.2444402830941335
2025-04-11 03:21:08,377 - ***** Epoch: 93: Eval results *****
2025-04-11 03:21:08,378 -   train_loss = 3.247923357146127
2025-04-11 03:21:22,857 - ***** Epoch: 94: Eval results *****
2025-04-11 03:21:22,857 -   train_loss = 3.249437826020377
2025-04-11 03:21:37,469 - ***** Epoch: 95: Eval results *****
2025-04-11 03:21:37,469 -   train_loss = 3.253887483051845
2025-04-11 03:21:51,678 - ***** Epoch: 96: Eval results *****
2025-04-11 03:21:51,679 -   train_loss = 3.253412161554609
2025-04-11 03:22:06,420 - ***** Epoch: 97: Eval results *****
2025-04-11 03:22:06,421 -   train_loss = 3.257537739617484
2025-04-11 03:22:21,461 - ***** Epoch: 98: Eval results *****
2025-04-11 03:22:21,462 -   train_loss = 3.2643692663737705
2025-04-11 03:22:35,444 - ***** Epoch: 99: Eval results *****
2025-04-11 03:22:35,444 -   train_loss = 3.2478441510881697
2025-04-11 03:22:50,292 - ***** Epoch: 100: Eval results *****
2025-04-11 03:22:50,292 -   train_loss = 3.2604271854673113
2025-04-11 03:22:51,941 - Pre-training finished...
2025-04-11 03:22:52,220 - Freeze all parameters but the last layer for efficiency
2025-04-11 03:22:52,232 - Multimodal Intent Recognition begins...
2025-04-11 03:22:52,232 - Training begins...
2025-04-11 03:23:08,958 - Initializing centroids with K-means++...
2025-04-11 03:23:09,110 - K-means++ used 0.15 s
2025-04-11 03:23:38,245 - K-means used 0.03 s
2025-04-11 03:23:39,497 - ***** Epoch: 1 *****
2025-04-11 03:23:39,497 - Supervised Training Loss: 4.925210
2025-04-11 03:23:39,498 - Unsupervised Training Loss: 5.182590
2025-04-11 03:24:09,598 - K-means used 0.03 s
2025-04-11 03:24:11,180 - ***** Epoch: 2 *****
2025-04-11 03:24:11,180 - Supervised Training Loss: 3.889520
2025-04-11 03:24:11,180 - Unsupervised Training Loss: 5.196760
2025-04-11 03:24:40,215 - K-means used 0.02 s
2025-04-11 03:24:41,829 - ***** Epoch: 3 *****
2025-04-11 03:24:41,829 - Supervised Training Loss: 5.343350
2025-04-11 03:24:41,829 - Unsupervised Training Loss: 5.035780
2025-04-11 03:25:11,138 - K-means used 0.02 s
2025-04-11 03:25:12,555 - ***** Epoch: 4 *****
2025-04-11 03:25:12,555 - Supervised Training Loss: 5.217730
2025-04-11 03:25:12,555 - Unsupervised Training Loss: 5.089300
2025-04-11 03:25:41,204 - K-means used 0.06 s
2025-04-11 03:25:42,706 - ***** Epoch: 5 *****
2025-04-11 03:25:42,707 - Supervised Training Loss: 4.909720
2025-04-11 03:25:42,707 - Unsupervised Training Loss: 5.125100
2025-04-11 03:26:11,710 - K-means used 0.02 s
2025-04-11 03:26:13,454 - ***** Epoch: 6 *****
2025-04-11 03:26:13,455 - Supervised Training Loss: 5.352020
2025-04-11 03:26:13,455 - Unsupervised Training Loss: 4.913980
2025-04-11 03:26:46,983 - K-means used 0.02 s
2025-04-11 03:26:48,545 - ***** Epoch: 7 *****
2025-04-11 03:26:48,546 - Supervised Training Loss: 5.271990
2025-04-11 03:26:48,546 - Unsupervised Training Loss: 5.024300
2025-04-11 03:27:23,238 - K-means used 0.02 s
2025-04-11 03:27:24,918 - ***** Epoch: 8 *****
2025-04-11 03:27:24,918 - Supervised Training Loss: 5.133010
2025-04-11 03:27:24,918 - Unsupervised Training Loss: 5.082580
2025-04-11 03:27:59,271 - K-means used 0.02 s
2025-04-11 03:28:01,063 - ***** Epoch: 9 *****
2025-04-11 03:28:01,063 - Supervised Training Loss: 5.349290
2025-04-11 03:28:01,063 - Unsupervised Training Loss: 5.116920
2025-04-11 03:28:32,108 - K-means used 0.06 s
2025-04-11 03:28:33,821 - ***** Epoch: 10 *****
2025-04-11 03:28:33,821 - Supervised Training Loss: 5.283470
2025-04-11 03:28:33,821 - Unsupervised Training Loss: 4.948520
2025-04-11 03:29:03,740 - K-means used 0.02 s
2025-04-11 03:29:05,576 - ***** Epoch: 11 *****
2025-04-11 03:29:05,577 - Supervised Training Loss: 5.199920
2025-04-11 03:29:05,577 - Unsupervised Training Loss: 5.043750
2025-04-11 03:29:33,404 - K-means used 0.06 s
2025-04-11 03:29:35,238 - ***** Epoch: 12 *****
2025-04-11 03:29:35,238 - Supervised Training Loss: 5.338720
2025-04-11 03:29:35,238 - Unsupervised Training Loss: 5.092130
2025-04-11 03:30:03,999 - K-means used 0.09 s
2025-04-11 03:30:05,912 - ***** Epoch: 13 *****
2025-04-11 03:30:05,912 - Supervised Training Loss: 5.294360
2025-04-11 03:30:05,912 - Unsupervised Training Loss: 4.817270
2025-04-11 03:30:34,149 - K-means used 0.02 s
2025-04-11 03:30:36,139 - ***** Epoch: 14 *****
2025-04-11 03:30:36,139 - Supervised Training Loss: 5.242230
2025-04-11 03:30:36,140 - Unsupervised Training Loss: 4.945590
2025-04-11 03:31:04,390 - K-means used 0.02 s
2025-04-11 03:31:06,518 - ***** Epoch: 15 *****
2025-04-11 03:31:06,518 - Supervised Training Loss: 5.092320
2025-04-11 03:31:06,518 - Unsupervised Training Loss: 5.054710
2025-04-11 03:31:34,336 - K-means used 0.04 s
2025-04-11 03:31:36,326 - ***** Epoch: 16 *****
2025-04-11 03:31:36,326 - Supervised Training Loss: 5.310220
2025-04-11 03:31:36,326 - Unsupervised Training Loss: 4.471170
2025-04-11 03:32:06,156 - K-means used 0.03 s
2025-04-11 03:32:08,164 - ***** Epoch: 17 *****
2025-04-11 03:32:08,164 - Supervised Training Loss: 5.278510
2025-04-11 03:32:08,164 - Unsupervised Training Loss: 4.715620
2025-04-11 03:32:26,594 - Training is finished...
2025-04-11 03:32:26,594 - Testing begins...
2025-04-11 03:32:33,313 - ***** Test results *****
2025-04-11 03:32:33,314 -   ACC = 37.98
2025-04-11 03:32:33,314 -   ARI = 17.57
2025-04-11 03:32:33,314 -   NMI = 41.72
2025-04-11 03:32:33,314 -   fmi = 22.79
2025-04-11 03:32:33,314 - Testing is finished...
2025-04-11 03:32:33,314 - Multimodal intent recognition is finished...
2025-04-11 03:32:33,314 - Results are saved in results/results_umc.csv
