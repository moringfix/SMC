2025-04-16 15:06:38,846 - 【无监督】进入了无监督的设定中, 加载数据集
2025-04-16 15:06:38,846 - data preparation...
2025-04-16 15:06:48,219 - Number of train samples = 1779
2025-04-16 15:06:48,220 - Number of testing samples = 445
2025-04-16 15:06:48,220 - data preparation...
2025-04-16 15:06:50,436 - num_train_examples = 1779
2025-04-16 15:06:50,436 - ============================== Params ==============================
2025-04-16 15:06:50,436 - logger_name: umc_umc_bert-base-uncased_MIntRec_0
2025-04-16 15:06:50,436 - dataset: MIntRec
2025-04-16 15:06:50,436 - multimodal_method: umc
2025-04-16 15:06:50,436 - method: umc
2025-04-16 15:06:50,436 - setting: unsupervised
2025-04-16 15:06:50,436 - text_backbone: bert-base-uncased
2025-04-16 15:06:50,436 - seed: 0
2025-04-16 15:06:50,437 - num_workers: 16
2025-04-16 15:06:50,437 - log_id: umc_umc_bert-base-uncased_MIntRec_0_2025-04-16-15-06-38
2025-04-16 15:06:50,437 - gpu_id: 1
2025-04-16 15:06:50,437 - data_path: /root/autodl-tmp/home/Share/Dataset/LZH
2025-04-16 15:06:50,437 - train: True
2025-04-16 15:06:50,437 - tune: True
2025-04-16 15:06:50,437 - save_model: True
2025-04-16 15:06:50,437 - save_results: True
2025-04-16 15:06:50,437 - log_path: logs
2025-04-16 15:06:50,437 - cache_path: cache
2025-04-16 15:06:50,437 - video_data_path: video_data
2025-04-16 15:06:50,437 - audio_data_path: audio_data
2025-04-16 15:06:50,437 - video_feats_path: swin_feats.pkl
2025-04-16 15:06:50,437 - audio_feats_path: wavlm_feats.pkl
2025-04-16 15:06:50,437 - results_path: results
2025-04-16 15:06:50,437 - output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/SMC/outputs_test2/MIntRec
2025-04-16 15:06:50,437 - model_path: models
2025-04-16 15:06:50,437 - config_file_name: umc_MIntRec
2025-04-16 15:06:50,437 - results_file_name: results_umc.csv
2025-04-16 15:06:50,437 - text_pretrained_model: uncased_L-12_H-768_A-12
2025-04-16 15:06:50,437 - pretrained_bert_model: uncased_L-12_H-768_A-12
2025-04-16 15:06:50,437 - pretrain_batch_size: 128
2025-04-16 15:06:50,437 - train_batch_size: 128
2025-04-16 15:06:50,437 - eval_batch_size: 128
2025-04-16 15:06:50,437 - test_batch_size: 128
2025-04-16 15:06:50,438 - num_pretrain_epochs: 100
2025-04-16 15:06:50,438 - num_train_epochs: 100
2025-04-16 15:06:50,438 - pretrain: [True]
2025-04-16 15:06:50,438 - aligned_method: ctc
2025-04-16 15:06:50,438 - need_aligned: False
2025-04-16 15:06:50,438 - freeze_pretrain_bert_parameters: [True]
2025-04-16 15:06:50,438 - freeze_train_bert_parameters: [True]
2025-04-16 15:06:50,438 - pretrain_temperature: [0.1]
2025-04-16 15:06:50,438 - train_temperature_sup: [0.5]
2025-04-16 15:06:50,438 - train_temperature_unsup: [2]
2025-04-16 15:06:50,438 - activation: tanh
2025-04-16 15:06:50,438 - lr_pre: [3e-05]
2025-04-16 15:06:50,438 - lr: [5e-05]
2025-04-16 15:06:50,438 - delta: [0.05]
2025-04-16 15:06:50,438 - thres: [0.1]
2025-04-16 15:06:50,438 - topk: [5]
2025-04-16 15:06:50,438 - weight_decay: 0.01
2025-04-16 15:06:50,438 - feat_dim: 768
2025-04-16 15:06:50,438 - hidden_size: 768
2025-04-16 15:06:50,438 - grad_clip: -1.0
2025-04-16 15:06:50,438 - warmup_proportion: [0.1]
2025-04-16 15:06:50,438 - hidden_dropout_prob: 0.1
2025-04-16 15:06:50,438 - weight: 1.0
2025-04-16 15:06:50,438 - loss_mode: rdrop
2025-04-16 15:06:50,438 - base_dim: 256
2025-04-16 15:06:50,439 - nheads: 8
2025-04-16 15:06:50,439 - attn_dropout: 0.1
2025-04-16 15:06:50,439 - relu_dropout: 0.1
2025-04-16 15:06:50,439 - embed_dropout: 0.01
2025-04-16 15:06:50,439 - res_dropout: 0.0
2025-04-16 15:06:50,439 - attn_mask: True
2025-04-16 15:06:50,439 - encoder_layers_1: 1
2025-04-16 15:06:50,439 - fusion_act: tanh
2025-04-16 15:06:50,439 - pred_output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/SMC/outputs_test2/MIntRec/umc_umc_MIntRec_bert-base-uncased_0
2025-04-16 15:06:50,439 - model_output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/SMC/outputs_test2/MIntRec/umc_umc_MIntRec_bert-base-uncased_0/models
2025-04-16 15:06:50,439 - text_seq_len: 30
2025-04-16 15:06:50,439 - video_seq_len: 230
2025-04-16 15:06:50,439 - audio_seq_len: 480
2025-04-16 15:06:50,439 - text_feat_dim: 768
2025-04-16 15:06:50,439 - video_feat_dim: 1024
2025-04-16 15:06:50,439 - audio_feat_dim: 768
2025-04-16 15:06:50,439 - num_labels: 20
2025-04-16 15:06:50,439 - num_train_examples: 1779
2025-04-16 15:06:50,440 - ============================== End Params ==============================
2025-04-16 15:06:51,839 - Freeze all parameters but the last layer for efficiency
2025-04-16 15:06:51,874 - Pre-training start...
2025-04-16 15:07:11,452 - ***** Epoch: 1: Eval results *****
2025-04-16 15:07:11,452 -   train_loss = 5.948308161326817
2025-04-16 15:07:33,125 - ***** Epoch: 2: Eval results *****
2025-04-16 15:07:33,126 -   train_loss = 5.944840703691755
2025-04-16 15:07:55,927 - ***** Epoch: 3: Eval results *****
2025-04-16 15:07:55,928 -   train_loss = 5.9152582713535855
2025-04-16 15:08:20,785 - ***** Epoch: 4: Eval results *****
2025-04-16 15:08:20,785 -   train_loss = 5.877590996878488
2025-04-16 15:08:41,947 - ***** Epoch: 5: Eval results *****
2025-04-16 15:08:41,947 -   train_loss = 5.761348792484829
2025-04-16 15:09:01,878 - ***** Epoch: 6: Eval results *****
2025-04-16 15:09:01,878 -   train_loss = 5.358462946755545
2025-04-16 15:09:24,301 - ***** Epoch: 7: Eval results *****
2025-04-16 15:09:24,301 -   train_loss = 4.641392537525722
2025-04-16 15:09:46,976 - ***** Epoch: 8: Eval results *****
2025-04-16 15:09:46,977 -   train_loss = 3.9226785557610646
2025-04-16 15:10:09,014 - ***** Epoch: 9: Eval results *****
2025-04-16 15:10:09,014 -   train_loss = 3.3218030588967458
2025-04-16 15:10:31,823 - ***** Epoch: 10: Eval results *****
2025-04-16 15:10:31,823 -   train_loss = 2.818396193640573
2025-04-16 15:10:55,085 - ***** Epoch: 11: Eval results *****
2025-04-16 15:10:55,086 -   train_loss = 2.462585210800171
2025-04-16 15:11:18,075 - ***** Epoch: 12: Eval results *****
2025-04-16 15:11:18,076 -   train_loss = 2.233554516519819
2025-04-16 15:11:44,064 - ***** Epoch: 13: Eval results *****
2025-04-16 15:11:44,065 -   train_loss = 2.0710644125938416
2025-04-16 15:12:07,960 - ***** Epoch: 14: Eval results *****
2025-04-16 15:12:07,960 -   train_loss = 1.9520979864256722
2025-04-16 15:12:31,010 - ***** Epoch: 15: Eval results *****
2025-04-16 15:12:31,011 -   train_loss = 1.8459420374461584
2025-04-16 15:12:55,768 - ***** Epoch: 16: Eval results *****
2025-04-16 15:12:55,768 -   train_loss = 1.749836802482605
2025-04-16 15:13:19,813 - ***** Epoch: 17: Eval results *****
2025-04-16 15:13:19,814 -   train_loss = 1.7007366929735457
2025-04-16 15:13:42,949 - ***** Epoch: 18: Eval results *****
2025-04-16 15:13:42,950 -   train_loss = 1.659919330051967
2025-04-16 15:14:06,005 - ***** Epoch: 19: Eval results *****
2025-04-16 15:14:06,006 -   train_loss = 1.6230391093662806
2025-04-16 15:14:28,092 - ***** Epoch: 20: Eval results *****
2025-04-16 15:14:28,092 -   train_loss = 1.5700156007494246
2025-04-16 15:14:53,166 - ***** Epoch: 21: Eval results *****
2025-04-16 15:14:53,166 -   train_loss = 1.5543595467294966
2025-04-16 15:15:15,517 - ***** Epoch: 22: Eval results *****
2025-04-16 15:15:15,518 -   train_loss = 1.512546820299966
2025-04-16 15:15:38,286 - ***** Epoch: 23: Eval results *****
2025-04-16 15:15:38,286 -   train_loss = 1.4884953583989824
2025-04-16 15:16:00,789 - ***** Epoch: 24: Eval results *****
2025-04-16 15:16:00,789 -   train_loss = 1.4484980702400208
2025-04-16 15:16:22,550 - ***** Epoch: 25: Eval results *****
2025-04-16 15:16:22,550 -   train_loss = 1.4384504130908422
2025-04-16 15:16:45,069 - ***** Epoch: 26: Eval results *****
2025-04-16 15:16:45,070 -   train_loss = 1.4134248409952437
2025-04-16 15:17:06,136 - ***** Epoch: 27: Eval results *****
2025-04-16 15:17:06,136 -   train_loss = 1.4035042439188277
2025-04-16 15:17:28,579 - ***** Epoch: 28: Eval results *****
2025-04-16 15:17:28,581 -   train_loss = 1.3795268961361475
2025-04-16 15:17:50,670 - ***** Epoch: 29: Eval results *****
2025-04-16 15:17:50,670 -   train_loss = 1.3724480186189925
2025-04-16 15:18:14,307 - ***** Epoch: 30: Eval results *****
2025-04-16 15:18:14,308 -   train_loss = 1.3527937872069222
2025-04-16 15:18:37,158 - ***** Epoch: 31: Eval results *****
2025-04-16 15:18:37,158 -   train_loss = 1.339205997330802
2025-04-16 15:18:59,433 - ***** Epoch: 32: Eval results *****
2025-04-16 15:18:59,433 -   train_loss = 1.3365864668573653
2025-04-16 15:19:21,478 - ***** Epoch: 33: Eval results *****
2025-04-16 15:19:21,479 -   train_loss = 1.3161698750087194
2025-04-16 15:19:44,558 - ***** Epoch: 34: Eval results *****
2025-04-16 15:19:44,559 -   train_loss = 1.3057106137275696
2025-04-16 15:20:05,313 - ***** Epoch: 35: Eval results *****
2025-04-16 15:20:05,313 -   train_loss = 1.3064734850611006
2025-04-16 15:20:25,372 - ***** Epoch: 36: Eval results *****
2025-04-16 15:20:25,372 -   train_loss = 1.2901365756988525
2025-04-16 15:20:47,185 - ***** Epoch: 37: Eval results *****
2025-04-16 15:20:47,186 -   train_loss = 1.2797287276812963
2025-04-16 15:21:11,082 - ***** Epoch: 38: Eval results *****
2025-04-16 15:21:11,082 -   train_loss = 1.265962038721357
2025-04-16 15:21:31,957 - ***** Epoch: 39: Eval results *****
2025-04-16 15:21:31,958 -   train_loss = 1.2672541567257471
2025-04-16 15:21:52,860 - ***** Epoch: 40: Eval results *****
2025-04-16 15:21:52,861 -   train_loss = 1.2533889412879944
2025-04-16 15:22:15,628 - ***** Epoch: 41: Eval results *****
2025-04-16 15:22:15,629 -   train_loss = 1.2485151546342033
2025-04-16 15:22:36,587 - ***** Epoch: 42: Eval results *****
2025-04-16 15:22:36,588 -   train_loss = 1.2516771980694361
2025-04-16 15:22:58,161 - ***** Epoch: 43: Eval results *****
2025-04-16 15:22:58,162 -   train_loss = 1.2336361748831612
2025-04-16 15:23:18,958 - ***** Epoch: 44: Eval results *****
2025-04-16 15:23:18,958 -   train_loss = 1.2376842839377267
2025-04-16 15:23:38,291 - ***** Epoch: 45: Eval results *****
2025-04-16 15:23:38,291 -   train_loss = 1.237496086529323
2025-04-16 15:23:59,249 - ***** Epoch: 46: Eval results *****
2025-04-16 15:23:59,250 -   train_loss = 1.2224466630390711
2025-04-16 15:24:24,045 - ***** Epoch: 47: Eval results *****
2025-04-16 15:24:24,046 -   train_loss = 1.2159348300525121
2025-04-16 15:24:46,337 - ***** Epoch: 48: Eval results *****
2025-04-16 15:24:46,337 -   train_loss = 1.2097120455333166
2025-04-16 15:25:07,380 - ***** Epoch: 49: Eval results *****
2025-04-16 15:25:07,381 -   train_loss = 1.2114353605679102
2025-04-16 15:25:29,070 - ***** Epoch: 50: Eval results *****
2025-04-16 15:25:29,071 -   train_loss = 1.2036064437457494
2025-04-16 15:25:50,649 - ***** Epoch: 51: Eval results *****
2025-04-16 15:25:50,650 -   train_loss = 1.2089083535330636
2025-04-16 15:26:10,180 - ***** Epoch: 52: Eval results *****
2025-04-16 15:26:10,181 -   train_loss = 1.204098709992
2025-04-16 15:26:29,989 - ***** Epoch: 53: Eval results *****
2025-04-16 15:26:29,989 -   train_loss = 1.2003087486539568
2025-04-16 15:26:51,485 - ***** Epoch: 54: Eval results *****
2025-04-16 15:26:51,485 -   train_loss = 1.2033536093575614
2025-04-16 15:27:13,481 - ***** Epoch: 55: Eval results *****
2025-04-16 15:27:13,481 -   train_loss = 1.1934996587889535
2025-04-16 15:27:39,497 - ***** Epoch: 56: Eval results *****
2025-04-16 15:27:39,497 -   train_loss = 1.1860239335468836
2025-04-16 15:28:02,121 - ***** Epoch: 57: Eval results *****
2025-04-16 15:28:02,121 -   train_loss = 1.1688565271241325
2025-04-16 15:28:23,761 - ***** Epoch: 58: Eval results *****
2025-04-16 15:28:23,762 -   train_loss = 1.1828912666865758
2025-04-16 15:28:45,584 - ***** Epoch: 59: Eval results *****
2025-04-16 15:28:45,584 -   train_loss = 1.177600588117327
2025-04-16 15:29:06,662 - ***** Epoch: 60: Eval results *****
2025-04-16 15:29:06,662 -   train_loss = 1.1671376824378967
2025-04-16 15:29:28,942 - ***** Epoch: 61: Eval results *****
2025-04-16 15:29:28,942 -   train_loss = 1.1766937630517142
2025-04-16 15:29:49,880 - ***** Epoch: 62: Eval results *****
2025-04-16 15:29:49,880 -   train_loss = 1.1638937592506409
2025-04-16 15:30:11,790 - ***** Epoch: 63: Eval results *****
2025-04-16 15:30:11,790 -   train_loss = 1.1685126764433724
2025-04-16 15:30:32,879 - ***** Epoch: 64: Eval results *****
2025-04-16 15:30:32,880 -   train_loss = 1.1607223323413305
2025-04-16 15:30:56,710 - ***** Epoch: 65: Eval results *****
2025-04-16 15:30:56,711 -   train_loss = 1.1597664952278137
2025-04-16 15:31:18,273 - ***** Epoch: 66: Eval results *****
2025-04-16 15:31:18,273 -   train_loss = 1.1603881972176688
2025-04-16 15:31:38,530 - ***** Epoch: 67: Eval results *****
2025-04-16 15:31:38,530 -   train_loss = 1.1496135592460632
2025-04-16 15:31:59,648 - ***** Epoch: 68: Eval results *****
2025-04-16 15:31:59,648 -   train_loss = 1.145224358354296
2025-04-16 15:32:21,460 - ***** Epoch: 69: Eval results *****
2025-04-16 15:32:21,461 -   train_loss = 1.1458462136132377
2025-04-16 15:32:41,922 - ***** Epoch: 70: Eval results *****
2025-04-16 15:32:41,922 -   train_loss = 1.150626310280391
2025-04-16 15:33:04,240 - ***** Epoch: 71: Eval results *****
2025-04-16 15:33:04,240 -   train_loss = 1.1423365558896745
2025-04-16 15:33:24,478 - ***** Epoch: 72: Eval results *****
2025-04-16 15:33:24,479 -   train_loss = 1.1532032319477625
2025-04-16 15:33:45,747 - ***** Epoch: 73: Eval results *****
2025-04-16 15:33:45,747 -   train_loss = 1.1520304850169591
2025-04-16 15:34:11,006 - ***** Epoch: 74: Eval results *****
2025-04-16 15:34:11,006 -   train_loss = 1.1471394470759801
2025-04-16 15:34:32,458 - ***** Epoch: 75: Eval results *****
2025-04-16 15:34:32,458 -   train_loss = 1.1486940213612147
2025-04-16 15:34:53,414 - ***** Epoch: 76: Eval results *****
2025-04-16 15:34:53,415 -   train_loss = 1.1404365130833216
2025-04-16 15:35:13,237 - ***** Epoch: 77: Eval results *****
2025-04-16 15:35:13,238 -   train_loss = 1.1339923909732275
2025-04-16 15:35:35,444 - ***** Epoch: 78: Eval results *****
2025-04-16 15:35:35,444 -   train_loss = 1.1389651979718889
2025-04-16 15:35:55,778 - ***** Epoch: 79: Eval results *****
2025-04-16 15:35:55,778 -   train_loss = 1.1425555007798331
2025-04-16 15:36:17,792 - ***** Epoch: 80: Eval results *****
2025-04-16 15:36:17,792 -   train_loss = 1.1244787658963884
2025-04-16 15:36:39,533 - ***** Epoch: 81: Eval results *****
2025-04-16 15:36:39,533 -   train_loss = 1.1409235766955785
2025-04-16 15:37:01,990 - ***** Epoch: 82: Eval results *****
2025-04-16 15:37:01,990 -   train_loss = 1.13343973670687
2025-04-16 15:37:26,972 - ***** Epoch: 83: Eval results *****
2025-04-16 15:37:26,973 -   train_loss = 1.1460311157362801
2025-04-16 15:37:48,017 - ***** Epoch: 84: Eval results *****
2025-04-16 15:37:48,017 -   train_loss = 1.1317983099392481
2025-04-16 15:38:10,453 - ***** Epoch: 85: Eval results *****
2025-04-16 15:38:10,453 -   train_loss = 1.135277271270752
2025-04-16 15:38:33,169 - ***** Epoch: 86: Eval results *****
2025-04-16 15:38:33,169 -   train_loss = 1.1317369597298759
2025-04-16 15:38:54,458 - ***** Epoch: 87: Eval results *****
2025-04-16 15:38:54,459 -   train_loss = 1.1390146698270525
2025-04-16 15:39:16,389 - ***** Epoch: 88: Eval results *****
2025-04-16 15:39:16,389 -   train_loss = 1.1357526694025313
2025-04-16 15:39:36,428 - ***** Epoch: 89: Eval results *****
2025-04-16 15:39:36,428 -   train_loss = 1.1242952176502772
2025-04-16 15:39:55,689 - ***** Epoch: 90: Eval results *****
2025-04-16 15:39:55,689 -   train_loss = 1.138107648917607
2025-04-16 15:40:16,577 - ***** Epoch: 91: Eval results *****
2025-04-16 15:40:16,577 -   train_loss = 1.1224046179226466
2025-04-16 15:40:39,810 - ***** Epoch: 92: Eval results *****
2025-04-16 15:40:39,810 -   train_loss = 1.1337539979389735
2025-04-16 15:41:02,042 - ***** Epoch: 93: Eval results *****
2025-04-16 15:41:02,042 -   train_loss = 1.1316068087305342
2025-04-16 15:41:23,203 - ***** Epoch: 94: Eval results *****
2025-04-16 15:41:23,204 -   train_loss = 1.1348109756197249
2025-04-16 15:41:43,922 - ***** Epoch: 95: Eval results *****
2025-04-16 15:41:43,922 -   train_loss = 1.130014419555664
2025-04-16 15:42:04,174 - ***** Epoch: 96: Eval results *****
2025-04-16 15:42:04,174 -   train_loss = 1.122752036367144
2025-04-16 15:42:26,238 - ***** Epoch: 97: Eval results *****
2025-04-16 15:42:26,239 -   train_loss = 1.1288612570081438
2025-04-16 15:42:46,947 - ***** Epoch: 98: Eval results *****
2025-04-16 15:42:46,947 -   train_loss = 1.1385548199926103
2025-04-16 15:43:09,368 - ***** Epoch: 99: Eval results *****
2025-04-16 15:43:09,369 -   train_loss = 1.1282994491713387
2025-04-16 15:43:32,175 - ***** Epoch: 100: Eval results *****
2025-04-16 15:43:32,175 -   train_loss = 1.1291024770055498
2025-04-16 15:43:32,765 - Pre-training finished...
2025-04-16 15:43:33,128 - Freeze all parameters but the last layer for efficiency
2025-04-16 15:43:33,140 - Multimodal Intent Recognition begins...
2025-04-16 15:43:33,141 - Training begins...
2025-04-16 15:43:53,041 - Initializing centroids with K-means++...
2025-04-16 15:43:53,307 - K-means++ used 0.27 s
2025-04-16 15:44:33,145 - K-means used 0.02 s
2025-04-16 15:44:35,543 - ***** Epoch: 1 *****
2025-04-16 15:44:35,544 - Supervised Training Loss: 4.360740
2025-04-16 15:44:35,544 - Unsupervised Training Loss: 5.503640
2025-04-16 15:45:11,438 - K-means used 0.02 s
2025-04-16 15:45:13,038 - ***** Epoch: 2 *****
2025-04-16 15:45:13,039 - Supervised Training Loss: 3.802120
2025-04-16 15:45:13,039 - Unsupervised Training Loss: 5.535330
2025-04-16 15:45:48,319 - K-means used 0.06 s
2025-04-16 15:45:50,006 - ***** Epoch: 3 *****
2025-04-16 15:45:50,006 - Supervised Training Loss: 4.928250
2025-04-16 15:45:50,006 - Unsupervised Training Loss: 5.399920
2025-04-16 15:46:23,100 - K-means used 0.04 s
2025-04-16 15:46:25,040 - ***** Epoch: 4 *****
2025-04-16 15:46:25,040 - Supervised Training Loss: 4.714250
2025-04-16 15:46:25,040 - Unsupervised Training Loss: 5.476090
2025-04-16 15:46:58,250 - K-means used 0.02 s
2025-04-16 15:47:00,002 - ***** Epoch: 5 *****
2025-04-16 15:47:00,002 - Supervised Training Loss: 4.427400
2025-04-16 15:47:00,002 - Unsupervised Training Loss: 5.515170
2025-04-16 15:47:37,830 - K-means used 0.03 s
2025-04-16 15:47:39,282 - ***** Epoch: 6 *****
2025-04-16 15:47:39,282 - Supervised Training Loss: 4.807770
2025-04-16 15:47:39,282 - Unsupervised Training Loss: 5.317050
2025-04-16 15:48:13,399 - K-means used 0.02 s
2025-04-16 15:48:15,190 - ***** Epoch: 7 *****
2025-04-16 15:48:15,190 - Supervised Training Loss: 4.699870
2025-04-16 15:48:15,190 - Unsupervised Training Loss: 5.438900
2025-04-16 15:48:50,361 - K-means used 0.02 s
2025-04-16 15:48:52,243 - ***** Epoch: 8 *****
2025-04-16 15:48:52,244 - Supervised Training Loss: 4.544800
2025-04-16 15:48:52,244 - Unsupervised Training Loss: 5.495860
2025-04-16 15:49:26,520 - K-means used 0.05 s
2025-04-16 15:49:28,201 - ***** Epoch: 9 *****
2025-04-16 15:49:28,201 - Supervised Training Loss: 4.759030
2025-04-16 15:49:28,201 - Unsupervised Training Loss: 5.535220
2025-04-16 15:50:02,898 - K-means used 0.1 s
2025-04-16 15:50:04,503 - ***** Epoch: 10 *****
2025-04-16 15:50:04,504 - Supervised Training Loss: 4.697870
2025-04-16 15:50:04,504 - Unsupervised Training Loss: 5.381480
2025-04-16 15:50:40,711 - K-means used 0.02 s
2025-04-16 15:50:42,418 - ***** Epoch: 11 *****
2025-04-16 15:50:42,419 - Supervised Training Loss: 4.619950
2025-04-16 15:50:42,419 - Unsupervised Training Loss: 5.457590
2025-04-16 15:51:17,032 - K-means used 0.02 s
2025-04-16 15:51:18,858 - ***** Epoch: 12 *****
2025-04-16 15:51:18,858 - Supervised Training Loss: 4.763860
2025-04-16 15:51:18,858 - Unsupervised Training Loss: 5.530910
2025-04-16 15:51:50,354 - K-means used 0.02 s
2025-04-16 15:51:52,308 - ***** Epoch: 13 *****
2025-04-16 15:51:52,308 - Supervised Training Loss: 4.721260
2025-04-16 15:51:52,308 - Unsupervised Training Loss: 5.250770
2025-04-16 15:52:24,063 - K-means used 0.02 s
2025-04-16 15:52:25,747 - ***** Epoch: 14 *****
2025-04-16 15:52:25,748 - Supervised Training Loss: 4.673330
2025-04-16 15:52:25,748 - Unsupervised Training Loss: 5.389960
2025-04-16 15:53:00,322 - K-means used 0.04 s
2025-04-16 15:53:02,364 - ***** Epoch: 15 *****
2025-04-16 15:53:02,364 - Supervised Training Loss: 4.515160
2025-04-16 15:53:02,365 - Unsupervised Training Loss: 5.496860
2025-04-16 15:53:35,552 - K-means used 0.03 s
2025-04-16 15:53:37,834 - ***** Epoch: 16 *****
2025-04-16 15:53:37,834 - Supervised Training Loss: 4.779690
2025-04-16 15:53:37,835 - Unsupervised Training Loss: 4.945290
2025-04-16 15:54:16,251 - K-means used 0.01 s
2025-04-16 15:54:18,650 - ***** Epoch: 17 *****
2025-04-16 15:54:18,650 - Supervised Training Loss: 4.757380
2025-04-16 15:54:18,650 - Unsupervised Training Loss: 5.148860
2025-04-16 15:54:42,310 - Training is finished...
2025-04-16 15:54:42,310 - Testing begins...
2025-04-16 15:54:50,302 - ***** Test results *****
2025-04-16 15:54:50,302 -   ACC = 31.01
2025-04-16 15:54:50,302 -   ARI = 11.69
2025-04-16 15:54:50,302 -   NMI = 37.31
2025-04-16 15:54:50,302 -   fmi = 17.09
2025-04-16 15:54:50,302 - Testing is finished...
2025-04-16 15:54:50,302 - Multimodal intent recognition is finished...
2025-04-16 15:54:50,302 - Results are saved in results/results_umc.csv
