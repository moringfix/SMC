2025-04-14 18:20:30,060 - ============================== Params ==============================
2025-04-14 18:20:30,060 - logger_name: umc_umc_bert-base-uncased_MIntRec_4
2025-04-14 18:20:30,060 - dataset: MIntRec
2025-04-14 18:20:30,060 - multimodal_method: umc
2025-04-14 18:20:30,060 - method: umc
2025-04-14 18:20:30,060 - text_backbone: bert-base-uncased
2025-04-14 18:20:30,060 - seed: 4
2025-04-14 18:20:30,060 - num_workers: 16
2025-04-14 18:20:30,060 - log_id: umc_umc_bert-base-uncased_MIntRec_4_2025-04-14-18-20-30
2025-04-14 18:20:30,060 - gpu_id: 0
2025-04-14 18:20:30,060 - data_path: /root/autodl-tmp/home/Share/Dataset/LZH
2025-04-14 18:20:30,060 - train: True
2025-04-14 18:20:30,060 - tune: True
2025-04-14 18:20:30,060 - save_model: True
2025-04-14 18:20:30,060 - save_results: True
2025-04-14 18:20:30,061 - log_path: logs
2025-04-14 18:20:30,061 - cache_path: cache
2025-04-14 18:20:30,061 - video_data_path: video_data
2025-04-14 18:20:30,061 - audio_data_path: audio_data
2025-04-14 18:20:30,061 - video_feats_path: swin_feats.pkl
2025-04-14 18:20:30,061 - audio_feats_path: wavlm_feats.pkl
2025-04-14 18:20:30,061 - results_path: results
2025-04-14 18:20:30,061 - output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/UMC/outputs/MIntRec
2025-04-14 18:20:30,061 - model_path: models
2025-04-14 18:20:30,061 - config_file_name: umc_MIntRec
2025-04-14 18:20:30,061 - results_file_name: results_umc.csv
2025-04-14 18:20:30,061 - text_pretrained_model: uncased_L-12_H-768_A-12
2025-04-14 18:20:30,061 - text_seq_len: 30
2025-04-14 18:20:30,061 - video_seq_len: 230
2025-04-14 18:20:30,061 - audio_seq_len: 480
2025-04-14 18:20:30,061 - text_feat_dim: 768
2025-04-14 18:20:30,061 - video_feat_dim: 1024
2025-04-14 18:20:30,061 - audio_feat_dim: 768
2025-04-14 18:20:30,061 - num_labels: 20
2025-04-14 18:20:30,061 - num_train_examples: 1779
2025-04-14 18:20:30,061 - pretrained_bert_model: uncased_L-12_H-768_A-12
2025-04-14 18:20:30,061 - pretrain_batch_size: 128
2025-04-14 18:20:30,061 - train_batch_size: 128
2025-04-14 18:20:30,061 - eval_batch_size: 128
2025-04-14 18:20:30,061 - test_batch_size: 128
2025-04-14 18:20:30,061 - num_pretrain_epochs: 100
2025-04-14 18:20:30,061 - num_train_epochs: 100
2025-04-14 18:20:30,061 - pretrain: [True]
2025-04-14 18:20:30,061 - aligned_method: ctc
2025-04-14 18:20:30,061 - need_aligned: False
2025-04-14 18:20:30,062 - freeze_pretrain_bert_parameters: [True]
2025-04-14 18:20:30,062 - freeze_train_bert_parameters: [True]
2025-04-14 18:20:30,062 - pretrain_temperature: [0.1]
2025-04-14 18:20:30,062 - train_temperature_sup: [7.6]
2025-04-14 18:20:30,062 - train_temperature_unsup: [0.9]
2025-04-14 18:20:30,062 - activation: tanh
2025-04-14 18:20:30,062 - lr_pre: 1e-05
2025-04-14 18:20:30,062 - lr: [0.0003]
2025-04-14 18:20:30,062 - delta: [0.05]
2025-04-14 18:20:30,062 - thres: [0.1]
2025-04-14 18:20:30,062 - topk: [5]
2025-04-14 18:20:30,062 - weight_decay: 0.01
2025-04-14 18:20:30,062 - feat_dim: 768
2025-04-14 18:20:30,062 - hidden_size: 768
2025-04-14 18:20:30,062 - grad_clip: -1.0
2025-04-14 18:20:30,062 - warmup_proportion: 0.5
2025-04-14 18:20:30,062 - hidden_dropout_prob: 0.1
2025-04-14 18:20:30,062 - weight: 1.0
2025-04-14 18:20:30,062 - loss_mode: rdrop
2025-04-14 18:20:30,062 - base_dim: 256
2025-04-14 18:20:30,062 - nheads: 8
2025-04-14 18:20:30,062 - attn_dropout: 0.1
2025-04-14 18:20:30,062 - relu_dropout: 0.1
2025-04-14 18:20:30,062 - embed_dropout: 0.01
2025-04-14 18:20:30,062 - res_dropout: 0.0
2025-04-14 18:20:30,062 - attn_mask: True
2025-04-14 18:20:30,062 - encoder_layers_1: 1
2025-04-14 18:20:30,062 - fusion_act: tanh
2025-04-14 18:20:30,062 - pred_output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/UMC/outputs/MIntRec/umc_umc_MIntRec_bert-base-uncased_4
2025-04-14 18:20:30,063 - model_output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/UMC/outputs/MIntRec/umc_umc_MIntRec_bert-base-uncased_4/models
2025-04-14 18:20:30,063 - ============================== End Params ==============================
2025-04-14 18:20:31,298 - Freeze all parameters but the last layer for efficiency
2025-04-14 18:20:31,335 - Pre-training start...
2025-04-14 18:20:46,652 - ***** Epoch: 1: Eval results *****
2025-04-14 18:20:46,653 -   train_loss = 5.970648084368024
2025-04-14 18:21:00,395 - ***** Epoch: 2: Eval results *****
2025-04-14 18:21:00,396 -   train_loss = 5.966461079461234
2025-04-14 18:21:16,076 - ***** Epoch: 3: Eval results *****
2025-04-14 18:21:16,076 -   train_loss = 5.965302569525583
2025-04-14 18:21:30,773 - ***** Epoch: 4: Eval results *****
2025-04-14 18:21:30,774 -   train_loss = 5.961013828005109
2025-04-14 18:21:46,409 - ***** Epoch: 5: Eval results *****
2025-04-14 18:21:46,410 -   train_loss = 5.962399448667254
2025-04-14 18:22:01,541 - ***** Epoch: 6: Eval results *****
2025-04-14 18:22:01,542 -   train_loss = 5.964002370834351
2025-04-14 18:22:17,383 - ***** Epoch: 7: Eval results *****
2025-04-14 18:22:17,384 -   train_loss = 5.956438950129917
2025-04-14 18:22:33,373 - ***** Epoch: 8: Eval results *****
2025-04-14 18:22:33,373 -   train_loss = 5.952266080038888
2025-04-14 18:22:48,902 - ***** Epoch: 9: Eval results *****
2025-04-14 18:22:48,903 -   train_loss = 5.946320056915283
2025-04-14 18:23:04,678 - ***** Epoch: 10: Eval results *****
2025-04-14 18:23:04,678 -   train_loss = 5.94390252658299
2025-04-14 18:23:20,767 - ***** Epoch: 11: Eval results *****
2025-04-14 18:23:20,768 -   train_loss = 5.934671810695103
2025-04-14 18:23:37,048 - ***** Epoch: 12: Eval results *****
2025-04-14 18:23:37,048 -   train_loss = 5.9290120261056085
2025-04-14 18:23:53,123 - ***** Epoch: 13: Eval results *****
2025-04-14 18:23:53,124 -   train_loss = 5.922977651868548
2025-04-14 18:24:09,321 - ***** Epoch: 14: Eval results *****
2025-04-14 18:24:09,322 -   train_loss = 5.913618734904698
2025-04-14 18:24:25,467 - ***** Epoch: 15: Eval results *****
2025-04-14 18:24:25,467 -   train_loss = 5.885918855667114
2025-04-14 18:24:41,199 - ***** Epoch: 16: Eval results *****
2025-04-14 18:24:41,200 -   train_loss = 5.866542032786778
2025-04-14 18:24:57,097 - ***** Epoch: 17: Eval results *****
2025-04-14 18:24:57,098 -   train_loss = 5.822826521737235
2025-04-14 18:25:12,977 - ***** Epoch: 18: Eval results *****
2025-04-14 18:25:12,977 -   train_loss = 5.7407021181924005
2025-04-14 18:25:28,677 - ***** Epoch: 19: Eval results *****
2025-04-14 18:25:28,678 -   train_loss = 5.642508677073887
2025-04-14 18:25:44,322 - ***** Epoch: 20: Eval results *****
2025-04-14 18:25:44,322 -   train_loss = 5.472390208925519
2025-04-14 18:26:00,121 - ***** Epoch: 21: Eval results *****
2025-04-14 18:26:00,121 -   train_loss = 5.229619230542864
2025-04-14 18:26:15,155 - ***** Epoch: 22: Eval results *****
2025-04-14 18:26:15,155 -   train_loss = 4.955741507666452
2025-04-14 18:26:30,454 - ***** Epoch: 23: Eval results *****
2025-04-14 18:26:30,454 -   train_loss = 4.683956146240234
2025-04-14 18:26:46,148 - ***** Epoch: 24: Eval results *****
2025-04-14 18:26:46,148 -   train_loss = 4.425085612705776
2025-04-14 18:27:02,455 - ***** Epoch: 25: Eval results *****
2025-04-14 18:27:02,455 -   train_loss = 4.114185895238604
2025-04-14 18:27:18,335 - ***** Epoch: 26: Eval results *****
2025-04-14 18:27:18,336 -   train_loss = 3.8869088206972395
2025-04-14 18:27:33,427 - ***** Epoch: 27: Eval results *****
2025-04-14 18:27:33,427 -   train_loss = 3.6783997331346785
2025-04-14 18:27:49,461 - ***** Epoch: 28: Eval results *****
2025-04-14 18:27:49,461 -   train_loss = 3.4911667619432722
2025-04-14 18:28:05,406 - ***** Epoch: 29: Eval results *****
2025-04-14 18:28:05,406 -   train_loss = 3.3222072465079173
2025-04-14 18:28:20,790 - ***** Epoch: 30: Eval results *****
2025-04-14 18:28:20,790 -   train_loss = 3.1734438283102855
2025-04-14 18:28:35,874 - ***** Epoch: 31: Eval results *****
2025-04-14 18:28:35,874 -   train_loss = 3.0303382192339217
2025-04-14 18:28:50,757 - ***** Epoch: 32: Eval results *****
2025-04-14 18:28:50,758 -   train_loss = 2.9039022752216885
2025-04-14 18:29:05,941 - ***** Epoch: 33: Eval results *****
2025-04-14 18:29:05,941 -   train_loss = 2.7921715804508755
2025-04-14 18:29:21,306 - ***** Epoch: 34: Eval results *****
2025-04-14 18:29:21,307 -   train_loss = 2.6812032801764354
2025-04-14 18:29:36,115 - ***** Epoch: 35: Eval results *****
2025-04-14 18:29:36,115 -   train_loss = 2.577368770326887
2025-04-14 18:29:51,540 - ***** Epoch: 36: Eval results *****
2025-04-14 18:29:51,540 -   train_loss = 2.4790665933064053
2025-04-14 18:30:07,163 - ***** Epoch: 37: Eval results *****
2025-04-14 18:30:07,163 -   train_loss = 2.418008736201695
2025-04-14 18:30:22,715 - ***** Epoch: 38: Eval results *****
2025-04-14 18:30:22,716 -   train_loss = 2.3388369253703525
2025-04-14 18:30:38,523 - ***** Epoch: 39: Eval results *****
2025-04-14 18:30:38,524 -   train_loss = 2.262122597013201
2025-04-14 18:30:54,305 - ***** Epoch: 40: Eval results *****
2025-04-14 18:30:54,305 -   train_loss = 2.2209037031446184
2025-04-14 18:31:10,370 - ***** Epoch: 41: Eval results *****
2025-04-14 18:31:10,370 -   train_loss = 2.167987278529576
2025-04-14 18:31:26,185 - ***** Epoch: 42: Eval results *****
2025-04-14 18:31:26,185 -   train_loss = 2.134170753615243
2025-04-14 18:31:41,976 - ***** Epoch: 43: Eval results *****
2025-04-14 18:31:41,977 -   train_loss = 2.0601467745644704
2025-04-14 18:31:57,765 - ***** Epoch: 44: Eval results *****
2025-04-14 18:31:57,765 -   train_loss = 2.0201016664505005
2025-04-14 18:32:13,627 - ***** Epoch: 45: Eval results *****
2025-04-14 18:32:13,628 -   train_loss = 1.9903226069041662
2025-04-14 18:32:29,421 - ***** Epoch: 46: Eval results *****
2025-04-14 18:32:29,421 -   train_loss = 1.9536106160708837
2025-04-14 18:32:45,646 - ***** Epoch: 47: Eval results *****
2025-04-14 18:32:45,646 -   train_loss = 1.9013313480785914
2025-04-14 18:33:02,017 - ***** Epoch: 48: Eval results *****
2025-04-14 18:33:02,018 -   train_loss = 1.8772331731660026
2025-04-14 18:33:17,396 - ***** Epoch: 49: Eval results *****
2025-04-14 18:33:17,396 -   train_loss = 1.8333850758416312
2025-04-14 18:33:33,193 - ***** Epoch: 50: Eval results *****
2025-04-14 18:33:33,193 -   train_loss = 1.8072478515761239
2025-04-14 18:33:48,737 - ***** Epoch: 51: Eval results *****
2025-04-14 18:33:48,738 -   train_loss = 1.7838449563298906
2025-04-14 18:34:04,283 - ***** Epoch: 52: Eval results *****
2025-04-14 18:34:04,283 -   train_loss = 1.7465388349124364
2025-04-14 18:34:20,223 - ***** Epoch: 53: Eval results *****
2025-04-14 18:34:20,224 -   train_loss = 1.725121293749128
2025-04-14 18:34:35,817 - ***** Epoch: 54: Eval results *****
2025-04-14 18:34:35,818 -   train_loss = 1.711163078035627
2025-04-14 18:34:51,148 - ***** Epoch: 55: Eval results *****
2025-04-14 18:34:51,148 -   train_loss = 1.6726623262677873
2025-04-14 18:35:06,372 - ***** Epoch: 56: Eval results *****
2025-04-14 18:35:06,373 -   train_loss = 1.680017420223781
2025-04-14 18:35:22,318 - ***** Epoch: 57: Eval results *****
2025-04-14 18:35:22,318 -   train_loss = 1.6551468457494463
2025-04-14 18:35:38,203 - ***** Epoch: 58: Eval results *****
2025-04-14 18:35:38,203 -   train_loss = 1.6328698907579695
2025-04-14 18:35:54,110 - ***** Epoch: 59: Eval results *****
2025-04-14 18:35:54,110 -   train_loss = 1.624602837221963
2025-04-14 18:36:09,673 - ***** Epoch: 60: Eval results *****
2025-04-14 18:36:09,674 -   train_loss = 1.61013948065894
2025-04-14 18:36:25,727 - ***** Epoch: 61: Eval results *****
2025-04-14 18:36:25,728 -   train_loss = 1.5860641258103507
2025-04-14 18:36:41,561 - ***** Epoch: 62: Eval results *****
2025-04-14 18:36:41,561 -   train_loss = 1.5950971245765686
2025-04-14 18:36:57,902 - ***** Epoch: 63: Eval results *****
2025-04-14 18:36:57,903 -   train_loss = 1.5782367842538017
2025-04-14 18:37:13,693 - ***** Epoch: 64: Eval results *****
2025-04-14 18:37:13,693 -   train_loss = 1.5496331368173872
2025-04-14 18:37:29,924 - ***** Epoch: 65: Eval results *****
2025-04-14 18:37:29,924 -   train_loss = 1.5445579971585954
2025-04-14 18:37:45,418 - ***** Epoch: 66: Eval results *****
2025-04-14 18:37:45,419 -   train_loss = 1.5389006989342826
2025-04-14 18:38:01,286 - ***** Epoch: 67: Eval results *****
2025-04-14 18:38:01,286 -   train_loss = 1.5336969324520655
2025-04-14 18:38:17,921 - ***** Epoch: 68: Eval results *****
2025-04-14 18:38:17,921 -   train_loss = 1.5168768082346236
2025-04-14 18:38:34,981 - ***** Epoch: 69: Eval results *****
2025-04-14 18:38:34,982 -   train_loss = 1.4933493052210127
2025-04-14 18:38:52,346 - ***** Epoch: 70: Eval results *****
2025-04-14 18:38:52,347 -   train_loss = 1.5009931240762984
2025-04-14 18:39:09,774 - ***** Epoch: 71: Eval results *****
2025-04-14 18:39:09,774 -   train_loss = 1.5056630628449577
2025-04-14 18:39:26,641 - ***** Epoch: 72: Eval results *****
2025-04-14 18:39:26,642 -   train_loss = 1.501506473336901
2025-04-14 18:39:43,330 - ***** Epoch: 73: Eval results *****
2025-04-14 18:39:43,330 -   train_loss = 1.4950505239622933
2025-04-14 18:40:00,153 - ***** Epoch: 74: Eval results *****
2025-04-14 18:40:00,154 -   train_loss = 1.4911161320550101
2025-04-14 18:40:17,040 - ***** Epoch: 75: Eval results *****
2025-04-14 18:40:17,040 -   train_loss = 1.4811289480754308
2025-04-14 18:40:33,766 - ***** Epoch: 76: Eval results *****
2025-04-14 18:40:33,766 -   train_loss = 1.48939448595047
2025-04-14 18:40:50,333 - ***** Epoch: 77: Eval results *****
2025-04-14 18:40:50,333 -   train_loss = 1.4780304431915283
2025-04-14 18:41:06,032 - ***** Epoch: 78: Eval results *****
2025-04-14 18:41:06,032 -   train_loss = 1.480181804725102
2025-04-14 18:41:22,124 - ***** Epoch: 79: Eval results *****
2025-04-14 18:41:22,124 -   train_loss = 1.4671125667435783
2025-04-14 18:41:37,946 - ***** Epoch: 80: Eval results *****
2025-04-14 18:41:37,947 -   train_loss = 1.4607499752725874
2025-04-14 18:41:53,830 - ***** Epoch: 81: Eval results *****
2025-04-14 18:41:53,831 -   train_loss = 1.4580600091389246
2025-04-14 18:42:09,775 - ***** Epoch: 82: Eval results *****
2025-04-14 18:42:09,776 -   train_loss = 1.4527483071599687
2025-04-14 18:42:24,876 - ***** Epoch: 83: Eval results *****
2025-04-14 18:42:24,877 -   train_loss = 1.4581644364765711
2025-04-14 18:42:40,712 - ***** Epoch: 84: Eval results *****
2025-04-14 18:42:40,713 -   train_loss = 1.4521907312529427
2025-04-14 18:42:57,763 - ***** Epoch: 85: Eval results *****
2025-04-14 18:42:57,764 -   train_loss = 1.4468951991626195
2025-04-14 18:43:14,500 - ***** Epoch: 86: Eval results *****
2025-04-14 18:43:14,501 -   train_loss = 1.4407719458852495
2025-04-14 18:43:31,111 - ***** Epoch: 87: Eval results *****
2025-04-14 18:43:31,111 -   train_loss = 1.4412515248571123
2025-04-14 18:43:46,757 - ***** Epoch: 88: Eval results *****
2025-04-14 18:43:46,757 -   train_loss = 1.4458748527935572
2025-04-14 18:44:02,685 - ***** Epoch: 89: Eval results *****
2025-04-14 18:44:02,685 -   train_loss = 1.4527638469423567
2025-04-14 18:44:19,046 - ***** Epoch: 90: Eval results *****
2025-04-14 18:44:19,046 -   train_loss = 1.444801492350442
2025-04-14 18:44:35,749 - ***** Epoch: 91: Eval results *****
2025-04-14 18:44:35,749 -   train_loss = 1.4313005294118608
2025-04-14 18:44:52,615 - ***** Epoch: 92: Eval results *****
2025-04-14 18:44:52,615 -   train_loss = 1.4385235224451338
2025-04-14 18:45:08,977 - ***** Epoch: 93: Eval results *****
2025-04-14 18:45:08,978 -   train_loss = 1.4401353597640991
2025-04-14 18:45:24,748 - ***** Epoch: 94: Eval results *****
2025-04-14 18:45:24,748 -   train_loss = 1.4438101393835885
2025-04-14 18:45:40,584 - ***** Epoch: 95: Eval results *****
2025-04-14 18:45:40,584 -   train_loss = 1.4387265699250358
2025-04-14 18:45:56,222 - ***** Epoch: 96: Eval results *****
2025-04-14 18:45:56,222 -   train_loss = 1.432632429259164
2025-04-14 18:46:11,737 - ***** Epoch: 97: Eval results *****
2025-04-14 18:46:11,737 -   train_loss = 1.4412085158484322
2025-04-14 18:46:27,236 - ***** Epoch: 98: Eval results *****
2025-04-14 18:46:27,236 -   train_loss = 1.442799951348986
2025-04-14 18:46:42,197 - ***** Epoch: 99: Eval results *****
2025-04-14 18:46:42,197 -   train_loss = 1.448082217148372
2025-04-14 18:46:57,190 - ***** Epoch: 100: Eval results *****
2025-04-14 18:46:57,190 -   train_loss = 1.4440207736832755
2025-04-14 18:46:57,736 - Pre-training finished...
2025-04-14 18:46:57,986 - Freeze all parameters but the last layer for efficiency
2025-04-14 18:46:57,996 - Multimodal Intent Recognition begins...
2025-04-14 18:46:57,996 - Training begins...
2025-04-14 18:47:14,878 - Initializing centroids with K-means++...
2025-04-14 18:47:14,972 - K-means++ used 0.09 s
2025-04-14 18:47:45,187 - K-means used 0.03 s
2025-04-14 18:47:46,565 - ***** Epoch: 1 *****
2025-04-14 18:47:46,565 - Supervised Training Loss: 5.289020
2025-04-14 18:47:46,566 - Unsupervised Training Loss: 5.088970
2025-04-14 18:48:16,529 - K-means used 0.02 s
2025-04-14 18:48:17,591 - ***** Epoch: 2 *****
2025-04-14 18:48:17,592 - Supervised Training Loss: 4.150630
2025-04-14 18:48:17,592 - Unsupervised Training Loss: 5.106350
2025-04-14 18:48:47,925 - K-means used 0.03 s
2025-04-14 18:48:49,280 - ***** Epoch: 3 *****
2025-04-14 18:48:49,280 - Supervised Training Loss: 5.765310
2025-04-14 18:48:49,280 - Unsupervised Training Loss: 4.952350
2025-04-14 18:49:18,499 - K-means used 0.06 s
2025-04-14 18:49:19,857 - ***** Epoch: 4 *****
2025-04-14 18:49:19,857 - Supervised Training Loss: 5.656590
2025-04-14 18:49:19,857 - Unsupervised Training Loss: 5.011540
2025-04-14 18:49:49,504 - K-means used 0.08 s
2025-04-14 18:49:50,790 - ***** Epoch: 5 *****
2025-04-14 18:49:50,790 - Supervised Training Loss: 5.385100
2025-04-14 18:49:50,791 - Unsupervised Training Loss: 5.069210
2025-04-14 18:50:21,148 - K-means used 0.02 s
2025-04-14 18:50:22,743 - ***** Epoch: 6 *****
2025-04-14 18:50:22,743 - Supervised Training Loss: 5.814120
2025-04-14 18:50:22,744 - Unsupervised Training Loss: 4.852640
2025-04-14 18:50:54,134 - K-means used 0.02 s
2025-04-14 18:50:55,675 - ***** Epoch: 7 *****
2025-04-14 18:50:55,675 - Supervised Training Loss: 5.738850
2025-04-14 18:50:55,675 - Unsupervised Training Loss: 4.983480
2025-04-14 18:51:25,718 - K-means used 0.02 s
2025-04-14 18:51:27,188 - ***** Epoch: 8 *****
2025-04-14 18:51:27,188 - Supervised Training Loss: 5.599560
2025-04-14 18:51:27,188 - Unsupervised Training Loss: 5.030630
2025-04-14 18:51:56,514 - K-means used 0.03 s
2025-04-14 18:51:57,971 - ***** Epoch: 9 *****
2025-04-14 18:51:57,972 - Supervised Training Loss: 5.837590
2025-04-14 18:51:57,972 - Unsupervised Training Loss: 5.061730
2025-04-14 18:52:28,202 - K-means used 0.13 s
2025-04-14 18:52:29,850 - ***** Epoch: 10 *****
2025-04-14 18:52:29,850 - Supervised Training Loss: 5.771330
2025-04-14 18:52:29,850 - Unsupervised Training Loss: 4.877790
2025-04-14 18:52:59,033 - K-means used 0.03 s
2025-04-14 18:53:01,318 - ***** Epoch: 11 *****
2025-04-14 18:53:01,319 - Supervised Training Loss: 5.703290
2025-04-14 18:53:01,319 - Unsupervised Training Loss: 4.942930
2025-04-14 18:53:31,207 - K-means used 0.04 s
2025-04-14 18:53:32,939 - ***** Epoch: 12 *****
2025-04-14 18:53:32,939 - Supervised Training Loss: 5.838300
2025-04-14 18:53:32,939 - Unsupervised Training Loss: 5.016360
2025-04-14 18:54:03,570 - K-means used 0.02 s
2025-04-14 18:54:05,333 - ***** Epoch: 13 *****
2025-04-14 18:54:05,334 - Supervised Training Loss: 5.798630
2025-04-14 18:54:05,334 - Unsupervised Training Loss: 4.738510
2025-04-14 18:54:34,179 - K-means used 0.02 s
2025-04-14 18:54:36,220 - ***** Epoch: 14 *****
2025-04-14 18:54:36,220 - Supervised Training Loss: 5.749160
2025-04-14 18:54:36,220 - Unsupervised Training Loss: 4.872800
2025-04-14 18:55:05,971 - K-means used 0.03 s
2025-04-14 18:55:07,935 - ***** Epoch: 15 *****
2025-04-14 18:55:07,935 - Supervised Training Loss: 5.597740
2025-04-14 18:55:07,935 - Unsupervised Training Loss: 4.963810
2025-04-14 18:55:38,686 - K-means used 0.02 s
2025-04-14 18:55:40,611 - ***** Epoch: 16 *****
2025-04-14 18:55:40,611 - Supervised Training Loss: 5.815940
2025-04-14 18:55:40,611 - Unsupervised Training Loss: 4.419150
2025-04-14 18:56:10,645 - K-means used 0.02 s
2025-04-14 18:56:12,678 - ***** Epoch: 17 *****
2025-04-14 18:56:12,678 - Supervised Training Loss: 5.779340
2025-04-14 18:56:12,679 - Unsupervised Training Loss: 4.632870
2025-04-14 18:56:31,872 - Training is finished...
2025-04-14 18:56:31,872 - Testing begins...
2025-04-14 18:56:39,443 - ***** Test results *****
2025-04-14 18:56:39,443 -   ACC = 40.45
2025-04-14 18:56:39,443 -   ARI = 21.12
2025-04-14 18:56:39,443 -   NMI = 46.49
2025-04-14 18:56:39,443 -   fmi = 26.05
2025-04-14 18:56:39,443 - Testing is finished...
2025-04-14 18:56:39,443 - Multimodal intent recognition is finished...
2025-04-14 18:56:39,443 - Results are saved in results/results_umc.csv
