2025-04-10 21:30:19,152 - ============================== Params ==============================
2025-04-10 21:30:19,152 - logger_name: umc_umc_bert-base-uncased_MIntRec_1
2025-04-10 21:30:19,152 - dataset: MIntRec
2025-04-10 21:30:19,152 - multimodal_method: umc
2025-04-10 21:30:19,152 - method: umc
2025-04-10 21:30:19,152 - text_backbone: bert-base-uncased
2025-04-10 21:30:19,152 - seed: 1
2025-04-10 21:30:19,152 - num_workers: 16
2025-04-10 21:30:19,152 - log_id: umc_umc_bert-base-uncased_MIntRec_1_2025-04-10-21-30-19
2025-04-10 21:30:19,152 - gpu_id: 0
2025-04-10 21:30:19,152 - data_path: /root/autodl-tmp/home/Share/Dataset/LZH
2025-04-10 21:30:19,152 - train: True
2025-04-10 21:30:19,152 - tune: True
2025-04-10 21:30:19,152 - save_model: True
2025-04-10 21:30:19,152 - save_results: True
2025-04-10 21:30:19,153 - log_path: logs
2025-04-10 21:30:19,153 - cache_path: cache
2025-04-10 21:30:19,153 - video_data_path: video_data
2025-04-10 21:30:19,153 - audio_data_path: audio_data
2025-04-10 21:30:19,153 - video_feats_path: swin_feats.pkl
2025-04-10 21:30:19,153 - audio_feats_path: wavlm_feats.pkl
2025-04-10 21:30:19,153 - results_path: results
2025-04-10 21:30:19,153 - output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/UMC/outputs/MIntRec
2025-04-10 21:30:19,153 - model_path: models
2025-04-10 21:30:19,153 - config_file_name: umc_MIntRec
2025-04-10 21:30:19,153 - results_file_name: results_umc.csv
2025-04-10 21:30:19,153 - text_pretrained_model: uncased_L-12_H-768_A-12
2025-04-10 21:30:19,153 - text_seq_len: 30
2025-04-10 21:30:19,153 - video_seq_len: 230
2025-04-10 21:30:19,153 - audio_seq_len: 480
2025-04-10 21:30:19,153 - text_feat_dim: 768
2025-04-10 21:30:19,153 - video_feat_dim: 1024
2025-04-10 21:30:19,153 - audio_feat_dim: 768
2025-04-10 21:30:19,153 - num_labels: 20
2025-04-10 21:30:19,153 - num_train_examples: 1779
2025-04-10 21:30:19,153 - pretrained_bert_model: uncased_L-12_H-768_A-12
2025-04-10 21:30:19,153 - pretrain_batch_size: 128
2025-04-10 21:30:19,153 - train_batch_size: 128
2025-04-10 21:30:19,153 - eval_batch_size: 128
2025-04-10 21:30:19,153 - test_batch_size: 128
2025-04-10 21:30:19,153 - num_pretrain_epochs: 100
2025-04-10 21:30:19,153 - num_train_epochs: 100
2025-04-10 21:30:19,153 - pretrain: [True]
2025-04-10 21:30:19,153 - aligned_method: ctc
2025-04-10 21:30:19,153 - need_aligned: False
2025-04-10 21:30:19,153 - freeze_pretrain_bert_parameters: [True]
2025-04-10 21:30:19,154 - freeze_train_bert_parameters: [True]
2025-04-10 21:30:19,154 - pretrain_temperature: [0.2]
2025-04-10 21:30:19,154 - train_temperature_sup: [1.4]
2025-04-10 21:30:19,154 - train_temperature_unsup: [1]
2025-04-10 21:30:19,154 - activation: tanh
2025-04-10 21:30:19,154 - lr_pre: 2e-05
2025-04-10 21:30:19,154 - lr: [0.0003]
2025-04-10 21:30:19,154 - delta: [0.05]
2025-04-10 21:30:19,154 - thres: [0.1]
2025-04-10 21:30:19,154 - topk: [5]
2025-04-10 21:30:19,154 - weight_decay: 0.01
2025-04-10 21:30:19,154 - feat_dim: 768
2025-04-10 21:30:19,154 - hidden_size: 768
2025-04-10 21:30:19,154 - grad_clip: -1.0
2025-04-10 21:30:19,154 - warmup_proportion: 0.1
2025-04-10 21:30:19,154 - hidden_dropout_prob: 0.1
2025-04-10 21:30:19,154 - weight: 1.0
2025-04-10 21:30:19,154 - loss_mode: rdrop
2025-04-10 21:30:19,154 - base_dim: 256
2025-04-10 21:30:19,154 - nheads: 8
2025-04-10 21:30:19,154 - attn_dropout: 0.1
2025-04-10 21:30:19,154 - relu_dropout: 0.1
2025-04-10 21:30:19,154 - embed_dropout: 0.1
2025-04-10 21:30:19,154 - res_dropout: 0.0
2025-04-10 21:30:19,154 - attn_mask: True
2025-04-10 21:30:19,154 - encoder_layers_1: 1
2025-04-10 21:30:19,154 - fusion_act: tanh
2025-04-10 21:30:19,154 - pred_output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/UMC/outputs/MIntRec/umc_umc_MIntRec_bert-base-uncased_1
2025-04-10 21:30:19,154 - model_output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/UMC/outputs/MIntRec/umc_umc_MIntRec_bert-base-uncased_1/models
2025-04-10 21:30:19,155 - ============================== End Params ==============================
2025-04-10 21:30:20,291 - Freeze all parameters but the last layer for efficiency
2025-04-10 21:30:20,326 - Pre-training start...
2025-04-10 21:30:34,641 - ***** Epoch: 1: Eval results *****
2025-04-10 21:30:34,641 -   train_loss = 5.9414922169276645
2025-04-10 21:30:47,844 - ***** Epoch: 2: Eval results *****
2025-04-10 21:30:47,844 -   train_loss = 5.941111019679478
2025-04-10 21:31:00,774 - ***** Epoch: 3: Eval results *****
2025-04-10 21:31:00,774 -   train_loss = 5.934085130691528
2025-04-10 21:31:14,863 - ***** Epoch: 4: Eval results *****
2025-04-10 21:31:14,863 -   train_loss = 5.929164954594204
2025-04-10 21:31:29,333 - ***** Epoch: 5: Eval results *****
2025-04-10 21:31:29,333 -   train_loss = 5.921181985310146
2025-04-10 21:31:43,620 - ***** Epoch: 6: Eval results *****
2025-04-10 21:31:43,621 -   train_loss = 5.892749037061419
2025-04-10 21:31:59,044 - ***** Epoch: 7: Eval results *****
2025-04-10 21:31:59,044 -   train_loss = 5.823347840990339
2025-04-10 21:32:13,799 - ***** Epoch: 8: Eval results *****
2025-04-10 21:32:13,800 -   train_loss = 5.5911979334695
2025-04-10 21:32:28,011 - ***** Epoch: 9: Eval results *****
2025-04-10 21:32:28,011 -   train_loss = 5.148698636463711
2025-04-10 21:32:42,473 - ***** Epoch: 10: Eval results *****
2025-04-10 21:32:42,473 -   train_loss = 4.642203978129795
2025-04-10 21:32:57,117 - ***** Epoch: 11: Eval results *****
2025-04-10 21:32:57,118 -   train_loss = 4.220354199409485
2025-04-10 21:33:11,545 - ***** Epoch: 12: Eval results *****
2025-04-10 21:33:11,545 -   train_loss = 3.9630529369626726
2025-04-10 21:33:26,206 - ***** Epoch: 13: Eval results *****
2025-04-10 21:33:26,207 -   train_loss = 3.7664303609303067
2025-04-10 21:33:40,617 - ***** Epoch: 14: Eval results *****
2025-04-10 21:33:40,618 -   train_loss = 3.610994270869664
2025-04-10 21:33:55,207 - ***** Epoch: 15: Eval results *****
2025-04-10 21:33:55,207 -   train_loss = 3.4929807697023665
2025-04-10 21:34:09,788 - ***** Epoch: 16: Eval results *****
2025-04-10 21:34:09,788 -   train_loss = 3.3967948811394826
2025-04-10 21:34:24,168 - ***** Epoch: 17: Eval results *****
2025-04-10 21:34:24,169 -   train_loss = 3.330802287374224
2025-04-10 21:34:38,438 - ***** Epoch: 18: Eval results *****
2025-04-10 21:34:38,438 -   train_loss = 3.265219569206238
2025-04-10 21:34:52,621 - ***** Epoch: 19: Eval results *****
2025-04-10 21:34:52,622 -   train_loss = 3.2200807332992554
2025-04-10 21:35:06,528 - ***** Epoch: 20: Eval results *****
2025-04-10 21:35:06,528 -   train_loss = 3.1885721513203213
2025-04-10 21:35:21,071 - ***** Epoch: 21: Eval results *****
2025-04-10 21:35:21,072 -   train_loss = 3.1414060252053395
2025-04-10 21:35:35,569 - ***** Epoch: 22: Eval results *****
2025-04-10 21:35:35,569 -   train_loss = 3.116873332432338
2025-04-10 21:35:50,208 - ***** Epoch: 23: Eval results *****
2025-04-10 21:35:50,208 -   train_loss = 3.076383658817836
2025-04-10 21:36:04,927 - ***** Epoch: 24: Eval results *****
2025-04-10 21:36:04,927 -   train_loss = 3.0458425283432007
2025-04-10 21:36:18,808 - ***** Epoch: 25: Eval results *****
2025-04-10 21:36:18,808 -   train_loss = 3.040169426373073
2025-04-10 21:36:33,353 - ***** Epoch: 26: Eval results *****
2025-04-10 21:36:33,353 -   train_loss = 2.998617206301008
2025-04-10 21:36:47,637 - ***** Epoch: 27: Eval results *****
2025-04-10 21:36:47,637 -   train_loss = 2.9869937556130544
2025-04-10 21:37:01,306 - ***** Epoch: 28: Eval results *****
2025-04-10 21:37:01,307 -   train_loss = 2.9537244183676585
2025-04-10 21:37:15,744 - ***** Epoch: 29: Eval results *****
2025-04-10 21:37:15,744 -   train_loss = 2.943010006632124
2025-04-10 21:37:30,134 - ***** Epoch: 30: Eval results *****
2025-04-10 21:37:30,135 -   train_loss = 2.92829806464059
2025-04-10 21:37:44,169 - ***** Epoch: 31: Eval results *****
2025-04-10 21:37:44,170 -   train_loss = 2.9145463364464894
2025-04-10 21:37:59,348 - ***** Epoch: 32: Eval results *****
2025-04-10 21:37:59,348 -   train_loss = 2.8914207901273454
2025-04-10 21:38:13,917 - ***** Epoch: 33: Eval results *****
2025-04-10 21:38:13,918 -   train_loss = 2.8783988101141795
2025-04-10 21:38:28,544 - ***** Epoch: 34: Eval results *****
2025-04-10 21:38:28,545 -   train_loss = 2.8530115400041853
2025-04-10 21:38:42,757 - ***** Epoch: 35: Eval results *****
2025-04-10 21:38:42,757 -   train_loss = 2.860517382621765
2025-04-10 21:38:57,124 - ***** Epoch: 36: Eval results *****
2025-04-10 21:38:57,124 -   train_loss = 2.851612993649074
2025-04-10 21:39:11,540 - ***** Epoch: 37: Eval results *****
2025-04-10 21:39:11,540 -   train_loss = 2.829296963555472
2025-04-10 21:39:25,454 - ***** Epoch: 38: Eval results *****
2025-04-10 21:39:25,455 -   train_loss = 2.821111968585423
2025-04-10 21:39:39,747 - ***** Epoch: 39: Eval results *****
2025-04-10 21:39:39,747 -   train_loss = 2.8107960053852628
2025-04-10 21:39:54,002 - ***** Epoch: 40: Eval results *****
2025-04-10 21:39:54,002 -   train_loss = 2.8077832460403442
2025-04-10 21:40:08,105 - ***** Epoch: 41: Eval results *****
2025-04-10 21:40:08,106 -   train_loss = 2.8007789509637013
2025-04-10 21:40:22,395 - ***** Epoch: 42: Eval results *****
2025-04-10 21:40:22,396 -   train_loss = 2.7837109565734863
2025-04-10 21:40:37,015 - ***** Epoch: 43: Eval results *****
2025-04-10 21:40:37,016 -   train_loss = 2.7754619121551514
2025-04-10 21:40:51,413 - ***** Epoch: 44: Eval results *****
2025-04-10 21:40:51,414 -   train_loss = 2.7686343703951155
2025-04-10 21:41:06,504 - ***** Epoch: 45: Eval results *****
2025-04-10 21:41:06,504 -   train_loss = 2.7658043248312816
2025-04-10 21:41:21,054 - ***** Epoch: 46: Eval results *****
2025-04-10 21:41:21,055 -   train_loss = 2.7522588797977994
2025-04-10 21:41:35,407 - ***** Epoch: 47: Eval results *****
2025-04-10 21:41:35,408 -   train_loss = 2.745284540312631
2025-04-10 21:41:49,552 - ***** Epoch: 48: Eval results *****
2025-04-10 21:41:49,552 -   train_loss = 2.7450277635029385
2025-04-10 21:42:03,537 - ***** Epoch: 49: Eval results *****
2025-04-10 21:42:03,537 -   train_loss = 2.742486902645656
2025-04-10 21:42:18,134 - ***** Epoch: 50: Eval results *****
2025-04-10 21:42:18,134 -   train_loss = 2.724837762968881
2025-04-10 21:42:34,065 - ***** Epoch: 51: Eval results *****
2025-04-10 21:42:34,066 -   train_loss = 2.7261721406664168
2025-04-10 21:42:50,059 - ***** Epoch: 52: Eval results *****
2025-04-10 21:42:50,059 -   train_loss = 2.7137028319495067
2025-04-10 21:43:05,878 - ***** Epoch: 53: Eval results *****
2025-04-10 21:43:05,878 -   train_loss = 2.7065816606794084
2025-04-10 21:43:21,814 - ***** Epoch: 54: Eval results *****
2025-04-10 21:43:21,814 -   train_loss = 2.7111086504799977
2025-04-10 21:43:37,385 - ***** Epoch: 55: Eval results *****
2025-04-10 21:43:37,386 -   train_loss = 2.693747009549822
2025-04-10 21:43:53,153 - ***** Epoch: 56: Eval results *****
2025-04-10 21:43:53,154 -   train_loss = 2.6974796567644392
2025-04-10 21:44:08,855 - ***** Epoch: 57: Eval results *****
2025-04-10 21:44:08,855 -   train_loss = 2.6924538101468767
2025-04-10 21:44:24,255 - ***** Epoch: 58: Eval results *****
2025-04-10 21:44:24,255 -   train_loss = 2.6983478580202376
2025-04-10 21:44:38,959 - ***** Epoch: 59: Eval results *****
2025-04-10 21:44:38,959 -   train_loss = 2.684529287474496
2025-04-10 21:44:53,817 - ***** Epoch: 60: Eval results *****
2025-04-10 21:44:53,817 -   train_loss = 2.682458451816014
2025-04-10 21:45:08,530 - ***** Epoch: 61: Eval results *****
2025-04-10 21:45:08,530 -   train_loss = 2.6825438908168246
2025-04-10 21:45:23,212 - ***** Epoch: 62: Eval results *****
2025-04-10 21:45:23,213 -   train_loss = 2.6809674160821095
2025-04-10 21:45:37,758 - ***** Epoch: 63: Eval results *****
2025-04-10 21:45:37,759 -   train_loss = 2.670265861919948
2025-04-10 21:45:52,641 - ***** Epoch: 64: Eval results *****
2025-04-10 21:45:52,642 -   train_loss = 2.67188629082271
2025-04-10 21:46:07,173 - ***** Epoch: 65: Eval results *****
2025-04-10 21:46:07,174 -   train_loss = 2.6697860956192017
2025-04-10 21:46:23,072 - ***** Epoch: 66: Eval results *****
2025-04-10 21:46:23,073 -   train_loss = 2.6630489145006453
2025-04-10 21:46:38,901 - ***** Epoch: 67: Eval results *****
2025-04-10 21:46:38,901 -   train_loss = 2.659203427178519
2025-04-10 21:46:53,826 - ***** Epoch: 68: Eval results *****
2025-04-10 21:46:53,826 -   train_loss = 2.6581952401569913
2025-04-10 21:47:08,418 - ***** Epoch: 69: Eval results *****
2025-04-10 21:47:08,418 -   train_loss = 2.6497950553894043
2025-04-10 21:47:23,455 - ***** Epoch: 70: Eval results *****
2025-04-10 21:47:23,455 -   train_loss = 2.6490303107670377
2025-04-10 21:47:37,852 - ***** Epoch: 71: Eval results *****
2025-04-10 21:47:37,852 -   train_loss = 2.6518512964248657
2025-04-10 21:47:52,337 - ***** Epoch: 72: Eval results *****
2025-04-10 21:47:52,337 -   train_loss = 2.645648036684309
2025-04-10 21:48:06,711 - ***** Epoch: 73: Eval results *****
2025-04-10 21:48:06,711 -   train_loss = 2.649307898112706
2025-04-10 21:48:21,204 - ***** Epoch: 74: Eval results *****
2025-04-10 21:48:21,205 -   train_loss = 2.6411931855337962
2025-04-10 21:48:35,337 - ***** Epoch: 75: Eval results *****
2025-04-10 21:48:35,337 -   train_loss = 2.637574110712324
2025-04-10 21:48:49,796 - ***** Epoch: 76: Eval results *****
2025-04-10 21:48:49,796 -   train_loss = 2.6397641556603566
2025-04-10 21:49:04,137 - ***** Epoch: 77: Eval results *****
2025-04-10 21:49:04,138 -   train_loss = 2.632952775274004
2025-04-10 21:49:18,525 - ***** Epoch: 78: Eval results *****
2025-04-10 21:49:18,525 -   train_loss = 2.6312946251460483
2025-04-10 21:49:32,527 - ***** Epoch: 79: Eval results *****
2025-04-10 21:49:32,528 -   train_loss = 2.6298243829182217
2025-04-10 21:49:45,848 - ***** Epoch: 80: Eval results *****
2025-04-10 21:49:45,849 -   train_loss = 2.6310131549835205
2025-04-10 21:49:59,693 - ***** Epoch: 81: Eval results *****
2025-04-10 21:49:59,693 -   train_loss = 2.625327927725656
2025-04-10 21:50:13,505 - ***** Epoch: 82: Eval results *****
2025-04-10 21:50:13,506 -   train_loss = 2.640681965010507
2025-04-10 21:50:27,874 - ***** Epoch: 83: Eval results *****
2025-04-10 21:50:27,874 -   train_loss = 2.624036192893982
2025-04-10 21:50:42,134 - ***** Epoch: 84: Eval results *****
2025-04-10 21:50:42,134 -   train_loss = 2.622092706816537
2025-04-10 21:50:56,527 - ***** Epoch: 85: Eval results *****
2025-04-10 21:50:56,527 -   train_loss = 2.64211482661111
2025-04-10 21:51:11,161 - ***** Epoch: 86: Eval results *****
2025-04-10 21:51:11,161 -   train_loss = 2.6252616473606656
2025-04-10 21:51:26,233 - ***** Epoch: 87: Eval results *****
2025-04-10 21:51:26,233 -   train_loss = 2.6254999807902744
2025-04-10 21:51:40,309 - ***** Epoch: 88: Eval results *****
2025-04-10 21:51:40,309 -   train_loss = 2.6296394552503313
2025-04-10 21:51:54,549 - ***** Epoch: 89: Eval results *****
2025-04-10 21:51:54,549 -   train_loss = 2.621389320918492
2025-04-10 21:52:08,453 - ***** Epoch: 90: Eval results *****
2025-04-10 21:52:08,453 -   train_loss = 2.6278580597468784
2025-04-10 21:52:22,568 - ***** Epoch: 91: Eval results *****
2025-04-10 21:52:22,568 -   train_loss = 2.637322187423706
2025-04-10 21:52:37,120 - ***** Epoch: 92: Eval results *****
2025-04-10 21:52:37,120 -   train_loss = 2.6262644018445696
2025-04-10 21:52:51,730 - ***** Epoch: 93: Eval results *****
2025-04-10 21:52:51,730 -   train_loss = 2.634240678378514
2025-04-10 21:53:06,177 - ***** Epoch: 94: Eval results *****
2025-04-10 21:53:06,178 -   train_loss = 2.6147362845284596
2025-04-10 21:53:20,473 - ***** Epoch: 95: Eval results *****
2025-04-10 21:53:20,473 -   train_loss = 2.6211113248552596
2025-04-10 21:53:34,754 - ***** Epoch: 96: Eval results *****
2025-04-10 21:53:34,754 -   train_loss = 2.6165091821125577
2025-04-10 21:53:48,837 - ***** Epoch: 97: Eval results *****
2025-04-10 21:53:48,838 -   train_loss = 2.624194996697562
2025-04-10 21:54:02,845 - ***** Epoch: 98: Eval results *****
2025-04-10 21:54:02,845 -   train_loss = 2.6185210602624074
2025-04-10 21:54:17,102 - ***** Epoch: 99: Eval results *****
2025-04-10 21:54:17,102 -   train_loss = 2.6231267963136946
2025-04-10 21:54:31,484 - ***** Epoch: 100: Eval results *****
2025-04-10 21:54:31,484 -   train_loss = 2.6304115567888533
2025-04-10 21:54:32,038 - Pre-training finished...
2025-04-10 21:54:32,285 - Freeze all parameters but the last layer for efficiency
2025-04-10 21:54:32,294 - Multimodal Intent Recognition begins...
2025-04-10 21:54:32,294 - Training begins...
2025-04-10 21:54:52,842 - Initializing centroids with K-means++...
2025-04-10 21:54:52,916 - K-means++ used 0.07 s
2025-04-10 21:55:22,846 - K-means used 0.02 s
2025-04-10 21:55:23,553 - ***** Epoch: 1 *****
2025-04-10 21:55:23,553 - Supervised Training Loss: 4.877790
2025-04-10 21:55:23,553 - Unsupervised Training Loss: 5.094890
2025-04-10 21:55:52,135 - K-means used 0.02 s
2025-04-10 21:55:52,876 - ***** Epoch: 2 *****
2025-04-10 21:55:52,876 - Supervised Training Loss: 5.459520
2025-04-10 21:55:52,876 - Unsupervised Training Loss: 5.122530
2025-04-10 21:56:20,945 - K-means used 0.01 s
2025-04-10 21:56:21,728 - ***** Epoch: 3 *****
2025-04-10 21:56:21,728 - Supervised Training Loss: 5.302470
2025-04-10 21:56:21,728 - Unsupervised Training Loss: 4.976320
2025-04-10 21:56:49,438 - K-means used 0.02 s
2025-04-10 21:56:50,217 - ***** Epoch: 4 *****
2025-04-10 21:56:50,217 - Supervised Training Loss: 5.165210
2025-04-10 21:56:50,217 - Unsupervised Training Loss: 5.040760
2025-04-10 21:57:17,317 - K-means used 0.01 s
2025-04-10 21:57:18,119 - ***** Epoch: 5 *****
2025-04-10 21:57:18,119 - Supervised Training Loss: 4.896690
2025-04-10 21:57:18,119 - Unsupervised Training Loss: 5.078330
2025-04-10 21:57:45,467 - K-means used 0.01 s
2025-04-10 21:57:46,397 - ***** Epoch: 6 *****
2025-04-10 21:57:46,397 - Supervised Training Loss: 5.299770
2025-04-10 21:57:46,397 - Unsupervised Training Loss: 4.850800
2025-04-10 21:58:14,398 - K-means used 0.01 s
2025-04-10 21:58:15,246 - ***** Epoch: 7 *****
2025-04-10 21:58:15,246 - Supervised Training Loss: 5.222040
2025-04-10 21:58:15,246 - Unsupervised Training Loss: 4.988830
2025-04-10 21:58:43,055 - K-means used 0.01 s
2025-04-10 21:58:43,950 - ***** Epoch: 8 *****
2025-04-10 21:58:43,950 - Supervised Training Loss: 5.087710
2025-04-10 21:58:43,950 - Unsupervised Training Loss: 5.044630
2025-04-10 21:59:11,960 - K-means used 0.01 s
2025-04-10 21:59:12,900 - ***** Epoch: 9 *****
2025-04-10 21:59:12,900 - Supervised Training Loss: 5.310670
2025-04-10 21:59:12,900 - Unsupervised Training Loss: 5.081110
2025-04-10 21:59:40,142 - K-means used 0.01 s
2025-04-10 21:59:41,141 - ***** Epoch: 10 *****
2025-04-10 21:59:41,141 - Supervised Training Loss: 5.250220
2025-04-10 21:59:41,142 - Unsupervised Training Loss: 4.928840
2025-04-10 22:00:08,753 - K-means used 0.01 s
2025-04-10 22:00:09,770 - ***** Epoch: 11 *****
2025-04-10 22:00:09,770 - Supervised Training Loss: 5.177030
2025-04-10 22:00:09,770 - Unsupervised Training Loss: 5.010030
2025-04-10 22:00:37,736 - K-means used 0.01 s
2025-04-10 22:00:38,821 - ***** Epoch: 12 *****
2025-04-10 22:00:38,821 - Supervised Training Loss: 5.314670
2025-04-10 22:00:38,821 - Unsupervised Training Loss: 5.071640
2025-04-10 22:01:05,471 - K-means used 0.01 s
2025-04-10 22:01:06,657 - ***** Epoch: 13 *****
2025-04-10 22:01:06,657 - Supervised Training Loss: 5.279220
2025-04-10 22:01:06,657 - Unsupervised Training Loss: 4.794840
2025-04-10 22:01:33,417 - K-means used 0.01 s
2025-04-10 22:01:34,560 - ***** Epoch: 14 *****
2025-04-10 22:01:34,560 - Supervised Training Loss: 5.227790
2025-04-10 22:01:34,560 - Unsupervised Training Loss: 4.933210
2025-04-10 22:02:02,176 - K-means used 0.01 s
2025-04-10 22:02:03,440 - ***** Epoch: 15 *****
2025-04-10 22:02:03,440 - Supervised Training Loss: 5.067740
2025-04-10 22:02:03,440 - Unsupervised Training Loss: 5.036820
2025-04-10 22:02:30,686 - K-means used 0.01 s
2025-04-10 22:02:32,120 - ***** Epoch: 16 *****
2025-04-10 22:02:32,120 - Supervised Training Loss: 5.301020
2025-04-10 22:02:32,120 - Unsupervised Training Loss: 4.456960
2025-04-10 22:02:59,919 - K-means used 0.01 s
2025-04-10 22:03:01,290 - ***** Epoch: 17 *****
2025-04-10 22:03:01,290 - Supervised Training Loss: 5.267110
2025-04-10 22:03:01,290 - Unsupervised Training Loss: 4.727150
2025-04-10 22:03:17,048 - Training is finished...
2025-04-10 22:03:17,049 - Testing begins...
2025-04-10 22:03:24,604 - ***** Test results *****
2025-04-10 22:03:24,604 -   ACC = 42.7
2025-04-10 22:03:24,604 -   ARI = 22.72
2025-04-10 22:03:24,604 -   NMI = 48.2
2025-04-10 22:03:24,604 -   fmi = 27.67
2025-04-10 22:03:24,604 - Testing is finished...
2025-04-10 22:03:24,604 - Multimodal intent recognition is finished...
2025-04-10 22:03:24,604 - Results are saved in results/results_umc.csv
