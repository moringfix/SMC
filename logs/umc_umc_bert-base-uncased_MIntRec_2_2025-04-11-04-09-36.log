2025-04-11 04:09:36,672 - ============================== Params ==============================
2025-04-11 04:09:36,672 - logger_name: umc_umc_bert-base-uncased_MIntRec_2
2025-04-11 04:09:36,672 - dataset: MIntRec
2025-04-11 04:09:36,672 - multimodal_method: umc
2025-04-11 04:09:36,672 - method: umc
2025-04-11 04:09:36,672 - text_backbone: bert-base-uncased
2025-04-11 04:09:36,672 - seed: 2
2025-04-11 04:09:36,672 - num_workers: 16
2025-04-11 04:09:36,672 - log_id: umc_umc_bert-base-uncased_MIntRec_2_2025-04-11-04-09-36
2025-04-11 04:09:36,672 - gpu_id: 0
2025-04-11 04:09:36,672 - data_path: /root/autodl-tmp/home/Share/Dataset/LZH
2025-04-11 04:09:36,672 - train: True
2025-04-11 04:09:36,672 - tune: True
2025-04-11 04:09:36,672 - save_model: True
2025-04-11 04:09:36,673 - save_results: True
2025-04-11 04:09:36,673 - log_path: logs
2025-04-11 04:09:36,673 - cache_path: cache
2025-04-11 04:09:36,673 - video_data_path: video_data
2025-04-11 04:09:36,673 - audio_data_path: audio_data
2025-04-11 04:09:36,673 - video_feats_path: swin_feats.pkl
2025-04-11 04:09:36,673 - audio_feats_path: wavlm_feats.pkl
2025-04-11 04:09:36,673 - results_path: results
2025-04-11 04:09:36,673 - output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/UMC/outputs/MIntRec
2025-04-11 04:09:36,673 - model_path: models
2025-04-11 04:09:36,673 - config_file_name: umc_MIntRec
2025-04-11 04:09:36,673 - results_file_name: results_umc.csv
2025-04-11 04:09:36,673 - text_pretrained_model: uncased_L-12_H-768_A-12
2025-04-11 04:09:36,673 - text_seq_len: 30
2025-04-11 04:09:36,673 - video_seq_len: 230
2025-04-11 04:09:36,673 - audio_seq_len: 480
2025-04-11 04:09:36,673 - text_feat_dim: 768
2025-04-11 04:09:36,673 - video_feat_dim: 1024
2025-04-11 04:09:36,673 - audio_feat_dim: 768
2025-04-11 04:09:36,673 - num_labels: 20
2025-04-11 04:09:36,673 - num_train_examples: 1779
2025-04-11 04:09:36,673 - pretrained_bert_model: uncased_L-12_H-768_A-12
2025-04-11 04:09:36,673 - pretrain_batch_size: 128
2025-04-11 04:09:36,673 - train_batch_size: 128
2025-04-11 04:09:36,673 - eval_batch_size: 128
2025-04-11 04:09:36,673 - test_batch_size: 128
2025-04-11 04:09:36,673 - num_pretrain_epochs: 100
2025-04-11 04:09:36,673 - num_train_epochs: 100
2025-04-11 04:09:36,673 - pretrain: [True]
2025-04-11 04:09:36,673 - aligned_method: ctc
2025-04-11 04:09:36,674 - need_aligned: False
2025-04-11 04:09:36,674 - freeze_pretrain_bert_parameters: [True]
2025-04-11 04:09:36,674 - freeze_train_bert_parameters: [True]
2025-04-11 04:09:36,674 - pretrain_temperature: [0.2]
2025-04-11 04:09:36,674 - train_temperature_sup: [1.4]
2025-04-11 04:09:36,674 - train_temperature_unsup: [1]
2025-04-11 04:09:36,674 - activation: tanh
2025-04-11 04:09:36,674 - lr_pre: 5e-06
2025-04-11 04:09:36,674 - lr: [0.0003]
2025-04-11 04:09:36,674 - delta: [0.05]
2025-04-11 04:09:36,674 - thres: [0.1]
2025-04-11 04:09:36,674 - topk: [5]
2025-04-11 04:09:36,674 - weight_decay: 0.01
2025-04-11 04:09:36,674 - feat_dim: 768
2025-04-11 04:09:36,674 - hidden_size: 768
2025-04-11 04:09:36,674 - grad_clip: -1.0
2025-04-11 04:09:36,674 - warmup_proportion: 0.5
2025-04-11 04:09:36,674 - hidden_dropout_prob: 0.1
2025-04-11 04:09:36,674 - weight: 1.0
2025-04-11 04:09:36,674 - loss_mode: rdrop
2025-04-11 04:09:36,674 - base_dim: 256
2025-04-11 04:09:36,674 - nheads: 8
2025-04-11 04:09:36,674 - attn_dropout: 0.1
2025-04-11 04:09:36,674 - relu_dropout: 0.1
2025-04-11 04:09:36,674 - embed_dropout: 0.1
2025-04-11 04:09:36,674 - res_dropout: 0.0
2025-04-11 04:09:36,674 - attn_mask: True
2025-04-11 04:09:36,674 - encoder_layers_1: 1
2025-04-11 04:09:36,674 - fusion_act: tanh
2025-04-11 04:09:36,675 - pred_output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/UMC/outputs/MIntRec/umc_umc_MIntRec_bert-base-uncased_2
2025-04-11 04:09:36,675 - model_output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/UMC/outputs/MIntRec/umc_umc_MIntRec_bert-base-uncased_2/models
2025-04-11 04:09:36,675 - ============================== End Params ==============================
2025-04-11 04:09:37,754 - Freeze all parameters but the last layer for efficiency
2025-04-11 04:09:37,788 - Pre-training start...
2025-04-11 04:09:52,657 - ***** Epoch: 1: Eval results *****
2025-04-11 04:09:52,658 -   train_loss = 5.941120897020612
2025-04-11 04:10:06,753 - ***** Epoch: 2: Eval results *****
2025-04-11 04:10:06,753 -   train_loss = 5.938479116984776
2025-04-11 04:10:22,645 - ***** Epoch: 3: Eval results *****
2025-04-11 04:10:22,646 -   train_loss = 5.9396071434021
2025-04-11 04:10:38,606 - ***** Epoch: 4: Eval results *****
2025-04-11 04:10:38,606 -   train_loss = 5.939692905970982
2025-04-11 04:10:54,395 - ***** Epoch: 5: Eval results *****
2025-04-11 04:10:54,396 -   train_loss = 5.94168370110648
2025-04-11 04:11:10,990 - ***** Epoch: 6: Eval results *****
2025-04-11 04:11:10,990 -   train_loss = 5.942262717655727
2025-04-11 04:11:27,466 - ***** Epoch: 7: Eval results *****
2025-04-11 04:11:27,466 -   train_loss = 5.940302099500384
2025-04-11 04:11:43,581 - ***** Epoch: 8: Eval results *****
2025-04-11 04:11:43,581 -   train_loss = 5.938018730708531
2025-04-11 04:11:59,021 - ***** Epoch: 9: Eval results *****
2025-04-11 04:11:59,022 -   train_loss = 5.936844212668283
2025-04-11 04:12:14,478 - ***** Epoch: 10: Eval results *****
2025-04-11 04:12:14,478 -   train_loss = 5.93748334475926
2025-04-11 04:12:29,939 - ***** Epoch: 11: Eval results *****
2025-04-11 04:12:29,940 -   train_loss = 5.934468848364694
2025-04-11 04:12:45,218 - ***** Epoch: 12: Eval results *****
2025-04-11 04:12:45,219 -   train_loss = 5.936625787190029
2025-04-11 04:13:00,728 - ***** Epoch: 13: Eval results *****
2025-04-11 04:13:00,729 -   train_loss = 5.9356909820011685
2025-04-11 04:13:16,589 - ***** Epoch: 14: Eval results *****
2025-04-11 04:13:16,590 -   train_loss = 5.932789359773908
2025-04-11 04:13:32,910 - ***** Epoch: 15: Eval results *****
2025-04-11 04:13:32,910 -   train_loss = 5.932807547705514
2025-04-11 04:13:49,656 - ***** Epoch: 16: Eval results *****
2025-04-11 04:13:49,657 -   train_loss = 5.927682774407523
2025-04-11 04:14:05,710 - ***** Epoch: 17: Eval results *****
2025-04-11 04:14:05,710 -   train_loss = 5.925927264349801
2025-04-11 04:14:21,986 - ***** Epoch: 18: Eval results *****
2025-04-11 04:14:21,986 -   train_loss = 5.926154000418527
2025-04-11 04:14:38,266 - ***** Epoch: 19: Eval results *****
2025-04-11 04:14:38,266 -   train_loss = 5.922073636736188
2025-04-11 04:14:54,549 - ***** Epoch: 20: Eval results *****
2025-04-11 04:14:54,550 -   train_loss = 5.915293591363089
2025-04-11 04:15:10,963 - ***** Epoch: 21: Eval results *****
2025-04-11 04:15:10,963 -   train_loss = 5.911245788846697
2025-04-11 04:15:27,439 - ***** Epoch: 22: Eval results *****
2025-04-11 04:15:27,439 -   train_loss = 5.900267839431763
2025-04-11 04:15:43,508 - ***** Epoch: 23: Eval results *****
2025-04-11 04:15:43,509 -   train_loss = 5.893831934247698
2025-04-11 04:16:00,255 - ***** Epoch: 24: Eval results *****
2025-04-11 04:16:00,256 -   train_loss = 5.879618883132935
2025-04-11 04:16:17,010 - ***** Epoch: 25: Eval results *****
2025-04-11 04:16:17,011 -   train_loss = 5.861505576542446
2025-04-11 04:16:33,656 - ***** Epoch: 26: Eval results *****
2025-04-11 04:16:33,656 -   train_loss = 5.833607980183193
2025-04-11 04:16:50,164 - ***** Epoch: 27: Eval results *****
2025-04-11 04:16:50,164 -   train_loss = 5.79280948638916
2025-04-11 04:17:06,474 - ***** Epoch: 28: Eval results *****
2025-04-11 04:17:06,475 -   train_loss = 5.740731716156006
2025-04-11 04:17:22,446 - ***** Epoch: 29: Eval results *****
2025-04-11 04:17:22,446 -   train_loss = 5.6643050738743375
2025-04-11 04:17:38,676 - ***** Epoch: 30: Eval results *****
2025-04-11 04:17:38,677 -   train_loss = 5.549862793513706
2025-04-11 04:17:54,853 - ***** Epoch: 31: Eval results *****
2025-04-11 04:17:54,853 -   train_loss = 5.407510484967913
2025-04-11 04:18:11,510 - ***** Epoch: 32: Eval results *****
2025-04-11 04:18:11,511 -   train_loss = 5.268784318651472
2025-04-11 04:18:31,102 - ***** Epoch: 33: Eval results *****
2025-04-11 04:18:31,103 -   train_loss = 5.112785850252424
2025-04-11 04:18:49,797 - ***** Epoch: 34: Eval results *****
2025-04-11 04:18:49,797 -   train_loss = 4.98032774244036
2025-04-11 04:19:09,419 - ***** Epoch: 35: Eval results *****
2025-04-11 04:19:09,420 -   train_loss = 4.84510122026716
2025-04-11 04:19:26,754 - ***** Epoch: 36: Eval results *****
2025-04-11 04:19:26,755 -   train_loss = 4.728635038648333
2025-04-11 04:19:43,526 - ***** Epoch: 37: Eval results *****
2025-04-11 04:19:43,526 -   train_loss = 4.607191290174212
2025-04-11 04:20:00,640 - ***** Epoch: 38: Eval results *****
2025-04-11 04:20:00,640 -   train_loss = 4.509349414280483
2025-04-11 04:20:17,490 - ***** Epoch: 39: Eval results *****
2025-04-11 04:20:17,490 -   train_loss = 4.413090944290161
2025-04-11 04:20:34,299 - ***** Epoch: 40: Eval results *****
2025-04-11 04:20:34,299 -   train_loss = 4.341772760663714
2025-04-11 04:20:50,799 - ***** Epoch: 41: Eval results *****
2025-04-11 04:20:50,800 -   train_loss = 4.251673119408744
2025-04-11 04:21:07,379 - ***** Epoch: 42: Eval results *****
2025-04-11 04:21:07,380 -   train_loss = 4.171872138977051
2025-04-11 04:21:23,925 - ***** Epoch: 43: Eval results *****
2025-04-11 04:21:23,925 -   train_loss = 4.114296776907785
2025-04-11 04:21:39,565 - ***** Epoch: 44: Eval results *****
2025-04-11 04:21:39,565 -   train_loss = 4.048405936786106
2025-04-11 04:21:55,697 - ***** Epoch: 45: Eval results *****
2025-04-11 04:21:55,697 -   train_loss = 3.9905701875686646
2025-04-11 04:22:12,538 - ***** Epoch: 46: Eval results *****
2025-04-11 04:22:12,539 -   train_loss = 3.92710702759879
2025-04-11 04:22:28,684 - ***** Epoch: 47: Eval results *****
2025-04-11 04:22:28,684 -   train_loss = 3.8750238248280118
2025-04-11 04:22:44,870 - ***** Epoch: 48: Eval results *****
2025-04-11 04:22:44,870 -   train_loss = 3.8234697580337524
2025-04-11 04:23:01,034 - ***** Epoch: 49: Eval results *****
2025-04-11 04:23:01,034 -   train_loss = 3.7712921925953458
2025-04-11 04:23:17,134 - ***** Epoch: 50: Eval results *****
2025-04-11 04:23:17,134 -   train_loss = 3.724227019718715
2025-04-11 04:23:33,005 - ***** Epoch: 51: Eval results *****
2025-04-11 04:23:33,006 -   train_loss = 3.6925962482179915
2025-04-11 04:23:48,473 - ***** Epoch: 52: Eval results *****
2025-04-11 04:23:48,474 -   train_loss = 3.6596809966223582
2025-04-11 04:24:04,366 - ***** Epoch: 53: Eval results *****
2025-04-11 04:24:04,366 -   train_loss = 3.6145661899021695
2025-04-11 04:24:19,818 - ***** Epoch: 54: Eval results *****
2025-04-11 04:24:19,818 -   train_loss = 3.585842660495213
2025-04-11 04:24:35,154 - ***** Epoch: 55: Eval results *****
2025-04-11 04:24:35,155 -   train_loss = 3.5512536764144897
2025-04-11 04:24:50,617 - ***** Epoch: 56: Eval results *****
2025-04-11 04:24:50,617 -   train_loss = 3.541317650250026
2025-04-11 04:25:06,357 - ***** Epoch: 57: Eval results *****
2025-04-11 04:25:06,357 -   train_loss = 3.5134834221431186
2025-04-11 04:25:21,930 - ***** Epoch: 58: Eval results *****
2025-04-11 04:25:21,931 -   train_loss = 3.4981384107044766
2025-04-11 04:25:37,577 - ***** Epoch: 59: Eval results *****
2025-04-11 04:25:37,578 -   train_loss = 3.4657727820532664
2025-04-11 04:25:53,360 - ***** Epoch: 60: Eval results *****
2025-04-11 04:25:53,360 -   train_loss = 3.44829637663705
2025-04-11 04:26:08,358 - ***** Epoch: 61: Eval results *****
2025-04-11 04:26:08,358 -   train_loss = 3.430536593709673
2025-04-11 04:26:23,340 - ***** Epoch: 62: Eval results *****
2025-04-11 04:26:23,340 -   train_loss = 3.4306193249566213
2025-04-11 04:26:38,138 - ***** Epoch: 63: Eval results *****
2025-04-11 04:26:38,138 -   train_loss = 3.4060401746204922
2025-04-11 04:26:52,959 - ***** Epoch: 64: Eval results *****
2025-04-11 04:26:52,960 -   train_loss = 3.3939630644662038
2025-04-11 04:27:08,558 - ***** Epoch: 65: Eval results *****
2025-04-11 04:27:08,559 -   train_loss = 3.3714484657560075
2025-04-11 04:27:24,505 - ***** Epoch: 66: Eval results *****
2025-04-11 04:27:24,505 -   train_loss = 3.3718951770237515
2025-04-11 04:27:40,120 - ***** Epoch: 67: Eval results *****
2025-04-11 04:27:40,121 -   train_loss = 3.3607854502541676
2025-04-11 04:27:55,746 - ***** Epoch: 68: Eval results *****
2025-04-11 04:27:55,747 -   train_loss = 3.346147928919111
2025-04-11 04:28:12,056 - ***** Epoch: 69: Eval results *****
2025-04-11 04:28:12,057 -   train_loss = 3.339195898600987
2025-04-11 04:28:27,720 - ***** Epoch: 70: Eval results *****
2025-04-11 04:28:27,720 -   train_loss = 3.330169217927115
2025-04-11 04:28:43,117 - ***** Epoch: 71: Eval results *****
2025-04-11 04:28:43,117 -   train_loss = 3.310338020324707
2025-04-11 04:28:58,365 - ***** Epoch: 72: Eval results *****
2025-04-11 04:28:58,365 -   train_loss = 3.296306388718741
2025-04-11 04:29:13,497 - ***** Epoch: 73: Eval results *****
2025-04-11 04:29:13,498 -   train_loss = 3.2919307265962874
2025-04-11 04:29:29,477 - ***** Epoch: 74: Eval results *****
2025-04-11 04:29:29,477 -   train_loss = 3.2906142473220825
2025-04-11 04:29:46,030 - ***** Epoch: 75: Eval results *****
2025-04-11 04:29:46,030 -   train_loss = 3.2741639614105225
2025-04-11 04:30:02,439 - ***** Epoch: 76: Eval results *****
2025-04-11 04:30:02,439 -   train_loss = 3.2768070868083408
2025-04-11 04:30:17,926 - ***** Epoch: 77: Eval results *****
2025-04-11 04:30:17,926 -   train_loss = 3.2566784620285034
2025-04-11 04:30:33,392 - ***** Epoch: 78: Eval results *****
2025-04-11 04:30:33,393 -   train_loss = 3.253750443458557
2025-04-11 04:30:50,062 - ***** Epoch: 79: Eval results *****
2025-04-11 04:30:50,063 -   train_loss = 3.2552118131092618
2025-04-11 04:31:05,959 - ***** Epoch: 80: Eval results *****
2025-04-11 04:31:05,959 -   train_loss = 3.261695282799857
2025-04-11 04:31:22,397 - ***** Epoch: 81: Eval results *****
2025-04-11 04:31:22,398 -   train_loss = 3.237949013710022
2025-04-11 04:31:38,080 - ***** Epoch: 82: Eval results *****
2025-04-11 04:31:38,081 -   train_loss = 3.2304873977388655
2025-04-11 04:31:53,250 - ***** Epoch: 83: Eval results *****
2025-04-11 04:31:53,250 -   train_loss = 3.2323103972843716
2025-04-11 04:32:08,645 - ***** Epoch: 84: Eval results *****
2025-04-11 04:32:08,645 -   train_loss = 3.2442945412227084
2025-04-11 04:32:24,226 - ***** Epoch: 85: Eval results *****
2025-04-11 04:32:24,226 -   train_loss = 3.2243313789367676
2025-04-11 04:32:41,237 - ***** Epoch: 86: Eval results *****
2025-04-11 04:32:41,238 -   train_loss = 3.2278615406581332
2025-04-11 04:32:58,487 - ***** Epoch: 87: Eval results *****
2025-04-11 04:32:58,487 -   train_loss = 3.2185210159846713
2025-04-11 04:33:16,110 - ***** Epoch: 88: Eval results *****
2025-04-11 04:33:16,111 -   train_loss = 3.2206007412501743
2025-04-11 04:33:32,753 - ***** Epoch: 89: Eval results *****
2025-04-11 04:33:32,753 -   train_loss = 3.22477126121521
2025-04-11 04:33:49,070 - ***** Epoch: 90: Eval results *****
2025-04-11 04:33:49,070 -   train_loss = 3.2206192186900546
2025-04-11 04:34:05,967 - ***** Epoch: 91: Eval results *****
2025-04-11 04:34:05,967 -   train_loss = 3.2171103954315186
2025-04-11 04:34:22,867 - ***** Epoch: 92: Eval results *****
2025-04-11 04:34:22,868 -   train_loss = 3.2219327177320207
2025-04-11 04:34:39,638 - ***** Epoch: 93: Eval results *****
2025-04-11 04:34:39,639 -   train_loss = 3.2253435850143433
2025-04-11 04:34:56,342 - ***** Epoch: 94: Eval results *****
2025-04-11 04:34:56,342 -   train_loss = 3.2256693840026855
2025-04-11 04:35:12,858 - ***** Epoch: 95: Eval results *****
2025-04-11 04:35:12,858 -   train_loss = 3.2187144926616122
2025-04-11 04:35:28,769 - ***** Epoch: 96: Eval results *****
2025-04-11 04:35:28,769 -   train_loss = 3.2168608052389964
2025-04-11 04:35:44,386 - ***** Epoch: 97: Eval results *****
2025-04-11 04:35:44,386 -   train_loss = 3.225855452673776
2025-04-11 04:35:59,577 - ***** Epoch: 98: Eval results *****
2025-04-11 04:35:59,578 -   train_loss = 3.2133811371667043
2025-04-11 04:36:15,513 - ***** Epoch: 99: Eval results *****
2025-04-11 04:36:15,513 -   train_loss = 3.2210695913859775
2025-04-11 04:36:31,622 - ***** Epoch: 100: Eval results *****
2025-04-11 04:36:31,623 -   train_loss = 3.2164435046059743
2025-04-11 04:36:32,125 - Pre-training finished...
2025-04-11 04:36:32,415 - Freeze all parameters but the last layer for efficiency
2025-04-11 04:36:32,424 - Multimodal Intent Recognition begins...
2025-04-11 04:36:32,424 - Training begins...
2025-04-11 04:36:47,820 - Initializing centroids with K-means++...
2025-04-11 04:36:47,901 - K-means++ used 0.08 s
2025-04-11 04:37:18,593 - K-means used 0.02 s
2025-04-11 04:37:19,958 - ***** Epoch: 1 *****
2025-04-11 04:37:19,959 - Supervised Training Loss: 4.896990
2025-04-11 04:37:19,960 - Unsupervised Training Loss: 5.184080
2025-04-11 04:37:48,846 - K-means used 0.02 s
2025-04-11 04:37:50,268 - ***** Epoch: 2 *****
2025-04-11 04:37:50,269 - Supervised Training Loss: 3.879580
2025-04-11 04:37:50,269 - Unsupervised Training Loss: 5.188570
2025-04-11 04:38:18,823 - K-means used 0.02 s
2025-04-11 04:38:20,244 - ***** Epoch: 3 *****
2025-04-11 04:38:20,244 - Supervised Training Loss: 5.335160
2025-04-11 04:38:20,244 - Unsupervised Training Loss: 5.041230
2025-04-11 04:38:51,565 - K-means used 0.02 s
2025-04-11 04:38:53,006 - ***** Epoch: 4 *****
2025-04-11 04:38:53,006 - Supervised Training Loss: 5.186160
2025-04-11 04:38:53,006 - Unsupervised Training Loss: 5.098090
2025-04-11 04:39:26,104 - K-means used 0.08 s
2025-04-11 04:39:27,297 - ***** Epoch: 5 *****
2025-04-11 04:39:27,297 - Supervised Training Loss: 4.921850
2025-04-11 04:39:27,297 - Unsupervised Training Loss: 5.124560
2025-04-11 04:39:58,314 - K-means used 0.02 s
2025-04-11 04:39:59,752 - ***** Epoch: 6 *****
2025-04-11 04:39:59,752 - Supervised Training Loss: 5.343110
2025-04-11 04:39:59,752 - Unsupervised Training Loss: 4.902080
2025-04-11 04:40:29,034 - K-means used 0.02 s
2025-04-11 04:40:30,531 - ***** Epoch: 7 *****
2025-04-11 04:40:30,531 - Supervised Training Loss: 5.262230
2025-04-11 04:40:30,531 - Unsupervised Training Loss: 5.030750
2025-04-11 04:41:00,108 - K-means used 0.06 s
2025-04-11 04:41:01,619 - ***** Epoch: 8 *****
2025-04-11 04:41:01,619 - Supervised Training Loss: 5.115240
2025-04-11 04:41:01,619 - Unsupervised Training Loss: 5.086880
2025-04-11 04:41:31,357 - K-means used 0.02 s
2025-04-11 04:41:32,971 - ***** Epoch: 9 *****
2025-04-11 04:41:32,971 - Supervised Training Loss: 5.333630
2025-04-11 04:41:32,972 - Unsupervised Training Loss: 5.120520
2025-04-11 04:42:02,261 - K-means used 0.03 s
2025-04-11 04:42:04,165 - ***** Epoch: 10 *****
2025-04-11 04:42:04,165 - Supervised Training Loss: 5.276590
2025-04-11 04:42:04,165 - Unsupervised Training Loss: 4.939150
2025-04-11 04:42:33,935 - K-means used 0.02 s
2025-04-11 04:42:35,586 - ***** Epoch: 11 *****
2025-04-11 04:42:35,587 - Supervised Training Loss: 5.193550
2025-04-11 04:42:35,587 - Unsupervised Training Loss: 5.027110
2025-04-11 04:43:04,907 - K-means used 0.06 s
2025-04-11 04:43:06,874 - ***** Epoch: 12 *****
2025-04-11 04:43:06,874 - Supervised Training Loss: 5.325760
2025-04-11 04:43:06,874 - Unsupervised Training Loss: 5.103390
2025-04-11 04:43:34,274 - K-means used 0.02 s
2025-04-11 04:43:36,180 - ***** Epoch: 13 *****
2025-04-11 04:43:36,180 - Supervised Training Loss: 5.285780
2025-04-11 04:43:36,180 - Unsupervised Training Loss: 4.820260
2025-04-11 04:44:09,203 - K-means used 0.1 s
2025-04-11 04:44:11,064 - ***** Epoch: 14 *****
2025-04-11 04:44:11,064 - Supervised Training Loss: 5.231250
2025-04-11 04:44:11,064 - Unsupervised Training Loss: 4.956070
2025-04-11 04:44:45,489 - K-means used 0.02 s
2025-04-11 04:44:47,513 - ***** Epoch: 15 *****
2025-04-11 04:44:47,513 - Supervised Training Loss: 5.081910
2025-04-11 04:44:47,513 - Unsupervised Training Loss: 5.049570
2025-04-11 04:45:20,118 - K-means used 0.02 s
2025-04-11 04:45:22,143 - ***** Epoch: 16 *****
2025-04-11 04:45:22,143 - Supervised Training Loss: 5.301310
2025-04-11 04:45:22,144 - Unsupervised Training Loss: 4.471640
2025-04-11 04:45:53,032 - K-means used 0.02 s
2025-04-11 04:45:55,126 - ***** Epoch: 17 *****
2025-04-11 04:45:55,126 - Supervised Training Loss: 5.268410
2025-04-11 04:45:55,126 - Unsupervised Training Loss: 4.714650
2025-04-11 04:46:13,758 - Training is finished...
2025-04-11 04:46:13,759 - Testing begins...
2025-04-11 04:46:20,894 - ***** Test results *****
2025-04-11 04:46:20,894 -   ACC = 37.98
2025-04-11 04:46:20,894 -   ARI = 20.37
2025-04-11 04:46:20,894 -   NMI = 42.93
2025-04-11 04:46:20,894 -   fmi = 25.58
2025-04-11 04:46:20,894 - Testing is finished...
2025-04-11 04:46:20,894 - Multimodal intent recognition is finished...
2025-04-11 04:46:20,894 - Results are saved in results/results_umc.csv
