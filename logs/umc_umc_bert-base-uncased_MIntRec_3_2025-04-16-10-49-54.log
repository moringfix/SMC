2025-04-16 10:49:54,222 - 进入了无监督的设定中, 加载数据集
2025-04-16 10:49:54,222 - data preparation...
2025-04-16 10:50:02,874 - Number of train samples = 1779
2025-04-16 10:50:02,875 - Number of testing samples = 445
2025-04-16 10:50:02,875 - data preparation...
2025-04-16 10:50:05,153 - num_train_examples = 1779
2025-04-16 10:50:05,154 - ============================== Params ==============================
2025-04-16 10:50:05,154 - logger_name: umc_umc_bert-base-uncased_MIntRec_3
2025-04-16 10:50:05,154 - dataset: MIntRec
2025-04-16 10:50:05,154 - multimodal_method: umc
2025-04-16 10:50:05,154 - method: umc
2025-04-16 10:50:05,154 - setting: unsupervised
2025-04-16 10:50:05,154 - text_backbone: bert-base-uncased
2025-04-16 10:50:05,154 - seed: 3
2025-04-16 10:50:05,154 - num_workers: 16
2025-04-16 10:50:05,154 - log_id: umc_umc_bert-base-uncased_MIntRec_3_2025-04-16-10-49-54
2025-04-16 10:50:05,154 - gpu_id: 0
2025-04-16 10:50:05,154 - data_path: /root/autodl-tmp/home/Share/Dataset/LZH
2025-04-16 10:50:05,154 - train: True
2025-04-16 10:50:05,154 - tune: True
2025-04-16 10:50:05,154 - save_model: True
2025-04-16 10:50:05,154 - save_results: True
2025-04-16 10:50:05,154 - log_path: logs
2025-04-16 10:50:05,155 - cache_path: cache
2025-04-16 10:50:05,155 - video_data_path: video_data
2025-04-16 10:50:05,155 - audio_data_path: audio_data
2025-04-16 10:50:05,155 - video_feats_path: swin_feats.pkl
2025-04-16 10:50:05,155 - audio_feats_path: wavlm_feats.pkl
2025-04-16 10:50:05,155 - results_path: results
2025-04-16 10:50:05,155 - output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/SMC/outputs_test/MIntRec
2025-04-16 10:50:05,155 - model_path: models
2025-04-16 10:50:05,155 - config_file_name: umc_MIntRec
2025-04-16 10:50:05,155 - results_file_name: results_umc.csv
2025-04-16 10:50:05,155 - text_pretrained_model: uncased_L-12_H-768_A-12
2025-04-16 10:50:05,155 - pretrained_bert_model: uncased_L-12_H-768_A-12
2025-04-16 10:50:05,155 - pretrain_batch_size: 128
2025-04-16 10:50:05,155 - train_batch_size: 128
2025-04-16 10:50:05,155 - eval_batch_size: 128
2025-04-16 10:50:05,156 - test_batch_size: 128
2025-04-16 10:50:05,156 - num_pretrain_epochs: 100
2025-04-16 10:50:05,156 - num_train_epochs: 100
2025-04-16 10:50:05,156 - pretrain: [True]
2025-04-16 10:50:05,156 - aligned_method: ctc
2025-04-16 10:50:05,156 - need_aligned: False
2025-04-16 10:50:05,156 - freeze_pretrain_bert_parameters: [True]
2025-04-16 10:50:05,156 - freeze_train_bert_parameters: [True]
2025-04-16 10:50:05,156 - pretrain_temperature: [0.1]
2025-04-16 10:50:05,156 - train_temperature_sup: [0.5]
2025-04-16 10:50:05,156 - train_temperature_unsup: [2]
2025-04-16 10:50:05,156 - activation: tanh
2025-04-16 10:50:05,156 - lr_pre: 1e-05
2025-04-16 10:50:05,156 - lr: [0.0001]
2025-04-16 10:50:05,156 - delta: [0.05]
2025-04-16 10:50:05,156 - thres: [0.1]
2025-04-16 10:50:05,156 - topk: [5]
2025-04-16 10:50:05,156 - weight_decay: 0.01
2025-04-16 10:50:05,156 - feat_dim: 768
2025-04-16 10:50:05,156 - hidden_size: 768
2025-04-16 10:50:05,156 - grad_clip: -1.0
2025-04-16 10:50:05,156 - warmup_proportion: 0.5
2025-04-16 10:50:05,156 - hidden_dropout_prob: 0.1
2025-04-16 10:50:05,156 - weight: 1.0
2025-04-16 10:50:05,156 - loss_mode: rdrop
2025-04-16 10:50:05,156 - base_dim: 256
2025-04-16 10:50:05,156 - nheads: 8
2025-04-16 10:50:05,156 - attn_dropout: 0.1
2025-04-16 10:50:05,157 - relu_dropout: 0.1
2025-04-16 10:50:05,157 - embed_dropout: 0.01
2025-04-16 10:50:05,157 - res_dropout: 0.0
2025-04-16 10:50:05,157 - attn_mask: True
2025-04-16 10:50:05,157 - encoder_layers_1: 1
2025-04-16 10:50:05,157 - fusion_act: tanh
2025-04-16 10:50:05,157 - pred_output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/SMC/outputs_test/MIntRec/umc_umc_MIntRec_bert-base-uncased_3
2025-04-16 10:50:05,157 - model_output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/SMC/outputs_test/MIntRec/umc_umc_MIntRec_bert-base-uncased_3/models
2025-04-16 10:50:05,157 - text_seq_len: 30
2025-04-16 10:50:05,157 - video_seq_len: 230
2025-04-16 10:50:05,157 - audio_seq_len: 480
2025-04-16 10:50:05,157 - text_feat_dim: 768
2025-04-16 10:50:05,157 - video_feat_dim: 1024
2025-04-16 10:50:05,157 - audio_feat_dim: 768
2025-04-16 10:50:05,157 - num_labels: 20
2025-04-16 10:50:05,157 - num_train_examples: 1779
2025-04-16 10:50:05,157 - ============================== End Params ==============================
2025-04-16 10:50:06,474 - Freeze all parameters but the last layer for efficiency
2025-04-16 10:50:06,508 - Pre-training start...
2025-04-16 10:50:23,385 - ***** Epoch: 1: Eval results *****
2025-04-16 10:50:23,385 -   train_loss = 5.958394391196115
2025-04-16 10:50:40,592 - ***** Epoch: 2: Eval results *****
2025-04-16 10:50:40,593 -   train_loss = 5.963605846677508
2025-04-16 10:50:57,703 - ***** Epoch: 3: Eval results *****
2025-04-16 10:50:57,703 -   train_loss = 5.962784835270473
2025-04-16 10:51:15,059 - ***** Epoch: 4: Eval results *****
2025-04-16 10:51:15,059 -   train_loss = 5.963015079498291
2025-04-16 10:51:32,531 - ***** Epoch: 5: Eval results *****
2025-04-16 10:51:32,531 -   train_loss = 5.963409628186907
2025-04-16 10:51:49,799 - ***** Epoch: 6: Eval results *****
2025-04-16 10:51:49,799 -   train_loss = 5.95563496862139
2025-04-16 10:52:07,582 - ***** Epoch: 7: Eval results *****
2025-04-16 10:52:07,582 -   train_loss = 5.9544409683772495
2025-04-16 10:52:25,241 - ***** Epoch: 8: Eval results *****
2025-04-16 10:52:25,241 -   train_loss = 5.953428336552212
2025-04-16 10:52:42,698 - ***** Epoch: 9: Eval results *****
2025-04-16 10:52:42,698 -   train_loss = 5.937513453619821
2025-04-16 10:52:59,827 - ***** Epoch: 10: Eval results *****
2025-04-16 10:52:59,828 -   train_loss = 5.931964090892246
2025-04-16 10:53:16,554 - ***** Epoch: 11: Eval results *****
2025-04-16 10:53:16,554 -   train_loss = 5.929917539869036
2025-04-16 10:53:34,041 - ***** Epoch: 12: Eval results *****
2025-04-16 10:53:34,042 -   train_loss = 5.918503931590489
2025-04-16 10:53:50,479 - ***** Epoch: 13: Eval results *****
2025-04-16 10:53:50,480 -   train_loss = 5.9092628955841064
2025-04-16 10:54:07,463 - ***** Epoch: 14: Eval results *****
2025-04-16 10:54:07,463 -   train_loss = 5.883241755621774
2025-04-16 10:54:24,630 - ***** Epoch: 15: Eval results *****
2025-04-16 10:54:24,631 -   train_loss = 5.855455296380179
2025-04-16 10:54:42,084 - ***** Epoch: 16: Eval results *****
2025-04-16 10:54:42,084 -   train_loss = 5.8266003131866455
2025-04-16 10:54:58,682 - ***** Epoch: 17: Eval results *****
2025-04-16 10:54:58,682 -   train_loss = 5.758595364434378
2025-04-16 10:55:16,445 - ***** Epoch: 18: Eval results *****
2025-04-16 10:55:16,445 -   train_loss = 5.659095219203404
2025-04-16 10:55:33,930 - ***** Epoch: 19: Eval results *****
2025-04-16 10:55:33,931 -   train_loss = 5.514867714473179
2025-04-16 10:55:50,949 - ***** Epoch: 20: Eval results *****
2025-04-16 10:55:50,949 -   train_loss = 5.304683549063546
2025-04-16 10:56:07,558 - ***** Epoch: 21: Eval results *****
2025-04-16 10:56:07,558 -   train_loss = 5.028524535042899
2025-04-16 10:56:24,455 - ***** Epoch: 22: Eval results *****
2025-04-16 10:56:24,456 -   train_loss = 4.743766410010202
2025-04-16 10:56:41,962 - ***** Epoch: 23: Eval results *****
2025-04-16 10:56:41,963 -   train_loss = 4.497014284133911
2025-04-16 10:56:58,665 - ***** Epoch: 24: Eval results *****
2025-04-16 10:56:58,665 -   train_loss = 4.278868300574167
2025-04-16 10:57:16,226 - ***** Epoch: 25: Eval results *****
2025-04-16 10:57:16,227 -   train_loss = 4.040535535131182
2025-04-16 10:57:32,935 - ***** Epoch: 26: Eval results *****
2025-04-16 10:57:32,935 -   train_loss = 3.843787363597325
2025-04-16 10:57:50,256 - ***** Epoch: 27: Eval results *****
2025-04-16 10:57:50,257 -   train_loss = 3.671750068664551
2025-04-16 10:58:07,438 - ***** Epoch: 28: Eval results *****
2025-04-16 10:58:07,439 -   train_loss = 3.511806539126805
2025-04-16 10:58:23,736 - ***** Epoch: 29: Eval results *****
2025-04-16 10:58:23,737 -   train_loss = 3.325914536203657
2025-04-16 10:58:40,929 - ***** Epoch: 30: Eval results *****
2025-04-16 10:58:40,929 -   train_loss = 3.1744313750948225
2025-04-16 10:59:00,264 - ***** Epoch: 31: Eval results *****
2025-04-16 10:59:00,264 -   train_loss = 3.0525875432150706
2025-04-16 10:59:18,256 - ***** Epoch: 32: Eval results *****
2025-04-16 10:59:18,256 -   train_loss = 2.9402808121272495
2025-04-16 10:59:37,942 - ***** Epoch: 33: Eval results *****
2025-04-16 10:59:37,942 -   train_loss = 2.7897267171314786
2025-04-16 10:59:56,270 - ***** Epoch: 34: Eval results *****
2025-04-16 10:59:56,271 -   train_loss = 2.712785039629255
2025-04-16 11:00:14,200 - ***** Epoch: 35: Eval results *****
2025-04-16 11:00:14,200 -   train_loss = 2.6475987945284163
2025-04-16 11:00:31,910 - ***** Epoch: 36: Eval results *****
2025-04-16 11:00:31,910 -   train_loss = 2.5477472884314403
2025-04-16 11:00:49,574 - ***** Epoch: 37: Eval results *****
2025-04-16 11:00:49,575 -   train_loss = 2.4363394805363248
2025-04-16 11:01:07,478 - ***** Epoch: 38: Eval results *****
2025-04-16 11:01:07,478 -   train_loss = 2.380130308015006
2025-04-16 11:01:25,160 - ***** Epoch: 39: Eval results *****
2025-04-16 11:01:25,160 -   train_loss = 2.306690216064453
2025-04-16 11:01:42,764 - ***** Epoch: 40: Eval results *****
2025-04-16 11:01:42,764 -   train_loss = 2.260338510785784
2025-04-16 11:01:59,869 - ***** Epoch: 41: Eval results *****
2025-04-16 11:01:59,869 -   train_loss = 2.1875518219811574
2025-04-16 11:02:17,287 - ***** Epoch: 42: Eval results *****
2025-04-16 11:02:17,287 -   train_loss = 2.142239434378488
2025-04-16 11:02:34,659 - ***** Epoch: 43: Eval results *****
2025-04-16 11:02:34,660 -   train_loss = 2.0754104937825884
2025-04-16 11:02:51,764 - ***** Epoch: 44: Eval results *****
2025-04-16 11:02:51,765 -   train_loss = 2.0342792017119273
2025-04-16 11:03:08,886 - ***** Epoch: 45: Eval results *****
2025-04-16 11:03:08,886 -   train_loss = 2.0134884885379245
2025-04-16 11:03:25,522 - ***** Epoch: 46: Eval results *****
2025-04-16 11:03:25,522 -   train_loss = 1.9587212375232153
2025-04-16 11:03:42,019 - ***** Epoch: 47: Eval results *****
2025-04-16 11:03:42,019 -   train_loss = 1.914073075566973
2025-04-16 11:03:58,739 - ***** Epoch: 48: Eval results *****
2025-04-16 11:03:58,740 -   train_loss = 1.8596136995724268
2025-04-16 11:04:15,761 - ***** Epoch: 49: Eval results *****
2025-04-16 11:04:15,762 -   train_loss = 1.8328484041350228
2025-04-16 11:04:32,804 - ***** Epoch: 50: Eval results *****
2025-04-16 11:04:32,804 -   train_loss = 1.8139105694634574
2025-04-16 11:04:49,870 - ***** Epoch: 51: Eval results *****
2025-04-16 11:04:49,871 -   train_loss = 1.7708241939544678
2025-04-16 11:05:06,981 - ***** Epoch: 52: Eval results *****
2025-04-16 11:05:06,981 -   train_loss = 1.7562080877167838
2025-04-16 11:05:23,747 - ***** Epoch: 53: Eval results *****
2025-04-16 11:05:23,748 -   train_loss = 1.7228997690337045
2025-04-16 11:05:40,777 - ***** Epoch: 54: Eval results *****
2025-04-16 11:05:40,777 -   train_loss = 1.7003247737884521
2025-04-16 11:05:58,074 - ***** Epoch: 55: Eval results *****
2025-04-16 11:05:58,075 -   train_loss = 1.682667417185647
2025-04-16 11:06:15,089 - ***** Epoch: 56: Eval results *****
2025-04-16 11:06:15,089 -   train_loss = 1.6563288399151392
2025-04-16 11:06:32,524 - ***** Epoch: 57: Eval results *****
2025-04-16 11:06:32,524 -   train_loss = 1.6509178962026323
2025-04-16 11:06:49,308 - ***** Epoch: 58: Eval results *****
2025-04-16 11:06:49,308 -   train_loss = 1.6433622070721217
2025-04-16 11:07:06,025 - ***** Epoch: 59: Eval results *****
2025-04-16 11:07:06,025 -   train_loss = 1.625234569822039
2025-04-16 11:07:22,995 - ***** Epoch: 60: Eval results *****
2025-04-16 11:07:22,996 -   train_loss = 1.6025020565305437
2025-04-16 11:07:39,679 - ***** Epoch: 61: Eval results *****
2025-04-16 11:07:39,679 -   train_loss = 1.5896337372916085
2025-04-16 11:07:57,068 - ***** Epoch: 62: Eval results *****
2025-04-16 11:07:57,069 -   train_loss = 1.5893564309392656
2025-04-16 11:08:14,674 - ***** Epoch: 63: Eval results *****
2025-04-16 11:08:14,675 -   train_loss = 1.5579829556601388
2025-04-16 11:08:31,703 - ***** Epoch: 64: Eval results *****
2025-04-16 11:08:31,704 -   train_loss = 1.55862329687391
2025-04-16 11:08:48,328 - ***** Epoch: 65: Eval results *****
2025-04-16 11:08:48,328 -   train_loss = 1.557980171271733
2025-04-16 11:09:05,933 - ***** Epoch: 66: Eval results *****
2025-04-16 11:09:05,933 -   train_loss = 1.5526028871536255
2025-04-16 11:09:22,345 - ***** Epoch: 67: Eval results *****
2025-04-16 11:09:22,346 -   train_loss = 1.5412122351782662
2025-04-16 11:09:39,217 - ***** Epoch: 68: Eval results *****
2025-04-16 11:09:39,218 -   train_loss = 1.5460652794156755
2025-04-16 11:09:55,884 - ***** Epoch: 69: Eval results *****
2025-04-16 11:09:55,884 -   train_loss = 1.523160423551287
2025-04-16 11:10:13,053 - ***** Epoch: 70: Eval results *****
2025-04-16 11:10:13,053 -   train_loss = 1.528994517666953
2025-04-16 11:10:29,964 - ***** Epoch: 71: Eval results *****
2025-04-16 11:10:29,964 -   train_loss = 1.5095447897911072
2025-04-16 11:10:47,329 - ***** Epoch: 72: Eval results *****
2025-04-16 11:10:47,329 -   train_loss = 1.5019689798355103
2025-04-16 11:11:04,672 - ***** Epoch: 73: Eval results *****
2025-04-16 11:11:04,672 -   train_loss = 1.4954066021101815
2025-04-16 11:11:22,400 - ***** Epoch: 74: Eval results *****
2025-04-16 11:11:22,400 -   train_loss = 1.4843975475856237
2025-04-16 11:11:39,956 - ***** Epoch: 75: Eval results *****
2025-04-16 11:11:39,956 -   train_loss = 1.499776039804731
2025-04-16 11:11:58,848 - ***** Epoch: 76: Eval results *****
2025-04-16 11:11:58,849 -   train_loss = 1.4869939599718367
2025-04-16 11:12:19,512 - ***** Epoch: 77: Eval results *****
2025-04-16 11:12:19,512 -   train_loss = 1.468133773122515
2025-04-16 11:12:38,954 - ***** Epoch: 78: Eval results *****
2025-04-16 11:12:38,954 -   train_loss = 1.4733101725578308
2025-04-16 11:12:57,200 - ***** Epoch: 79: Eval results *****
2025-04-16 11:12:57,201 -   train_loss = 1.470147430896759
2025-04-16 11:13:15,345 - ***** Epoch: 80: Eval results *****
2025-04-16 11:13:15,345 -   train_loss = 1.4804044791630335
2025-04-16 11:13:32,478 - ***** Epoch: 81: Eval results *****
2025-04-16 11:13:32,478 -   train_loss = 1.4597301483154297
2025-04-16 11:13:48,876 - ***** Epoch: 82: Eval results *****
2025-04-16 11:13:48,876 -   train_loss = 1.4593450341905867
2025-04-16 11:14:07,670 - ***** Epoch: 83: Eval results *****
2025-04-16 11:14:07,670 -   train_loss = 1.4670886908258711
2025-04-16 11:14:25,634 - ***** Epoch: 84: Eval results *****
2025-04-16 11:14:25,634 -   train_loss = 1.4570799725396293
2025-04-16 11:14:43,564 - ***** Epoch: 85: Eval results *****
2025-04-16 11:14:43,564 -   train_loss = 1.4552770001547677
2025-04-16 11:15:01,218 - ***** Epoch: 86: Eval results *****
2025-04-16 11:15:01,219 -   train_loss = 1.4516822951180595
2025-04-16 11:15:18,572 - ***** Epoch: 87: Eval results *****
2025-04-16 11:15:18,572 -   train_loss = 1.4528398684092931
2025-04-16 11:15:35,347 - ***** Epoch: 88: Eval results *****
2025-04-16 11:15:35,347 -   train_loss = 1.4528947728020805
2025-04-16 11:15:51,564 - ***** Epoch: 89: Eval results *****
2025-04-16 11:15:51,564 -   train_loss = 1.4481311185019357
2025-04-16 11:16:07,778 - ***** Epoch: 90: Eval results *****
2025-04-16 11:16:07,778 -   train_loss = 1.4567870668002538
2025-04-16 11:16:24,320 - ***** Epoch: 91: Eval results *****
2025-04-16 11:16:24,320 -   train_loss = 1.4528983575957162
2025-04-16 11:16:40,146 - ***** Epoch: 92: Eval results *****
2025-04-16 11:16:40,146 -   train_loss = 1.4478634425571986
2025-04-16 11:16:56,474 - ***** Epoch: 93: Eval results *****
2025-04-16 11:16:56,474 -   train_loss = 1.4463383896010262
2025-04-16 11:17:12,533 - ***** Epoch: 94: Eval results *****
2025-04-16 11:17:12,534 -   train_loss = 1.4453147394316537
2025-04-16 11:17:29,060 - ***** Epoch: 95: Eval results *****
2025-04-16 11:17:29,060 -   train_loss = 1.436013204710824
2025-04-16 11:17:45,117 - ***** Epoch: 96: Eval results *****
2025-04-16 11:17:45,117 -   train_loss = 1.4477193781307764
2025-04-16 11:18:01,129 - ***** Epoch: 97: Eval results *****
2025-04-16 11:18:01,129 -   train_loss = 1.4438733628817968
2025-04-16 11:18:16,610 - ***** Epoch: 98: Eval results *****
2025-04-16 11:18:16,611 -   train_loss = 1.4547363775117057
2025-04-16 11:18:32,664 - ***** Epoch: 99: Eval results *****
2025-04-16 11:18:32,665 -   train_loss = 1.4453875507627214
2025-04-16 11:18:48,822 - ***** Epoch: 100: Eval results *****
2025-04-16 11:18:48,822 -   train_loss = 1.447544242654528
2025-04-16 11:18:49,369 - Pre-training finished...
2025-04-16 11:18:49,722 - Freeze all parameters but the last layer for efficiency
2025-04-16 11:18:49,732 - Multimodal Intent Recognition begins...
2025-04-16 11:18:49,732 - Training begins...
2025-04-16 11:19:04,874 - Initializing centroids with K-means++...
2025-04-16 11:19:04,952 - K-means++ used 0.08 s
2025-04-16 11:19:34,078 - K-means used 0.03 s
2025-04-16 11:19:35,198 - ***** Epoch: 1 *****
2025-04-16 11:19:35,199 - Supervised Training Loss: 4.347070
2025-04-16 11:19:35,201 - Unsupervised Training Loss: 5.529110
2025-04-16 11:20:04,479 - K-means used 0.02 s
2025-04-16 11:20:05,566 - ***** Epoch: 2 *****
2025-04-16 11:20:05,567 - Supervised Training Loss: 5.011980
2025-04-16 11:20:05,567 - Unsupervised Training Loss: 5.560170
2025-04-16 11:20:34,223 - K-means used 0.02 s
2025-04-16 11:20:35,323 - ***** Epoch: 3 *****
2025-04-16 11:20:35,324 - Supervised Training Loss: 4.885680
2025-04-16 11:20:35,324 - Unsupervised Training Loss: 5.425790
2025-04-16 11:21:04,574 - K-means used 0.02 s
2025-04-16 11:21:05,833 - ***** Epoch: 4 *****
2025-04-16 11:21:05,833 - Supervised Training Loss: 4.693980
2025-04-16 11:21:05,833 - Unsupervised Training Loss: 5.496300
2025-04-16 11:21:35,179 - K-means used 0.03 s
2025-04-16 11:21:36,362 - ***** Epoch: 5 *****
2025-04-16 11:21:36,362 - Supervised Training Loss: 4.389480
2025-04-16 11:21:36,362 - Unsupervised Training Loss: 5.533590
2025-04-16 11:22:03,253 - K-means used 0.03 s
2025-04-16 11:22:04,479 - ***** Epoch: 6 *****
2025-04-16 11:22:04,479 - Supervised Training Loss: 4.740580
2025-04-16 11:22:04,479 - Unsupervised Training Loss: 5.342770
2025-04-16 11:22:32,434 - K-means used 0.02 s
2025-04-16 11:22:33,864 - ***** Epoch: 7 *****
2025-04-16 11:22:33,864 - Supervised Training Loss: 4.600150
2025-04-16 11:22:33,865 - Unsupervised Training Loss: 5.442200
2025-04-16 11:23:01,996 - K-means used 0.01 s
2025-04-16 11:23:03,358 - ***** Epoch: 8 *****
2025-04-16 11:23:03,358 - Supervised Training Loss: 4.408300
2025-04-16 11:23:03,358 - Unsupervised Training Loss: 5.496760
2025-04-16 11:23:32,262 - K-means used 0.02 s
2025-04-16 11:23:33,665 - ***** Epoch: 9 *****
2025-04-16 11:23:33,665 - Supervised Training Loss: 4.575010
2025-04-16 11:23:33,666 - Unsupervised Training Loss: 4.930730
2025-04-16 11:24:00,461 - K-means used 0.03 s
2025-04-16 11:24:02,107 - ***** Epoch: 10 *****
2025-04-16 11:24:02,107 - Supervised Training Loss: 4.492370
2025-04-16 11:24:02,107 - Unsupervised Training Loss: 5.378540
2025-04-16 11:24:30,514 - K-means used 0.02 s
2025-04-16 11:24:32,036 - ***** Epoch: 11 *****
2025-04-16 11:24:32,036 - Supervised Training Loss: 4.390950
2025-04-16 11:24:32,036 - Unsupervised Training Loss: 5.463000
2025-04-16 11:25:00,528 - K-means used 0.02 s
2025-04-16 11:25:02,196 - ***** Epoch: 12 *****
2025-04-16 11:25:02,196 - Supervised Training Loss: 4.517010
2025-04-16 11:25:02,196 - Unsupervised Training Loss: 5.519740
2025-04-16 11:25:31,499 - K-means used 0.02 s
2025-04-16 11:25:33,016 - ***** Epoch: 13 *****
2025-04-16 11:25:33,017 - Supervised Training Loss: 4.470410
2025-04-16 11:25:33,017 - Unsupervised Training Loss: 5.247620
2025-04-16 11:26:02,311 - K-means used 0.04 s
2025-04-16 11:26:03,951 - ***** Epoch: 14 *****
2025-04-16 11:26:03,951 - Supervised Training Loss: 4.419400
2025-04-16 11:26:03,951 - Unsupervised Training Loss: 5.380550
2025-04-16 11:26:31,871 - K-means used 0.02 s
2025-04-16 11:26:33,557 - ***** Epoch: 15 *****
2025-04-16 11:26:33,558 - Supervised Training Loss: 4.310990
2025-04-16 11:26:33,558 - Unsupervised Training Loss: 5.474090
2025-04-16 11:27:02,520 - K-means used 0.02 s
2025-04-16 11:27:04,594 - ***** Epoch: 16 *****
2025-04-16 11:27:04,594 - Supervised Training Loss: 4.505570
2025-04-16 11:27:04,595 - Unsupervised Training Loss: 4.948740
2025-04-16 11:27:36,121 - K-means used 0.02 s
2025-04-16 11:27:38,025 - ***** Epoch: 17 *****
2025-04-16 11:27:38,025 - Supervised Training Loss: 4.493750
2025-04-16 11:27:38,025 - Unsupervised Training Loss: 5.147070
2025-04-16 11:27:58,016 - Training is finished...
2025-04-16 11:27:58,016 - Testing begins...
2025-04-16 11:28:06,969 - ***** Test results *****
2025-04-16 11:28:06,970 -   ACC = 40.0
2025-04-16 11:28:06,970 -   ARI = 20.77
2025-04-16 11:28:06,970 -   NMI = 48.29
2025-04-16 11:28:06,970 -   fmi = 25.75
2025-04-16 11:28:06,970 - Testing is finished...
2025-04-16 11:28:06,970 - Multimodal intent recognition is finished...
2025-04-16 11:28:06,970 - Results are saved in results/results_umc.csv
