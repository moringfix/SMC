2025-04-16 16:43:56,922 - 【无监督】进入了无监督的设定中, 加载数据集
2025-04-16 16:43:56,922 - data preparation...
2025-04-16 16:44:06,325 - Number of train samples = 1779
2025-04-16 16:44:06,325 - Number of testing samples = 445
2025-04-16 16:44:06,325 - data preparation...
2025-04-16 16:44:08,545 - num_train_examples = 1779
2025-04-16 16:44:08,546 - ============================== Params ==============================
2025-04-16 16:44:08,546 - logger_name: umc_umc_bert-base-uncased_MIntRec_2
2025-04-16 16:44:08,546 - dataset: MIntRec
2025-04-16 16:44:08,546 - multimodal_method: umc
2025-04-16 16:44:08,546 - method: umc
2025-04-16 16:44:08,546 - setting: unsupervised
2025-04-16 16:44:08,546 - text_backbone: bert-base-uncased
2025-04-16 16:44:08,546 - seed: 2
2025-04-16 16:44:08,546 - num_workers: 16
2025-04-16 16:44:08,546 - log_id: umc_umc_bert-base-uncased_MIntRec_2_2025-04-16-16-43-56
2025-04-16 16:44:08,546 - gpu_id: 1
2025-04-16 16:44:08,546 - data_path: /root/autodl-tmp/home/Share/Dataset/LZH
2025-04-16 16:44:08,546 - train: True
2025-04-16 16:44:08,546 - tune: True
2025-04-16 16:44:08,546 - save_model: True
2025-04-16 16:44:08,546 - save_results: True
2025-04-16 16:44:08,546 - log_path: logs
2025-04-16 16:44:08,546 - cache_path: cache
2025-04-16 16:44:08,546 - video_data_path: video_data
2025-04-16 16:44:08,546 - audio_data_path: audio_data
2025-04-16 16:44:08,546 - video_feats_path: swin_feats.pkl
2025-04-16 16:44:08,546 - audio_feats_path: wavlm_feats.pkl
2025-04-16 16:44:08,546 - results_path: results
2025-04-16 16:44:08,547 - output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/SMC/outputs_test2/MIntRec
2025-04-16 16:44:08,547 - model_path: models
2025-04-16 16:44:08,547 - config_file_name: umc_MIntRec
2025-04-16 16:44:08,547 - results_file_name: results_umc.csv
2025-04-16 16:44:08,547 - text_pretrained_model: uncased_L-12_H-768_A-12
2025-04-16 16:44:08,547 - pretrained_bert_model: uncased_L-12_H-768_A-12
2025-04-16 16:44:08,547 - pretrain_batch_size: 128
2025-04-16 16:44:08,547 - train_batch_size: 128
2025-04-16 16:44:08,547 - eval_batch_size: 128
2025-04-16 16:44:08,547 - test_batch_size: 128
2025-04-16 16:44:08,547 - num_pretrain_epochs: 100
2025-04-16 16:44:08,547 - num_train_epochs: 100
2025-04-16 16:44:08,547 - pretrain: [True]
2025-04-16 16:44:08,547 - aligned_method: ctc
2025-04-16 16:44:08,547 - need_aligned: False
2025-04-16 16:44:08,547 - freeze_pretrain_bert_parameters: [True]
2025-04-16 16:44:08,548 - freeze_train_bert_parameters: [True]
2025-04-16 16:44:08,548 - pretrain_temperature: [0.1]
2025-04-16 16:44:08,548 - train_temperature_sup: [0.5]
2025-04-16 16:44:08,548 - train_temperature_unsup: [2]
2025-04-16 16:44:08,548 - activation: tanh
2025-04-16 16:44:08,548 - lr_pre: [3e-05]
2025-04-16 16:44:08,548 - lr: [5e-05]
2025-04-16 16:44:08,548 - delta: [0.05]
2025-04-16 16:44:08,548 - thres: [0.1]
2025-04-16 16:44:08,548 - topk: [5]
2025-04-16 16:44:08,548 - weight_decay: 0.01
2025-04-16 16:44:08,548 - feat_dim: 768
2025-04-16 16:44:08,548 - hidden_size: 768
2025-04-16 16:44:08,548 - grad_clip: -1.0
2025-04-16 16:44:08,548 - warmup_proportion: [0.1]
2025-04-16 16:44:08,548 - hidden_dropout_prob: 0.1
2025-04-16 16:44:08,548 - weight: 1.0
2025-04-16 16:44:08,548 - loss_mode: rdrop
2025-04-16 16:44:08,548 - base_dim: 256
2025-04-16 16:44:08,548 - nheads: 8
2025-04-16 16:44:08,548 - attn_dropout: 0.1
2025-04-16 16:44:08,548 - relu_dropout: 0.1
2025-04-16 16:44:08,548 - embed_dropout: 0.01
2025-04-16 16:44:08,548 - res_dropout: 0.0
2025-04-16 16:44:08,548 - attn_mask: True
2025-04-16 16:44:08,548 - encoder_layers_1: 1
2025-04-16 16:44:08,548 - fusion_act: tanh
2025-04-16 16:44:08,548 - pred_output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/SMC/outputs_test2/MIntRec/umc_umc_MIntRec_bert-base-uncased_2
2025-04-16 16:44:08,548 - model_output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/SMC/outputs_test2/MIntRec/umc_umc_MIntRec_bert-base-uncased_2/models
2025-04-16 16:44:08,549 - text_seq_len: 30
2025-04-16 16:44:08,549 - video_seq_len: 230
2025-04-16 16:44:08,549 - audio_seq_len: 480
2025-04-16 16:44:08,549 - text_feat_dim: 768
2025-04-16 16:44:08,549 - video_feat_dim: 1024
2025-04-16 16:44:08,549 - audio_feat_dim: 768
2025-04-16 16:44:08,549 - num_labels: 20
2025-04-16 16:44:08,549 - num_train_examples: 1779
2025-04-16 16:44:08,549 - ============================== End Params ==============================
2025-04-16 16:44:09,953 - Freeze all parameters but the last layer for efficiency
2025-04-16 16:44:09,988 - Pre-training start...
2025-04-16 16:44:31,039 - ***** Epoch: 1: Eval results *****
2025-04-16 16:44:31,039 -   train_loss = 5.959239789417812
2025-04-16 16:44:52,162 - ***** Epoch: 2: Eval results *****
2025-04-16 16:44:52,163 -   train_loss = 5.947718688419887
2025-04-16 16:45:12,654 - ***** Epoch: 3: Eval results *****
2025-04-16 16:45:12,654 -   train_loss = 5.9276041984558105
2025-04-16 16:45:35,648 - ***** Epoch: 4: Eval results *****
2025-04-16 16:45:35,648 -   train_loss = 5.892525809151786
2025-04-16 16:45:56,549 - ***** Epoch: 5: Eval results *****
2025-04-16 16:45:56,549 -   train_loss = 5.796255009514945
2025-04-16 16:46:18,370 - ***** Epoch: 6: Eval results *****
2025-04-16 16:46:18,370 -   train_loss = 5.43671144757952
2025-04-16 16:46:38,746 - ***** Epoch: 7: Eval results *****
2025-04-16 16:46:38,746 -   train_loss = 4.663543462753296
2025-04-16 16:47:01,129 - ***** Epoch: 8: Eval results *****
2025-04-16 16:47:01,129 -   train_loss = 3.85812280859266
2025-04-16 16:47:26,754 - ***** Epoch: 9: Eval results *****
2025-04-16 16:47:26,754 -   train_loss = 3.226691552570888
2025-04-16 16:47:48,578 - ***** Epoch: 10: Eval results *****
2025-04-16 16:47:48,578 -   train_loss = 2.7451973983219693
2025-04-16 16:48:10,540 - ***** Epoch: 11: Eval results *****
2025-04-16 16:48:10,540 -   train_loss = 2.4121022735323225
2025-04-16 16:48:32,479 - ***** Epoch: 12: Eval results *****
2025-04-16 16:48:32,479 -   train_loss = 2.179476499557495
2025-04-16 16:48:53,268 - ***** Epoch: 13: Eval results *****
2025-04-16 16:48:53,269 -   train_loss = 2.0355106507028853
2025-04-16 16:49:14,782 - ***** Epoch: 14: Eval results *****
2025-04-16 16:49:14,783 -   train_loss = 1.9173736912863595
2025-04-16 16:49:36,442 - ***** Epoch: 15: Eval results *****
2025-04-16 16:49:36,442 -   train_loss = 1.8360973681722368
2025-04-16 16:49:57,780 - ***** Epoch: 16: Eval results *****
2025-04-16 16:49:57,780 -   train_loss = 1.756413119179862
2025-04-16 16:50:19,180 - ***** Epoch: 17: Eval results *****
2025-04-16 16:50:19,180 -   train_loss = 1.6904628361974443
2025-04-16 16:50:38,864 - ***** Epoch: 18: Eval results *****
2025-04-16 16:50:38,865 -   train_loss = 1.629030806677682
2025-04-16 16:51:01,477 - ***** Epoch: 19: Eval results *****
2025-04-16 16:51:01,478 -   train_loss = 1.5979356850896562
2025-04-16 16:51:22,126 - ***** Epoch: 20: Eval results *****
2025-04-16 16:51:22,126 -   train_loss = 1.5482597691672189
2025-04-16 16:51:42,906 - ***** Epoch: 21: Eval results *****
2025-04-16 16:51:42,906 -   train_loss = 1.522044803415026
2025-04-16 16:52:04,973 - ***** Epoch: 22: Eval results *****
2025-04-16 16:52:04,974 -   train_loss = 1.4857980012893677
2025-04-16 16:52:25,612 - ***** Epoch: 23: Eval results *****
2025-04-16 16:52:25,612 -   train_loss = 1.4825579353741236
2025-04-16 16:52:45,642 - ***** Epoch: 24: Eval results *****
2025-04-16 16:52:45,643 -   train_loss = 1.4470423289707728
2025-04-16 16:53:07,268 - ***** Epoch: 25: Eval results *****
2025-04-16 16:53:07,269 -   train_loss = 1.43179623569761
2025-04-16 16:53:28,470 - ***** Epoch: 26: Eval results *****
2025-04-16 16:53:28,470 -   train_loss = 1.410162159374782
2025-04-16 16:53:49,899 - ***** Epoch: 27: Eval results *****
2025-04-16 16:53:49,900 -   train_loss = 1.397167342049735
2025-04-16 16:54:16,098 - ***** Epoch: 28: Eval results *****
2025-04-16 16:54:16,098 -   train_loss = 1.3688335163252694
2025-04-16 16:54:38,563 - ***** Epoch: 29: Eval results *****
2025-04-16 16:54:38,563 -   train_loss = 1.3564103926931108
2025-04-16 16:54:59,870 - ***** Epoch: 30: Eval results *****
2025-04-16 16:54:59,870 -   train_loss = 1.3542975187301636
2025-04-16 16:55:22,325 - ***** Epoch: 31: Eval results *****
2025-04-16 16:55:22,326 -   train_loss = 1.3410991259983607
2025-04-16 16:55:43,008 - ***** Epoch: 32: Eval results *****
2025-04-16 16:55:43,009 -   train_loss = 1.317427090236119
2025-04-16 16:56:05,691 - ***** Epoch: 33: Eval results *****
2025-04-16 16:56:05,692 -   train_loss = 1.3188054817063468
2025-04-16 16:56:27,761 - ***** Epoch: 34: Eval results *****
2025-04-16 16:56:27,761 -   train_loss = 1.3111985155514307
2025-04-16 16:56:48,882 - ***** Epoch: 35: Eval results *****
2025-04-16 16:56:48,882 -   train_loss = 1.2898970246315002
2025-04-16 16:57:09,577 - ***** Epoch: 36: Eval results *****
2025-04-16 16:57:09,578 -   train_loss = 1.289960401398795
2025-04-16 16:57:31,407 - ***** Epoch: 37: Eval results *****
2025-04-16 16:57:31,407 -   train_loss = 1.282652633530753
2025-04-16 16:57:53,991 - ***** Epoch: 38: Eval results *****
2025-04-16 16:57:53,991 -   train_loss = 1.2701617223875863
2025-04-16 16:58:14,410 - ***** Epoch: 39: Eval results *****
2025-04-16 16:58:14,411 -   train_loss = 1.2662594829286848
2025-04-16 16:58:34,474 - ***** Epoch: 40: Eval results *****
2025-04-16 16:58:34,475 -   train_loss = 1.2626782996313912
2025-04-16 16:58:56,105 - ***** Epoch: 41: Eval results *****
2025-04-16 16:58:56,106 -   train_loss = 1.2532944168363298
2025-04-16 16:59:18,602 - ***** Epoch: 42: Eval results *****
2025-04-16 16:59:18,602 -   train_loss = 1.243653655052185
2025-04-16 16:59:41,553 - ***** Epoch: 43: Eval results *****
2025-04-16 16:59:41,554 -   train_loss = 1.2508086136409216
2025-04-16 17:00:02,281 - ***** Epoch: 44: Eval results *****
2025-04-16 17:00:02,281 -   train_loss = 1.2342520441327776
2025-04-16 17:00:23,405 - ***** Epoch: 45: Eval results *****
2025-04-16 17:00:23,405 -   train_loss = 1.2297742111342294
2025-04-16 17:00:45,378 - ***** Epoch: 46: Eval results *****
2025-04-16 17:00:45,378 -   train_loss = 1.224377419267382
2025-04-16 17:01:10,682 - ***** Epoch: 47: Eval results *****
2025-04-16 17:01:10,682 -   train_loss = 1.222017867224557
2025-04-16 17:01:31,246 - ***** Epoch: 48: Eval results *****
2025-04-16 17:01:31,246 -   train_loss = 1.2207717640059335
2025-04-16 17:01:53,644 - ***** Epoch: 49: Eval results *****
2025-04-16 17:01:53,644 -   train_loss = 1.2135419590132577
2025-04-16 17:02:15,066 - ***** Epoch: 50: Eval results *****
2025-04-16 17:02:15,066 -   train_loss = 1.1989709053720747
2025-04-16 17:02:36,188 - ***** Epoch: 51: Eval results *****
2025-04-16 17:02:36,188 -   train_loss = 1.2015839559691293
2025-04-16 17:02:57,907 - ***** Epoch: 52: Eval results *****
2025-04-16 17:02:57,907 -   train_loss = 1.2020690611430578
2025-04-16 17:03:19,713 - ***** Epoch: 53: Eval results *****
2025-04-16 17:03:19,714 -   train_loss = 1.1887620432036263
2025-04-16 17:03:41,381 - ***** Epoch: 54: Eval results *****
2025-04-16 17:03:41,381 -   train_loss = 1.1886175530297416
2025-04-16 17:04:01,964 - ***** Epoch: 55: Eval results *****
2025-04-16 17:04:01,964 -   train_loss = 1.1879582234791346
2025-04-16 17:04:25,512 - ***** Epoch: 56: Eval results *****
2025-04-16 17:04:25,512 -   train_loss = 1.18441846540996
2025-04-16 17:04:47,766 - ***** Epoch: 57: Eval results *****
2025-04-16 17:04:47,766 -   train_loss = 1.179244407585689
2025-04-16 17:05:09,760 - ***** Epoch: 58: Eval results *****
2025-04-16 17:05:09,760 -   train_loss = 1.1835137605667114
2025-04-16 17:05:30,954 - ***** Epoch: 59: Eval results *****
2025-04-16 17:05:30,954 -   train_loss = 1.1761959620884486
2025-04-16 17:05:51,237 - ***** Epoch: 60: Eval results *****
2025-04-16 17:05:51,237 -   train_loss = 1.1745778237070357
2025-04-16 17:06:11,704 - ***** Epoch: 61: Eval results *****
2025-04-16 17:06:11,704 -   train_loss = 1.1651778987475805
2025-04-16 17:06:33,658 - ***** Epoch: 62: Eval results *****
2025-04-16 17:06:33,659 -   train_loss = 1.171075165271759
2025-04-16 17:06:55,981 - ***** Epoch: 63: Eval results *****
2025-04-16 17:06:55,982 -   train_loss = 1.1667781557355608
2025-04-16 17:07:18,561 - ***** Epoch: 64: Eval results *****
2025-04-16 17:07:18,561 -   train_loss = 1.155555077961513
2025-04-16 17:07:39,913 - ***** Epoch: 65: Eval results *****
2025-04-16 17:07:39,913 -   train_loss = 1.1587419850485665
2025-04-16 17:08:02,590 - ***** Epoch: 66: Eval results *****
2025-04-16 17:08:02,590 -   train_loss = 1.1632082292011805
2025-04-16 17:08:24,475 - ***** Epoch: 67: Eval results *****
2025-04-16 17:08:24,476 -   train_loss = 1.1598139149802071
2025-04-16 17:08:46,384 - ***** Epoch: 68: Eval results *****
2025-04-16 17:08:46,385 -   train_loss = 1.1585387672696794
2025-04-16 17:09:08,019 - ***** Epoch: 69: Eval results *****
2025-04-16 17:09:08,020 -   train_loss = 1.1539840953690665
2025-04-16 17:09:29,582 - ***** Epoch: 70: Eval results *****
2025-04-16 17:09:29,582 -   train_loss = 1.1551711474146162
2025-04-16 17:09:51,815 - ***** Epoch: 71: Eval results *****
2025-04-16 17:09:51,815 -   train_loss = 1.149034423487527
2025-04-16 17:10:13,988 - ***** Epoch: 72: Eval results *****
2025-04-16 17:10:13,988 -   train_loss = 1.1428496497017997
2025-04-16 17:10:36,697 - ***** Epoch: 73: Eval results *****
2025-04-16 17:10:36,697 -   train_loss = 1.1543447630746024
2025-04-16 17:10:57,846 - ***** Epoch: 74: Eval results *****
2025-04-16 17:10:57,846 -   train_loss = 1.1456978406224931
2025-04-16 17:11:21,592 - ***** Epoch: 75: Eval results *****
2025-04-16 17:11:21,593 -   train_loss = 1.1474881172180176
2025-04-16 17:11:44,095 - ***** Epoch: 76: Eval results *****
2025-04-16 17:11:44,096 -   train_loss = 1.143247434071132
2025-04-16 17:12:03,746 - ***** Epoch: 77: Eval results *****
2025-04-16 17:12:03,747 -   train_loss = 1.138322923864637
2025-04-16 17:12:24,376 - ***** Epoch: 78: Eval results *****
2025-04-16 17:12:24,377 -   train_loss = 1.135513390813555
2025-04-16 17:12:45,714 - ***** Epoch: 79: Eval results *****
2025-04-16 17:12:45,714 -   train_loss = 1.1345853464944022
2025-04-16 17:13:05,728 - ***** Epoch: 80: Eval results *****
2025-04-16 17:13:05,728 -   train_loss = 1.1410225204059057
2025-04-16 17:13:26,003 - ***** Epoch: 81: Eval results *****
2025-04-16 17:13:26,003 -   train_loss = 1.132186574595315
2025-04-16 17:13:48,106 - ***** Epoch: 82: Eval results *****
2025-04-16 17:13:48,106 -   train_loss = 1.1307915874889918
2025-04-16 17:14:09,483 - ***** Epoch: 83: Eval results *****
2025-04-16 17:14:09,484 -   train_loss = 1.1281269192695618
2025-04-16 17:14:34,509 - ***** Epoch: 84: Eval results *****
2025-04-16 17:14:34,509 -   train_loss = 1.14356872013637
2025-04-16 17:14:56,440 - ***** Epoch: 85: Eval results *****
2025-04-16 17:14:56,441 -   train_loss = 1.133529441697257
2025-04-16 17:15:18,711 - ***** Epoch: 86: Eval results *****
2025-04-16 17:15:18,712 -   train_loss = 1.1338142326899938
2025-04-16 17:15:40,798 - ***** Epoch: 87: Eval results *****
2025-04-16 17:15:40,798 -   train_loss = 1.1342328957148962
2025-04-16 17:16:02,168 - ***** Epoch: 88: Eval results *****
2025-04-16 17:16:02,169 -   train_loss = 1.131952396460942
2025-04-16 17:16:23,397 - ***** Epoch: 89: Eval results *****
2025-04-16 17:16:23,397 -   train_loss = 1.1280044998441423
2025-04-16 17:16:45,430 - ***** Epoch: 90: Eval results *****
2025-04-16 17:16:45,430 -   train_loss = 1.1309433664594377
2025-04-16 17:17:07,349 - ***** Epoch: 91: Eval results *****
2025-04-16 17:17:07,350 -   train_loss = 1.129930513245719
2025-04-16 17:17:29,363 - ***** Epoch: 92: Eval results *****
2025-04-16 17:17:29,364 -   train_loss = 1.1351645248276847
2025-04-16 17:17:53,352 - ***** Epoch: 93: Eval results *****
2025-04-16 17:17:53,352 -   train_loss = 1.1387160164969308
2025-04-16 17:18:16,808 - ***** Epoch: 94: Eval results *****
2025-04-16 17:18:16,808 -   train_loss = 1.1316897698811121
2025-04-16 17:18:38,831 - ***** Epoch: 95: Eval results *****
2025-04-16 17:18:38,832 -   train_loss = 1.126645803451538
2025-04-16 17:18:59,793 - ***** Epoch: 96: Eval results *****
2025-04-16 17:18:59,794 -   train_loss = 1.1460869227136885
2025-04-16 17:19:19,274 - ***** Epoch: 97: Eval results *****
2025-04-16 17:19:19,274 -   train_loss = 1.1368345958845956
2025-04-16 17:19:42,300 - ***** Epoch: 98: Eval results *****
2025-04-16 17:19:42,300 -   train_loss = 1.1266636848449707
2025-04-16 17:20:03,729 - ***** Epoch: 99: Eval results *****
2025-04-16 17:20:03,730 -   train_loss = 1.1388819217681885
2025-04-16 17:20:25,548 - ***** Epoch: 100: Eval results *****
2025-04-16 17:20:25,549 -   train_loss = 1.1387544785227095
2025-04-16 17:20:26,193 - Pre-training finished...
2025-04-16 17:20:26,557 - Freeze all parameters but the last layer for efficiency
2025-04-16 17:20:26,567 - Multimodal Intent Recognition begins...
2025-04-16 17:20:26,568 - Training begins...
2025-04-16 17:20:44,050 - Initializing centroids with K-means++...
2025-04-16 17:20:44,208 - K-means++ used 0.16 s
2025-04-16 17:21:25,913 - K-means used 0.05 s
2025-04-16 17:21:28,327 - ***** Epoch: 1 *****
2025-04-16 17:21:28,327 - Supervised Training Loss: 4.395810
2025-04-16 17:21:28,328 - Unsupervised Training Loss: 5.502180
2025-04-16 17:22:06,465 - K-means used 0.02 s
2025-04-16 17:22:08,033 - ***** Epoch: 2 *****
2025-04-16 17:22:08,033 - Supervised Training Loss: 3.948280
2025-04-16 17:22:08,033 - Unsupervised Training Loss: 5.533330
2025-04-16 17:22:43,896 - K-means used 0.12 s
2025-04-16 17:22:45,321 - ***** Epoch: 3 *****
2025-04-16 17:22:45,322 - Supervised Training Loss: 4.873870
2025-04-16 17:22:45,322 - Unsupervised Training Loss: 5.402390
2025-04-16 17:23:21,402 - K-means used 0.02 s
2025-04-16 17:23:22,902 - ***** Epoch: 4 *****
2025-04-16 17:23:22,902 - Supervised Training Loss: 4.677620
2025-04-16 17:23:22,902 - Unsupervised Training Loss: 5.474470
2025-04-16 17:23:54,898 - K-means used 0.05 s
2025-04-16 17:23:56,346 - ***** Epoch: 5 *****
2025-04-16 17:23:56,347 - Supervised Training Loss: 4.413340
2025-04-16 17:23:56,347 - Unsupervised Training Loss: 5.513170
2025-04-16 17:24:33,607 - K-means used 0.05 s
2025-04-16 17:24:35,235 - ***** Epoch: 6 *****
2025-04-16 17:24:35,235 - Supervised Training Loss: 4.804890
2025-04-16 17:24:35,236 - Unsupervised Training Loss: 5.300240
2025-04-16 17:25:09,728 - K-means used 0.04 s
2025-04-16 17:25:11,412 - ***** Epoch: 7 *****
2025-04-16 17:25:11,412 - Supervised Training Loss: 4.683790
2025-04-16 17:25:11,412 - Unsupervised Training Loss: 5.430060
2025-04-16 17:25:44,996 - K-means used 0.06 s
2025-04-16 17:25:47,208 - ***** Epoch: 8 *****
2025-04-16 17:25:47,208 - Supervised Training Loss: 4.546250
2025-04-16 17:25:47,208 - Unsupervised Training Loss: 5.488880
2025-04-16 17:26:23,603 - K-means used 0.05 s
2025-04-16 17:26:26,027 - ***** Epoch: 9 *****
2025-04-16 17:26:26,027 - Supervised Training Loss: 4.731220
2025-04-16 17:26:26,027 - Unsupervised Training Loss: 5.532850
2025-04-16 17:27:00,913 - K-means used 0.02 s
2025-04-16 17:27:03,053 - ***** Epoch: 10 *****
2025-04-16 17:27:03,053 - Supervised Training Loss: 4.671290
2025-04-16 17:27:03,053 - Unsupervised Training Loss: 5.373530
2025-04-16 17:27:39,841 - K-means used 0.02 s
2025-04-16 17:27:41,522 - ***** Epoch: 11 *****
2025-04-16 17:27:41,522 - Supervised Training Loss: 4.585860
2025-04-16 17:27:41,522 - Unsupervised Training Loss: 5.457030
2025-04-16 17:28:15,173 - K-means used 0.02 s
2025-04-16 17:28:16,985 - ***** Epoch: 12 *****
2025-04-16 17:28:16,985 - Supervised Training Loss: 4.714060
2025-04-16 17:28:16,985 - Unsupervised Training Loss: 5.522350
2025-04-16 17:28:48,437 - K-means used 0.03 s
2025-04-16 17:28:51,214 - ***** Epoch: 13 *****
2025-04-16 17:28:51,215 - Supervised Training Loss: 4.685670
2025-04-16 17:28:51,215 - Unsupervised Training Loss: 5.254020
2025-04-16 17:29:24,848 - K-means used 0.01 s
2025-04-16 17:29:27,235 - ***** Epoch: 14 *****
2025-04-16 17:29:27,236 - Supervised Training Loss: 4.630490
2025-04-16 17:29:27,236 - Unsupervised Training Loss: 5.390900
2025-04-16 17:30:00,406 - K-means used 0.04 s
2025-04-16 17:30:02,852 - ***** Epoch: 15 *****
2025-04-16 17:30:02,853 - Supervised Training Loss: 4.491290
2025-04-16 17:30:02,853 - Unsupervised Training Loss: 5.491520
2025-04-16 17:30:37,176 - K-means used 0.02 s
2025-04-16 17:30:39,830 - ***** Epoch: 16 *****
2025-04-16 17:30:39,831 - Supervised Training Loss: 4.739240
2025-04-16 17:30:39,831 - Unsupervised Training Loss: 4.960500
2025-04-16 17:31:17,150 - K-means used 0.02 s
2025-04-16 17:31:20,157 - ***** Epoch: 17 *****
2025-04-16 17:31:20,157 - Supervised Training Loss: 4.724340
2025-04-16 17:31:20,157 - Unsupervised Training Loss: 5.179340
2025-04-16 17:31:43,098 - Training is finished...
2025-04-16 17:31:43,099 - Testing begins...
2025-04-16 17:31:50,601 - ***** Test results *****
2025-04-16 17:31:50,602 -   ACC = 38.2
2025-04-16 17:31:50,602 -   ARI = 20.6
2025-04-16 17:31:50,602 -   NMI = 46.89
2025-04-16 17:31:50,602 -   fmi = 25.52
2025-04-16 17:31:50,602 - Testing is finished...
2025-04-16 17:31:50,602 - Multimodal intent recognition is finished...
2025-04-16 17:31:50,602 - Results are saved in results/results_umc.csv
