2025-04-16 18:00:34,842 - 【无监督】进入了无监督的设定中, 加载数据集
2025-04-16 18:00:34,842 - data preparation...
2025-04-16 18:00:44,252 - Number of train samples = 1779
2025-04-16 18:00:44,252 - Number of testing samples = 445
2025-04-16 18:00:44,252 - data preparation...
2025-04-16 18:00:46,675 - num_train_examples = 1779
2025-04-16 18:00:46,676 - ============================== Params ==============================
2025-04-16 18:00:46,676 - logger_name: umc_umc_bert-base-uncased_MIntRec_0
2025-04-16 18:00:46,676 - dataset: MIntRec
2025-04-16 18:00:46,676 - multimodal_method: umc
2025-04-16 18:00:46,676 - method: umc
2025-04-16 18:00:46,676 - setting: unsupervised
2025-04-16 18:00:46,676 - text_backbone: bert-base-uncased
2025-04-16 18:00:46,676 - seed: 0
2025-04-16 18:00:46,676 - num_workers: 16
2025-04-16 18:00:46,676 - log_id: umc_umc_bert-base-uncased_MIntRec_0_2025-04-16-18-00-34
2025-04-16 18:00:46,676 - gpu_id: 1
2025-04-16 18:00:46,676 - data_path: /root/autodl-tmp/home/Share/Dataset/LZH
2025-04-16 18:00:46,676 - train: True
2025-04-16 18:00:46,676 - tune: True
2025-04-16 18:00:46,676 - save_model: True
2025-04-16 18:00:46,676 - save_results: True
2025-04-16 18:00:46,676 - log_path: logs
2025-04-16 18:00:46,676 - cache_path: cache
2025-04-16 18:00:46,676 - video_data_path: video_data
2025-04-16 18:00:46,676 - audio_data_path: audio_data
2025-04-16 18:00:46,676 - video_feats_path: swin_feats.pkl
2025-04-16 18:00:46,676 - audio_feats_path: wavlm_feats.pkl
2025-04-16 18:00:46,676 - results_path: results
2025-04-16 18:00:46,676 - output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/SMC/outputs_test2/MIntRec
2025-04-16 18:00:46,676 - model_path: models
2025-04-16 18:00:46,676 - config_file_name: umc_MIntRec
2025-04-16 18:00:46,677 - results_file_name: results_umc.csv
2025-04-16 18:00:46,677 - text_pretrained_model: uncased_L-12_H-768_A-12
2025-04-16 18:00:46,677 - pretrained_bert_model: uncased_L-12_H-768_A-12
2025-04-16 18:00:46,677 - pretrain_batch_size: 128
2025-04-16 18:00:46,677 - train_batch_size: 128
2025-04-16 18:00:46,677 - eval_batch_size: 128
2025-04-16 18:00:46,677 - test_batch_size: 128
2025-04-16 18:00:46,677 - num_pretrain_epochs: 100
2025-04-16 18:00:46,677 - num_train_epochs: 100
2025-04-16 18:00:46,677 - pretrain: [True]
2025-04-16 18:00:46,677 - aligned_method: ctc
2025-04-16 18:00:46,677 - need_aligned: False
2025-04-16 18:00:46,677 - freeze_pretrain_bert_parameters: [True]
2025-04-16 18:00:46,677 - freeze_train_bert_parameters: [True]
2025-04-16 18:00:46,677 - pretrain_temperature: [0.1]
2025-04-16 18:00:46,677 - train_temperature_sup: [0.5]
2025-04-16 18:00:46,677 - train_temperature_unsup: [2]
2025-04-16 18:00:46,677 - activation: tanh
2025-04-16 18:00:46,677 - lr_pre: [5e-06]
2025-04-16 18:00:46,677 - lr: [5e-05]
2025-04-16 18:00:46,677 - delta: [0.05]
2025-04-16 18:00:46,677 - thres: [0.1]
2025-04-16 18:00:46,677 - topk: [5]
2025-04-16 18:00:46,677 - weight_decay: 0.01
2025-04-16 18:00:46,677 - feat_dim: 768
2025-04-16 18:00:46,677 - hidden_size: 768
2025-04-16 18:00:46,677 - grad_clip: -1.0
2025-04-16 18:00:46,677 - warmup_proportion: [0.1]
2025-04-16 18:00:46,677 - hidden_dropout_prob: 0.1
2025-04-16 18:00:46,678 - weight: 1.0
2025-04-16 18:00:46,678 - loss_mode: rdrop
2025-04-16 18:00:46,678 - base_dim: 256
2025-04-16 18:00:46,678 - nheads: 8
2025-04-16 18:00:46,678 - attn_dropout: 0.1
2025-04-16 18:00:46,678 - relu_dropout: 0.1
2025-04-16 18:00:46,678 - embed_dropout: 0.01
2025-04-16 18:00:46,678 - res_dropout: 0.0
2025-04-16 18:00:46,678 - attn_mask: True
2025-04-16 18:00:46,678 - encoder_layers_1: 1
2025-04-16 18:00:46,678 - fusion_act: tanh
2025-04-16 18:00:46,678 - pred_output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/SMC/outputs_test2/MIntRec/umc_umc_MIntRec_bert-base-uncased_0
2025-04-16 18:00:46,678 - model_output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/SMC/outputs_test2/MIntRec/umc_umc_MIntRec_bert-base-uncased_0/models
2025-04-16 18:00:46,678 - text_seq_len: 30
2025-04-16 18:00:46,678 - video_seq_len: 230
2025-04-16 18:00:46,678 - audio_seq_len: 480
2025-04-16 18:00:46,678 - text_feat_dim: 768
2025-04-16 18:00:46,678 - video_feat_dim: 1024
2025-04-16 18:00:46,678 - audio_feat_dim: 768
2025-04-16 18:00:46,678 - num_labels: 20
2025-04-16 18:00:46,678 - num_train_examples: 1779
2025-04-16 18:00:46,678 - ============================== End Params ==============================
2025-04-16 18:00:47,894 - Freeze all parameters but the last layer for efficiency
2025-04-16 18:00:47,935 - Pre-training start...
2025-04-16 18:01:14,046 - ***** Epoch: 1: Eval results *****
2025-04-16 18:01:14,046 -   train_loss = 5.949416399002075
2025-04-16 18:01:35,965 - ***** Epoch: 2: Eval results *****
2025-04-16 18:01:35,965 -   train_loss = 5.954183680670602
2025-04-16 18:01:56,898 - ***** Epoch: 3: Eval results *****
2025-04-16 18:01:56,899 -   train_loss = 5.940770489828927
2025-04-16 18:02:20,090 - ***** Epoch: 4: Eval results *****
2025-04-16 18:02:20,090 -   train_loss = 5.937885761260986
2025-04-16 18:02:43,029 - ***** Epoch: 5: Eval results *****
2025-04-16 18:02:43,030 -   train_loss = 5.930625404630389
2025-04-16 18:03:06,222 - ***** Epoch: 6: Eval results *****
2025-04-16 18:03:06,222 -   train_loss = 5.925838913236346
2025-04-16 18:03:29,382 - ***** Epoch: 7: Eval results *****
2025-04-16 18:03:29,382 -   train_loss = 5.919382197516305
2025-04-16 18:03:52,122 - ***** Epoch: 8: Eval results *****
2025-04-16 18:03:52,122 -   train_loss = 5.898484740938459
2025-04-16 18:04:17,872 - ***** Epoch: 9: Eval results *****
2025-04-16 18:04:17,872 -   train_loss = 5.8838061945778986
2025-04-16 18:04:40,463 - ***** Epoch: 10: Eval results *****
2025-04-16 18:04:40,464 -   train_loss = 5.835139206477574
2025-04-16 18:05:02,312 - ***** Epoch: 11: Eval results *****
2025-04-16 18:05:02,312 -   train_loss = 5.768001931054251
2025-04-16 18:05:23,374 - ***** Epoch: 12: Eval results *****
2025-04-16 18:05:23,374 -   train_loss = 5.616409029279437
2025-04-16 18:05:44,654 - ***** Epoch: 13: Eval results *****
2025-04-16 18:05:44,654 -   train_loss = 5.420703819819859
2025-04-16 18:06:05,978 - ***** Epoch: 14: Eval results *****
2025-04-16 18:06:05,978 -   train_loss = 5.164638723645892
2025-04-16 18:06:28,930 - ***** Epoch: 15: Eval results *****
2025-04-16 18:06:28,931 -   train_loss = 4.925718205315726
2025-04-16 18:06:50,709 - ***** Epoch: 16: Eval results *****
2025-04-16 18:06:50,709 -   train_loss = 4.674512658800397
2025-04-16 18:07:10,593 - ***** Epoch: 17: Eval results *****
2025-04-16 18:07:10,593 -   train_loss = 4.448994193758283
2025-04-16 18:07:34,036 - ***** Epoch: 18: Eval results *****
2025-04-16 18:07:34,037 -   train_loss = 4.24450205053602
2025-04-16 18:07:56,918 - ***** Epoch: 19: Eval results *****
2025-04-16 18:07:56,919 -   train_loss = 4.09529938016619
2025-04-16 18:08:22,614 - ***** Epoch: 20: Eval results *****
2025-04-16 18:08:22,614 -   train_loss = 3.918502143451146
2025-04-16 18:08:44,563 - ***** Epoch: 21: Eval results *****
2025-04-16 18:08:44,563 -   train_loss = 3.804989610399519
2025-04-16 18:09:08,157 - ***** Epoch: 22: Eval results *****
2025-04-16 18:09:08,157 -   train_loss = 3.6679896116256714
2025-04-16 18:09:31,237 - ***** Epoch: 23: Eval results *****
2025-04-16 18:09:31,237 -   train_loss = 3.574867708342416
2025-04-16 18:09:53,643 - ***** Epoch: 24: Eval results *****
2025-04-16 18:09:53,644 -   train_loss = 3.4417998109545027
2025-04-16 18:10:14,087 - ***** Epoch: 25: Eval results *****
2025-04-16 18:10:14,088 -   train_loss = 3.349523663520813
2025-04-16 18:10:35,925 - ***** Epoch: 26: Eval results *****
2025-04-16 18:10:35,926 -   train_loss = 3.258759447506496
2025-04-16 18:10:58,320 - ***** Epoch: 27: Eval results *****
2025-04-16 18:10:58,320 -   train_loss = 3.1759572199412753
2025-04-16 18:11:21,756 - ***** Epoch: 28: Eval results *****
2025-04-16 18:11:21,757 -   train_loss = 3.068414943558829
2025-04-16 18:11:44,044 - ***** Epoch: 29: Eval results *****
2025-04-16 18:11:44,045 -   train_loss = 3.0061133759362355
2025-04-16 18:12:05,497 - ***** Epoch: 30: Eval results *****
2025-04-16 18:12:05,498 -   train_loss = 2.944753783089774
2025-04-16 18:12:25,155 - ***** Epoch: 31: Eval results *****
2025-04-16 18:12:25,155 -   train_loss = 2.879548021725246
2025-04-16 18:12:47,063 - ***** Epoch: 32: Eval results *****
2025-04-16 18:12:47,063 -   train_loss = 2.826939480645316
2025-04-16 18:13:10,174 - ***** Epoch: 33: Eval results *****
2025-04-16 18:13:10,174 -   train_loss = 2.7660002197538103
2025-04-16 18:13:32,520 - ***** Epoch: 34: Eval results *****
2025-04-16 18:13:32,521 -   train_loss = 2.736724240439279
2025-04-16 18:13:55,146 - ***** Epoch: 35: Eval results *****
2025-04-16 18:13:55,146 -   train_loss = 2.695247462817601
2025-04-16 18:14:17,433 - ***** Epoch: 36: Eval results *****
2025-04-16 18:14:17,433 -   train_loss = 2.653800334249224
2025-04-16 18:14:42,577 - ***** Epoch: 37: Eval results *****
2025-04-16 18:14:42,577 -   train_loss = 2.5935988085610524
2025-04-16 18:15:04,365 - ***** Epoch: 38: Eval results *****
2025-04-16 18:15:04,365 -   train_loss = 2.5552256447928294
2025-04-16 18:15:26,982 - ***** Epoch: 39: Eval results *****
2025-04-16 18:15:26,982 -   train_loss = 2.5394083091190884
2025-04-16 18:15:49,996 - ***** Epoch: 40: Eval results *****
2025-04-16 18:15:49,996 -   train_loss = 2.502670236996242
2025-04-16 18:16:12,100 - ***** Epoch: 41: Eval results *****
2025-04-16 18:16:12,100 -   train_loss = 2.4842988082340787
2025-04-16 18:16:32,819 - ***** Epoch: 42: Eval results *****
2025-04-16 18:16:32,819 -   train_loss = 2.464065296309335
2025-04-16 18:16:53,700 - ***** Epoch: 43: Eval results *****
2025-04-16 18:16:53,700 -   train_loss = 2.4276261159351895
2025-04-16 18:17:14,760 - ***** Epoch: 44: Eval results *****
2025-04-16 18:17:14,761 -   train_loss = 2.3995552573885237
2025-04-16 18:17:37,271 - ***** Epoch: 45: Eval results *****
2025-04-16 18:17:37,271 -   train_loss = 2.3856436354773387
2025-04-16 18:18:02,584 - ***** Epoch: 46: Eval results *****
2025-04-16 18:18:02,584 -   train_loss = 2.352421828678676
2025-04-16 18:18:23,792 - ***** Epoch: 47: Eval results *****
2025-04-16 18:18:23,793 -   train_loss = 2.345115610531398
2025-04-16 18:18:45,173 - ***** Epoch: 48: Eval results *****
2025-04-16 18:18:45,173 -   train_loss = 2.310841611453465
2025-04-16 18:19:05,865 - ***** Epoch: 49: Eval results *****
2025-04-16 18:19:05,866 -   train_loss = 2.2948495830808366
2025-04-16 18:19:27,262 - ***** Epoch: 50: Eval results *****
2025-04-16 18:19:27,262 -   train_loss = 2.2667820283344815
2025-04-16 18:19:49,206 - ***** Epoch: 51: Eval results *****
2025-04-16 18:19:49,207 -   train_loss = 2.2750508785247803
2025-04-16 18:20:10,566 - ***** Epoch: 52: Eval results *****
2025-04-16 18:20:10,567 -   train_loss = 2.240959201540266
2025-04-16 18:20:31,298 - ***** Epoch: 53: Eval results *****
2025-04-16 18:20:31,298 -   train_loss = 2.248711313520159
2025-04-16 18:20:52,117 - ***** Epoch: 54: Eval results *****
2025-04-16 18:20:52,118 -   train_loss = 2.239757605961391
2025-04-16 18:21:11,714 - ***** Epoch: 55: Eval results *****
2025-04-16 18:21:11,714 -   train_loss = 2.2151619025639127
2025-04-16 18:21:36,042 - ***** Epoch: 56: Eval results *****
2025-04-16 18:21:36,042 -   train_loss = 2.194186040333339
2025-04-16 18:21:58,611 - ***** Epoch: 57: Eval results *****
2025-04-16 18:21:58,612 -   train_loss = 2.1671960864748274
2025-04-16 18:22:19,572 - ***** Epoch: 58: Eval results *****
2025-04-16 18:22:19,573 -   train_loss = 2.1750318663460866
2025-04-16 18:22:40,870 - ***** Epoch: 59: Eval results *****
2025-04-16 18:22:40,870 -   train_loss = 2.1421469960893904
2025-04-16 18:23:00,893 - ***** Epoch: 60: Eval results *****
2025-04-16 18:23:00,894 -   train_loss = 2.140318359647478
2025-04-16 18:23:22,746 - ***** Epoch: 61: Eval results *****
2025-04-16 18:23:22,746 -   train_loss = 2.136159232684544
2025-04-16 18:23:44,590 - ***** Epoch: 62: Eval results *****
2025-04-16 18:23:44,590 -   train_loss = 2.1314026628221785
2025-04-16 18:24:06,750 - ***** Epoch: 63: Eval results *****
2025-04-16 18:24:06,750 -   train_loss = 2.126272303717477
2025-04-16 18:24:27,402 - ***** Epoch: 64: Eval results *****
2025-04-16 18:24:27,402 -   train_loss = 2.085205282483782
2025-04-16 18:24:49,834 - ***** Epoch: 65: Eval results *****
2025-04-16 18:24:49,834 -   train_loss = 2.1121104955673218
2025-04-16 18:25:12,263 - ***** Epoch: 66: Eval results *****
2025-04-16 18:25:12,264 -   train_loss = 2.0889069693429128
2025-04-16 18:25:32,894 - ***** Epoch: 67: Eval results *****
2025-04-16 18:25:32,894 -   train_loss = 2.064515539578029
2025-04-16 18:25:54,166 - ***** Epoch: 68: Eval results *****
2025-04-16 18:25:54,166 -   train_loss = 2.0726971115384782
2025-04-16 18:26:14,479 - ***** Epoch: 69: Eval results *****
2025-04-16 18:26:14,479 -   train_loss = 2.0572291868073598
2025-04-16 18:26:34,960 - ***** Epoch: 70: Eval results *****
2025-04-16 18:26:34,960 -   train_loss = 2.072041392326355
2025-04-16 18:26:55,258 - ***** Epoch: 71: Eval results *****
2025-04-16 18:26:55,258 -   train_loss = 2.0614031553268433
2025-04-16 18:27:15,982 - ***** Epoch: 72: Eval results *****
2025-04-16 18:27:15,983 -   train_loss = 2.060278058052063
2025-04-16 18:27:36,570 - ***** Epoch: 73: Eval results *****
2025-04-16 18:27:36,570 -   train_loss = 2.052029711859567
2025-04-16 18:27:57,015 - ***** Epoch: 74: Eval results *****
2025-04-16 18:27:57,015 -   train_loss = 2.051611057349614
2025-04-16 18:28:20,584 - ***** Epoch: 75: Eval results *****
2025-04-16 18:28:20,584 -   train_loss = 2.053767817361014
2025-04-16 18:28:42,490 - ***** Epoch: 76: Eval results *****
2025-04-16 18:28:42,491 -   train_loss = 2.0331520523343767
2025-04-16 18:29:03,225 - ***** Epoch: 77: Eval results *****
2025-04-16 18:29:03,226 -   train_loss = 2.0154054846082414
2025-04-16 18:29:24,796 - ***** Epoch: 78: Eval results *****
2025-04-16 18:29:24,796 -   train_loss = 2.023065311568124
2025-04-16 18:29:46,584 - ***** Epoch: 79: Eval results *****
2025-04-16 18:29:46,585 -   train_loss = 2.0249903968402316
2025-04-16 18:30:08,955 - ***** Epoch: 80: Eval results *****
2025-04-16 18:30:08,956 -   train_loss = 2.0129242709704807
2025-04-16 18:30:31,173 - ***** Epoch: 81: Eval results *****
2025-04-16 18:30:31,173 -   train_loss = 2.009406268596649
2025-04-16 18:30:52,068 - ***** Epoch: 82: Eval results *****
2025-04-16 18:30:52,068 -   train_loss = 2.008207678794861
2025-04-16 18:31:17,955 - ***** Epoch: 83: Eval results *****
2025-04-16 18:31:17,956 -   train_loss = 2.0213587284088135
2025-04-16 18:31:40,205 - ***** Epoch: 84: Eval results *****
2025-04-16 18:31:40,205 -   train_loss = 2.01031825372151
2025-04-16 18:32:02,429 - ***** Epoch: 85: Eval results *****
2025-04-16 18:32:02,429 -   train_loss = 2.008369071143014
2025-04-16 18:32:25,179 - ***** Epoch: 86: Eval results *****
2025-04-16 18:32:25,179 -   train_loss = 2.0092483248029436
2025-04-16 18:32:46,686 - ***** Epoch: 87: Eval results *****
2025-04-16 18:32:46,687 -   train_loss = 1.985931158065796
2025-04-16 18:33:06,298 - ***** Epoch: 88: Eval results *****
2025-04-16 18:33:06,298 -   train_loss = 1.994444796017238
2025-04-16 18:33:27,574 - ***** Epoch: 89: Eval results *****
2025-04-16 18:33:27,574 -   train_loss = 1.997705842767443
2025-04-16 18:33:50,368 - ***** Epoch: 90: Eval results *****
2025-04-16 18:33:50,368 -   train_loss = 2.0044930492128645
2025-04-16 18:34:11,918 - ***** Epoch: 91: Eval results *****
2025-04-16 18:34:11,918 -   train_loss = 1.9883575098855155
2025-04-16 18:34:37,665 - ***** Epoch: 92: Eval results *****
2025-04-16 18:34:37,665 -   train_loss = 1.9930893438202995
2025-04-16 18:34:58,219 - ***** Epoch: 93: Eval results *****
2025-04-16 18:34:58,219 -   train_loss = 1.9934434464999609
2025-04-16 18:35:18,309 - ***** Epoch: 94: Eval results *****
2025-04-16 18:35:18,309 -   train_loss = 1.9886541281427657
2025-04-16 18:35:40,065 - ***** Epoch: 95: Eval results *****
2025-04-16 18:35:40,066 -   train_loss = 1.9874055470739092
2025-04-16 18:36:02,002 - ***** Epoch: 96: Eval results *****
2025-04-16 18:36:02,002 -   train_loss = 1.9812538964407784
2025-04-16 18:36:23,143 - ***** Epoch: 97: Eval results *****
2025-04-16 18:36:23,144 -   train_loss = 1.9892759834017073
2025-04-16 18:36:43,424 - ***** Epoch: 98: Eval results *****
2025-04-16 18:36:43,424 -   train_loss = 2.003417934690203
2025-04-16 18:37:04,092 - ***** Epoch: 99: Eval results *****
2025-04-16 18:37:04,092 -   train_loss = 1.9858171258653914
2025-04-16 18:37:24,737 - ***** Epoch: 100: Eval results *****
2025-04-16 18:37:24,738 -   train_loss = 1.9975887281554086
2025-04-16 18:37:26,491 - Pre-training finished...
2025-04-16 18:37:26,880 - Freeze all parameters but the last layer for efficiency
2025-04-16 18:37:26,889 - Multimodal Intent Recognition begins...
2025-04-16 18:37:26,889 - Training begins...
2025-04-16 18:37:43,370 - Initializing centroids with K-means++...
2025-04-16 18:37:43,512 - K-means++ used 0.14 s
2025-04-16 18:38:26,515 - K-means used 0.03 s
2025-04-16 18:38:28,438 - ***** Epoch: 1 *****
2025-04-16 18:38:28,438 - Supervised Training Loss: 4.352330
2025-04-16 18:38:28,439 - Unsupervised Training Loss: 5.574140
2025-04-16 18:39:03,301 - K-means used 0.03 s
2025-04-16 18:39:04,729 - ***** Epoch: 2 *****
2025-04-16 18:39:04,730 - Supervised Training Loss: 4.967320
2025-04-16 18:39:04,730 - Unsupervised Training Loss: 5.586140
2025-04-16 18:39:39,772 - K-means used 0.03 s
2025-04-16 18:39:41,368 - ***** Epoch: 3 *****
2025-04-16 18:39:41,368 - Supervised Training Loss: 4.765600
2025-04-16 18:39:41,368 - Unsupervised Training Loss: 5.432290
2025-04-16 18:40:15,023 - K-means used 0.09 s
2025-04-16 18:40:17,254 - ***** Epoch: 4 *****
2025-04-16 18:40:17,254 - Supervised Training Loss: 4.573300
2025-04-16 18:40:17,254 - Unsupervised Training Loss: 5.499920
2025-04-16 18:40:54,902 - K-means used 0.09 s
2025-04-16 18:40:57,863 - ***** Epoch: 5 *****
2025-04-16 18:40:57,863 - Supervised Training Loss: 4.262840
2025-04-16 18:40:57,864 - Unsupervised Training Loss: 5.540880
2025-04-16 18:41:32,496 - K-means used 0.04 s
2025-04-16 18:41:34,013 - ***** Epoch: 6 *****
2025-04-16 18:41:34,013 - Supervised Training Loss: 4.695540
2025-04-16 18:41:34,013 - Unsupervised Training Loss: 5.332480
2025-04-16 18:42:09,305 - K-means used 0.04 s
2025-04-16 18:42:11,041 - ***** Epoch: 7 *****
2025-04-16 18:42:11,041 - Supervised Training Loss: 4.596600
2025-04-16 18:42:11,041 - Unsupervised Training Loss: 5.451230
2025-04-16 18:42:44,284 - K-means used 0.02 s
2025-04-16 18:42:45,720 - ***** Epoch: 8 *****
2025-04-16 18:42:45,721 - Supervised Training Loss: 4.461820
2025-04-16 18:42:45,721 - Unsupervised Training Loss: 5.505380
2025-04-16 18:43:21,261 - K-means used 0.02 s
2025-04-16 18:43:23,116 - ***** Epoch: 9 *****
2025-04-16 18:43:23,116 - Supervised Training Loss: 4.685110
2025-04-16 18:43:23,116 - Unsupervised Training Loss: 5.547590
2025-04-16 18:43:57,874 - K-means used 0.02 s
2025-04-16 18:43:59,634 - ***** Epoch: 10 *****
2025-04-16 18:43:59,634 - Supervised Training Loss: 4.615910
2025-04-16 18:43:59,634 - Unsupervised Training Loss: 5.380630
2025-04-16 18:44:38,197 - K-means used 0.02 s
2025-04-16 18:44:40,481 - ***** Epoch: 11 *****
2025-04-16 18:44:40,481 - Supervised Training Loss: 4.529770
2025-04-16 18:44:40,481 - Unsupervised Training Loss: 5.466440
2025-04-16 18:45:15,239 - K-means used 0.02 s
2025-04-16 18:45:16,923 - ***** Epoch: 12 *****
2025-04-16 18:45:16,923 - Supervised Training Loss: 4.673790
2025-04-16 18:45:16,923 - Unsupervised Training Loss: 5.535220
2025-04-16 18:45:49,698 - K-means used 0.04 s
2025-04-16 18:45:52,301 - ***** Epoch: 13 *****
2025-04-16 18:45:52,301 - Supervised Training Loss: 4.630250
2025-04-16 18:45:52,302 - Unsupervised Training Loss: 5.259030
2025-04-16 18:46:25,797 - K-means used 0.14 s
2025-04-16 18:46:28,203 - ***** Epoch: 14 *****
2025-04-16 18:46:28,203 - Supervised Training Loss: 4.586070
2025-04-16 18:46:28,204 - Unsupervised Training Loss: 5.388430
2025-04-16 18:47:03,584 - K-means used 0.02 s
2025-04-16 18:47:05,996 - ***** Epoch: 15 *****
2025-04-16 18:47:05,996 - Supervised Training Loss: 4.468980
2025-04-16 18:47:05,996 - Unsupervised Training Loss: 5.485610
2025-04-16 18:47:42,698 - K-means used 0.04 s
2025-04-16 18:47:44,971 - ***** Epoch: 16 *****
2025-04-16 18:47:44,971 - Supervised Training Loss: 4.677460
2025-04-16 18:47:44,971 - Unsupervised Training Loss: 4.931990
2025-04-16 18:48:20,308 - K-means used 0.03 s
2025-04-16 18:48:22,551 - ***** Epoch: 17 *****
2025-04-16 18:48:22,551 - Supervised Training Loss: 4.656350
2025-04-16 18:48:22,551 - Unsupervised Training Loss: 5.165740
2025-04-16 18:48:46,581 - Training is finished...
2025-04-16 18:48:46,582 - Testing begins...
2025-04-16 18:48:54,964 - ***** Test results *****
2025-04-16 18:48:54,964 -   ACC = 35.06
2025-04-16 18:48:54,964 -   ARI = 17.12
2025-04-16 18:48:54,964 -   NMI = 42.33
2025-04-16 18:48:54,964 -   fmi = 22.28
2025-04-16 18:48:54,964 - Testing is finished...
2025-04-16 18:48:54,964 - Multimodal intent recognition is finished...
2025-04-16 18:48:54,964 - Results are saved in results/results_umc.csv
