2025-04-11 12:11:06,795 - ============================== Params ==============================
2025-04-11 12:11:06,796 - logger_name: umc_umc_bert-base-uncased_MIntRec_2
2025-04-11 12:11:06,796 - dataset: MIntRec
2025-04-11 12:11:06,796 - multimodal_method: umc
2025-04-11 12:11:06,796 - method: umc
2025-04-11 12:11:06,796 - text_backbone: bert-base-uncased
2025-04-11 12:11:06,796 - seed: 2
2025-04-11 12:11:06,796 - num_workers: 16
2025-04-11 12:11:06,796 - log_id: umc_umc_bert-base-uncased_MIntRec_2_2025-04-11-12-11-06
2025-04-11 12:11:06,796 - gpu_id: 0
2025-04-11 12:11:06,796 - data_path: /root/autodl-tmp/home/Share/Dataset/LZH
2025-04-11 12:11:06,796 - train: True
2025-04-11 12:11:06,796 - tune: True
2025-04-11 12:11:06,796 - save_model: True
2025-04-11 12:11:06,796 - save_results: True
2025-04-11 12:11:06,796 - log_path: logs
2025-04-11 12:11:06,796 - cache_path: cache
2025-04-11 12:11:06,796 - video_data_path: video_data
2025-04-11 12:11:06,796 - audio_data_path: audio_data
2025-04-11 12:11:06,796 - video_feats_path: swin_feats.pkl
2025-04-11 12:11:06,796 - audio_feats_path: wavlm_feats.pkl
2025-04-11 12:11:06,796 - results_path: results
2025-04-11 12:11:06,796 - output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/UMC/outputs/MIntRec
2025-04-11 12:11:06,796 - model_path: models
2025-04-11 12:11:06,797 - config_file_name: umc_MIntRec
2025-04-11 12:11:06,797 - results_file_name: results_umc.csv
2025-04-11 12:11:06,797 - text_pretrained_model: uncased_L-12_H-768_A-12
2025-04-11 12:11:06,797 - text_seq_len: 30
2025-04-11 12:11:06,797 - video_seq_len: 230
2025-04-11 12:11:06,797 - audio_seq_len: 480
2025-04-11 12:11:06,797 - text_feat_dim: 768
2025-04-11 12:11:06,797 - video_feat_dim: 1024
2025-04-11 12:11:06,797 - audio_feat_dim: 768
2025-04-11 12:11:06,797 - num_labels: 20
2025-04-11 12:11:06,797 - num_train_examples: 1779
2025-04-11 12:11:06,797 - pretrained_bert_model: uncased_L-12_H-768_A-12
2025-04-11 12:11:06,797 - pretrain_batch_size: 128
2025-04-11 12:11:06,797 - train_batch_size: 128
2025-04-11 12:11:06,797 - eval_batch_size: 128
2025-04-11 12:11:06,797 - test_batch_size: 128
2025-04-11 12:11:06,797 - num_pretrain_epochs: 100
2025-04-11 12:11:06,797 - num_train_epochs: 100
2025-04-11 12:11:06,797 - pretrain: [True]
2025-04-11 12:11:06,797 - aligned_method: ctc
2025-04-11 12:11:06,797 - need_aligned: False
2025-04-11 12:11:06,797 - freeze_pretrain_bert_parameters: [True]
2025-04-11 12:11:06,797 - freeze_train_bert_parameters: [True]
2025-04-11 12:11:06,797 - pretrain_temperature: [0.2]
2025-04-11 12:11:06,797 - train_temperature_sup: [1.4]
2025-04-11 12:11:06,797 - train_temperature_unsup: [1]
2025-04-11 12:11:06,798 - activation: tanh
2025-04-11 12:11:06,798 - lr_pre: 1e-05
2025-04-11 12:11:06,798 - lr: [0.0003]
2025-04-11 12:11:06,798 - delta: [0.05]
2025-04-11 12:11:06,798 - thres: [0.1]
2025-04-11 12:11:06,798 - topk: [5]
2025-04-11 12:11:06,798 - weight_decay: 0.01
2025-04-11 12:11:06,798 - feat_dim: 768
2025-04-11 12:11:06,798 - hidden_size: 768
2025-04-11 12:11:06,798 - grad_clip: -1.0
2025-04-11 12:11:06,798 - warmup_proportion: 0.5
2025-04-11 12:11:06,798 - hidden_dropout_prob: 0.1
2025-04-11 12:11:06,798 - weight: 1.0
2025-04-11 12:11:06,798 - loss_mode: rdrop
2025-04-11 12:11:06,798 - base_dim: 256
2025-04-11 12:11:06,798 - nheads: 8
2025-04-11 12:11:06,798 - attn_dropout: 0.1
2025-04-11 12:11:06,798 - relu_dropout: 0.1
2025-04-11 12:11:06,798 - embed_dropout: 0.1
2025-04-11 12:11:06,798 - res_dropout: 0.0
2025-04-11 12:11:06,799 - attn_mask: True
2025-04-11 12:11:06,799 - encoder_layers_1: 1
2025-04-11 12:11:06,799 - fusion_act: tanh
2025-04-11 12:11:06,799 - pred_output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/UMC/outputs/MIntRec/umc_umc_MIntRec_bert-base-uncased_2
2025-04-11 12:11:06,799 - model_output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/UMC/outputs/MIntRec/umc_umc_MIntRec_bert-base-uncased_2/models
2025-04-11 12:11:06,799 - ============================== End Params ==============================
2025-04-11 12:11:07,897 - Freeze all parameters but the last layer for efficiency
2025-04-11 12:11:07,931 - Pre-training start...
2025-04-11 12:11:21,665 - ***** Epoch: 1: Eval results *****
2025-04-11 12:11:21,666 -   train_loss = 5.941108567374093
2025-04-11 12:11:35,667 - ***** Epoch: 2: Eval results *****
2025-04-11 12:11:35,668 -   train_loss = 5.938371113368443
2025-04-11 12:11:50,505 - ***** Epoch: 3: Eval results *****
2025-04-11 12:11:50,505 -   train_loss = 5.939299004418509
2025-04-11 12:12:04,949 - ***** Epoch: 4: Eval results *****
2025-04-11 12:12:04,949 -   train_loss = 5.939103024346488
2025-04-11 12:12:19,813 - ***** Epoch: 5: Eval results *****
2025-04-11 12:12:19,813 -   train_loss = 5.940683228628976
2025-04-11 12:12:34,893 - ***** Epoch: 6: Eval results *****
2025-04-11 12:12:34,894 -   train_loss = 5.940733262470791
2025-04-11 12:12:50,311 - ***** Epoch: 7: Eval results *****
2025-04-11 12:12:50,311 -   train_loss = 5.9381894043513705
2025-04-11 12:13:05,647 - ***** Epoch: 8: Eval results *****
2025-04-11 12:13:05,647 -   train_loss = 5.935137067522321
2025-04-11 12:13:21,681 - ***** Epoch: 9: Eval results *****
2025-04-11 12:13:21,681 -   train_loss = 5.93314494405474
2025-04-11 12:13:37,241 - ***** Epoch: 10: Eval results *****
2025-04-11 12:13:37,241 -   train_loss = 5.932451929364886
2025-04-11 12:13:52,158 - ***** Epoch: 11: Eval results *****
2025-04-11 12:13:52,158 -   train_loss = 5.928289447511945
2025-04-11 12:14:06,658 - ***** Epoch: 12: Eval results *****
2025-04-11 12:14:06,658 -   train_loss = 5.927937541689191
2025-04-11 12:14:21,722 - ***** Epoch: 13: Eval results *****
2025-04-11 12:14:21,723 -   train_loss = 5.924584252493722
2025-04-11 12:14:36,490 - ***** Epoch: 14: Eval results *****
2025-04-11 12:14:36,490 -   train_loss = 5.918468645640782
2025-04-11 12:14:51,493 - ***** Epoch: 15: Eval results *****
2025-04-11 12:14:51,493 -   train_loss = 5.912800005504063
2025-04-11 12:15:07,022 - ***** Epoch: 16: Eval results *****
2025-04-11 12:15:07,022 -   train_loss = 5.9001951558249335
2025-04-11 12:15:22,833 - ***** Epoch: 17: Eval results *****
2025-04-11 12:15:22,833 -   train_loss = 5.884821346827915
2025-04-11 12:15:39,158 - ***** Epoch: 18: Eval results *****
2025-04-11 12:15:39,158 -   train_loss = 5.865109000887189
2025-04-11 12:15:55,385 - ***** Epoch: 19: Eval results *****
2025-04-11 12:15:55,385 -   train_loss = 5.827920164380755
2025-04-11 12:16:12,142 - ***** Epoch: 20: Eval results *****
2025-04-11 12:16:12,142 -   train_loss = 5.766090154647827
2025-04-11 12:16:28,457 - ***** Epoch: 21: Eval results *****
2025-04-11 12:16:28,457 -   train_loss = 5.6561001028333395
2025-04-11 12:16:42,651 - ***** Epoch: 22: Eval results *****
2025-04-11 12:16:42,652 -   train_loss = 5.496997458594186
2025-04-11 12:16:57,813 - ***** Epoch: 23: Eval results *****
2025-04-11 12:16:57,813 -   train_loss = 5.294610977172852
2025-04-11 12:17:13,047 - ***** Epoch: 24: Eval results *****
2025-04-11 12:17:13,047 -   train_loss = 5.096315690449306
2025-04-11 12:17:26,891 - ***** Epoch: 25: Eval results *****
2025-04-11 12:17:26,891 -   train_loss = 4.9035725593566895
2025-04-11 12:17:42,046 - ***** Epoch: 26: Eval results *****
2025-04-11 12:17:42,046 -   train_loss = 4.730490480150495
2025-04-11 12:17:57,744 - ***** Epoch: 27: Eval results *****
2025-04-11 12:17:57,744 -   train_loss = 4.5778210163116455
2025-04-11 12:18:13,227 - ***** Epoch: 28: Eval results *****
2025-04-11 12:18:13,228 -   train_loss = 4.444247347967965
2025-04-11 12:18:28,942 - ***** Epoch: 29: Eval results *****
2025-04-11 12:18:28,943 -   train_loss = 4.316713673727853
2025-04-11 12:18:44,746 - ***** Epoch: 30: Eval results *****
2025-04-11 12:18:44,746 -   train_loss = 4.209991386958531
2025-04-11 12:19:00,136 - ***** Epoch: 31: Eval results *****
2025-04-11 12:19:00,136 -   train_loss = 4.097934859139579
2025-04-11 12:19:15,422 - ***** Epoch: 32: Eval results *****
2025-04-11 12:19:15,422 -   train_loss = 4.01469840322222
2025-04-11 12:19:29,099 - ***** Epoch: 33: Eval results *****
2025-04-11 12:19:29,100 -   train_loss = 3.924820133617946
2025-04-11 12:19:43,666 - ***** Epoch: 34: Eval results *****
2025-04-11 12:19:43,667 -   train_loss = 3.850408911705017
2025-04-11 12:19:58,566 - ***** Epoch: 35: Eval results *****
2025-04-11 12:19:58,566 -   train_loss = 3.7754556110927036
2025-04-11 12:20:12,519 - ***** Epoch: 36: Eval results *****
2025-04-11 12:20:12,520 -   train_loss = 3.715530957494463
2025-04-11 12:20:26,737 - ***** Epoch: 37: Eval results *****
2025-04-11 12:20:26,737 -   train_loss = 3.6421659844262257
2025-04-11 12:20:42,352 - ***** Epoch: 38: Eval results *****
2025-04-11 12:20:42,352 -   train_loss = 3.593568887029375
2025-04-11 12:20:58,108 - ***** Epoch: 39: Eval results *****
2025-04-11 12:20:58,109 -   train_loss = 3.5427870750427246
2025-04-11 12:21:13,582 - ***** Epoch: 40: Eval results *****
2025-04-11 12:21:13,582 -   train_loss = 3.5126806838171825
2025-04-11 12:21:28,941 - ***** Epoch: 41: Eval results *****
2025-04-11 12:21:28,941 -   train_loss = 3.46442289011819
2025-04-11 12:21:44,556 - ***** Epoch: 42: Eval results *****
2025-04-11 12:21:44,556 -   train_loss = 3.4260295629501343
2025-04-11 12:22:00,190 - ***** Epoch: 43: Eval results *****
2025-04-11 12:22:00,191 -   train_loss = 3.3951282501220703
2025-04-11 12:22:15,508 - ***** Epoch: 44: Eval results *****
2025-04-11 12:22:15,508 -   train_loss = 3.355915904045105
2025-04-11 12:22:31,436 - ***** Epoch: 45: Eval results *****
2025-04-11 12:22:31,436 -   train_loss = 3.323690176010132
2025-04-11 12:22:47,176 - ***** Epoch: 46: Eval results *****
2025-04-11 12:22:47,176 -   train_loss = 3.2835004159382413
2025-04-11 12:23:01,720 - ***** Epoch: 47: Eval results *****
2025-04-11 12:23:01,720 -   train_loss = 3.2587956190109253
2025-04-11 12:23:17,049 - ***** Epoch: 48: Eval results *****
2025-04-11 12:23:17,049 -   train_loss = 3.232885309628078
2025-04-11 12:23:33,163 - ***** Epoch: 49: Eval results *****
2025-04-11 12:23:33,163 -   train_loss = 3.2043101446969167
2025-04-11 12:23:48,939 - ***** Epoch: 50: Eval results *****
2025-04-11 12:23:48,940 -   train_loss = 3.1782492910112654
2025-04-11 12:24:04,521 - ***** Epoch: 51: Eval results *****
2025-04-11 12:24:04,522 -   train_loss = 3.159089037350246
2025-04-11 12:24:20,446 - ***** Epoch: 52: Eval results *****
2025-04-11 12:24:20,446 -   train_loss = 3.138270480292184
2025-04-11 12:24:35,584 - ***** Epoch: 53: Eval results *****
2025-04-11 12:24:35,584 -   train_loss = 3.1045447758265903
2025-04-11 12:24:51,505 - ***** Epoch: 54: Eval results *****
2025-04-11 12:24:51,505 -   train_loss = 3.0859165021351407
2025-04-11 12:25:05,294 - ***** Epoch: 55: Eval results *****
2025-04-11 12:25:05,294 -   train_loss = 3.0615971429007396
2025-04-11 12:25:20,265 - ***** Epoch: 56: Eval results *****
2025-04-11 12:25:20,265 -   train_loss = 3.0578303847994124
2025-04-11 12:25:35,091 - ***** Epoch: 57: Eval results *****
2025-04-11 12:25:35,092 -   train_loss = 3.03336877482278
2025-04-11 12:25:49,689 - ***** Epoch: 58: Eval results *****
2025-04-11 12:25:49,690 -   train_loss = 3.030148983001709
2025-04-11 12:26:03,847 - ***** Epoch: 59: Eval results *****
2025-04-11 12:26:03,847 -   train_loss = 3.0101841347558156
2025-04-11 12:26:19,218 - ***** Epoch: 60: Eval results *****
2025-04-11 12:26:19,218 -   train_loss = 2.9929306847708568
2025-04-11 12:26:34,210 - ***** Epoch: 61: Eval results *****
2025-04-11 12:26:34,210 -   train_loss = 2.984086036682129
2025-04-11 12:26:50,014 - ***** Epoch: 62: Eval results *****
2025-04-11 12:26:50,015 -   train_loss = 2.9892065695353915
2025-04-11 12:27:06,129 - ***** Epoch: 63: Eval results *****
2025-04-11 12:27:06,129 -   train_loss = 2.975484013557434
2025-04-11 12:27:21,570 - ***** Epoch: 64: Eval results *****
2025-04-11 12:27:21,570 -   train_loss = 2.969584379877363
2025-04-11 12:27:37,145 - ***** Epoch: 65: Eval results *****
2025-04-11 12:27:37,146 -   train_loss = 2.9529645102364674
2025-04-11 12:27:51,929 - ***** Epoch: 66: Eval results *****
2025-04-11 12:27:51,930 -   train_loss = 2.9549672433308194
2025-04-11 12:28:05,825 - ***** Epoch: 67: Eval results *****
2025-04-11 12:28:05,825 -   train_loss = 2.946038944380624
2025-04-11 12:28:21,800 - ***** Epoch: 68: Eval results *****
2025-04-11 12:28:21,800 -   train_loss = 2.9388163770948137
2025-04-11 12:28:36,423 - ***** Epoch: 69: Eval results *****
2025-04-11 12:28:36,424 -   train_loss = 2.9356610434395924
2025-04-11 12:28:50,652 - ***** Epoch: 70: Eval results *****
2025-04-11 12:28:50,652 -   train_loss = 2.938629456928798
2025-04-11 12:29:04,905 - ***** Epoch: 71: Eval results *****
2025-04-11 12:29:04,906 -   train_loss = 2.9209495953151157
2025-04-11 12:29:20,372 - ***** Epoch: 72: Eval results *****
2025-04-11 12:29:20,372 -   train_loss = 2.9082655906677246
2025-04-11 12:29:35,468 - ***** Epoch: 73: Eval results *****
2025-04-11 12:29:35,468 -   train_loss = 2.915149654660906
2025-04-11 12:29:51,072 - ***** Epoch: 74: Eval results *****
2025-04-11 12:29:51,072 -   train_loss = 2.9094229425702776
2025-04-11 12:30:06,894 - ***** Epoch: 75: Eval results *****
2025-04-11 12:30:06,894 -   train_loss = 2.9040272406169345
2025-04-11 12:30:22,533 - ***** Epoch: 76: Eval results *****
2025-04-11 12:30:22,533 -   train_loss = 2.9006641592298235
2025-04-11 12:30:38,270 - ***** Epoch: 77: Eval results *****
2025-04-11 12:30:38,271 -   train_loss = 2.8890299797058105
2025-04-11 12:30:53,073 - ***** Epoch: 78: Eval results *****
2025-04-11 12:30:53,074 -   train_loss = 2.889224444116865
2025-04-11 12:31:07,333 - ***** Epoch: 79: Eval results *****
2025-04-11 12:31:07,333 -   train_loss = 2.891612563814436
2025-04-11 12:31:21,956 - ***** Epoch: 80: Eval results *****
2025-04-11 12:31:21,956 -   train_loss = 2.8941050257001604
2025-04-11 12:31:36,677 - ***** Epoch: 81: Eval results *****
2025-04-11 12:31:36,678 -   train_loss = 2.8807753324508667
2025-04-11 12:31:50,651 - ***** Epoch: 82: Eval results *****
2025-04-11 12:31:50,652 -   train_loss = 2.875806518963405
2025-04-11 12:32:04,633 - ***** Epoch: 83: Eval results *****
2025-04-11 12:32:04,633 -   train_loss = 2.880609597478594
2025-04-11 12:32:20,158 - ***** Epoch: 84: Eval results *****
2025-04-11 12:32:20,158 -   train_loss = 2.8885092564991544
2025-04-11 12:32:36,599 - ***** Epoch: 85: Eval results *****
2025-04-11 12:32:36,599 -   train_loss = 2.8735191992350986
2025-04-11 12:32:53,469 - ***** Epoch: 86: Eval results *****
2025-04-11 12:32:53,470 -   train_loss = 2.877445255007063
2025-04-11 12:33:09,961 - ***** Epoch: 87: Eval results *****
2025-04-11 12:33:09,961 -   train_loss = 2.8650707517351424
2025-04-11 12:33:25,076 - ***** Epoch: 88: Eval results *****
2025-04-11 12:33:25,076 -   train_loss = 2.8692377976008823
2025-04-11 12:33:40,178 - ***** Epoch: 89: Eval results *****
2025-04-11 12:33:40,179 -   train_loss = 2.872607810156686
2025-04-11 12:33:55,400 - ***** Epoch: 90: Eval results *****
2025-04-11 12:33:55,401 -   train_loss = 2.8736878974097118
2025-04-11 12:34:10,976 - ***** Epoch: 91: Eval results *****
2025-04-11 12:34:10,976 -   train_loss = 2.868307658604213
2025-04-11 12:34:26,470 - ***** Epoch: 92: Eval results *****
2025-04-11 12:34:26,470 -   train_loss = 2.870382990155901
2025-04-11 12:34:41,280 - ***** Epoch: 93: Eval results *****
2025-04-11 12:34:41,280 -   train_loss = 2.8706925255911693
2025-04-11 12:34:55,221 - ***** Epoch: 94: Eval results *****
2025-04-11 12:34:55,221 -   train_loss = 2.8741844381604875
2025-04-11 12:35:09,222 - ***** Epoch: 95: Eval results *****
2025-04-11 12:35:09,223 -   train_loss = 2.866432820047651
2025-04-11 12:35:24,513 - ***** Epoch: 96: Eval results *****
2025-04-11 12:35:24,513 -   train_loss = 2.867954748017447
2025-04-11 12:35:39,762 - ***** Epoch: 97: Eval results *****
2025-04-11 12:35:39,762 -   train_loss = 2.8695272377559116
2025-04-11 12:35:55,288 - ***** Epoch: 98: Eval results *****
2025-04-11 12:35:55,288 -   train_loss = 2.8685665811811174
2025-04-11 12:36:10,737 - ***** Epoch: 99: Eval results *****
2025-04-11 12:36:10,738 -   train_loss = 2.872917209352766
2025-04-11 12:36:25,795 - ***** Epoch: 100: Eval results *****
2025-04-11 12:36:25,795 -   train_loss = 2.8693419013704573
2025-04-11 12:36:27,479 - Pre-training finished...
2025-04-11 12:36:27,745 - Freeze all parameters but the last layer for efficiency
2025-04-11 12:36:27,754 - Multimodal Intent Recognition begins...
2025-04-11 12:36:27,754 - Training begins...
2025-04-11 12:36:43,309 - Initializing centroids with K-means++...
2025-04-11 12:36:43,391 - K-means++ used 0.08 s
2025-04-11 12:37:10,608 - K-means used 0.04 s
2025-04-11 12:37:12,422 - ***** Epoch: 1 *****
2025-04-11 12:37:12,423 - Supervised Training Loss: 4.906840
2025-04-11 12:37:12,424 - Unsupervised Training Loss: 5.121570
2025-04-11 12:37:42,136 - K-means used 0.03 s
2025-04-11 12:37:43,448 - ***** Epoch: 2 *****
2025-04-11 12:37:43,448 - Supervised Training Loss: 3.885970
2025-04-11 12:37:43,449 - Unsupervised Training Loss: 5.144880
2025-04-11 12:38:10,022 - K-means used 0.03 s
2025-04-11 12:38:11,366 - ***** Epoch: 3 *****
2025-04-11 12:38:11,366 - Supervised Training Loss: 5.351220
2025-04-11 12:38:11,366 - Unsupervised Training Loss: 5.011440
2025-04-11 12:38:40,016 - K-means used 0.03 s
2025-04-11 12:38:41,355 - ***** Epoch: 4 *****
2025-04-11 12:38:41,356 - Supervised Training Loss: 5.216090
2025-04-11 12:38:41,356 - Unsupervised Training Loss: 5.082230
2025-04-11 12:39:09,919 - K-means used 0.06 s
2025-04-11 12:39:11,557 - ***** Epoch: 5 *****
2025-04-11 12:39:11,557 - Supervised Training Loss: 4.946920
2025-04-11 12:39:11,557 - Unsupervised Training Loss: 5.106260
2025-04-11 12:39:42,788 - K-means used 0.02 s
2025-04-11 12:39:44,221 - ***** Epoch: 6 *****
2025-04-11 12:39:44,221 - Supervised Training Loss: 5.344490
2025-04-11 12:39:44,221 - Unsupervised Training Loss: 4.900130
2025-04-11 12:40:14,770 - K-means used 0.02 s
2025-04-11 12:40:16,680 - ***** Epoch: 7 *****
2025-04-11 12:40:16,680 - Supervised Training Loss: 5.265890
2025-04-11 12:40:16,680 - Unsupervised Training Loss: 5.023760
2025-04-11 12:40:47,422 - K-means used 0.02 s
2025-04-11 12:40:49,004 - ***** Epoch: 8 *****
2025-04-11 12:40:49,004 - Supervised Training Loss: 5.109170
2025-04-11 12:40:49,004 - Unsupervised Training Loss: 5.072030
2025-04-11 12:41:18,638 - K-means used 0.02 s
2025-04-11 12:41:20,197 - ***** Epoch: 9 *****
2025-04-11 12:41:20,197 - Supervised Training Loss: 5.325330
2025-04-11 12:41:20,197 - Unsupervised Training Loss: 5.101380
2025-04-11 12:41:55,313 - K-means used 0.05 s
2025-04-11 12:41:56,977 - ***** Epoch: 10 *****
2025-04-11 12:41:56,977 - Supervised Training Loss: 5.261910
2025-04-11 12:41:56,977 - Unsupervised Training Loss: 4.941110
2025-04-11 12:42:28,634 - K-means used 0.02 s
2025-04-11 12:42:30,535 - ***** Epoch: 11 *****
2025-04-11 12:42:30,536 - Supervised Training Loss: 5.182480
2025-04-11 12:42:30,536 - Unsupervised Training Loss: 5.025560
2025-04-11 12:43:02,465 - K-means used 0.02 s
2025-04-11 12:43:04,420 - ***** Epoch: 12 *****
2025-04-11 12:43:04,421 - Supervised Training Loss: 5.314630
2025-04-11 12:43:04,421 - Unsupervised Training Loss: 5.087560
2025-04-11 12:43:35,901 - K-means used 0.03 s
2025-04-11 12:43:37,715 - ***** Epoch: 13 *****
2025-04-11 12:43:37,715 - Supervised Training Loss: 5.276300
2025-04-11 12:43:37,715 - Unsupervised Training Loss: 4.797960
2025-04-11 12:44:06,308 - K-means used 0.03 s
2025-04-11 12:44:08,348 - ***** Epoch: 14 *****
2025-04-11 12:44:08,348 - Supervised Training Loss: 5.225230
2025-04-11 12:44:08,349 - Unsupervised Training Loss: 4.937550
2025-04-11 12:44:38,024 - K-means used 0.03 s
2025-04-11 12:44:39,923 - ***** Epoch: 15 *****
2025-04-11 12:44:39,924 - Supervised Training Loss: 5.072500
2025-04-11 12:44:39,924 - Unsupervised Training Loss: 5.045690
2025-04-11 12:45:10,098 - K-means used 0.05 s
2025-04-11 12:45:12,101 - ***** Epoch: 16 *****
2025-04-11 12:45:12,101 - Supervised Training Loss: 5.288930
2025-04-11 12:45:12,101 - Unsupervised Training Loss: 4.522000
2025-04-11 12:45:39,944 - K-means used 0.01 s
2025-04-11 12:45:42,184 - ***** Epoch: 17 *****
2025-04-11 12:45:42,184 - Supervised Training Loss: 5.258050
2025-04-11 12:45:42,184 - Unsupervised Training Loss: 4.710800
2025-04-11 12:46:00,957 - Training is finished...
2025-04-11 12:46:00,957 - Testing begins...
2025-04-11 12:46:10,801 - ***** Test results *****
2025-04-11 12:46:10,802 -   ACC = 38.2
2025-04-11 12:46:10,802 -   ARI = 17.89
2025-04-11 12:46:10,802 -   NMI = 44.38
2025-04-11 12:46:10,802 -   fmi = 23.29
2025-04-11 12:46:10,802 - Testing is finished...
2025-04-11 12:46:10,802 - Multimodal intent recognition is finished...
2025-04-11 12:46:10,802 - Results are saved in results/results_umc.csv
