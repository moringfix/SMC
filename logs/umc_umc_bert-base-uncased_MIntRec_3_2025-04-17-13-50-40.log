2025-04-17 13:50:40,025 - 【无监督】进入了无监督的设定中, 加载数据集
2025-04-17 13:50:40,025 - data preparation...
2025-04-17 13:50:49,149 - Number of train samples = 1779
2025-04-17 13:50:49,149 - Number of testing samples = 445
2025-04-17 13:50:49,150 - data preparation...
2025-04-17 13:50:51,490 - num_train_examples = 1779
2025-04-17 13:50:51,490 - ============================== Params ==============================
2025-04-17 13:50:51,490 - logger_name: umc_umc_bert-base-uncased_MIntRec_3
2025-04-17 13:50:51,490 - dataset: MIntRec
2025-04-17 13:50:51,490 - multimodal_method: umc
2025-04-17 13:50:51,490 - method: umc
2025-04-17 13:50:51,490 - setting: unsupervised
2025-04-17 13:50:51,490 - merge_dev: False
2025-04-17 13:50:51,490 - text_backbone: bert-base-uncased
2025-04-17 13:50:51,491 - seed: 3
2025-04-17 13:50:51,491 - num_workers: 16
2025-04-17 13:50:51,491 - log_id: umc_umc_bert-base-uncased_MIntRec_3_2025-04-17-13-50-40
2025-04-17 13:50:51,491 - gpu_id: 1
2025-04-17 13:50:51,491 - data_path: /root/autodl-tmp/home/Share/Dataset/LZH
2025-04-17 13:50:51,491 - train: True
2025-04-17 13:50:51,491 - tune: True
2025-04-17 13:50:51,491 - save_model: True
2025-04-17 13:50:51,491 - save_results: True
2025-04-17 13:50:51,491 - log_path: logs
2025-04-17 13:50:51,491 - cache_path: cache
2025-04-17 13:50:51,491 - video_data_path: video_data
2025-04-17 13:50:51,491 - audio_data_path: audio_data
2025-04-17 13:50:51,491 - video_feats_path: swin_feats.pkl
2025-04-17 13:50:51,491 - audio_feats_path: wavlm_feats.pkl
2025-04-17 13:50:51,491 - results_path: results
2025-04-17 13:50:51,492 - output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/SMC/outputs_test2/MIntRec
2025-04-17 13:50:51,492 - model_path: models
2025-04-17 13:50:51,492 - config_file_name: umc_MIntRec
2025-04-17 13:50:51,492 - results_file_name: results_umc_pre.csv
2025-04-17 13:50:51,492 - text_pretrained_model: uncased_L-12_H-768_A-12
2025-04-17 13:50:51,492 - pretrained_bert_model: uncased_L-12_H-768_A-12
2025-04-17 13:50:51,492 - pretrain_batch_size: 128
2025-04-17 13:50:51,492 - train_batch_size: 128
2025-04-17 13:50:51,492 - eval_batch_size: 128
2025-04-17 13:50:51,492 - test_batch_size: 128
2025-04-17 13:50:51,492 - num_pretrain_epochs: 100
2025-04-17 13:50:51,492 - num_train_epochs: 100
2025-04-17 13:50:51,492 - pretrain: [True]
2025-04-17 13:50:51,492 - aligned_method: ctc
2025-04-17 13:50:51,492 - need_aligned: False
2025-04-17 13:50:51,492 - freeze_pretrain_bert_parameters: [True]
2025-04-17 13:50:51,492 - freeze_train_bert_parameters: [True]
2025-04-17 13:50:51,492 - pretrain_temperature: [0.1, 0.2, 0.4, 0.5]
2025-04-17 13:50:51,492 - train_temperature_sup: [0.5]
2025-04-17 13:50:51,492 - train_temperature_unsup: [2]
2025-04-17 13:50:51,492 - activation: tanh
2025-04-17 13:50:51,492 - lr_pre: [1e-05]
2025-04-17 13:50:51,492 - lr: [5e-05]
2025-04-17 13:50:51,492 - delta: [0.05]
2025-04-17 13:50:51,492 - thres: [0.1]
2025-04-17 13:50:51,492 - topk: [5]
2025-04-17 13:50:51,492 - weight_decay: 0.01
2025-04-17 13:50:51,492 - feat_dim: 768
2025-04-17 13:50:51,492 - hidden_size: 768
2025-04-17 13:50:51,493 - grad_clip: -1.0
2025-04-17 13:50:51,493 - warmup_proportion: [0.1]
2025-04-17 13:50:51,493 - hidden_dropout_prob: 0.1
2025-04-17 13:50:51,493 - weight: 1.0
2025-04-17 13:50:51,493 - loss_mode: rdrop
2025-04-17 13:50:51,493 - base_dim: 256
2025-04-17 13:50:51,493 - nheads: 8
2025-04-17 13:50:51,493 - attn_dropout: 0.1
2025-04-17 13:50:51,493 - relu_dropout: 0.1
2025-04-17 13:50:51,493 - embed_dropout: 0.01
2025-04-17 13:50:51,493 - res_dropout: 0.0
2025-04-17 13:50:51,493 - attn_mask: True
2025-04-17 13:50:51,493 - encoder_layers_1: 1
2025-04-17 13:50:51,493 - fusion_act: tanh
2025-04-17 13:50:51,493 - pred_output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/SMC/outputs_test2/MIntRec/umc_umc_MIntRec_bert-base-uncased_3
2025-04-17 13:50:51,493 - model_output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/SMC/outputs_test2/MIntRec/umc_umc_MIntRec_bert-base-uncased_3/models
2025-04-17 13:50:51,493 - text_seq_len: 30
2025-04-17 13:50:51,493 - video_seq_len: 230
2025-04-17 13:50:51,493 - audio_seq_len: 480
2025-04-17 13:50:51,493 - text_feat_dim: 768
2025-04-17 13:50:51,493 - video_feat_dim: 1024
2025-04-17 13:50:51,493 - audio_feat_dim: 768
2025-04-17 13:50:51,493 - num_labels: 20
2025-04-17 13:50:51,493 - num_train_examples: 1779
2025-04-17 13:50:51,493 - ============================== End Params ==============================
2025-04-17 13:50:52,746 - Freeze all parameters but the last layer for efficiency
2025-04-17 13:50:52,780 - Pre-training start...
2025-04-17 13:51:09,345 - ***** Epoch: 1: Eval results *****
2025-04-17 13:51:09,345 -   train_loss = 5.958007914679391
2025-04-17 13:51:26,034 - ***** Epoch: 2: Eval results *****
2025-04-17 13:51:26,034 -   train_loss = 5.960551057543073
2025-04-17 13:51:43,104 - ***** Epoch: 3: Eval results *****
2025-04-17 13:51:43,104 -   train_loss = 5.954593011311123
2025-04-17 13:52:00,366 - ***** Epoch: 4: Eval results *****
2025-04-17 13:52:00,367 -   train_loss = 5.946140357426235
2025-04-17 13:52:16,713 - ***** Epoch: 5: Eval results *****
2025-04-17 13:52:16,714 -   train_loss = 5.934501068932669
2025-04-17 13:52:34,258 - ***** Epoch: 6: Eval results *****
2025-04-17 13:52:34,259 -   train_loss = 5.907594953264509
2025-04-17 13:52:51,386 - ***** Epoch: 7: Eval results *****
2025-04-17 13:52:51,386 -   train_loss = 5.8713314192635675
2025-04-17 13:53:08,986 - ***** Epoch: 8: Eval results *****
2025-04-17 13:53:08,986 -   train_loss = 5.786895683833531
2025-04-17 13:53:25,893 - ***** Epoch: 9: Eval results *****
2025-04-17 13:53:25,894 -   train_loss = 5.57973609651838
2025-04-17 13:53:43,294 - ***** Epoch: 10: Eval results *****
2025-04-17 13:53:43,294 -   train_loss = 5.1481443132672995
2025-04-17 13:54:00,021 - ***** Epoch: 11: Eval results *****
2025-04-17 13:54:00,022 -   train_loss = 4.622122798647199
2025-04-17 13:54:17,700 - ***** Epoch: 12: Eval results *****
2025-04-17 13:54:17,700 -   train_loss = 4.183251517159598
2025-04-17 13:54:34,895 - ***** Epoch: 13: Eval results *****
2025-04-17 13:54:34,895 -   train_loss = 3.8389804533549716
2025-04-17 13:54:52,228 - ***** Epoch: 14: Eval results *****
2025-04-17 13:54:52,228 -   train_loss = 3.5383073602403914
2025-04-17 13:55:09,742 - ***** Epoch: 15: Eval results *****
2025-04-17 13:55:09,743 -   train_loss = 3.292990974017552
2025-04-17 13:55:26,784 - ***** Epoch: 16: Eval results *****
2025-04-17 13:55:26,785 -   train_loss = 3.0950201409203664
2025-04-17 13:55:44,198 - ***** Epoch: 17: Eval results *****
2025-04-17 13:55:44,198 -   train_loss = 2.9213048219680786
2025-04-17 13:56:01,476 - ***** Epoch: 18: Eval results *****
2025-04-17 13:56:01,477 -   train_loss = 2.7749585253851756
2025-04-17 13:56:18,563 - ***** Epoch: 19: Eval results *****
2025-04-17 13:56:18,563 -   train_loss = 2.639635051999773
2025-04-17 13:56:36,233 - ***** Epoch: 20: Eval results *****
2025-04-17 13:56:36,233 -   train_loss = 2.529211299760001
2025-04-17 13:56:53,127 - ***** Epoch: 21: Eval results *****
2025-04-17 13:56:53,127 -   train_loss = 2.4439116375786916
2025-04-17 13:57:10,497 - ***** Epoch: 22: Eval results *****
2025-04-17 13:57:10,498 -   train_loss = 2.360613465309143
2025-04-17 13:57:27,664 - ***** Epoch: 23: Eval results *****
2025-04-17 13:57:27,664 -   train_loss = 2.2924124683652605
2025-04-17 13:57:45,280 - ***** Epoch: 24: Eval results *****
2025-04-17 13:57:45,281 -   train_loss = 2.2366832494735718
2025-04-17 13:58:04,078 - ***** Epoch: 25: Eval results *****
2025-04-17 13:58:04,078 -   train_loss = 2.1638788325445995
2025-04-17 13:58:22,284 - ***** Epoch: 26: Eval results *****
2025-04-17 13:58:22,284 -   train_loss = 2.119429247719901
2025-04-17 13:58:40,738 - ***** Epoch: 27: Eval results *****
2025-04-17 13:58:40,738 -   train_loss = 2.09537535905838
2025-04-17 13:58:57,881 - ***** Epoch: 28: Eval results *****
2025-04-17 13:58:57,882 -   train_loss = 2.06866455078125
2025-04-17 13:59:15,301 - ***** Epoch: 29: Eval results *****
2025-04-17 13:59:15,302 -   train_loss = 1.998945678983416
2025-04-17 13:59:32,704 - ***** Epoch: 30: Eval results *****
2025-04-17 13:59:32,704 -   train_loss = 1.9564786808831351
2025-04-17 13:59:50,094 - ***** Epoch: 31: Eval results *****
2025-04-17 13:59:50,094 -   train_loss = 1.9374686820166451
2025-04-17 14:00:07,443 - ***** Epoch: 32: Eval results *****
2025-04-17 14:00:07,443 -   train_loss = 1.9183548944337028
2025-04-17 14:00:24,725 - ***** Epoch: 33: Eval results *****
2025-04-17 14:00:24,725 -   train_loss = 1.8680011204310827
2025-04-17 14:00:41,556 - ***** Epoch: 34: Eval results *****
2025-04-17 14:00:41,556 -   train_loss = 1.8557632395199366
2025-04-17 14:00:58,552 - ***** Epoch: 35: Eval results *****
2025-04-17 14:00:58,552 -   train_loss = 1.8527493051120214
2025-04-17 14:01:15,041 - ***** Epoch: 36: Eval results *****
2025-04-17 14:01:15,041 -   train_loss = 1.8205450347491674
2025-04-17 14:01:31,818 - ***** Epoch: 37: Eval results *****
2025-04-17 14:01:31,819 -   train_loss = 1.787735606942858
2025-04-17 14:01:48,281 - ***** Epoch: 38: Eval results *****
2025-04-17 14:01:48,281 -   train_loss = 1.7770877395357405
2025-04-17 14:02:05,286 - ***** Epoch: 39: Eval results *****
2025-04-17 14:02:05,287 -   train_loss = 1.7553522161075048
2025-04-17 14:02:21,527 - ***** Epoch: 40: Eval results *****
2025-04-17 14:02:21,528 -   train_loss = 1.7541275705610002
2025-04-17 14:02:39,832 - ***** Epoch: 41: Eval results *****
2025-04-17 14:02:39,832 -   train_loss = 1.7256557600838798
2025-04-17 14:02:58,557 - ***** Epoch: 42: Eval results *****
2025-04-17 14:02:58,558 -   train_loss = 1.7165442620004927
2025-04-17 14:03:17,439 - ***** Epoch: 43: Eval results *****
2025-04-17 14:03:17,439 -   train_loss = 1.6894015754972185
2025-04-17 14:03:36,395 - ***** Epoch: 44: Eval results *****
2025-04-17 14:03:36,398 -   train_loss = 1.6844561525753565
2025-04-17 14:03:54,361 - ***** Epoch: 45: Eval results *****
2025-04-17 14:03:54,361 -   train_loss = 1.688397969518389
2025-04-17 14:04:11,625 - ***** Epoch: 46: Eval results *****
2025-04-17 14:04:11,625 -   train_loss = 1.66765216418675
2025-04-17 14:04:28,423 - ***** Epoch: 47: Eval results *****
2025-04-17 14:04:28,423 -   train_loss = 1.6542827912739344
2025-04-17 14:04:45,443 - ***** Epoch: 48: Eval results *****
2025-04-17 14:04:45,443 -   train_loss = 1.6272259439740862
2025-04-17 14:05:02,410 - ***** Epoch: 49: Eval results *****
2025-04-17 14:05:02,411 -   train_loss = 1.6237848145621163
2025-04-17 14:05:19,037 - ***** Epoch: 50: Eval results *****
2025-04-17 14:05:19,037 -   train_loss = 1.6333612203598022
2025-04-17 14:05:36,093 - ***** Epoch: 51: Eval results *****
2025-04-17 14:05:36,093 -   train_loss = 1.6103438564709254
2025-04-17 14:05:53,254 - ***** Epoch: 52: Eval results *****
2025-04-17 14:05:53,254 -   train_loss = 1.614291446549552
2025-04-17 14:06:09,600 - ***** Epoch: 53: Eval results *****
2025-04-17 14:06:09,600 -   train_loss = 1.5990405167852129
2025-04-17 14:06:26,863 - ***** Epoch: 54: Eval results *****
2025-04-17 14:06:26,864 -   train_loss = 1.58974723305021
2025-04-17 14:06:44,254 - ***** Epoch: 55: Eval results *****
2025-04-17 14:06:44,254 -   train_loss = 1.5830196738243103
2025-04-17 14:07:01,428 - ***** Epoch: 56: Eval results *****
2025-04-17 14:07:01,429 -   train_loss = 1.5684688176427568
2025-04-17 14:07:18,505 - ***** Epoch: 57: Eval results *****
2025-04-17 14:07:18,505 -   train_loss = 1.5711401530674525
2025-04-17 14:07:34,479 - ***** Epoch: 58: Eval results *****
2025-04-17 14:07:34,480 -   train_loss = 1.5722980414118086
2025-04-17 14:07:51,018 - ***** Epoch: 59: Eval results *****
2025-04-17 14:07:51,018 -   train_loss = 1.5631077119282313
2025-04-17 14:08:08,077 - ***** Epoch: 60: Eval results *****
2025-04-17 14:08:08,078 -   train_loss = 1.5476104702268327
2025-04-17 14:08:25,151 - ***** Epoch: 61: Eval results *****
2025-04-17 14:08:25,151 -   train_loss = 1.5422000799860274
2025-04-17 14:08:41,789 - ***** Epoch: 62: Eval results *****
2025-04-17 14:08:41,789 -   train_loss = 1.5492847221238273
2025-04-17 14:08:58,037 - ***** Epoch: 63: Eval results *****
2025-04-17 14:08:58,038 -   train_loss = 1.5224066717284066
2025-04-17 14:09:14,595 - ***** Epoch: 64: Eval results *****
2025-04-17 14:09:14,595 -   train_loss = 1.5292690226009913
2025-04-17 14:09:31,609 - ***** Epoch: 65: Eval results *****
2025-04-17 14:09:31,609 -   train_loss = 1.532229517187391
2025-04-17 14:09:48,043 - ***** Epoch: 66: Eval results *****
2025-04-17 14:09:48,043 -   train_loss = 1.5335332751274109
2025-04-17 14:10:05,108 - ***** Epoch: 67: Eval results *****
2025-04-17 14:10:05,109 -   train_loss = 1.5244801810809545
2025-04-17 14:10:22,105 - ***** Epoch: 68: Eval results *****
2025-04-17 14:10:22,105 -   train_loss = 1.5339738300868444
2025-04-17 14:10:39,058 - ***** Epoch: 69: Eval results *****
2025-04-17 14:10:39,058 -   train_loss = 1.5132990224020821
2025-04-17 14:10:56,046 - ***** Epoch: 70: Eval results *****
2025-04-17 14:10:56,046 -   train_loss = 1.522208333015442
2025-04-17 14:11:12,716 - ***** Epoch: 71: Eval results *****
2025-04-17 14:11:12,716 -   train_loss = 1.505313209124974
2025-04-17 14:11:29,757 - ***** Epoch: 72: Eval results *****
2025-04-17 14:11:29,758 -   train_loss = 1.5013820699283056
2025-04-17 14:11:46,847 - ***** Epoch: 73: Eval results *****
2025-04-17 14:11:46,847 -   train_loss = 1.4964019826480321
2025-04-17 14:12:03,859 - ***** Epoch: 74: Eval results *****
2025-04-17 14:12:03,859 -   train_loss = 1.4898431045668465
2025-04-17 14:12:21,544 - ***** Epoch: 75: Eval results *****
2025-04-17 14:12:21,545 -   train_loss = 1.5040971551622664
2025-04-17 14:12:38,886 - ***** Epoch: 76: Eval results *****
2025-04-17 14:12:38,887 -   train_loss = 1.4950679114886694
2025-04-17 14:12:56,288 - ***** Epoch: 77: Eval results *****
2025-04-17 14:12:56,288 -   train_loss = 1.4771728515625
2025-04-17 14:13:13,206 - ***** Epoch: 78: Eval results *****
2025-04-17 14:13:13,206 -   train_loss = 1.4835715634482247
2025-04-17 14:13:29,932 - ***** Epoch: 79: Eval results *****
2025-04-17 14:13:29,933 -   train_loss = 1.4819990737097604
2025-04-17 14:13:46,813 - ***** Epoch: 80: Eval results *****
2025-04-17 14:13:46,814 -   train_loss = 1.4950675198010035
2025-04-17 14:14:03,681 - ***** Epoch: 81: Eval results *****
2025-04-17 14:14:03,681 -   train_loss = 1.4746928470475333
2025-04-17 14:14:20,750 - ***** Epoch: 82: Eval results *****
2025-04-17 14:14:20,750 -   train_loss = 1.4750004751341683
2025-04-17 14:14:37,857 - ***** Epoch: 83: Eval results *****
2025-04-17 14:14:37,857 -   train_loss = 1.4834086298942566
2025-04-17 14:14:55,397 - ***** Epoch: 84: Eval results *****
2025-04-17 14:14:55,397 -   train_loss = 1.4755179371152605
2025-04-17 14:15:12,733 - ***** Epoch: 85: Eval results *****
2025-04-17 14:15:12,733 -   train_loss = 1.47446494443076
2025-04-17 14:15:29,490 - ***** Epoch: 86: Eval results *****
2025-04-17 14:15:29,490 -   train_loss = 1.4739460093634469
2025-04-17 14:15:46,774 - ***** Epoch: 87: Eval results *****
2025-04-17 14:15:46,774 -   train_loss = 1.4717774476323808
2025-04-17 14:16:03,941 - ***** Epoch: 88: Eval results *****
2025-04-17 14:16:03,942 -   train_loss = 1.4736958656992232
2025-04-17 14:16:21,202 - ***** Epoch: 89: Eval results *****
2025-04-17 14:16:21,202 -   train_loss = 1.4697628021240234
2025-04-17 14:16:38,691 - ***** Epoch: 90: Eval results *****
2025-04-17 14:16:38,692 -   train_loss = 1.47857323714665
2025-04-17 14:16:55,807 - ***** Epoch: 91: Eval results *****
2025-04-17 14:16:55,808 -   train_loss = 1.4763818979263306
2025-04-17 14:17:12,653 - ***** Epoch: 92: Eval results *****
2025-04-17 14:17:12,653 -   train_loss = 1.4672053115708488
2025-04-17 14:17:29,753 - ***** Epoch: 93: Eval results *****
2025-04-17 14:17:29,753 -   train_loss = 1.469337625162942
2025-04-17 14:17:46,501 - ***** Epoch: 94: Eval results *****
2025-04-17 14:17:46,501 -   train_loss = 1.4645106196403503
2025-04-17 14:18:03,768 - ***** Epoch: 95: Eval results *****
2025-04-17 14:18:03,768 -   train_loss = 1.457760819367
2025-04-17 14:18:20,576 - ***** Epoch: 96: Eval results *****
2025-04-17 14:18:20,577 -   train_loss = 1.4683018667357308
2025-04-17 14:18:37,542 - ***** Epoch: 97: Eval results *****
2025-04-17 14:18:37,542 -   train_loss = 1.4659046956471034
2025-04-17 14:18:54,390 - ***** Epoch: 98: Eval results *****
2025-04-17 14:18:54,390 -   train_loss = 1.4771093215261186
2025-04-17 14:19:11,447 - ***** Epoch: 99: Eval results *****
2025-04-17 14:19:11,448 -   train_loss = 1.4671089904648917
2025-04-17 14:19:28,885 - ***** Epoch: 100: Eval results *****
2025-04-17 14:19:28,885 -   train_loss = 1.4687404802867345
2025-04-17 14:19:30,479 - Pre-training finished...
2025-04-17 14:19:30,837 - Freeze all parameters but the last layer for efficiency
2025-04-17 14:19:30,846 - Multimodal Intent Recognition begins...
2025-04-17 14:19:30,846 - Training begins...
2025-04-17 14:19:46,691 - Initializing centroids with K-means++...
2025-04-17 14:19:46,779 - K-means++ used 0.09 s
2025-04-17 14:20:18,489 - K-means used 0.02 s
2025-04-17 14:20:19,621 - ***** Epoch: 1 *****
2025-04-17 14:20:19,621 - Supervised Training Loss: 4.369070
2025-04-17 14:20:19,623 - Unsupervised Training Loss: 5.531930
2025-04-17 14:20:50,708 - K-means used 0.02 s
2025-04-17 14:20:51,758 - ***** Epoch: 2 *****
2025-04-17 14:20:51,758 - Supervised Training Loss: 3.668690
2025-04-17 14:20:51,758 - Unsupervised Training Loss: 5.560180
2025-04-17 14:21:20,294 - K-means used 0.02 s
2025-04-17 14:21:21,403 - ***** Epoch: 3 *****
2025-04-17 14:21:21,404 - Supervised Training Loss: 4.817710
2025-04-17 14:21:21,404 - Unsupervised Training Loss: 5.429490
2025-04-17 14:21:50,784 - K-means used 0.02 s
2025-04-17 14:21:51,910 - ***** Epoch: 4 *****
2025-04-17 14:21:51,911 - Supervised Training Loss: 4.626290
2025-04-17 14:21:51,911 - Unsupervised Training Loss: 5.486620
2025-04-17 14:22:21,328 - K-means used 0.02 s
2025-04-17 14:22:22,647 - ***** Epoch: 5 *****
2025-04-17 14:22:22,648 - Supervised Training Loss: 4.300630
2025-04-17 14:22:22,648 - Unsupervised Training Loss: 5.529740
2025-04-17 14:22:53,314 - K-means used 0.02 s
2025-04-17 14:22:54,534 - ***** Epoch: 6 *****
2025-04-17 14:22:54,534 - Supervised Training Loss: 4.710450
2025-04-17 14:22:54,534 - Unsupervised Training Loss: 5.327420
2025-04-17 14:23:26,939 - K-means used 0.02 s
2025-04-17 14:23:28,106 - ***** Epoch: 7 *****
2025-04-17 14:23:28,106 - Supervised Training Loss: 4.608350
2025-04-17 14:23:28,106 - Unsupervised Training Loss: 5.443260
2025-04-17 14:23:59,769 - K-means used 0.02 s
2025-04-17 14:24:01,199 - ***** Epoch: 8 *****
2025-04-17 14:24:01,199 - Supervised Training Loss: 4.457210
2025-04-17 14:24:01,199 - Unsupervised Training Loss: 5.503530
2025-04-17 14:24:32,407 - K-means used 0.02 s
2025-04-17 14:24:33,711 - ***** Epoch: 9 *****
2025-04-17 14:24:33,711 - Supervised Training Loss: 4.666760
2025-04-17 14:24:33,711 - Unsupervised Training Loss: 5.542010
2025-04-17 14:25:03,087 - K-means used 0.02 s
2025-04-17 14:25:04,461 - ***** Epoch: 10 *****
2025-04-17 14:25:04,461 - Supervised Training Loss: 4.600360
2025-04-17 14:25:04,461 - Unsupervised Training Loss: 5.380790
2025-04-17 14:25:34,013 - K-means used 0.02 s
2025-04-17 14:25:35,408 - ***** Epoch: 11 *****
2025-04-17 14:25:35,409 - Supervised Training Loss: 4.522480
2025-04-17 14:25:35,409 - Unsupervised Training Loss: 5.454560
2025-04-17 14:26:04,979 - K-means used 0.01 s
2025-04-17 14:26:06,610 - ***** Epoch: 12 *****
2025-04-17 14:26:06,611 - Supervised Training Loss: 4.656530
2025-04-17 14:26:06,611 - Unsupervised Training Loss: 5.530010
2025-04-17 14:26:36,325 - K-means used 0.02 s
2025-04-17 14:26:37,802 - ***** Epoch: 13 *****
2025-04-17 14:26:37,802 - Supervised Training Loss: 4.615580
2025-04-17 14:26:37,802 - Unsupervised Training Loss: 5.239220
2025-04-17 14:27:06,417 - K-means used 0.02 s
2025-04-17 14:27:07,988 - ***** Epoch: 14 *****
2025-04-17 14:27:07,989 - Supervised Training Loss: 4.569310
2025-04-17 14:27:07,989 - Unsupervised Training Loss: 5.387820
2025-04-17 14:27:37,217 - K-means used 0.01 s
2025-04-17 14:27:38,912 - ***** Epoch: 15 *****
2025-04-17 14:27:38,913 - Supervised Training Loss: 4.423420
2025-04-17 14:27:38,913 - Unsupervised Training Loss: 5.494730
2025-04-17 14:28:10,697 - K-means used 0.02 s
2025-04-17 14:28:12,421 - ***** Epoch: 16 *****
2025-04-17 14:28:12,422 - Supervised Training Loss: 4.669970
2025-04-17 14:28:12,422 - Unsupervised Training Loss: 4.913890
2025-04-17 14:28:40,937 - K-means used 0.02 s
2025-04-17 14:28:42,710 - ***** Epoch: 17 *****
2025-04-17 14:28:42,711 - Supervised Training Loss: 4.652830
2025-04-17 14:28:42,711 - Unsupervised Training Loss: 5.152010
2025-04-17 14:29:02,836 - Training is finished...
2025-04-17 14:29:02,836 - Testing begins...
2025-04-17 14:29:09,778 - ***** Test results *****
2025-04-17 14:29:09,778 -   ACC = 40.45
2025-04-17 14:29:09,778 -   ARI = 18.27
2025-04-17 14:29:09,778 -   NMI = 44.2
2025-04-17 14:29:09,778 -   fmi = 23.41
2025-04-17 14:29:09,779 - Testing is finished...
2025-04-17 14:29:09,779 - Multimodal intent recognition is finished...
2025-04-17 14:29:09,779 - Results are saved in results/results_umc_pre.csv
2025-04-17 14:29:10,861 - Freeze all parameters but the last layer for efficiency
2025-04-17 14:29:10,902 - Pre-training start...
2025-04-17 14:29:11,798 - ***** Epoch: 1: Eval results *****
2025-04-17 14:29:11,799 -   train_loss = 5.680746078491211
2025-04-17 14:29:12,672 - ***** Epoch: 2: Eval results *****
2025-04-17 14:29:12,673 -   train_loss = 5.688532829284668
2025-04-17 14:29:13,541 - ***** Epoch: 3: Eval results *****
2025-04-17 14:29:13,541 -   train_loss = 5.670039653778076
2025-04-17 14:29:14,401 - ***** Epoch: 4: Eval results *****
2025-04-17 14:29:14,401 -   train_loss = 5.677886009216309
2025-04-17 14:29:15,261 - ***** Epoch: 5: Eval results *****
2025-04-17 14:29:15,261 -   train_loss = 5.674598693847656
2025-04-17 14:29:16,118 - ***** Epoch: 6: Eval results *****
2025-04-17 14:29:16,118 -   train_loss = 5.681734561920166
2025-04-17 14:29:16,936 - ***** Epoch: 7: Eval results *****
2025-04-17 14:29:16,937 -   train_loss = 5.664730072021484
2025-04-17 14:29:17,750 - ***** Epoch: 8: Eval results *****
2025-04-17 14:29:17,750 -   train_loss = 5.665646076202393
2025-04-17 14:29:18,595 - ***** Epoch: 9: Eval results *****
2025-04-17 14:29:18,595 -   train_loss = 5.675380229949951
2025-04-17 14:29:19,290 - ***** Epoch: 10: Eval results *****
2025-04-17 14:29:19,290 -   train_loss = 5.676319599151611
2025-04-17 14:29:19,992 - ***** Epoch: 11: Eval results *****
2025-04-17 14:29:19,992 -   train_loss = 5.664687156677246
2025-04-17 14:29:20,688 - ***** Epoch: 12: Eval results *****
2025-04-17 14:29:20,688 -   train_loss = 5.666262149810791
2025-04-17 14:29:21,389 - ***** Epoch: 13: Eval results *****
2025-04-17 14:29:21,390 -   train_loss = 5.665752410888672
2025-04-17 14:29:22,100 - ***** Epoch: 14: Eval results *****
2025-04-17 14:29:22,100 -   train_loss = 5.6805925369262695
2025-04-17 14:29:22,955 - ***** Epoch: 15: Eval results *****
2025-04-17 14:29:22,956 -   train_loss = 5.657242298126221
2025-04-17 14:29:23,838 - ***** Epoch: 16: Eval results *****
2025-04-17 14:29:23,838 -   train_loss = 5.670019149780273
2025-04-17 14:29:24,658 - ***** Epoch: 17: Eval results *****
2025-04-17 14:29:24,658 -   train_loss = 5.653044700622559
2025-04-17 14:29:25,502 - ***** Epoch: 18: Eval results *****
2025-04-17 14:29:25,502 -   train_loss = 5.648664951324463
2025-04-17 14:29:26,304 - ***** Epoch: 19: Eval results *****
2025-04-17 14:29:26,305 -   train_loss = 5.646177768707275
2025-04-17 14:29:26,994 - ***** Epoch: 20: Eval results *****
2025-04-17 14:29:26,995 -   train_loss = 5.650406360626221
2025-04-17 14:29:27,710 - ***** Epoch: 21: Eval results *****
2025-04-17 14:29:27,710 -   train_loss = 5.639389514923096
2025-04-17 14:29:28,548 - ***** Epoch: 22: Eval results *****
2025-04-17 14:29:28,549 -   train_loss = 5.6564836502075195
2025-04-17 14:29:29,364 - ***** Epoch: 23: Eval results *****
2025-04-17 14:29:29,364 -   train_loss = 5.659708023071289
2025-04-17 14:29:30,112 - ***** Epoch: 24: Eval results *****
2025-04-17 14:29:30,112 -   train_loss = 5.6584391593933105
2025-04-17 14:29:30,999 - ***** Epoch: 25: Eval results *****
2025-04-17 14:29:30,999 -   train_loss = 5.655052661895752
2025-04-17 14:29:31,834 - ***** Epoch: 26: Eval results *****
2025-04-17 14:29:31,834 -   train_loss = 5.64423942565918
2025-04-17 14:29:32,664 - ***** Epoch: 27: Eval results *****
2025-04-17 14:29:32,664 -   train_loss = 5.651057720184326
2025-04-17 14:29:33,469 - ***** Epoch: 28: Eval results *****
2025-04-17 14:29:33,469 -   train_loss = 5.651513576507568
2025-04-17 14:29:34,167 - ***** Epoch: 29: Eval results *****
2025-04-17 14:29:34,168 -   train_loss = 5.650424480438232
2025-04-17 14:29:34,864 - ***** Epoch: 30: Eval results *****
2025-04-17 14:29:34,864 -   train_loss = 5.6312575340271
2025-04-17 14:29:35,747 - ***** Epoch: 31: Eval results *****
2025-04-17 14:29:35,748 -   train_loss = 5.632662773132324
2025-04-17 14:29:36,570 - ***** Epoch: 32: Eval results *****
2025-04-17 14:29:36,571 -   train_loss = 5.634532928466797
2025-04-17 14:29:37,466 - ***** Epoch: 33: Eval results *****
2025-04-17 14:29:37,466 -   train_loss = 5.641489505767822
2025-04-17 14:29:38,282 - ***** Epoch: 34: Eval results *****
2025-04-17 14:29:38,282 -   train_loss = 5.618261814117432
2025-04-17 14:29:39,168 - ***** Epoch: 35: Eval results *****
2025-04-17 14:29:39,169 -   train_loss = 5.626597881317139
2025-04-17 14:29:39,975 - ***** Epoch: 36: Eval results *****
2025-04-17 14:29:39,976 -   train_loss = 5.615105628967285
2025-04-17 14:29:40,862 - ***** Epoch: 37: Eval results *****
2025-04-17 14:29:40,862 -   train_loss = 5.62951135635376
2025-04-17 14:29:41,669 - ***** Epoch: 38: Eval results *****
2025-04-17 14:29:41,670 -   train_loss = 5.605558395385742
2025-04-17 14:29:42,367 - ***** Epoch: 39: Eval results *****
2025-04-17 14:29:42,368 -   train_loss = 5.606897830963135
2025-04-17 14:29:43,254 - ***** Epoch: 40: Eval results *****
2025-04-17 14:29:43,255 -   train_loss = 5.592051029205322
2025-04-17 14:29:44,088 - ***** Epoch: 41: Eval results *****
2025-04-17 14:29:44,088 -   train_loss = 5.585092067718506
2025-04-17 14:29:44,913 - ***** Epoch: 42: Eval results *****
2025-04-17 14:29:44,913 -   train_loss = 5.5841217041015625
2025-04-17 14:29:45,739 - ***** Epoch: 43: Eval results *****
2025-04-17 14:29:45,740 -   train_loss = 5.585884094238281
2025-04-17 14:29:46,565 - ***** Epoch: 44: Eval results *****
2025-04-17 14:29:46,565 -   train_loss = 5.573464393615723
2025-04-17 14:29:47,366 - ***** Epoch: 45: Eval results *****
2025-04-17 14:29:47,366 -   train_loss = 5.58012056350708
2025-04-17 14:29:48,073 - ***** Epoch: 46: Eval results *****
2025-04-17 14:29:48,074 -   train_loss = 5.572744846343994
2025-04-17 14:29:48,948 - ***** Epoch: 47: Eval results *****
2025-04-17 14:29:48,948 -   train_loss = 5.556433200836182
2025-04-17 14:29:49,759 - ***** Epoch: 48: Eval results *****
2025-04-17 14:29:49,760 -   train_loss = 5.558675289154053
2025-04-17 14:29:50,453 - ***** Epoch: 49: Eval results *****
2025-04-17 14:29:50,453 -   train_loss = 5.554935455322266
2025-04-17 14:29:51,148 - ***** Epoch: 50: Eval results *****
2025-04-17 14:29:51,148 -   train_loss = 5.520244121551514
2025-04-17 14:29:51,845 - ***** Epoch: 51: Eval results *****
2025-04-17 14:29:51,845 -   train_loss = 5.521662712097168
2025-04-17 14:29:52,534 - ***** Epoch: 52: Eval results *****
2025-04-17 14:29:52,534 -   train_loss = 5.550349235534668
2025-04-17 14:29:53,229 - ***** Epoch: 53: Eval results *****
2025-04-17 14:29:53,229 -   train_loss = 5.50820255279541
2025-04-17 14:29:53,926 - ***** Epoch: 54: Eval results *****
2025-04-17 14:29:53,926 -   train_loss = 5.500367164611816
2025-04-17 14:29:54,618 - ***** Epoch: 55: Eval results *****
2025-04-17 14:29:54,619 -   train_loss = 5.479164123535156
2025-04-17 14:29:55,312 - ***** Epoch: 56: Eval results *****
2025-04-17 14:29:55,312 -   train_loss = 5.482106685638428
2025-04-17 14:29:56,005 - ***** Epoch: 57: Eval results *****
2025-04-17 14:29:56,006 -   train_loss = 5.476052761077881
2025-04-17 14:29:56,748 - ***** Epoch: 58: Eval results *****
2025-04-17 14:29:56,748 -   train_loss = 5.440390586853027
2025-04-17 14:29:57,618 - ***** Epoch: 59: Eval results *****
2025-04-17 14:29:57,618 -   train_loss = 5.4506683349609375
2025-04-17 14:29:58,415 - ***** Epoch: 60: Eval results *****
2025-04-17 14:29:58,416 -   train_loss = 5.435996055603027
2025-04-17 14:29:59,289 - ***** Epoch: 61: Eval results *****
2025-04-17 14:29:59,289 -   train_loss = 5.400471210479736
2025-04-17 14:30:00,114 - ***** Epoch: 62: Eval results *****
2025-04-17 14:30:00,114 -   train_loss = 5.385774612426758
2025-04-17 14:30:00,950 - ***** Epoch: 63: Eval results *****
2025-04-17 14:30:00,950 -   train_loss = 5.367758750915527
2025-04-17 14:30:01,811 - ***** Epoch: 64: Eval results *****
2025-04-17 14:30:01,811 -   train_loss = 5.382754802703857
2025-04-17 14:30:02,642 - ***** Epoch: 65: Eval results *****
2025-04-17 14:30:02,643 -   train_loss = 5.346269607543945
2025-04-17 14:30:03,465 - ***** Epoch: 66: Eval results *****
2025-04-17 14:30:03,465 -   train_loss = 5.376320838928223
2025-04-17 14:30:04,292 - ***** Epoch: 67: Eval results *****
2025-04-17 14:30:04,293 -   train_loss = 5.317187786102295
2025-04-17 14:30:05,098 - ***** Epoch: 68: Eval results *****
2025-04-17 14:30:05,098 -   train_loss = 5.298742294311523
2025-04-17 14:30:05,943 - ***** Epoch: 69: Eval results *****
2025-04-17 14:30:05,943 -   train_loss = 5.305815696716309
2025-04-17 14:30:06,636 - ***** Epoch: 70: Eval results *****
2025-04-17 14:30:06,636 -   train_loss = 5.287991046905518
2025-04-17 14:30:07,342 - ***** Epoch: 71: Eval results *****
2025-04-17 14:30:07,342 -   train_loss = 5.264924049377441
2025-04-17 14:30:08,037 - ***** Epoch: 72: Eval results *****
2025-04-17 14:30:08,037 -   train_loss = 5.266911029815674
2025-04-17 14:30:08,890 - ***** Epoch: 73: Eval results *****
2025-04-17 14:30:08,890 -   train_loss = 5.244382381439209
2025-04-17 14:30:09,596 - ***** Epoch: 74: Eval results *****
2025-04-17 14:30:09,596 -   train_loss = 5.242937088012695
2025-04-17 14:30:10,296 - ***** Epoch: 75: Eval results *****
2025-04-17 14:30:10,296 -   train_loss = 5.1931610107421875
2025-04-17 14:30:11,164 - ***** Epoch: 76: Eval results *****
2025-04-17 14:30:11,164 -   train_loss = 5.203429222106934
2025-04-17 14:30:11,960 - ***** Epoch: 77: Eval results *****
2025-04-17 14:30:11,960 -   train_loss = 5.180716514587402
2025-04-17 14:30:12,656 - ***** Epoch: 78: Eval results *****
2025-04-17 14:30:12,656 -   train_loss = 5.169215202331543
2025-04-17 14:30:13,350 - ***** Epoch: 79: Eval results *****
2025-04-17 14:30:13,350 -   train_loss = 5.150118350982666
2025-04-17 14:30:14,220 - ***** Epoch: 80: Eval results *****
2025-04-17 14:30:14,220 -   train_loss = 5.120574951171875
2025-04-17 14:30:15,050 - ***** Epoch: 81: Eval results *****
2025-04-17 14:30:15,050 -   train_loss = 5.06900691986084
2025-04-17 14:30:15,872 - ***** Epoch: 82: Eval results *****
2025-04-17 14:30:15,872 -   train_loss = 5.0728983879089355
2025-04-17 14:30:16,685 - ***** Epoch: 83: Eval results *****
2025-04-17 14:30:16,685 -   train_loss = 5.077847480773926
2025-04-17 14:30:17,554 - ***** Epoch: 84: Eval results *****
2025-04-17 14:30:17,555 -   train_loss = 4.997527599334717
2025-04-17 14:30:18,366 - ***** Epoch: 85: Eval results *****
2025-04-17 14:30:18,367 -   train_loss = 5.030362129211426
2025-04-17 14:30:19,258 - ***** Epoch: 86: Eval results *****
2025-04-17 14:30:19,258 -   train_loss = 4.992527008056641
2025-04-17 14:30:20,064 - ***** Epoch: 87: Eval results *****
2025-04-17 14:30:20,064 -   train_loss = 4.990078449249268
2025-04-17 14:30:20,762 - ***** Epoch: 88: Eval results *****
2025-04-17 14:30:20,762 -   train_loss = 4.985766887664795
2025-04-17 14:30:21,464 - ***** Epoch: 89: Eval results *****
2025-04-17 14:30:21,465 -   train_loss = 4.955620288848877
2025-04-17 14:30:22,162 - ***** Epoch: 90: Eval results *****
2025-04-17 14:30:22,163 -   train_loss = 4.958067417144775
2025-04-17 14:30:22,896 - ***** Epoch: 91: Eval results *****
2025-04-17 14:30:22,896 -   train_loss = 4.913761138916016
2025-04-17 14:30:23,618 - ***** Epoch: 92: Eval results *****
2025-04-17 14:30:23,618 -   train_loss = 4.890507698059082
2025-04-17 14:30:24,450 - ***** Epoch: 93: Eval results *****
2025-04-17 14:30:24,451 -   train_loss = 4.89884090423584
2025-04-17 14:30:25,314 - ***** Epoch: 94: Eval results *****
2025-04-17 14:30:25,314 -   train_loss = 4.854097843170166
2025-04-17 14:30:26,137 - ***** Epoch: 95: Eval results *****
2025-04-17 14:30:26,138 -   train_loss = 4.846578121185303
2025-04-17 14:30:26,965 - ***** Epoch: 96: Eval results *****
2025-04-17 14:30:26,965 -   train_loss = 4.8666768074035645
2025-04-17 14:30:27,764 - ***** Epoch: 97: Eval results *****
2025-04-17 14:30:27,764 -   train_loss = 4.788143157958984
2025-04-17 14:30:28,578 - ***** Epoch: 98: Eval results *****
2025-04-17 14:30:28,579 -   train_loss = 4.815699577331543
2025-04-17 14:30:29,276 - ***** Epoch: 99: Eval results *****
2025-04-17 14:30:29,277 -   train_loss = 4.78986120223999
2025-04-17 14:30:29,973 - ***** Epoch: 100: Eval results *****
2025-04-17 14:30:29,973 -   train_loss = 4.768197059631348
2025-04-17 14:30:31,692 - Pre-training finished...
2025-04-17 14:30:32,058 - Freeze all parameters but the last layer for efficiency
2025-04-17 14:30:32,068 - Multimodal Intent Recognition begins...
2025-04-17 14:30:32,068 - Training begins...
2025-04-17 14:30:42,307 - Initializing centroids with K-means++...
2025-04-17 14:30:42,360 - K-means++ used 0.05 s
2025-04-17 14:31:14,401 - K-means used 0.1 s
2025-04-17 14:31:15,414 - ***** Epoch: 1 *****
2025-04-17 14:31:15,414 - Supervised Training Loss: 5.160200
2025-04-17 14:31:15,414 - Unsupervised Training Loss: 5.822390
2025-04-17 14:31:44,932 - K-means used 0.04 s
2025-04-17 14:31:45,996 - ***** Epoch: 2 *****
2025-04-17 14:31:45,997 - Supervised Training Loss: 4.271730
2025-04-17 14:31:45,997 - Unsupervised Training Loss: 5.802340
2025-04-17 14:32:15,508 - K-means used 0.04 s
2025-04-17 14:32:16,650 - ***** Epoch: 3 *****
2025-04-17 14:32:16,650 - Supervised Training Loss: 5.310970
2025-04-17 14:32:16,650 - Unsupervised Training Loss: 5.586190
2025-04-17 14:32:46,353 - K-means used 0.03 s
2025-04-17 14:32:47,448 - ***** Epoch: 4 *****
2025-04-17 14:32:47,448 - Supervised Training Loss: 5.022380
2025-04-17 14:32:47,448 - Unsupervised Training Loss: 5.595060
2025-04-17 14:33:16,631 - K-means used 0.03 s
2025-04-17 14:33:17,765 - ***** Epoch: 5 *****
2025-04-17 14:33:17,765 - Supervised Training Loss: 4.571310
2025-04-17 14:33:17,765 - Unsupervised Training Loss: 5.596220
2025-04-17 14:33:47,162 - K-means used 0.03 s
2025-04-17 14:33:48,450 - ***** Epoch: 6 *****
2025-04-17 14:33:48,450 - Supervised Training Loss: 4.930240
2025-04-17 14:33:48,450 - Unsupervised Training Loss: 5.395390
2025-04-17 14:34:18,898 - K-means used 0.03 s
2025-04-17 14:34:20,440 - ***** Epoch: 7 *****
2025-04-17 14:34:20,440 - Supervised Training Loss: 4.841350
2025-04-17 14:34:20,440 - Unsupervised Training Loss: 5.487210
2025-04-17 14:34:53,113 - K-means used 0.05 s
2025-04-17 14:34:54,352 - ***** Epoch: 8 *****
2025-04-17 14:34:54,353 - Supervised Training Loss: 4.669380
2025-04-17 14:34:54,353 - Unsupervised Training Loss: 5.548420
2025-04-17 14:35:25,339 - K-means used 0.02 s
2025-04-17 14:35:26,686 - ***** Epoch: 9 *****
2025-04-17 14:35:26,686 - Supervised Training Loss: 4.899260
2025-04-17 14:35:26,687 - Unsupervised Training Loss: 5.579620
2025-04-17 14:35:55,721 - K-means used 0.02 s
2025-04-17 14:35:57,389 - ***** Epoch: 10 *****
2025-04-17 14:35:57,390 - Supervised Training Loss: 4.824980
2025-04-17 14:35:57,390 - Unsupervised Training Loss: 5.429330
2025-04-17 14:36:31,320 - K-means used 0.02 s
2025-04-17 14:36:32,716 - ***** Epoch: 11 *****
2025-04-17 14:36:32,716 - Supervised Training Loss: 4.744570
2025-04-17 14:36:32,716 - Unsupervised Training Loss: 5.501290
2025-04-17 14:37:02,521 - K-means used 0.02 s
2025-04-17 14:37:04,268 - ***** Epoch: 12 *****
2025-04-17 14:37:04,268 - Supervised Training Loss: 4.879370
2025-04-17 14:37:04,268 - Unsupervised Training Loss: 5.565480
2025-04-17 14:37:31,812 - K-means used 0.03 s
2025-04-17 14:37:33,664 - ***** Epoch: 13 *****
2025-04-17 14:37:33,664 - Supervised Training Loss: 4.851160
2025-04-17 14:37:33,664 - Unsupervised Training Loss: 5.286340
2025-04-17 14:38:02,575 - K-means used 0.02 s
2025-04-17 14:38:04,458 - ***** Epoch: 14 *****
2025-04-17 14:38:04,458 - Supervised Training Loss: 4.789640
2025-04-17 14:38:04,458 - Unsupervised Training Loss: 5.427930
2025-04-17 14:38:32,050 - K-means used 0.02 s
2025-04-17 14:38:33,960 - ***** Epoch: 15 *****
2025-04-17 14:38:33,960 - Supervised Training Loss: 4.665340
2025-04-17 14:38:33,960 - Unsupervised Training Loss: 5.528100
2025-04-17 14:39:01,115 - K-means used 0.02 s
2025-04-17 14:39:02,998 - ***** Epoch: 16 *****
2025-04-17 14:39:02,998 - Supervised Training Loss: 4.860100
2025-04-17 14:39:02,998 - Unsupervised Training Loss: 4.980150
2025-04-17 14:39:35,788 - K-means used 0.02 s
2025-04-17 14:39:37,881 - ***** Epoch: 17 *****
2025-04-17 14:39:37,881 - Supervised Training Loss: 4.815350
2025-04-17 14:39:37,881 - Unsupervised Training Loss: 5.210620
2025-04-17 14:39:57,121 - Training is finished...
2025-04-17 14:39:57,121 - Testing begins...
2025-04-17 14:40:05,177 - ***** Test results *****
2025-04-17 14:40:05,178 -   ACC = 20.9
2025-04-17 14:40:05,178 -   ARI = 6.54
2025-04-17 14:40:05,178 -   NMI = 29.25
2025-04-17 14:40:05,178 -   fmi = 12.61
2025-04-17 14:40:05,178 - Testing is finished...
2025-04-17 14:40:05,178 - Multimodal intent recognition is finished...
2025-04-17 14:40:05,178 - Results are saved in results/results_umc_pre.csv
2025-04-17 14:40:06,243 - Freeze all parameters but the last layer for efficiency
2025-04-17 14:40:06,289 - Pre-training start...
2025-04-17 14:40:07,120 - ***** Epoch: 1: Eval results *****
2025-04-17 14:40:07,120 -   train_loss = 5.686822414398193
2025-04-17 14:40:07,905 - ***** Epoch: 2: Eval results *****
2025-04-17 14:40:07,906 -   train_loss = 5.67728853225708
2025-04-17 14:40:08,730 - ***** Epoch: 3: Eval results *****
2025-04-17 14:40:08,730 -   train_loss = 5.689601898193359
2025-04-17 14:40:09,518 - ***** Epoch: 4: Eval results *****
2025-04-17 14:40:09,518 -   train_loss = 5.683967590332031
2025-04-17 14:40:10,278 - ***** Epoch: 5: Eval results *****
2025-04-17 14:40:10,278 -   train_loss = 5.685415267944336
2025-04-17 14:40:11,094 - ***** Epoch: 6: Eval results *****
2025-04-17 14:40:11,094 -   train_loss = 5.684756278991699
2025-04-17 14:40:11,762 - ***** Epoch: 7: Eval results *****
2025-04-17 14:40:11,762 -   train_loss = 5.686472415924072
2025-04-17 14:40:12,576 - ***** Epoch: 8: Eval results *****
2025-04-17 14:40:12,576 -   train_loss = 5.681875705718994
2025-04-17 14:40:13,382 - ***** Epoch: 9: Eval results *****
2025-04-17 14:40:13,382 -   train_loss = 5.682265758514404
2025-04-17 14:40:14,177 - ***** Epoch: 10: Eval results *****
2025-04-17 14:40:14,178 -   train_loss = 5.687868595123291
2025-04-17 14:40:14,989 - ***** Epoch: 11: Eval results *****
2025-04-17 14:40:14,989 -   train_loss = 5.681246757507324
2025-04-17 14:40:15,818 - ***** Epoch: 12: Eval results *****
2025-04-17 14:40:15,818 -   train_loss = 5.690756797790527
2025-04-17 14:40:16,619 - ***** Epoch: 13: Eval results *****
2025-04-17 14:40:16,619 -   train_loss = 5.686124324798584
2025-04-17 14:40:17,498 - ***** Epoch: 14: Eval results *****
2025-04-17 14:40:17,498 -   train_loss = 5.68412446975708
2025-04-17 14:40:18,288 - ***** Epoch: 15: Eval results *****
2025-04-17 14:40:18,289 -   train_loss = 5.681431770324707
2025-04-17 14:40:18,967 - ***** Epoch: 16: Eval results *****
2025-04-17 14:40:18,967 -   train_loss = 5.685633659362793
2025-04-17 14:40:19,652 - ***** Epoch: 17: Eval results *****
2025-04-17 14:40:19,652 -   train_loss = 5.67981481552124
2025-04-17 14:40:20,329 - ***** Epoch: 18: Eval results *****
2025-04-17 14:40:20,330 -   train_loss = 5.679732322692871
2025-04-17 14:40:21,060 - ***** Epoch: 19: Eval results *****
2025-04-17 14:40:21,061 -   train_loss = 5.67338228225708
2025-04-17 14:40:21,775 - ***** Epoch: 20: Eval results *****
2025-04-17 14:40:21,775 -   train_loss = 5.681036949157715
2025-04-17 14:40:22,432 - ***** Epoch: 21: Eval results *****
2025-04-17 14:40:22,432 -   train_loss = 5.676116466522217
2025-04-17 14:40:23,254 - ***** Epoch: 22: Eval results *****
2025-04-17 14:40:23,254 -   train_loss = 5.673295021057129
2025-04-17 14:40:24,035 - ***** Epoch: 23: Eval results *****
2025-04-17 14:40:24,035 -   train_loss = 5.677053451538086
2025-04-17 14:40:24,803 - ***** Epoch: 24: Eval results *****
2025-04-17 14:40:24,804 -   train_loss = 5.674532413482666
2025-04-17 14:40:25,465 - ***** Epoch: 25: Eval results *****
2025-04-17 14:40:25,466 -   train_loss = 5.6662397384643555
2025-04-17 14:40:26,286 - ***** Epoch: 26: Eval results *****
2025-04-17 14:40:26,287 -   train_loss = 5.661246299743652
2025-04-17 14:40:26,950 - ***** Epoch: 27: Eval results *****
2025-04-17 14:40:26,950 -   train_loss = 5.656779766082764
2025-04-17 14:40:27,754 - ***** Epoch: 28: Eval results *****
2025-04-17 14:40:27,754 -   train_loss = 5.659879684448242
2025-04-17 14:40:28,402 - ***** Epoch: 29: Eval results *****
2025-04-17 14:40:28,403 -   train_loss = 5.6640706062316895
2025-04-17 14:40:29,059 - ***** Epoch: 30: Eval results *****
2025-04-17 14:40:29,059 -   train_loss = 5.650392055511475
2025-04-17 14:40:29,716 - ***** Epoch: 31: Eval results *****
2025-04-17 14:40:29,717 -   train_loss = 5.65418815612793
2025-04-17 14:40:30,378 - ***** Epoch: 32: Eval results *****
2025-04-17 14:40:30,378 -   train_loss = 5.645633220672607
2025-04-17 14:40:31,165 - ***** Epoch: 33: Eval results *****
2025-04-17 14:40:31,166 -   train_loss = 5.646008491516113
2025-04-17 14:40:31,833 - ***** Epoch: 34: Eval results *****
2025-04-17 14:40:31,833 -   train_loss = 5.642954349517822
2025-04-17 14:40:32,596 - ***** Epoch: 35: Eval results *****
2025-04-17 14:40:32,596 -   train_loss = 5.648737907409668
2025-04-17 14:40:33,421 - ***** Epoch: 36: Eval results *****
2025-04-17 14:40:33,421 -   train_loss = 5.632767200469971
2025-04-17 14:40:34,175 - ***** Epoch: 37: Eval results *****
2025-04-17 14:40:34,176 -   train_loss = 5.634073257446289
2025-04-17 14:40:35,006 - ***** Epoch: 38: Eval results *****
2025-04-17 14:40:35,007 -   train_loss = 5.626350402832031
2025-04-17 14:40:35,788 - ***** Epoch: 39: Eval results *****
2025-04-17 14:40:35,788 -   train_loss = 5.617928981781006
2025-04-17 14:40:36,561 - ***** Epoch: 40: Eval results *****
2025-04-17 14:40:36,561 -   train_loss = 5.620861530303955
2025-04-17 14:40:37,208 - ***** Epoch: 41: Eval results *****
2025-04-17 14:40:37,209 -   train_loss = 5.610734939575195
2025-04-17 14:40:37,856 - ***** Epoch: 42: Eval results *****
2025-04-17 14:40:37,856 -   train_loss = 5.610102653503418
2025-04-17 14:40:38,505 - ***** Epoch: 43: Eval results *****
2025-04-17 14:40:38,506 -   train_loss = 5.6072258949279785
2025-04-17 14:40:39,150 - ***** Epoch: 44: Eval results *****
2025-04-17 14:40:39,150 -   train_loss = 5.607826232910156
2025-04-17 14:40:39,800 - ***** Epoch: 45: Eval results *****
2025-04-17 14:40:39,800 -   train_loss = 5.594851016998291
2025-04-17 14:40:40,453 - ***** Epoch: 46: Eval results *****
2025-04-17 14:40:40,453 -   train_loss = 5.590458393096924
2025-04-17 14:40:41,258 - ***** Epoch: 47: Eval results *****
2025-04-17 14:40:41,258 -   train_loss = 5.57922887802124
2025-04-17 14:40:42,033 - ***** Epoch: 48: Eval results *****
2025-04-17 14:40:42,033 -   train_loss = 5.589338302612305
2025-04-17 14:40:42,816 - ***** Epoch: 49: Eval results *****
2025-04-17 14:40:42,816 -   train_loss = 5.567126750946045
2025-04-17 14:40:43,612 - ***** Epoch: 50: Eval results *****
2025-04-17 14:40:43,613 -   train_loss = 5.573012351989746
2025-04-17 14:40:44,387 - ***** Epoch: 51: Eval results *****
2025-04-17 14:40:44,388 -   train_loss = 5.553224563598633
2025-04-17 14:40:45,143 - ***** Epoch: 52: Eval results *****
2025-04-17 14:40:45,144 -   train_loss = 5.545780658721924
2025-04-17 14:40:45,977 - ***** Epoch: 53: Eval results *****
2025-04-17 14:40:45,978 -   train_loss = 5.557011127471924
2025-04-17 14:40:46,742 - ***** Epoch: 54: Eval results *****
2025-04-17 14:40:46,742 -   train_loss = 5.525883674621582
2025-04-17 14:40:47,421 - ***** Epoch: 55: Eval results *****
2025-04-17 14:40:47,421 -   train_loss = 5.535564422607422
2025-04-17 14:40:48,121 - ***** Epoch: 56: Eval results *****
2025-04-17 14:40:48,121 -   train_loss = 5.509378910064697
2025-04-17 14:40:48,773 - ***** Epoch: 57: Eval results *****
2025-04-17 14:40:48,773 -   train_loss = 5.5183587074279785
2025-04-17 14:40:49,436 - ***** Epoch: 58: Eval results *****
2025-04-17 14:40:49,436 -   train_loss = 5.508512496948242
2025-04-17 14:40:50,259 - ***** Epoch: 59: Eval results *****
2025-04-17 14:40:50,259 -   train_loss = 5.496630668640137
2025-04-17 14:40:50,918 - ***** Epoch: 60: Eval results *****
2025-04-17 14:40:50,918 -   train_loss = 5.490949630737305
2025-04-17 14:40:51,749 - ***** Epoch: 61: Eval results *****
2025-04-17 14:40:51,750 -   train_loss = 5.478060722351074
2025-04-17 14:40:52,428 - ***** Epoch: 62: Eval results *****
2025-04-17 14:40:52,428 -   train_loss = 5.469007968902588
2025-04-17 14:40:53,090 - ***** Epoch: 63: Eval results *****
2025-04-17 14:40:53,090 -   train_loss = 5.461328029632568
2025-04-17 14:40:53,762 - ***** Epoch: 64: Eval results *****
2025-04-17 14:40:53,763 -   train_loss = 5.440201759338379
2025-04-17 14:40:54,445 - ***** Epoch: 65: Eval results *****
2025-04-17 14:40:54,446 -   train_loss = 5.419175148010254
2025-04-17 14:40:55,328 - ***** Epoch: 66: Eval results *****
2025-04-17 14:40:55,328 -   train_loss = 5.4178786277771
2025-04-17 14:40:56,122 - ***** Epoch: 67: Eval results *****
2025-04-17 14:40:56,122 -   train_loss = 5.410615921020508
2025-04-17 14:40:56,982 - ***** Epoch: 68: Eval results *****
2025-04-17 14:40:56,982 -   train_loss = 5.410935878753662
2025-04-17 14:40:57,781 - ***** Epoch: 69: Eval results *****
2025-04-17 14:40:57,781 -   train_loss = 5.395938396453857
2025-04-17 14:40:58,563 - ***** Epoch: 70: Eval results *****
2025-04-17 14:40:58,563 -   train_loss = 5.396173000335693
2025-04-17 14:40:59,400 - ***** Epoch: 71: Eval results *****
2025-04-17 14:40:59,401 -   train_loss = 5.381355285644531
2025-04-17 14:41:00,078 - ***** Epoch: 72: Eval results *****
2025-04-17 14:41:00,078 -   train_loss = 5.366568088531494
2025-04-17 14:41:00,761 - ***** Epoch: 73: Eval results *****
2025-04-17 14:41:00,762 -   train_loss = 5.343966484069824
2025-04-17 14:41:01,446 - ***** Epoch: 74: Eval results *****
2025-04-17 14:41:01,446 -   train_loss = 5.357617378234863
2025-04-17 14:41:02,106 - ***** Epoch: 75: Eval results *****
2025-04-17 14:41:02,107 -   train_loss = 5.334014892578125
2025-04-17 14:41:02,770 - ***** Epoch: 76: Eval results *****
2025-04-17 14:41:02,770 -   train_loss = 5.350843906402588
2025-04-17 14:41:03,430 - ***** Epoch: 77: Eval results *****
2025-04-17 14:41:03,430 -   train_loss = 5.3346757888793945
2025-04-17 14:41:04,092 - ***** Epoch: 78: Eval results *****
2025-04-17 14:41:04,092 -   train_loss = 5.297370910644531
2025-04-17 14:41:04,760 - ***** Epoch: 79: Eval results *****
2025-04-17 14:41:04,761 -   train_loss = 5.293211460113525
2025-04-17 14:41:05,423 - ***** Epoch: 80: Eval results *****
2025-04-17 14:41:05,424 -   train_loss = 5.279118061065674
2025-04-17 14:41:06,098 - ***** Epoch: 81: Eval results *****
2025-04-17 14:41:06,098 -   train_loss = 5.294773578643799
2025-04-17 14:41:06,784 - ***** Epoch: 82: Eval results *****
2025-04-17 14:41:06,785 -   train_loss = 5.270832061767578
2025-04-17 14:41:07,584 - ***** Epoch: 83: Eval results *****
2025-04-17 14:41:07,585 -   train_loss = 5.26092004776001
2025-04-17 14:41:08,405 - ***** Epoch: 84: Eval results *****
2025-04-17 14:41:08,405 -   train_loss = 5.257217884063721
2025-04-17 14:41:09,190 - ***** Epoch: 85: Eval results *****
2025-04-17 14:41:09,190 -   train_loss = 5.246354103088379
2025-04-17 14:41:09,958 - ***** Epoch: 86: Eval results *****
2025-04-17 14:41:09,958 -   train_loss = 5.227024078369141
2025-04-17 14:41:10,761 - ***** Epoch: 87: Eval results *****
2025-04-17 14:41:10,761 -   train_loss = 5.245567321777344
2025-04-17 14:41:11,553 - ***** Epoch: 88: Eval results *****
2025-04-17 14:41:11,554 -   train_loss = 5.216480255126953
2025-04-17 14:41:12,310 - ***** Epoch: 89: Eval results *****
2025-04-17 14:41:12,310 -   train_loss = 5.195617198944092
2025-04-17 14:41:12,976 - ***** Epoch: 90: Eval results *****
2025-04-17 14:41:12,977 -   train_loss = 5.1814045906066895
2025-04-17 14:41:13,781 - ***** Epoch: 91: Eval results *****
2025-04-17 14:41:13,782 -   train_loss = 5.184701442718506
2025-04-17 14:41:14,438 - ***** Epoch: 92: Eval results *****
2025-04-17 14:41:14,439 -   train_loss = 5.178230285644531
2025-04-17 14:41:15,088 - ***** Epoch: 93: Eval results *****
2025-04-17 14:41:15,088 -   train_loss = 5.1554036140441895
2025-04-17 14:41:15,750 - ***** Epoch: 94: Eval results *****
2025-04-17 14:41:15,750 -   train_loss = 5.164320945739746
2025-04-17 14:41:16,529 - ***** Epoch: 95: Eval results *****
2025-04-17 14:41:16,530 -   train_loss = 5.1642303466796875
2025-04-17 14:41:17,181 - ***** Epoch: 96: Eval results *****
2025-04-17 14:41:17,181 -   train_loss = 5.129848480224609
2025-04-17 14:41:17,838 - ***** Epoch: 97: Eval results *****
2025-04-17 14:41:17,838 -   train_loss = 5.113727569580078
2025-04-17 14:41:18,477 - ***** Epoch: 98: Eval results *****
2025-04-17 14:41:18,478 -   train_loss = 5.13619327545166
2025-04-17 14:41:19,295 - ***** Epoch: 99: Eval results *****
2025-04-17 14:41:19,296 -   train_loss = 5.100593566894531
2025-04-17 14:41:19,950 - ***** Epoch: 100: Eval results *****
2025-04-17 14:41:19,950 -   train_loss = 5.073517322540283
2025-04-17 14:41:21,552 - Pre-training finished...
2025-04-17 14:41:21,927 - Freeze all parameters but the last layer for efficiency
2025-04-17 14:41:21,937 - Multimodal Intent Recognition begins...
2025-04-17 14:41:21,937 - Training begins...
2025-04-17 14:41:32,341 - Initializing centroids with K-means++...
2025-04-17 14:41:32,404 - K-means++ used 0.06 s
2025-04-17 14:42:06,990 - K-means used 0.03 s
2025-04-17 14:42:08,117 - ***** Epoch: 1 *****
2025-04-17 14:42:08,117 - Supervised Training Loss: 5.235520
2025-04-17 14:42:08,117 - Unsupervised Training Loss: 5.815630
2025-04-17 14:42:39,516 - K-means used 0.02 s
2025-04-17 14:42:40,640 - ***** Epoch: 2 *****
2025-04-17 14:42:40,641 - Supervised Training Loss: 4.012260
2025-04-17 14:42:40,641 - Unsupervised Training Loss: 5.790180
2025-04-17 14:43:12,938 - K-means used 0.02 s
2025-04-17 14:43:14,102 - ***** Epoch: 3 *****
2025-04-17 14:43:14,103 - Supervised Training Loss: 5.271450
2025-04-17 14:43:14,103 - Unsupervised Training Loss: 5.570310
2025-04-17 14:43:43,009 - K-means used 0.02 s
2025-04-17 14:43:44,191 - ***** Epoch: 4 *****
2025-04-17 14:43:44,191 - Supervised Training Loss: 4.952060
2025-04-17 14:43:44,191 - Unsupervised Training Loss: 5.576180
2025-04-17 14:44:12,112 - K-means used 0.03 s
2025-04-17 14:44:13,342 - ***** Epoch: 5 *****
2025-04-17 14:44:13,342 - Supervised Training Loss: 4.546760
2025-04-17 14:44:13,342 - Unsupervised Training Loss: 5.586770
2025-04-17 14:44:40,506 - K-means used 0.03 s
2025-04-17 14:44:41,717 - ***** Epoch: 6 *****
2025-04-17 14:44:41,718 - Supervised Training Loss: 4.897320
2025-04-17 14:44:41,718 - Unsupervised Training Loss: 5.386000
2025-04-17 14:45:08,970 - K-means used 0.02 s
2025-04-17 14:45:10,277 - ***** Epoch: 7 *****
2025-04-17 14:45:10,278 - Supervised Training Loss: 4.773240
2025-04-17 14:45:10,278 - Unsupervised Training Loss: 5.490770
2025-04-17 14:45:39,134 - K-means used 0.02 s
2025-04-17 14:45:40,433 - ***** Epoch: 8 *****
2025-04-17 14:45:40,433 - Supervised Training Loss: 4.623060
2025-04-17 14:45:40,433 - Unsupervised Training Loss: 5.542240
2025-04-17 14:46:09,220 - K-means used 0.02 s
2025-04-17 14:46:10,547 - ***** Epoch: 9 *****
2025-04-17 14:46:10,548 - Supervised Training Loss: 4.836390
2025-04-17 14:46:10,548 - Unsupervised Training Loss: 5.574760
2025-04-17 14:46:36,818 - K-means used 0.03 s
2025-04-17 14:46:38,208 - ***** Epoch: 10 *****
2025-04-17 14:46:38,208 - Supervised Training Loss: 4.743940
2025-04-17 14:46:38,208 - Unsupervised Training Loss: 5.423140
2025-04-17 14:47:05,852 - K-means used 0.03 s
2025-04-17 14:47:07,253 - ***** Epoch: 11 *****
2025-04-17 14:47:07,253 - Supervised Training Loss: 4.658530
2025-04-17 14:47:07,253 - Unsupervised Training Loss: 5.497120
2025-04-17 14:47:36,224 - K-means used 0.02 s
2025-04-17 14:47:37,776 - ***** Epoch: 12 *****
2025-04-17 14:47:37,776 - Supervised Training Loss: 4.791010
2025-04-17 14:47:37,776 - Unsupervised Training Loss: 5.563270
2025-04-17 14:48:03,654 - K-means used 0.02 s
2025-04-17 14:48:05,219 - ***** Epoch: 13 *****
2025-04-17 14:48:05,219 - Supervised Training Loss: 4.750910
2025-04-17 14:48:05,219 - Unsupervised Training Loss: 5.292120
2025-04-17 14:48:32,580 - K-means used 0.02 s
2025-04-17 14:48:34,148 - ***** Epoch: 14 *****
2025-04-17 14:48:34,148 - Supervised Training Loss: 4.707350
2025-04-17 14:48:34,148 - Unsupervised Training Loss: 5.408420
2025-04-17 14:49:01,063 - K-means used 0.02 s
2025-04-17 14:49:02,756 - ***** Epoch: 15 *****
2025-04-17 14:49:02,756 - Supervised Training Loss: 4.581690
2025-04-17 14:49:02,756 - Unsupervised Training Loss: 5.520160
2025-04-17 14:49:30,820 - K-means used 0.02 s
2025-04-17 14:49:32,560 - ***** Epoch: 16 *****
2025-04-17 14:49:32,560 - Supervised Training Loss: 4.782630
2025-04-17 14:49:32,560 - Unsupervised Training Loss: 4.948790
2025-04-17 14:50:00,498 - K-means used 0.02 s
2025-04-17 14:50:02,393 - ***** Epoch: 17 *****
2025-04-17 14:50:02,394 - Supervised Training Loss: 4.759770
2025-04-17 14:50:02,394 - Unsupervised Training Loss: 5.186630
2025-04-17 14:50:20,881 - Training is finished...
2025-04-17 14:50:20,881 - Testing begins...
2025-04-17 14:50:27,933 - ***** Test results *****
2025-04-17 14:50:27,934 -   ACC = 26.29
2025-04-17 14:50:27,934 -   ARI = 9.79
2025-04-17 14:50:27,934 -   NMI = 33.62
2025-04-17 14:50:27,935 -   fmi = 15.36
2025-04-17 14:50:27,935 - Testing is finished...
2025-04-17 14:50:27,935 - Multimodal intent recognition is finished...
2025-04-17 14:50:27,935 - Results are saved in results/results_umc_pre.csv
2025-04-17 14:50:29,060 - Freeze all parameters but the last layer for efficiency
2025-04-17 14:50:29,103 - Pre-training start...
2025-04-17 14:50:29,947 - ***** Epoch: 1: Eval results *****
2025-04-17 14:50:29,948 -   train_loss = 5.680638313293457
2025-04-17 14:50:30,778 - ***** Epoch: 2: Eval results *****
2025-04-17 14:50:30,778 -   train_loss = 5.677120208740234
2025-04-17 14:50:31,582 - ***** Epoch: 3: Eval results *****
2025-04-17 14:50:31,583 -   train_loss = 5.6743855476379395
2025-04-17 14:50:32,289 - ***** Epoch: 4: Eval results *****
2025-04-17 14:50:32,289 -   train_loss = 5.678496837615967
2025-04-17 14:50:33,171 - ***** Epoch: 5: Eval results *****
2025-04-17 14:50:33,171 -   train_loss = 5.67100191116333
2025-04-17 14:50:34,040 - ***** Epoch: 6: Eval results *****
2025-04-17 14:50:34,040 -   train_loss = 5.675856590270996
2025-04-17 14:50:34,866 - ***** Epoch: 7: Eval results *****
2025-04-17 14:50:34,867 -   train_loss = 5.678028583526611
2025-04-17 14:50:35,705 - ***** Epoch: 8: Eval results *****
2025-04-17 14:50:35,705 -   train_loss = 5.682135581970215
2025-04-17 14:50:36,537 - ***** Epoch: 9: Eval results *****
2025-04-17 14:50:36,537 -   train_loss = 5.6821465492248535
2025-04-17 14:50:37,391 - ***** Epoch: 10: Eval results *****
2025-04-17 14:50:37,392 -   train_loss = 5.668406963348389
2025-04-17 14:50:38,221 - ***** Epoch: 11: Eval results *****
2025-04-17 14:50:38,222 -   train_loss = 5.671123504638672
2025-04-17 14:50:39,048 - ***** Epoch: 12: Eval results *****
2025-04-17 14:50:39,048 -   train_loss = 5.664889335632324
2025-04-17 14:50:39,851 - ***** Epoch: 13: Eval results *****
2025-04-17 14:50:39,851 -   train_loss = 5.674590587615967
2025-04-17 14:50:40,554 - ***** Epoch: 14: Eval results *****
2025-04-17 14:50:40,554 -   train_loss = 5.671926498413086
2025-04-17 14:50:41,255 - ***** Epoch: 15: Eval results *****
2025-04-17 14:50:41,255 -   train_loss = 5.66957426071167
2025-04-17 14:50:42,129 - ***** Epoch: 16: Eval results *****
2025-04-17 14:50:42,129 -   train_loss = 5.673149585723877
2025-04-17 14:50:42,932 - ***** Epoch: 17: Eval results *****
2025-04-17 14:50:42,932 -   train_loss = 5.67064094543457
2025-04-17 14:50:43,777 - ***** Epoch: 18: Eval results *****
2025-04-17 14:50:43,777 -   train_loss = 5.664865493774414
2025-04-17 14:50:44,629 - ***** Epoch: 19: Eval results *****
2025-04-17 14:50:44,629 -   train_loss = 5.6607160568237305
2025-04-17 14:50:45,437 - ***** Epoch: 20: Eval results *****
2025-04-17 14:50:45,437 -   train_loss = 5.665711879730225
2025-04-17 14:50:46,128 - ***** Epoch: 21: Eval results *****
2025-04-17 14:50:46,128 -   train_loss = 5.661871910095215
2025-04-17 14:50:46,952 - ***** Epoch: 22: Eval results *****
2025-04-17 14:50:46,952 -   train_loss = 5.6609697341918945
2025-04-17 14:50:47,819 - ***** Epoch: 23: Eval results *****
2025-04-17 14:50:47,819 -   train_loss = 5.6618266105651855
2025-04-17 14:50:48,651 - ***** Epoch: 24: Eval results *****
2025-04-17 14:50:48,651 -   train_loss = 5.661746978759766
2025-04-17 14:50:49,441 - ***** Epoch: 25: Eval results *****
2025-04-17 14:50:49,441 -   train_loss = 5.661101818084717
2025-04-17 14:50:50,151 - ***** Epoch: 26: Eval results *****
2025-04-17 14:50:50,152 -   train_loss = 5.6629815101623535
2025-04-17 14:50:50,995 - ***** Epoch: 27: Eval results *****
2025-04-17 14:50:50,995 -   train_loss = 5.64888334274292
2025-04-17 14:50:51,829 - ***** Epoch: 28: Eval results *****
2025-04-17 14:50:51,830 -   train_loss = 5.656088829040527
2025-04-17 14:50:52,621 - ***** Epoch: 29: Eval results *****
2025-04-17 14:50:52,622 -   train_loss = 5.651358604431152
2025-04-17 14:50:53,486 - ***** Epoch: 30: Eval results *****
2025-04-17 14:50:53,486 -   train_loss = 5.6557087898254395
2025-04-17 14:50:54,307 - ***** Epoch: 31: Eval results *****
2025-04-17 14:50:54,307 -   train_loss = 5.6506195068359375
2025-04-17 14:50:55,110 - ***** Epoch: 32: Eval results *****
2025-04-17 14:50:55,110 -   train_loss = 5.6473894119262695
2025-04-17 14:50:55,995 - ***** Epoch: 33: Eval results *****
2025-04-17 14:50:55,995 -   train_loss = 5.638733386993408
2025-04-17 14:50:56,816 - ***** Epoch: 34: Eval results *****
2025-04-17 14:50:56,817 -   train_loss = 5.636129379272461
2025-04-17 14:50:57,640 - ***** Epoch: 35: Eval results *****
2025-04-17 14:50:57,640 -   train_loss = 5.6189727783203125
2025-04-17 14:50:58,458 - ***** Epoch: 36: Eval results *****
2025-04-17 14:50:58,458 -   train_loss = 5.6276984214782715
2025-04-17 14:50:59,278 - ***** Epoch: 37: Eval results *****
2025-04-17 14:50:59,278 -   train_loss = 5.622107982635498
2025-04-17 14:51:00,098 - ***** Epoch: 38: Eval results *****
2025-04-17 14:51:00,098 -   train_loss = 5.615401268005371
2025-04-17 14:51:00,929 - ***** Epoch: 39: Eval results *****
2025-04-17 14:51:00,929 -   train_loss = 5.625314712524414
2025-04-17 14:51:01,753 - ***** Epoch: 40: Eval results *****
2025-04-17 14:51:01,753 -   train_loss = 5.617980480194092
2025-04-17 14:51:02,542 - ***** Epoch: 41: Eval results *****
2025-04-17 14:51:02,542 -   train_loss = 5.621326446533203
2025-04-17 14:51:03,233 - ***** Epoch: 42: Eval results *****
2025-04-17 14:51:03,233 -   train_loss = 5.602060794830322
2025-04-17 14:51:03,929 - ***** Epoch: 43: Eval results *****
2025-04-17 14:51:03,930 -   train_loss = 5.594943523406982
2025-04-17 14:51:04,620 - ***** Epoch: 44: Eval results *****
2025-04-17 14:51:04,620 -   train_loss = 5.602564334869385
2025-04-17 14:51:05,481 - ***** Epoch: 45: Eval results *****
2025-04-17 14:51:05,481 -   train_loss = 5.579536437988281
2025-04-17 14:51:06,273 - ***** Epoch: 46: Eval results *****
2025-04-17 14:51:06,273 -   train_loss = 5.58556604385376
2025-04-17 14:51:06,966 - ***** Epoch: 47: Eval results *****
2025-04-17 14:51:06,966 -   train_loss = 5.580099105834961
2025-04-17 14:51:07,649 - ***** Epoch: 48: Eval results *****
2025-04-17 14:51:07,649 -   train_loss = 5.573632717132568
2025-04-17 14:51:08,345 - ***** Epoch: 49: Eval results *****
2025-04-17 14:51:08,345 -   train_loss = 5.56166410446167
2025-04-17 14:51:09,029 - ***** Epoch: 50: Eval results *****
2025-04-17 14:51:09,030 -   train_loss = 5.576808452606201
2025-04-17 14:51:09,718 - ***** Epoch: 51: Eval results *****
2025-04-17 14:51:09,718 -   train_loss = 5.553400039672852
2025-04-17 14:51:10,404 - ***** Epoch: 52: Eval results *****
2025-04-17 14:51:10,405 -   train_loss = 5.551400184631348
2025-04-17 14:51:11,089 - ***** Epoch: 53: Eval results *****
2025-04-17 14:51:11,089 -   train_loss = 5.55891752243042
2025-04-17 14:51:11,774 - ***** Epoch: 54: Eval results *****
2025-04-17 14:51:11,774 -   train_loss = 5.524528980255127
2025-04-17 14:51:12,456 - ***** Epoch: 55: Eval results *****
2025-04-17 14:51:12,456 -   train_loss = 5.5308518409729
2025-04-17 14:51:13,137 - ***** Epoch: 56: Eval results *****
2025-04-17 14:51:13,137 -   train_loss = 5.521805763244629
2025-04-17 14:51:13,821 - ***** Epoch: 57: Eval results *****
2025-04-17 14:51:13,822 -   train_loss = 5.529664039611816
2025-04-17 14:51:14,506 - ***** Epoch: 58: Eval results *****
2025-04-17 14:51:14,507 -   train_loss = 5.517563819885254
2025-04-17 14:51:15,189 - ***** Epoch: 59: Eval results *****
2025-04-17 14:51:15,189 -   train_loss = 5.504945278167725
2025-04-17 14:51:15,878 - ***** Epoch: 60: Eval results *****
2025-04-17 14:51:15,878 -   train_loss = 5.504542827606201
2025-04-17 14:51:16,741 - ***** Epoch: 61: Eval results *****
2025-04-17 14:51:16,741 -   train_loss = 5.4940996170043945
2025-04-17 14:51:17,555 - ***** Epoch: 62: Eval results *****
2025-04-17 14:51:17,556 -   train_loss = 5.481814861297607
2025-04-17 14:51:18,338 - ***** Epoch: 63: Eval results *****
2025-04-17 14:51:18,339 -   train_loss = 5.480257511138916
2025-04-17 14:51:19,213 - ***** Epoch: 64: Eval results *****
2025-04-17 14:51:19,213 -   train_loss = 5.46413516998291
2025-04-17 14:51:20,046 - ***** Epoch: 65: Eval results *****
2025-04-17 14:51:20,046 -   train_loss = 5.446689128875732
2025-04-17 14:51:20,858 - ***** Epoch: 66: Eval results *****
2025-04-17 14:51:20,859 -   train_loss = 5.42401123046875
2025-04-17 14:51:21,736 - ***** Epoch: 67: Eval results *****
2025-04-17 14:51:21,736 -   train_loss = 5.445692539215088
2025-04-17 14:51:22,428 - ***** Epoch: 68: Eval results *****
2025-04-17 14:51:22,428 -   train_loss = 5.422534942626953
2025-04-17 14:51:23,125 - ***** Epoch: 69: Eval results *****
2025-04-17 14:51:23,125 -   train_loss = 5.4246134757995605
2025-04-17 14:51:23,812 - ***** Epoch: 70: Eval results *****
2025-04-17 14:51:23,812 -   train_loss = 5.397860527038574
2025-04-17 14:51:24,661 - ***** Epoch: 71: Eval results *****
2025-04-17 14:51:24,661 -   train_loss = 5.41298770904541
2025-04-17 14:51:25,541 - ***** Epoch: 72: Eval results *****
2025-04-17 14:51:25,542 -   train_loss = 5.387081146240234
2025-04-17 14:51:26,390 - ***** Epoch: 73: Eval results *****
2025-04-17 14:51:26,390 -   train_loss = 5.381616115570068
2025-04-17 14:51:27,205 - ***** Epoch: 74: Eval results *****
2025-04-17 14:51:27,205 -   train_loss = 5.381402492523193
2025-04-17 14:51:28,018 - ***** Epoch: 75: Eval results *****
2025-04-17 14:51:28,019 -   train_loss = 5.364797592163086
2025-04-17 14:51:28,862 - ***** Epoch: 76: Eval results *****
2025-04-17 14:51:28,862 -   train_loss = 5.372869968414307
2025-04-17 14:51:29,659 - ***** Epoch: 77: Eval results *****
2025-04-17 14:51:29,659 -   train_loss = 5.357400894165039
2025-04-17 14:51:30,365 - ***** Epoch: 78: Eval results *****
2025-04-17 14:51:30,365 -   train_loss = 5.34430456161499
2025-04-17 14:51:31,217 - ***** Epoch: 79: Eval results *****
2025-04-17 14:51:31,217 -   train_loss = 5.34301233291626
2025-04-17 14:51:31,913 - ***** Epoch: 80: Eval results *****
2025-04-17 14:51:31,914 -   train_loss = 5.3317952156066895
2025-04-17 14:51:32,789 - ***** Epoch: 81: Eval results *****
2025-04-17 14:51:32,790 -   train_loss = 5.344175815582275
2025-04-17 14:51:33,584 - ***** Epoch: 82: Eval results *****
2025-04-17 14:51:33,584 -   train_loss = 5.311824321746826
2025-04-17 14:51:34,458 - ***** Epoch: 83: Eval results *****
2025-04-17 14:51:34,458 -   train_loss = 5.323263645172119
2025-04-17 14:51:35,287 - ***** Epoch: 84: Eval results *****
2025-04-17 14:51:35,288 -   train_loss = 5.300314426422119
2025-04-17 14:51:36,095 - ***** Epoch: 85: Eval results *****
2025-04-17 14:51:36,096 -   train_loss = 5.3017683029174805
2025-04-17 14:51:36,781 - ***** Epoch: 86: Eval results *****
2025-04-17 14:51:36,781 -   train_loss = 5.299839019775391
2025-04-17 14:51:37,477 - ***** Epoch: 87: Eval results *****
2025-04-17 14:51:37,477 -   train_loss = 5.270263671875
2025-04-17 14:51:38,165 - ***** Epoch: 88: Eval results *****
2025-04-17 14:51:38,165 -   train_loss = 5.275022506713867
2025-04-17 14:51:39,006 - ***** Epoch: 89: Eval results *****
2025-04-17 14:51:39,007 -   train_loss = 5.275966644287109
2025-04-17 14:51:39,829 - ***** Epoch: 90: Eval results *****
2025-04-17 14:51:39,829 -   train_loss = 5.244873523712158
2025-04-17 14:51:40,654 - ***** Epoch: 91: Eval results *****
2025-04-17 14:51:40,654 -   train_loss = 5.24537992477417
2025-04-17 14:51:41,471 - ***** Epoch: 92: Eval results *****
2025-04-17 14:51:41,471 -   train_loss = 5.236313343048096
2025-04-17 14:51:42,312 - ***** Epoch: 93: Eval results *****
2025-04-17 14:51:42,312 -   train_loss = 5.230067253112793
2025-04-17 14:51:43,150 - ***** Epoch: 94: Eval results *****
2025-04-17 14:51:43,150 -   train_loss = 5.2303690910339355
2025-04-17 14:51:43,948 - ***** Epoch: 95: Eval results *****
2025-04-17 14:51:43,949 -   train_loss = 5.216726303100586
2025-04-17 14:51:44,834 - ***** Epoch: 96: Eval results *****
2025-04-17 14:51:44,834 -   train_loss = 5.20155668258667
2025-04-17 14:51:45,634 - ***** Epoch: 97: Eval results *****
2025-04-17 14:51:45,634 -   train_loss = 5.209664821624756
2025-04-17 14:51:46,320 - ***** Epoch: 98: Eval results *****
2025-04-17 14:51:46,320 -   train_loss = 5.191969871520996
2025-04-17 14:51:47,023 - ***** Epoch: 99: Eval results *****
2025-04-17 14:51:47,023 -   train_loss = 5.206172943115234
2025-04-17 14:51:47,866 - ***** Epoch: 100: Eval results *****
2025-04-17 14:51:47,866 -   train_loss = 5.200983047485352
2025-04-17 14:51:49,575 - Pre-training finished...
2025-04-17 14:51:49,958 - Freeze all parameters but the last layer for efficiency
2025-04-17 14:51:49,967 - Multimodal Intent Recognition begins...
2025-04-17 14:51:49,968 - Training begins...
2025-04-17 14:52:01,030 - Initializing centroids with K-means++...
2025-04-17 14:52:01,093 - K-means++ used 0.06 s
2025-04-17 14:52:31,882 - K-means used 0.03 s
2025-04-17 14:52:32,918 - ***** Epoch: 1 *****
2025-04-17 14:52:32,918 - Supervised Training Loss: 5.222550
2025-04-17 14:52:32,919 - Unsupervised Training Loss: 5.819600
2025-04-17 14:52:59,716 - K-means used 0.02 s
2025-04-17 14:53:00,897 - ***** Epoch: 2 *****
2025-04-17 14:53:00,897 - Supervised Training Loss: 5.674810
2025-04-17 14:53:00,897 - Unsupervised Training Loss: 5.805360
2025-04-17 14:53:28,219 - K-means used 0.04 s
2025-04-17 14:53:29,601 - ***** Epoch: 3 *****
2025-04-17 14:53:29,602 - Supervised Training Loss: 5.314940
2025-04-17 14:53:29,602 - Unsupervised Training Loss: 5.573000
2025-04-17 14:53:59,382 - K-means used 0.03 s
2025-04-17 14:54:01,312 - ***** Epoch: 4 *****
2025-04-17 14:54:01,312 - Supervised Training Loss: 4.891110
2025-04-17 14:54:01,312 - Unsupervised Training Loss: 5.578110
2025-04-17 14:54:32,556 - K-means used 0.02 s
2025-04-17 14:54:33,789 - ***** Epoch: 5 *****
2025-04-17 14:54:33,789 - Supervised Training Loss: 4.486480
2025-04-17 14:54:33,790 - Unsupervised Training Loss: 5.596120
2025-04-17 14:55:03,001 - K-means used 0.04 s
2025-04-17 14:55:04,273 - ***** Epoch: 6 *****
2025-04-17 14:55:04,273 - Supervised Training Loss: 4.856660
2025-04-17 14:55:04,273 - Unsupervised Training Loss: 5.370610
2025-04-17 14:55:35,702 - K-means used 0.02 s
2025-04-17 14:55:37,140 - ***** Epoch: 7 *****
2025-04-17 14:55:37,140 - Supervised Training Loss: 4.741350
2025-04-17 14:55:37,140 - Unsupervised Training Loss: 5.479030
2025-04-17 14:56:09,637 - K-means used 0.01 s
2025-04-17 14:56:10,931 - ***** Epoch: 8 *****
2025-04-17 14:56:10,932 - Supervised Training Loss: 4.575330
2025-04-17 14:56:10,932 - Unsupervised Training Loss: 5.531510
2025-04-17 14:56:41,340 - K-means used 0.02 s
2025-04-17 14:56:42,768 - ***** Epoch: 9 *****
2025-04-17 14:56:42,768 - Supervised Training Loss: 4.795080
2025-04-17 14:56:42,768 - Unsupervised Training Loss: 5.576800
2025-04-17 14:57:10,583 - K-means used 0.03 s
2025-04-17 14:57:12,020 - ***** Epoch: 10 *****
2025-04-17 14:57:12,020 - Supervised Training Loss: 4.728380
2025-04-17 14:57:12,020 - Unsupervised Training Loss: 5.419050
2025-04-17 14:57:41,929 - K-means used 0.02 s
2025-04-17 14:57:43,466 - ***** Epoch: 11 *****
2025-04-17 14:57:43,466 - Supervised Training Loss: 4.639190
2025-04-17 14:57:43,466 - Unsupervised Training Loss: 5.496370
2025-04-17 14:58:15,901 - K-means used 0.02 s
2025-04-17 14:58:17,504 - ***** Epoch: 12 *****
2025-04-17 14:58:17,504 - Supervised Training Loss: 4.774290
2025-04-17 14:58:17,504 - Unsupervised Training Loss: 5.558150
2025-04-17 14:58:48,663 - K-means used 0.02 s
2025-04-17 14:58:50,356 - ***** Epoch: 13 *****
2025-04-17 14:58:50,356 - Supervised Training Loss: 4.736740
2025-04-17 14:58:50,356 - Unsupervised Training Loss: 5.287250
2025-04-17 14:59:16,633 - K-means used 0.02 s
2025-04-17 14:59:18,256 - ***** Epoch: 14 *****
2025-04-17 14:59:18,257 - Supervised Training Loss: 4.688590
2025-04-17 14:59:18,257 - Unsupervised Training Loss: 5.412090
2025-04-17 14:59:44,122 - K-means used 0.01 s
2025-04-17 14:59:45,928 - ***** Epoch: 15 *****
2025-04-17 14:59:45,929 - Supervised Training Loss: 4.546880
2025-04-17 14:59:45,929 - Unsupervised Training Loss: 5.518150
2025-04-17 15:00:13,196 - K-means used 0.02 s
2025-04-17 15:00:14,949 - ***** Epoch: 16 *****
2025-04-17 15:00:14,949 - Supervised Training Loss: 4.766890
2025-04-17 15:00:14,949 - Unsupervised Training Loss: 4.988390
2025-04-17 15:00:44,016 - K-means used 0.02 s
2025-04-17 15:00:45,966 - ***** Epoch: 17 *****
2025-04-17 15:00:45,967 - Supervised Training Loss: 4.736800
2025-04-17 15:00:45,967 - Unsupervised Training Loss: 5.206490
2025-04-17 15:01:05,257 - Training is finished...
2025-04-17 15:01:05,258 - Testing begins...
2025-04-17 15:01:12,800 - ***** Test results *****
2025-04-17 15:01:12,801 -   ACC = 22.47
2025-04-17 15:01:12,801 -   ARI = 7.72
2025-04-17 15:01:12,801 -   NMI = 31.23
2025-04-17 15:01:12,801 -   fmi = 13.76
2025-04-17 15:01:12,801 - Testing is finished...
2025-04-17 15:01:12,801 - Multimodal intent recognition is finished...
2025-04-17 15:01:12,801 - Results are saved in results/results_umc_pre.csv
