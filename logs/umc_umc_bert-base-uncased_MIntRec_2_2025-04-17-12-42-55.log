2025-04-17 12:42:55,463 - 【无监督】进入了无监督的设定中, 加载数据集
2025-04-17 12:42:55,463 - data preparation...
2025-04-17 12:43:04,439 - Number of train samples = 1779
2025-04-17 12:43:04,440 - Number of testing samples = 445
2025-04-17 12:43:04,440 - data preparation...
2025-04-17 12:43:06,764 - num_train_examples = 1779
2025-04-17 12:43:06,765 - ============================== Params ==============================
2025-04-17 12:43:06,765 - logger_name: umc_umc_bert-base-uncased_MIntRec_2
2025-04-17 12:43:06,765 - dataset: MIntRec
2025-04-17 12:43:06,765 - multimodal_method: umc
2025-04-17 12:43:06,765 - method: umc
2025-04-17 12:43:06,765 - setting: unsupervised
2025-04-17 12:43:06,765 - merge_dev: True
2025-04-17 12:43:06,765 - text_backbone: bert-base-uncased
2025-04-17 12:43:06,765 - seed: 2
2025-04-17 12:43:06,765 - num_workers: 16
2025-04-17 12:43:06,765 - log_id: umc_umc_bert-base-uncased_MIntRec_2_2025-04-17-12-42-55
2025-04-17 12:43:06,765 - gpu_id: 1
2025-04-17 12:43:06,765 - data_path: /root/autodl-tmp/home/Share/Dataset/LZH
2025-04-17 12:43:06,765 - train: True
2025-04-17 12:43:06,765 - tune: True
2025-04-17 12:43:06,765 - save_model: True
2025-04-17 12:43:06,765 - save_results: True
2025-04-17 12:43:06,765 - log_path: logs
2025-04-17 12:43:06,765 - cache_path: cache
2025-04-17 12:43:06,765 - video_data_path: video_data
2025-04-17 12:43:06,765 - audio_data_path: audio_data
2025-04-17 12:43:06,765 - video_feats_path: swin_feats.pkl
2025-04-17 12:43:06,765 - audio_feats_path: wavlm_feats.pkl
2025-04-17 12:43:06,766 - results_path: results
2025-04-17 12:43:06,766 - output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/SMC/outputs_test2/MIntRec
2025-04-17 12:43:06,766 - model_path: models
2025-04-17 12:43:06,766 - config_file_name: umc_MIntRec
2025-04-17 12:43:06,766 - results_file_name: results_umc_pre.csv
2025-04-17 12:43:06,766 - text_pretrained_model: uncased_L-12_H-768_A-12
2025-04-17 12:43:06,766 - pretrained_bert_model: uncased_L-12_H-768_A-12
2025-04-17 12:43:06,766 - pretrain_batch_size: 128
2025-04-17 12:43:06,766 - train_batch_size: 128
2025-04-17 12:43:06,766 - eval_batch_size: 128
2025-04-17 12:43:06,766 - test_batch_size: 128
2025-04-17 12:43:06,766 - num_pretrain_epochs: 100
2025-04-17 12:43:06,766 - num_train_epochs: 100
2025-04-17 12:43:06,766 - pretrain: [True]
2025-04-17 12:43:06,766 - aligned_method: ctc
2025-04-17 12:43:06,766 - need_aligned: False
2025-04-17 12:43:06,766 - freeze_pretrain_bert_parameters: [True]
2025-04-17 12:43:06,766 - freeze_train_bert_parameters: [True]
2025-04-17 12:43:06,766 - pretrain_temperature: [0.1, 0.2, 0.4, 0.5]
2025-04-17 12:43:06,766 - train_temperature_sup: [0.5]
2025-04-17 12:43:06,766 - train_temperature_unsup: [2]
2025-04-17 12:43:06,766 - activation: tanh
2025-04-17 12:43:06,766 - lr_pre: [1e-05]
2025-04-17 12:43:06,766 - lr: [5e-05]
2025-04-17 12:43:06,766 - delta: [0.05]
2025-04-17 12:43:06,766 - thres: [0.1]
2025-04-17 12:43:06,766 - topk: [5]
2025-04-17 12:43:06,766 - weight_decay: 0.01
2025-04-17 12:43:06,767 - feat_dim: 768
2025-04-17 12:43:06,767 - hidden_size: 768
2025-04-17 12:43:06,767 - grad_clip: -1.0
2025-04-17 12:43:06,767 - warmup_proportion: [0.1]
2025-04-17 12:43:06,767 - hidden_dropout_prob: 0.1
2025-04-17 12:43:06,767 - weight: 1.0
2025-04-17 12:43:06,767 - loss_mode: rdrop
2025-04-17 12:43:06,767 - base_dim: 256
2025-04-17 12:43:06,767 - nheads: 8
2025-04-17 12:43:06,767 - attn_dropout: 0.1
2025-04-17 12:43:06,767 - relu_dropout: 0.1
2025-04-17 12:43:06,767 - embed_dropout: 0.01
2025-04-17 12:43:06,767 - res_dropout: 0.0
2025-04-17 12:43:06,767 - attn_mask: True
2025-04-17 12:43:06,767 - encoder_layers_1: 1
2025-04-17 12:43:06,767 - fusion_act: tanh
2025-04-17 12:43:06,767 - pred_output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/SMC/outputs_test2/MIntRec/umc_umc_MIntRec_bert-base-uncased_2
2025-04-17 12:43:06,768 - model_output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/SMC/outputs_test2/MIntRec/umc_umc_MIntRec_bert-base-uncased_2/models
2025-04-17 12:43:06,768 - text_seq_len: 30
2025-04-17 12:43:06,768 - video_seq_len: 230
2025-04-17 12:43:06,768 - audio_seq_len: 480
2025-04-17 12:43:06,768 - text_feat_dim: 768
2025-04-17 12:43:06,768 - video_feat_dim: 1024
2025-04-17 12:43:06,768 - audio_feat_dim: 768
2025-04-17 12:43:06,768 - num_labels: 20
2025-04-17 12:43:06,768 - num_train_examples: 1779
2025-04-17 12:43:06,768 - ============================== End Params ==============================
2025-04-17 12:43:07,955 - Freeze all parameters but the last layer for efficiency
2025-04-17 12:43:07,989 - Pre-training start...
2025-04-17 12:43:24,520 - ***** Epoch: 1: Eval results *****
2025-04-17 12:43:24,521 -   train_loss = 5.960222380501883
2025-04-17 12:43:41,213 - ***** Epoch: 2: Eval results *****
2025-04-17 12:43:41,214 -   train_loss = 5.955563613346645
2025-04-17 12:43:57,736 - ***** Epoch: 3: Eval results *****
2025-04-17 12:43:57,736 -   train_loss = 5.947875772203718
2025-04-17 12:44:14,922 - ***** Epoch: 4: Eval results *****
2025-04-17 12:44:14,923 -   train_loss = 5.9364684990474155
2025-04-17 12:44:32,123 - ***** Epoch: 5: Eval results *****
2025-04-17 12:44:32,124 -   train_loss = 5.9259121758597235
2025-04-17 12:44:49,486 - ***** Epoch: 6: Eval results *****
2025-04-17 12:44:49,486 -   train_loss = 5.906855923788888
2025-04-17 12:45:06,788 - ***** Epoch: 7: Eval results *****
2025-04-17 12:45:06,789 -   train_loss = 5.871513264519828
2025-04-17 12:45:23,581 - ***** Epoch: 8: Eval results *****
2025-04-17 12:45:23,582 -   train_loss = 5.7943223885127475
2025-04-17 12:45:40,153 - ***** Epoch: 9: Eval results *****
2025-04-17 12:45:40,153 -   train_loss = 5.613539287022182
2025-04-17 12:45:56,882 - ***** Epoch: 10: Eval results *****
2025-04-17 12:45:56,882 -   train_loss = 5.200139454432896
2025-04-17 12:46:14,100 - ***** Epoch: 11: Eval results *****
2025-04-17 12:46:14,100 -   train_loss = 4.66622839655195
2025-04-17 12:46:31,054 - ***** Epoch: 12: Eval results *****
2025-04-17 12:46:31,055 -   train_loss = 4.1977622509002686
2025-04-17 12:46:48,446 - ***** Epoch: 13: Eval results *****
2025-04-17 12:46:48,446 -   train_loss = 3.8100816011428833
2025-04-17 12:47:05,273 - ***** Epoch: 14: Eval results *****
2025-04-17 12:47:05,274 -   train_loss = 3.499461599758693
2025-04-17 12:47:21,936 - ***** Epoch: 15: Eval results *****
2025-04-17 12:47:21,936 -   train_loss = 3.25012629372733
2025-04-17 12:47:39,819 - ***** Epoch: 16: Eval results *****
2025-04-17 12:47:39,819 -   train_loss = 3.0527684688568115
2025-04-17 12:47:56,899 - ***** Epoch: 17: Eval results *****
2025-04-17 12:47:56,899 -   train_loss = 2.8787548542022705
2025-04-17 12:48:13,910 - ***** Epoch: 18: Eval results *****
2025-04-17 12:48:13,910 -   train_loss = 2.728548663003104
2025-04-17 12:48:30,190 - ***** Epoch: 19: Eval results *****
2025-04-17 12:48:30,191 -   train_loss = 2.6255264452525546
2025-04-17 12:48:47,393 - ***** Epoch: 20: Eval results *****
2025-04-17 12:48:47,394 -   train_loss = 2.5309856278555736
2025-04-17 12:49:05,076 - ***** Epoch: 21: Eval results *****
2025-04-17 12:49:05,076 -   train_loss = 2.4248629297528947
2025-04-17 12:49:21,980 - ***** Epoch: 22: Eval results *****
2025-04-17 12:49:21,980 -   train_loss = 2.3437873465674266
2025-04-17 12:49:39,502 - ***** Epoch: 23: Eval results *****
2025-04-17 12:49:39,502 -   train_loss = 2.3067284481866017
2025-04-17 12:49:56,489 - ***** Epoch: 24: Eval results *****
2025-04-17 12:49:56,490 -   train_loss = 2.2271834441593716
2025-04-17 12:50:13,500 - ***** Epoch: 25: Eval results *****
2025-04-17 12:50:13,500 -   train_loss = 2.1715394258499146
2025-04-17 12:50:30,657 - ***** Epoch: 26: Eval results *****
2025-04-17 12:50:30,657 -   train_loss = 2.1251277582986012
2025-04-17 12:50:48,240 - ***** Epoch: 27: Eval results *****
2025-04-17 12:50:48,240 -   train_loss = 2.08181585584368
2025-04-17 12:51:05,978 - ***** Epoch: 28: Eval results *****
2025-04-17 12:51:05,978 -   train_loss = 2.0322450739996776
2025-04-17 12:51:23,004 - ***** Epoch: 29: Eval results *****
2025-04-17 12:51:23,005 -   train_loss = 2.0037753922598704
2025-04-17 12:51:40,289 - ***** Epoch: 30: Eval results *****
2025-04-17 12:51:40,289 -   train_loss = 1.990344558443342
2025-04-17 12:51:57,551 - ***** Epoch: 31: Eval results *****
2025-04-17 12:51:57,551 -   train_loss = 1.9455304827008928
2025-04-17 12:52:14,393 - ***** Epoch: 32: Eval results *****
2025-04-17 12:52:14,393 -   train_loss = 1.9125711747578211
2025-04-17 12:52:31,689 - ***** Epoch: 33: Eval results *****
2025-04-17 12:52:31,689 -   train_loss = 1.8985932128770011
2025-04-17 12:52:47,997 - ***** Epoch: 34: Eval results *****
2025-04-17 12:52:47,997 -   train_loss = 1.877917570727212
2025-04-17 12:53:04,426 - ***** Epoch: 35: Eval results *****
2025-04-17 12:53:04,426 -   train_loss = 1.845435185091836
2025-04-17 12:53:21,243 - ***** Epoch: 36: Eval results *****
2025-04-17 12:53:21,243 -   train_loss = 1.8495239870888847
2025-04-17 12:53:38,252 - ***** Epoch: 37: Eval results *****
2025-04-17 12:53:38,253 -   train_loss = 1.8217476606369019
2025-04-17 12:53:55,130 - ***** Epoch: 38: Eval results *****
2025-04-17 12:53:55,130 -   train_loss = 1.7958612186568124
2025-04-17 12:54:12,344 - ***** Epoch: 39: Eval results *****
2025-04-17 12:54:12,344 -   train_loss = 1.7804962226322718
2025-04-17 12:54:29,532 - ***** Epoch: 40: Eval results *****
2025-04-17 12:54:29,532 -   train_loss = 1.7674791387149267
2025-04-17 12:54:46,265 - ***** Epoch: 41: Eval results *****
2025-04-17 12:54:46,265 -   train_loss = 1.7458167842456274
2025-04-17 12:55:03,136 - ***** Epoch: 42: Eval results *****
2025-04-17 12:55:03,136 -   train_loss = 1.7402137943676539
2025-04-17 12:55:20,171 - ***** Epoch: 43: Eval results *****
2025-04-17 12:55:20,172 -   train_loss = 1.7334567393575395
2025-04-17 12:55:37,798 - ***** Epoch: 44: Eval results *****
2025-04-17 12:55:37,799 -   train_loss = 1.7130620394434248
2025-04-17 12:55:57,530 - ***** Epoch: 45: Eval results *****
2025-04-17 12:55:57,530 -   train_loss = 1.6952350735664368
2025-04-17 12:56:16,984 - ***** Epoch: 46: Eval results *****
2025-04-17 12:56:16,984 -   train_loss = 1.6793787138802665
2025-04-17 12:56:37,470 - ***** Epoch: 47: Eval results *****
2025-04-17 12:56:37,471 -   train_loss = 1.6747444442340307
2025-04-17 12:56:56,490 - ***** Epoch: 48: Eval results *****
2025-04-17 12:56:56,490 -   train_loss = 1.672433512551444
2025-04-17 12:57:14,530 - ***** Epoch: 49: Eval results *****
2025-04-17 12:57:14,530 -   train_loss = 1.6525301933288574
2025-04-17 12:57:32,334 - ***** Epoch: 50: Eval results *****
2025-04-17 12:57:32,334 -   train_loss = 1.635344581944602
2025-04-17 12:57:49,314 - ***** Epoch: 51: Eval results *****
2025-04-17 12:57:49,315 -   train_loss = 1.6385328599384852
2025-04-17 12:58:06,360 - ***** Epoch: 52: Eval results *****
2025-04-17 12:58:06,361 -   train_loss = 1.6280050703457423
2025-04-17 12:58:23,046 - ***** Epoch: 53: Eval results *****
2025-04-17 12:58:23,046 -   train_loss = 1.59919250862939
2025-04-17 12:58:39,491 - ***** Epoch: 54: Eval results *****
2025-04-17 12:58:39,491 -   train_loss = 1.6038856165749686
2025-04-17 12:58:55,570 - ***** Epoch: 55: Eval results *****
2025-04-17 12:58:55,571 -   train_loss = 1.5817046420914787
2025-04-17 12:59:11,655 - ***** Epoch: 56: Eval results *****
2025-04-17 12:59:11,656 -   train_loss = 1.596117181437356
2025-04-17 12:59:26,718 - ***** Epoch: 57: Eval results *****
2025-04-17 12:59:26,718 -   train_loss = 1.5791670765195573
2025-04-17 12:59:41,826 - ***** Epoch: 58: Eval results *****
2025-04-17 12:59:41,826 -   train_loss = 1.573352268763951
2025-04-17 12:59:56,658 - ***** Epoch: 59: Eval results *****
2025-04-17 12:59:56,658 -   train_loss = 1.5681071196283614
2025-04-17 13:00:11,537 - ***** Epoch: 60: Eval results *****
2025-04-17 13:00:11,537 -   train_loss = 1.5492034724780492
2025-04-17 13:00:26,589 - ***** Epoch: 61: Eval results *****
2025-04-17 13:00:26,589 -   train_loss = 1.5489981429917472
2025-04-17 13:00:41,829 - ***** Epoch: 62: Eval results *****
2025-04-17 13:00:41,830 -   train_loss = 1.5553927677018302
2025-04-17 13:00:57,336 - ***** Epoch: 63: Eval results *****
2025-04-17 13:00:57,337 -   train_loss = 1.5519570537975855
2025-04-17 13:01:12,187 - ***** Epoch: 64: Eval results *****
2025-04-17 13:01:12,188 -   train_loss = 1.5421176041875566
2025-04-17 13:01:27,378 - ***** Epoch: 65: Eval results *****
2025-04-17 13:01:27,378 -   train_loss = 1.5327143924576896
2025-04-17 13:01:42,540 - ***** Epoch: 66: Eval results *****
2025-04-17 13:01:42,541 -   train_loss = 1.5367456248828344
2025-04-17 13:01:58,127 - ***** Epoch: 67: Eval results *****
2025-04-17 13:01:58,127 -   train_loss = 1.5286986912999834
2025-04-17 13:02:13,185 - ***** Epoch: 68: Eval results *****
2025-04-17 13:02:13,185 -   train_loss = 1.5276958090918404
2025-04-17 13:02:28,826 - ***** Epoch: 69: Eval results *****
2025-04-17 13:02:28,826 -   train_loss = 1.5199217796325684
2025-04-17 13:02:44,030 - ***** Epoch: 70: Eval results *****
2025-04-17 13:02:44,030 -   train_loss = 1.5239042469433375
2025-04-17 13:02:59,230 - ***** Epoch: 71: Eval results *****
2025-04-17 13:02:59,230 -   train_loss = 1.5096774441855294
2025-04-17 13:03:14,566 - ***** Epoch: 72: Eval results *****
2025-04-17 13:03:14,566 -   train_loss = 1.497619160584041
2025-04-17 13:03:30,267 - ***** Epoch: 73: Eval results *****
2025-04-17 13:03:30,267 -   train_loss = 1.5146839363234383
2025-04-17 13:03:45,233 - ***** Epoch: 74: Eval results *****
2025-04-17 13:03:45,233 -   train_loss = 1.5055718592235021
2025-04-17 13:04:00,547 - ***** Epoch: 75: Eval results *****
2025-04-17 13:04:00,548 -   train_loss = 1.5026614665985107
2025-04-17 13:04:16,120 - ***** Epoch: 76: Eval results *****
2025-04-17 13:04:16,120 -   train_loss = 1.4973712137767248
2025-04-17 13:04:31,662 - ***** Epoch: 77: Eval results *****
2025-04-17 13:04:31,663 -   train_loss = 1.4901610357420785
2025-04-17 13:04:46,772 - ***** Epoch: 78: Eval results *****
2025-04-17 13:04:46,772 -   train_loss = 1.4842806203024728
2025-04-17 13:05:02,184 - ***** Epoch: 79: Eval results *****
2025-04-17 13:05:02,184 -   train_loss = 1.4858035360063826
2025-04-17 13:05:17,458 - ***** Epoch: 80: Eval results *****
2025-04-17 13:05:17,458 -   train_loss = 1.4936731457710266
2025-04-17 13:05:32,840 - ***** Epoch: 81: Eval results *****
2025-04-17 13:05:32,840 -   train_loss = 1.4845935021127974
2025-04-17 13:05:47,910 - ***** Epoch: 82: Eval results *****
2025-04-17 13:05:47,911 -   train_loss = 1.4768412794385637
2025-04-17 13:06:03,436 - ***** Epoch: 83: Eval results *****
2025-04-17 13:06:03,437 -   train_loss = 1.4826573388917106
2025-04-17 13:06:18,282 - ***** Epoch: 84: Eval results *****
2025-04-17 13:06:18,283 -   train_loss = 1.4956067374774389
2025-04-17 13:06:33,310 - ***** Epoch: 85: Eval results *****
2025-04-17 13:06:33,311 -   train_loss = 1.4838196975844247
2025-04-17 13:06:48,759 - ***** Epoch: 86: Eval results *****
2025-04-17 13:06:48,759 -   train_loss = 1.4759339775357927
2025-04-17 13:07:04,446 - ***** Epoch: 87: Eval results *****
2025-04-17 13:07:04,446 -   train_loss = 1.4848897457122803
2025-04-17 13:07:20,905 - ***** Epoch: 88: Eval results *****
2025-04-17 13:07:20,906 -   train_loss = 1.4827022893088204
2025-04-17 13:07:37,442 - ***** Epoch: 89: Eval results *****
2025-04-17 13:07:37,443 -   train_loss = 1.4798686078616552
2025-04-17 13:07:53,309 - ***** Epoch: 90: Eval results *****
2025-04-17 13:07:53,310 -   train_loss = 1.4794437629835946
2025-04-17 13:08:09,160 - ***** Epoch: 91: Eval results *****
2025-04-17 13:08:09,161 -   train_loss = 1.474611520767212
2025-04-17 13:08:25,693 - ***** Epoch: 92: Eval results *****
2025-04-17 13:08:25,694 -   train_loss = 1.4827740362712316
2025-04-17 13:08:42,162 - ***** Epoch: 93: Eval results *****
2025-04-17 13:08:42,162 -   train_loss = 1.4874377335820879
2025-04-17 13:08:58,254 - ***** Epoch: 94: Eval results *****
2025-04-17 13:08:58,255 -   train_loss = 1.481482412133898
2025-04-17 13:09:13,961 - ***** Epoch: 95: Eval results *****
2025-04-17 13:09:13,961 -   train_loss = 1.4761152352605547
2025-04-17 13:09:29,035 - ***** Epoch: 96: Eval results *****
2025-04-17 13:09:29,036 -   train_loss = 1.4903350387300764
2025-04-17 13:09:43,992 - ***** Epoch: 97: Eval results *****
2025-04-17 13:09:43,993 -   train_loss = 1.4880118199757166
2025-04-17 13:09:59,768 - ***** Epoch: 98: Eval results *****
2025-04-17 13:09:59,769 -   train_loss = 1.4754684226853507
2025-04-17 13:10:15,121 - ***** Epoch: 99: Eval results *****
2025-04-17 13:10:15,121 -   train_loss = 1.481796213558742
2025-04-17 13:10:30,990 - ***** Epoch: 100: Eval results *****
2025-04-17 13:10:30,991 -   train_loss = 1.483039345060076
2025-04-17 13:10:32,666 - Pre-training finished...
2025-04-17 13:10:33,030 - Freeze all parameters but the last layer for efficiency
2025-04-17 13:10:33,042 - Multimodal Intent Recognition begins...
2025-04-17 13:10:33,043 - Training begins...
2025-04-17 13:10:49,486 - Initializing centroids with K-means++...
2025-04-17 13:10:49,715 - K-means++ used 0.23 s
2025-04-17 13:11:18,538 - K-means used 0.02 s
2025-04-17 13:11:19,605 - ***** Epoch: 1 *****
2025-04-17 13:11:19,605 - Supervised Training Loss: 4.375290
2025-04-17 13:11:19,606 - Unsupervised Training Loss: 5.530080
2025-04-17 13:11:47,114 - K-means used 0.02 s
2025-04-17 13:11:48,221 - ***** Epoch: 2 *****
2025-04-17 13:11:48,221 - Supervised Training Loss: 4.974370
2025-04-17 13:11:48,222 - Unsupervised Training Loss: 5.557290
2025-04-17 13:12:14,864 - K-means used 0.02 s
2025-04-17 13:12:16,033 - ***** Epoch: 3 *****
2025-04-17 13:12:16,034 - Supervised Training Loss: 4.800160
2025-04-17 13:12:16,034 - Unsupervised Training Loss: 5.427780
2025-04-17 13:12:43,172 - K-means used 0.02 s
2025-04-17 13:12:44,550 - ***** Epoch: 4 *****
2025-04-17 13:12:44,550 - Supervised Training Loss: 4.609470
2025-04-17 13:12:44,550 - Unsupervised Training Loss: 5.487660
2025-04-17 13:13:11,665 - K-means used 0.02 s
2025-04-17 13:13:12,845 - ***** Epoch: 5 *****
2025-04-17 13:13:12,845 - Supervised Training Loss: 4.342720
2025-04-17 13:13:12,845 - Unsupervised Training Loss: 5.527310
2025-04-17 13:13:40,311 - K-means used 0.03 s
2025-04-17 13:13:41,543 - ***** Epoch: 6 *****
2025-04-17 13:13:41,543 - Supervised Training Loss: 4.694710
2025-04-17 13:13:41,543 - Unsupervised Training Loss: 5.318060
2025-04-17 13:14:09,632 - K-means used 0.02 s
2025-04-17 13:14:10,894 - ***** Epoch: 7 *****
2025-04-17 13:14:10,894 - Supervised Training Loss: 4.592890
2025-04-17 13:14:10,894 - Unsupervised Training Loss: 5.439350
2025-04-17 13:14:38,450 - K-means used 0.02 s
2025-04-17 13:14:39,748 - ***** Epoch: 8 *****
2025-04-17 13:14:39,748 - Supervised Training Loss: 4.434770
2025-04-17 13:14:39,748 - Unsupervised Training Loss: 5.503280
2025-04-17 13:15:07,669 - K-means used 0.03 s
2025-04-17 13:15:08,994 - ***** Epoch: 9 *****
2025-04-17 13:15:08,994 - Supervised Training Loss: 4.649110
2025-04-17 13:15:08,994 - Unsupervised Training Loss: 5.541090
2025-04-17 13:15:37,077 - K-means used 0.02 s
2025-04-17 13:15:38,593 - ***** Epoch: 10 *****
2025-04-17 13:15:38,593 - Supervised Training Loss: 4.589060
2025-04-17 13:15:38,593 - Unsupervised Training Loss: 5.382130
2025-04-17 13:16:06,865 - K-means used 0.02 s
2025-04-17 13:16:08,366 - ***** Epoch: 11 *****
2025-04-17 13:16:08,367 - Supervised Training Loss: 4.503590
2025-04-17 13:16:08,367 - Unsupervised Training Loss: 5.461610
2025-04-17 13:16:36,733 - K-means used 0.02 s
2025-04-17 13:16:38,237 - ***** Epoch: 12 *****
2025-04-17 13:16:38,238 - Supervised Training Loss: 4.648360
2025-04-17 13:16:38,238 - Unsupervised Training Loss: 5.526890
2025-04-17 13:17:04,686 - K-means used 0.01 s
2025-04-17 13:17:06,394 - ***** Epoch: 13 *****
2025-04-17 13:17:06,394 - Supervised Training Loss: 4.616610
2025-04-17 13:17:06,394 - Unsupervised Training Loss: 5.255870
2025-04-17 13:17:34,442 - K-means used 0.02 s
2025-04-17 13:17:36,133 - ***** Epoch: 14 *****
2025-04-17 13:17:36,133 - Supervised Training Loss: 4.566100
2025-04-17 13:17:36,134 - Unsupervised Training Loss: 5.394030
2025-04-17 13:18:04,506 - K-means used 0.02 s
2025-04-17 13:18:06,451 - ***** Epoch: 15 *****
2025-04-17 13:18:06,452 - Supervised Training Loss: 4.458220
2025-04-17 13:18:06,452 - Unsupervised Training Loss: 5.488390
2025-04-17 13:18:37,263 - K-means used 0.02 s
2025-04-17 13:18:39,140 - ***** Epoch: 16 *****
2025-04-17 13:18:39,140 - Supervised Training Loss: 4.664310
2025-04-17 13:18:39,140 - Unsupervised Training Loss: 4.933240
2025-04-17 13:19:08,757 - K-means used 0.03 s
2025-04-17 13:19:10,540 - ***** Epoch: 17 *****
2025-04-17 13:19:10,540 - Supervised Training Loss: 4.655190
2025-04-17 13:19:10,540 - Unsupervised Training Loss: 5.164350
2025-04-17 13:19:28,873 - Training is finished...
2025-04-17 13:19:28,873 - Testing begins...
2025-04-17 13:19:36,900 - ***** Test results *****
2025-04-17 13:19:36,901 -   ACC = 41.8
2025-04-17 13:19:36,901 -   ARI = 20.93
2025-04-17 13:19:36,901 -   NMI = 48.84
2025-04-17 13:19:36,901 -   fmi = 26.08
2025-04-17 13:19:36,901 - Testing is finished...
2025-04-17 13:19:36,901 - Multimodal intent recognition is finished...
2025-04-17 13:19:36,901 - Results are saved in results/results_umc_pre.csv
2025-04-17 13:19:37,989 - Freeze all parameters but the last layer for efficiency
2025-04-17 13:19:38,028 - Pre-training start...
2025-04-17 13:19:38,746 - ***** Epoch: 1: Eval results *****
2025-04-17 13:19:38,746 -   train_loss = 5.684266090393066
2025-04-17 13:19:39,478 - ***** Epoch: 2: Eval results *****
2025-04-17 13:19:39,478 -   train_loss = 5.677481174468994
2025-04-17 13:19:40,204 - ***** Epoch: 3: Eval results *****
2025-04-17 13:19:40,204 -   train_loss = 5.685318946838379
2025-04-17 13:19:40,929 - ***** Epoch: 4: Eval results *****
2025-04-17 13:19:40,929 -   train_loss = 5.675864219665527
2025-04-17 13:19:41,650 - ***** Epoch: 5: Eval results *****
2025-04-17 13:19:41,650 -   train_loss = 5.689932346343994
2025-04-17 13:19:42,393 - ***** Epoch: 6: Eval results *****
2025-04-17 13:19:42,393 -   train_loss = 5.70091438293457
2025-04-17 13:19:43,112 - ***** Epoch: 7: Eval results *****
2025-04-17 13:19:43,112 -   train_loss = 5.675170421600342
2025-04-17 13:19:43,788 - ***** Epoch: 8: Eval results *****
2025-04-17 13:19:43,788 -   train_loss = 5.681436538696289
2025-04-17 13:19:44,522 - ***** Epoch: 9: Eval results *****
2025-04-17 13:19:44,523 -   train_loss = 5.682096481323242
2025-04-17 13:19:45,250 - ***** Epoch: 10: Eval results *****
2025-04-17 13:19:45,250 -   train_loss = 5.676109790802002
2025-04-17 13:19:45,969 - ***** Epoch: 11: Eval results *****
2025-04-17 13:19:45,969 -   train_loss = 5.683821678161621
2025-04-17 13:19:46,704 - ***** Epoch: 12: Eval results *****
2025-04-17 13:19:46,704 -   train_loss = 5.664058208465576
2025-04-17 13:19:47,406 - ***** Epoch: 13: Eval results *****
2025-04-17 13:19:47,407 -   train_loss = 5.677842140197754
2025-04-17 13:19:48,052 - ***** Epoch: 14: Eval results *****
2025-04-17 13:19:48,052 -   train_loss = 5.683716297149658
2025-04-17 13:19:48,703 - ***** Epoch: 15: Eval results *****
2025-04-17 13:19:48,704 -   train_loss = 5.682174205780029
2025-04-17 13:19:49,363 - ***** Epoch: 16: Eval results *****
2025-04-17 13:19:49,363 -   train_loss = 5.6870927810668945
2025-04-17 13:19:50,006 - ***** Epoch: 17: Eval results *****
2025-04-17 13:19:50,007 -   train_loss = 5.6850266456604
2025-04-17 13:19:50,660 - ***** Epoch: 18: Eval results *****
2025-04-17 13:19:50,660 -   train_loss = 5.688640594482422
2025-04-17 13:19:51,316 - ***** Epoch: 19: Eval results *****
2025-04-17 13:19:51,316 -   train_loss = 5.687802314758301
2025-04-17 13:19:51,966 - ***** Epoch: 20: Eval results *****
2025-04-17 13:19:51,967 -   train_loss = 5.681174278259277
2025-04-17 13:19:52,724 - ***** Epoch: 21: Eval results *****
2025-04-17 13:19:52,724 -   train_loss = 5.672938346862793
2025-04-17 13:19:53,454 - ***** Epoch: 22: Eval results *****
2025-04-17 13:19:53,454 -   train_loss = 5.6827778816223145
2025-04-17 13:19:54,169 - ***** Epoch: 23: Eval results *****
2025-04-17 13:19:54,170 -   train_loss = 5.667990684509277
2025-04-17 13:19:54,870 - ***** Epoch: 24: Eval results *****
2025-04-17 13:19:54,870 -   train_loss = 5.685157775878906
2025-04-17 13:19:55,594 - ***** Epoch: 25: Eval results *****
2025-04-17 13:19:55,594 -   train_loss = 5.661807060241699
2025-04-17 13:19:56,341 - ***** Epoch: 26: Eval results *****
2025-04-17 13:19:56,342 -   train_loss = 5.667686939239502
2025-04-17 13:19:57,061 - ***** Epoch: 27: Eval results *****
2025-04-17 13:19:57,061 -   train_loss = 5.669468879699707
2025-04-17 13:19:57,782 - ***** Epoch: 28: Eval results *****
2025-04-17 13:19:57,782 -   train_loss = 5.657943248748779
2025-04-17 13:19:58,500 - ***** Epoch: 29: Eval results *****
2025-04-17 13:19:58,501 -   train_loss = 5.669308662414551
2025-04-17 13:19:59,222 - ***** Epoch: 30: Eval results *****
2025-04-17 13:19:59,222 -   train_loss = 5.638742446899414
2025-04-17 13:19:59,864 - ***** Epoch: 31: Eval results *****
2025-04-17 13:19:59,864 -   train_loss = 5.67428731918335
2025-04-17 13:20:00,633 - ***** Epoch: 32: Eval results *****
2025-04-17 13:20:00,633 -   train_loss = 5.6406025886535645
2025-04-17 13:20:01,355 - ***** Epoch: 33: Eval results *****
2025-04-17 13:20:01,355 -   train_loss = 5.647681713104248
2025-04-17 13:20:02,052 - ***** Epoch: 34: Eval results *****
2025-04-17 13:20:02,052 -   train_loss = 5.662820339202881
2025-04-17 13:20:02,837 - ***** Epoch: 35: Eval results *****
2025-04-17 13:20:02,838 -   train_loss = 5.656589031219482
2025-04-17 13:20:03,572 - ***** Epoch: 36: Eval results *****
2025-04-17 13:20:03,572 -   train_loss = 5.630325794219971
2025-04-17 13:20:04,300 - ***** Epoch: 37: Eval results *****
2025-04-17 13:20:04,301 -   train_loss = 5.6553168296813965
2025-04-17 13:20:04,958 - ***** Epoch: 38: Eval results *****
2025-04-17 13:20:04,958 -   train_loss = 5.642873287200928
2025-04-17 13:20:05,608 - ***** Epoch: 39: Eval results *****
2025-04-17 13:20:05,609 -   train_loss = 5.632483005523682
2025-04-17 13:20:06,259 - ***** Epoch: 40: Eval results *****
2025-04-17 13:20:06,260 -   train_loss = 5.642070770263672
2025-04-17 13:20:07,029 - ***** Epoch: 41: Eval results *****
2025-04-17 13:20:07,029 -   train_loss = 5.642653942108154
2025-04-17 13:20:07,770 - ***** Epoch: 42: Eval results *****
2025-04-17 13:20:07,771 -   train_loss = 5.613040924072266
2025-04-17 13:20:08,502 - ***** Epoch: 43: Eval results *****
2025-04-17 13:20:08,502 -   train_loss = 5.626049995422363
2025-04-17 13:20:09,218 - ***** Epoch: 44: Eval results *****
2025-04-17 13:20:09,218 -   train_loss = 5.622767448425293
2025-04-17 13:20:09,934 - ***** Epoch: 45: Eval results *****
2025-04-17 13:20:09,934 -   train_loss = 5.6072492599487305
2025-04-17 13:20:10,660 - ***** Epoch: 46: Eval results *****
2025-04-17 13:20:10,660 -   train_loss = 5.618450164794922
2025-04-17 13:20:11,385 - ***** Epoch: 47: Eval results *****
2025-04-17 13:20:11,386 -   train_loss = 5.5991950035095215
2025-04-17 13:20:12,131 - ***** Epoch: 48: Eval results *****
2025-04-17 13:20:12,131 -   train_loss = 5.601926326751709
2025-04-17 13:20:12,862 - ***** Epoch: 49: Eval results *****
2025-04-17 13:20:12,862 -   train_loss = 5.598696708679199
2025-04-17 13:20:13,589 - ***** Epoch: 50: Eval results *****
2025-04-17 13:20:13,589 -   train_loss = 5.607367992401123
2025-04-17 13:20:14,257 - ***** Epoch: 51: Eval results *****
2025-04-17 13:20:14,258 -   train_loss = 5.609690189361572
2025-04-17 13:20:14,924 - ***** Epoch: 52: Eval results *****
2025-04-17 13:20:14,925 -   train_loss = 5.587191581726074
2025-04-17 13:20:15,709 - ***** Epoch: 53: Eval results *****
2025-04-17 13:20:15,709 -   train_loss = 5.58609676361084
2025-04-17 13:20:16,431 - ***** Epoch: 54: Eval results *****
2025-04-17 13:20:16,431 -   train_loss = 5.563869476318359
2025-04-17 13:20:17,090 - ***** Epoch: 55: Eval results *****
2025-04-17 13:20:17,091 -   train_loss = 5.539008140563965
2025-04-17 13:20:17,869 - ***** Epoch: 56: Eval results *****
2025-04-17 13:20:17,869 -   train_loss = 5.572059154510498
2025-04-17 13:20:18,538 - ***** Epoch: 57: Eval results *****
2025-04-17 13:20:18,538 -   train_loss = 5.543806552886963
2025-04-17 13:20:19,186 - ***** Epoch: 58: Eval results *****
2025-04-17 13:20:19,187 -   train_loss = 5.536573886871338
2025-04-17 13:20:19,953 - ***** Epoch: 59: Eval results *****
2025-04-17 13:20:19,953 -   train_loss = 5.513543605804443
2025-04-17 13:20:20,658 - ***** Epoch: 60: Eval results *****
2025-04-17 13:20:20,658 -   train_loss = 5.512966632843018
2025-04-17 13:20:21,320 - ***** Epoch: 61: Eval results *****
2025-04-17 13:20:21,321 -   train_loss = 5.4950971603393555
2025-04-17 13:20:21,973 - ***** Epoch: 62: Eval results *****
2025-04-17 13:20:21,973 -   train_loss = 5.5099406242370605
2025-04-17 13:20:22,630 - ***** Epoch: 63: Eval results *****
2025-04-17 13:20:22,630 -   train_loss = 5.497294902801514
2025-04-17 13:20:23,283 - ***** Epoch: 64: Eval results *****
2025-04-17 13:20:23,284 -   train_loss = 5.493518352508545
2025-04-17 13:20:23,933 - ***** Epoch: 65: Eval results *****
2025-04-17 13:20:23,933 -   train_loss = 5.474151611328125
2025-04-17 13:20:24,588 - ***** Epoch: 66: Eval results *****
2025-04-17 13:20:24,588 -   train_loss = 5.469660758972168
2025-04-17 13:20:25,254 - ***** Epoch: 67: Eval results *****
2025-04-17 13:20:25,254 -   train_loss = 5.4414801597595215
2025-04-17 13:20:26,013 - ***** Epoch: 68: Eval results *****
2025-04-17 13:20:26,013 -   train_loss = 5.429600238800049
2025-04-17 13:20:26,740 - ***** Epoch: 69: Eval results *****
2025-04-17 13:20:26,740 -   train_loss = 5.420328617095947
2025-04-17 13:20:27,462 - ***** Epoch: 70: Eval results *****
2025-04-17 13:20:27,462 -   train_loss = 5.4549407958984375
2025-04-17 13:20:28,178 - ***** Epoch: 71: Eval results *****
2025-04-17 13:20:28,178 -   train_loss = 5.3683342933654785
2025-04-17 13:20:28,896 - ***** Epoch: 72: Eval results *****
2025-04-17 13:20:28,896 -   train_loss = 5.406032085418701
2025-04-17 13:20:29,613 - ***** Epoch: 73: Eval results *****
2025-04-17 13:20:29,613 -   train_loss = 5.334901809692383
2025-04-17 13:20:30,328 - ***** Epoch: 74: Eval results *****
2025-04-17 13:20:30,328 -   train_loss = 5.321406841278076
2025-04-17 13:20:30,982 - ***** Epoch: 75: Eval results *****
2025-04-17 13:20:30,983 -   train_loss = 5.327437877655029
2025-04-17 13:20:31,727 - ***** Epoch: 76: Eval results *****
2025-04-17 13:20:31,727 -   train_loss = 5.314979076385498
2025-04-17 13:20:32,465 - ***** Epoch: 77: Eval results *****
2025-04-17 13:20:32,465 -   train_loss = 5.300647735595703
2025-04-17 13:20:33,206 - ***** Epoch: 78: Eval results *****
2025-04-17 13:20:33,206 -   train_loss = 5.313232421875
2025-04-17 13:20:33,916 - ***** Epoch: 79: Eval results *****
2025-04-17 13:20:33,916 -   train_loss = 5.285952568054199
2025-04-17 13:20:34,565 - ***** Epoch: 80: Eval results *****
2025-04-17 13:20:34,566 -   train_loss = 5.240023612976074
2025-04-17 13:20:35,312 - ***** Epoch: 81: Eval results *****
2025-04-17 13:20:35,313 -   train_loss = 5.251610279083252
2025-04-17 13:20:36,084 - ***** Epoch: 82: Eval results *****
2025-04-17 13:20:36,084 -   train_loss = 5.239856719970703
2025-04-17 13:20:36,801 - ***** Epoch: 83: Eval results *****
2025-04-17 13:20:36,801 -   train_loss = 5.220701217651367
2025-04-17 13:20:37,527 - ***** Epoch: 84: Eval results *****
2025-04-17 13:20:37,527 -   train_loss = 5.121901512145996
2025-04-17 13:20:38,246 - ***** Epoch: 85: Eval results *****
2025-04-17 13:20:38,247 -   train_loss = 5.158467769622803
2025-04-17 13:20:38,960 - ***** Epoch: 86: Eval results *****
2025-04-17 13:20:38,960 -   train_loss = 5.168690204620361
2025-04-17 13:20:39,684 - ***** Epoch: 87: Eval results *****
2025-04-17 13:20:39,684 -   train_loss = 5.127784252166748
2025-04-17 13:20:40,398 - ***** Epoch: 88: Eval results *****
2025-04-17 13:20:40,398 -   train_loss = 5.111044883728027
2025-04-17 13:20:41,122 - ***** Epoch: 89: Eval results *****
2025-04-17 13:20:41,122 -   train_loss = 5.106838703155518
2025-04-17 13:20:41,844 - ***** Epoch: 90: Eval results *****
2025-04-17 13:20:41,845 -   train_loss = 5.10310697555542
2025-04-17 13:20:42,568 - ***** Epoch: 91: Eval results *****
2025-04-17 13:20:42,569 -   train_loss = 5.0683979988098145
2025-04-17 13:20:43,278 - ***** Epoch: 92: Eval results *****
2025-04-17 13:20:43,278 -   train_loss = 5.014721393585205
2025-04-17 13:20:44,016 - ***** Epoch: 93: Eval results *****
2025-04-17 13:20:44,016 -   train_loss = 5.023109436035156
2025-04-17 13:20:44,750 - ***** Epoch: 94: Eval results *****
2025-04-17 13:20:44,751 -   train_loss = 4.956388473510742
2025-04-17 13:20:45,502 - ***** Epoch: 95: Eval results *****
2025-04-17 13:20:45,503 -   train_loss = 4.960769176483154
2025-04-17 13:20:46,220 - ***** Epoch: 96: Eval results *****
2025-04-17 13:20:46,220 -   train_loss = 4.983060359954834
2025-04-17 13:20:46,933 - ***** Epoch: 97: Eval results *****
2025-04-17 13:20:46,933 -   train_loss = 4.944901466369629
2025-04-17 13:20:47,640 - ***** Epoch: 98: Eval results *****
2025-04-17 13:20:47,640 -   train_loss = 4.903806209564209
2025-04-17 13:20:48,416 - ***** Epoch: 99: Eval results *****
2025-04-17 13:20:48,416 -   train_loss = 4.872550964355469
2025-04-17 13:20:49,151 - ***** Epoch: 100: Eval results *****
2025-04-17 13:20:49,152 -   train_loss = 4.900812149047852
2025-04-17 13:20:50,812 - Pre-training finished...
2025-04-17 13:20:51,118 - Freeze all parameters but the last layer for efficiency
2025-04-17 13:20:51,128 - Multimodal Intent Recognition begins...
2025-04-17 13:20:51,128 - Training begins...
2025-04-17 13:21:02,008 - Initializing centroids with K-means++...
2025-04-17 13:21:02,066 - K-means++ used 0.06 s
2025-04-17 13:21:31,063 - K-means used 0.03 s
2025-04-17 13:21:32,180 - ***** Epoch: 1 *****
2025-04-17 13:21:32,181 - Supervised Training Loss: 5.173160
2025-04-17 13:21:32,181 - Unsupervised Training Loss: 5.828270
2025-04-17 13:21:58,424 - K-means used 0.03 s
2025-04-17 13:21:59,766 - ***** Epoch: 2 *****
2025-04-17 13:21:59,766 - Supervised Training Loss: 4.029240
2025-04-17 13:21:59,766 - Unsupervised Training Loss: 5.791950
2025-04-17 13:22:28,748 - K-means used 0.03 s
2025-04-17 13:22:29,820 - ***** Epoch: 3 *****
2025-04-17 13:22:29,820 - Supervised Training Loss: 5.300310
2025-04-17 13:22:29,820 - Unsupervised Training Loss: 5.573010
2025-04-17 13:22:55,896 - K-means used 0.04 s
2025-04-17 13:22:57,091 - ***** Epoch: 4 *****
2025-04-17 13:22:57,091 - Supervised Training Loss: 5.036150
2025-04-17 13:22:57,091 - Unsupervised Training Loss: 5.584760
2025-04-17 13:23:22,430 - K-means used 0.02 s
2025-04-17 13:23:23,663 - ***** Epoch: 5 *****
2025-04-17 13:23:23,663 - Supervised Training Loss: 4.611470
2025-04-17 13:23:23,663 - Unsupervised Training Loss: 5.593300
2025-04-17 13:23:53,915 - K-means used 0.03 s
2025-04-17 13:23:55,298 - ***** Epoch: 6 *****
2025-04-17 13:23:55,298 - Supervised Training Loss: 4.941430
2025-04-17 13:23:55,298 - Unsupervised Training Loss: 5.375780
2025-04-17 13:24:22,517 - K-means used 0.02 s
2025-04-17 13:24:23,902 - ***** Epoch: 7 *****
2025-04-17 13:24:23,902 - Supervised Training Loss: 4.823620
2025-04-17 13:24:23,902 - Unsupervised Training Loss: 5.487000
2025-04-17 13:24:50,196 - K-means used 0.05 s
2025-04-17 13:24:51,544 - ***** Epoch: 8 *****
2025-04-17 13:24:51,545 - Supervised Training Loss: 4.685780
2025-04-17 13:24:51,545 - Unsupervised Training Loss: 5.538340
2025-04-17 13:25:18,594 - K-means used 0.02 s
2025-04-17 13:25:20,110 - ***** Epoch: 9 *****
2025-04-17 13:25:20,110 - Supervised Training Loss: 4.871130
2025-04-17 13:25:20,110 - Unsupervised Training Loss: 5.575760
2025-04-17 13:25:51,530 - K-means used 0.02 s
2025-04-17 13:25:52,977 - ***** Epoch: 10 *****
2025-04-17 13:25:52,977 - Supervised Training Loss: 4.810850
2025-04-17 13:25:52,977 - Unsupervised Training Loss: 5.404410
2025-04-17 13:26:22,436 - K-means used 0.02 s
2025-04-17 13:26:23,890 - ***** Epoch: 11 *****
2025-04-17 13:26:23,890 - Supervised Training Loss: 4.711150
2025-04-17 13:26:23,890 - Unsupervised Training Loss: 5.494710
2025-04-17 13:26:51,208 - K-means used 0.03 s
2025-04-17 13:26:52,865 - ***** Epoch: 12 *****
2025-04-17 13:26:52,865 - Supervised Training Loss: 4.834620
2025-04-17 13:26:52,865 - Unsupervised Training Loss: 5.560600
2025-04-17 13:27:19,058 - K-means used 0.02 s
2025-04-17 13:27:20,703 - ***** Epoch: 13 *****
2025-04-17 13:27:20,703 - Supervised Training Loss: 4.787040
2025-04-17 13:27:20,703 - Unsupervised Training Loss: 5.289540
2025-04-17 13:27:51,331 - K-means used 0.02 s
2025-04-17 13:27:52,920 - ***** Epoch: 14 *****
2025-04-17 13:27:52,920 - Supervised Training Loss: 4.735750
2025-04-17 13:27:52,920 - Unsupervised Training Loss: 5.409970
2025-04-17 13:28:22,592 - K-means used 0.02 s
2025-04-17 13:28:24,343 - ***** Epoch: 15 *****
2025-04-17 13:28:24,343 - Supervised Training Loss: 4.590250
2025-04-17 13:28:24,343 - Unsupervised Training Loss: 5.521660
2025-04-17 13:28:52,464 - K-means used 0.03 s
2025-04-17 13:28:55,174 - ***** Epoch: 16 *****
2025-04-17 13:28:55,175 - Supervised Training Loss: 4.794980
2025-04-17 13:28:55,175 - Unsupervised Training Loss: 4.927980
2025-04-17 13:29:24,560 - K-means used 0.02 s
2025-04-17 13:29:26,536 - ***** Epoch: 17 *****
2025-04-17 13:29:26,536 - Supervised Training Loss: 4.759560
2025-04-17 13:29:26,536 - Unsupervised Training Loss: 5.203430
2025-04-17 13:29:45,368 - Training is finished...
2025-04-17 13:29:45,368 - Testing begins...
2025-04-17 13:29:53,151 - ***** Test results *****
2025-04-17 13:29:53,151 -   ACC = 27.87
2025-04-17 13:29:53,151 -   ARI = 11.29
2025-04-17 13:29:53,196 -   NMI = 35.89
2025-04-17 13:29:53,196 -   fmi = 16.94
2025-04-17 13:29:53,196 - Testing is finished...
2025-04-17 13:29:53,196 - Multimodal intent recognition is finished...
2025-04-17 13:29:53,196 - Results are saved in results/results_umc_pre.csv
2025-04-17 13:29:54,310 - Freeze all parameters but the last layer for efficiency
2025-04-17 13:29:54,349 - Pre-training start...
2025-04-17 13:29:55,010 - ***** Epoch: 1: Eval results *****
2025-04-17 13:29:55,010 -   train_loss = 5.662360668182373
2025-04-17 13:29:55,658 - ***** Epoch: 2: Eval results *****
2025-04-17 13:29:55,658 -   train_loss = 5.662261486053467
2025-04-17 13:29:56,302 - ***** Epoch: 3: Eval results *****
2025-04-17 13:29:56,303 -   train_loss = 5.666710376739502
2025-04-17 13:29:56,938 - ***** Epoch: 4: Eval results *****
2025-04-17 13:29:56,939 -   train_loss = 5.663914203643799
2025-04-17 13:29:57,549 - ***** Epoch: 5: Eval results *****
2025-04-17 13:29:57,549 -   train_loss = 5.666170597076416
2025-04-17 13:29:58,169 - ***** Epoch: 6: Eval results *****
2025-04-17 13:29:58,169 -   train_loss = 5.66572904586792
2025-04-17 13:29:58,795 - ***** Epoch: 7: Eval results *****
2025-04-17 13:29:58,796 -   train_loss = 5.664112567901611
2025-04-17 13:29:59,420 - ***** Epoch: 8: Eval results *****
2025-04-17 13:29:59,420 -   train_loss = 5.66949987411499
2025-04-17 13:30:00,035 - ***** Epoch: 9: Eval results *****
2025-04-17 13:30:00,035 -   train_loss = 5.667442798614502
2025-04-17 13:30:00,670 - ***** Epoch: 10: Eval results *****
2025-04-17 13:30:00,670 -   train_loss = 5.665513038635254
2025-04-17 13:30:01,305 - ***** Epoch: 11: Eval results *****
2025-04-17 13:30:01,305 -   train_loss = 5.6669158935546875
2025-04-17 13:30:01,928 - ***** Epoch: 12: Eval results *****
2025-04-17 13:30:01,928 -   train_loss = 5.661361217498779
2025-04-17 13:30:02,559 - ***** Epoch: 13: Eval results *****
2025-04-17 13:30:02,559 -   train_loss = 5.659858703613281
2025-04-17 13:30:03,207 - ***** Epoch: 14: Eval results *****
2025-04-17 13:30:03,207 -   train_loss = 5.6642045974731445
2025-04-17 13:30:03,854 - ***** Epoch: 15: Eval results *****
2025-04-17 13:30:03,854 -   train_loss = 5.656766414642334
2025-04-17 13:30:04,470 - ***** Epoch: 16: Eval results *****
2025-04-17 13:30:04,471 -   train_loss = 5.658822059631348
2025-04-17 13:30:05,114 - ***** Epoch: 17: Eval results *****
2025-04-17 13:30:05,114 -   train_loss = 5.651207447052002
2025-04-17 13:30:05,750 - ***** Epoch: 18: Eval results *****
2025-04-17 13:30:05,751 -   train_loss = 5.644379138946533
2025-04-17 13:30:06,378 - ***** Epoch: 19: Eval results *****
2025-04-17 13:30:06,378 -   train_loss = 5.654776573181152
2025-04-17 13:30:07,020 - ***** Epoch: 20: Eval results *****
2025-04-17 13:30:07,020 -   train_loss = 5.651123046875
2025-04-17 13:30:07,649 - ***** Epoch: 21: Eval results *****
2025-04-17 13:30:07,649 -   train_loss = 5.649642467498779
2025-04-17 13:30:08,273 - ***** Epoch: 22: Eval results *****
2025-04-17 13:30:08,274 -   train_loss = 5.650149822235107
2025-04-17 13:30:08,896 - ***** Epoch: 23: Eval results *****
2025-04-17 13:30:08,896 -   train_loss = 5.647974014282227
2025-04-17 13:30:09,522 - ***** Epoch: 24: Eval results *****
2025-04-17 13:30:09,522 -   train_loss = 5.652666091918945
2025-04-17 13:30:10,139 - ***** Epoch: 25: Eval results *****
2025-04-17 13:30:10,139 -   train_loss = 5.64660120010376
2025-04-17 13:30:10,761 - ***** Epoch: 26: Eval results *****
2025-04-17 13:30:10,761 -   train_loss = 5.649085998535156
2025-04-17 13:30:11,385 - ***** Epoch: 27: Eval results *****
2025-04-17 13:30:11,385 -   train_loss = 5.635847568511963
2025-04-17 13:30:12,001 - ***** Epoch: 28: Eval results *****
2025-04-17 13:30:12,002 -   train_loss = 5.64297342300415
2025-04-17 13:30:12,633 - ***** Epoch: 29: Eval results *****
2025-04-17 13:30:12,634 -   train_loss = 5.632572174072266
2025-04-17 13:30:13,263 - ***** Epoch: 30: Eval results *****
2025-04-17 13:30:13,263 -   train_loss = 5.633228302001953
2025-04-17 13:30:13,880 - ***** Epoch: 31: Eval results *****
2025-04-17 13:30:13,880 -   train_loss = 5.629647731781006
2025-04-17 13:30:14,510 - ***** Epoch: 32: Eval results *****
2025-04-17 13:30:14,510 -   train_loss = 5.628254413604736
2025-04-17 13:30:15,125 - ***** Epoch: 33: Eval results *****
2025-04-17 13:30:15,125 -   train_loss = 5.623981475830078
2025-04-17 13:30:15,770 - ***** Epoch: 34: Eval results *****
2025-04-17 13:30:15,771 -   train_loss = 5.615442276000977
2025-04-17 13:30:16,393 - ***** Epoch: 35: Eval results *****
2025-04-17 13:30:16,393 -   train_loss = 5.617547988891602
2025-04-17 13:30:17,017 - ***** Epoch: 36: Eval results *****
2025-04-17 13:30:17,018 -   train_loss = 5.613725185394287
2025-04-17 13:30:17,642 - ***** Epoch: 37: Eval results *****
2025-04-17 13:30:17,642 -   train_loss = 5.608669281005859
2025-04-17 13:30:18,270 - ***** Epoch: 38: Eval results *****
2025-04-17 13:30:18,271 -   train_loss = 5.590849876403809
2025-04-17 13:30:18,908 - ***** Epoch: 39: Eval results *****
2025-04-17 13:30:18,908 -   train_loss = 5.590299129486084
2025-04-17 13:30:19,551 - ***** Epoch: 40: Eval results *****
2025-04-17 13:30:19,551 -   train_loss = 5.593144416809082
2025-04-17 13:30:20,187 - ***** Epoch: 41: Eval results *****
2025-04-17 13:30:20,188 -   train_loss = 5.597867488861084
2025-04-17 13:30:20,808 - ***** Epoch: 42: Eval results *****
2025-04-17 13:30:20,808 -   train_loss = 5.578293323516846
2025-04-17 13:30:21,418 - ***** Epoch: 43: Eval results *****
2025-04-17 13:30:21,418 -   train_loss = 5.574304580688477
2025-04-17 13:30:22,051 - ***** Epoch: 44: Eval results *****
2025-04-17 13:30:22,051 -   train_loss = 5.570832252502441
2025-04-17 13:30:22,684 - ***** Epoch: 45: Eval results *****
2025-04-17 13:30:22,685 -   train_loss = 5.559317111968994
2025-04-17 13:30:23,320 - ***** Epoch: 46: Eval results *****
2025-04-17 13:30:23,320 -   train_loss = 5.553697109222412
2025-04-17 13:30:23,937 - ***** Epoch: 47: Eval results *****
2025-04-17 13:30:23,937 -   train_loss = 5.548407077789307
2025-04-17 13:30:24,562 - ***** Epoch: 48: Eval results *****
2025-04-17 13:30:24,563 -   train_loss = 5.555455684661865
2025-04-17 13:30:25,190 - ***** Epoch: 49: Eval results *****
2025-04-17 13:30:25,190 -   train_loss = 5.548157691955566
2025-04-17 13:30:25,845 - ***** Epoch: 50: Eval results *****
2025-04-17 13:30:25,845 -   train_loss = 5.527398586273193
2025-04-17 13:30:26,469 - ***** Epoch: 51: Eval results *****
2025-04-17 13:30:26,469 -   train_loss = 5.528002738952637
2025-04-17 13:30:27,089 - ***** Epoch: 52: Eval results *****
2025-04-17 13:30:27,090 -   train_loss = 5.517401218414307
2025-04-17 13:30:27,712 - ***** Epoch: 53: Eval results *****
2025-04-17 13:30:27,713 -   train_loss = 5.519374847412109
2025-04-17 13:30:28,337 - ***** Epoch: 54: Eval results *****
2025-04-17 13:30:28,337 -   train_loss = 5.49005651473999
2025-04-17 13:30:28,955 - ***** Epoch: 55: Eval results *****
2025-04-17 13:30:28,955 -   train_loss = 5.490825653076172
2025-04-17 13:30:29,573 - ***** Epoch: 56: Eval results *****
2025-04-17 13:30:29,573 -   train_loss = 5.4904961585998535
2025-04-17 13:30:30,193 - ***** Epoch: 57: Eval results *****
2025-04-17 13:30:30,194 -   train_loss = 5.491238117218018
2025-04-17 13:30:30,807 - ***** Epoch: 58: Eval results *****
2025-04-17 13:30:30,808 -   train_loss = 5.467035293579102
2025-04-17 13:30:31,426 - ***** Epoch: 59: Eval results *****
2025-04-17 13:30:31,426 -   train_loss = 5.467410564422607
2025-04-17 13:30:32,048 - ***** Epoch: 60: Eval results *****
2025-04-17 13:30:32,048 -   train_loss = 5.432498931884766
2025-04-17 13:30:32,664 - ***** Epoch: 61: Eval results *****
2025-04-17 13:30:32,664 -   train_loss = 5.455753326416016
2025-04-17 13:30:33,281 - ***** Epoch: 62: Eval results *****
2025-04-17 13:30:33,281 -   train_loss = 5.42634916305542
2025-04-17 13:30:33,906 - ***** Epoch: 63: Eval results *****
2025-04-17 13:30:33,906 -   train_loss = 5.4157395362854
2025-04-17 13:30:34,521 - ***** Epoch: 64: Eval results *****
2025-04-17 13:30:34,521 -   train_loss = 5.434456825256348
2025-04-17 13:30:35,141 - ***** Epoch: 65: Eval results *****
2025-04-17 13:30:35,141 -   train_loss = 5.397164821624756
2025-04-17 13:30:35,798 - ***** Epoch: 66: Eval results *****
2025-04-17 13:30:35,798 -   train_loss = 5.410065650939941
2025-04-17 13:30:36,417 - ***** Epoch: 67: Eval results *****
2025-04-17 13:30:36,418 -   train_loss = 5.380188941955566
2025-04-17 13:30:37,034 - ***** Epoch: 68: Eval results *****
2025-04-17 13:30:37,035 -   train_loss = 5.389409065246582
2025-04-17 13:30:37,652 - ***** Epoch: 69: Eval results *****
2025-04-17 13:30:37,652 -   train_loss = 5.347517967224121
2025-04-17 13:30:38,277 - ***** Epoch: 70: Eval results *****
2025-04-17 13:30:38,277 -   train_loss = 5.362607002258301
2025-04-17 13:30:38,889 - ***** Epoch: 71: Eval results *****
2025-04-17 13:30:38,890 -   train_loss = 5.357741832733154
2025-04-17 13:30:39,512 - ***** Epoch: 72: Eval results *****
2025-04-17 13:30:39,512 -   train_loss = 5.356119632720947
2025-04-17 13:30:40,126 - ***** Epoch: 73: Eval results *****
2025-04-17 13:30:40,126 -   train_loss = 5.336642265319824
2025-04-17 13:30:40,740 - ***** Epoch: 74: Eval results *****
2025-04-17 13:30:40,740 -   train_loss = 5.338955879211426
2025-04-17 13:30:41,353 - ***** Epoch: 75: Eval results *****
2025-04-17 13:30:41,353 -   train_loss = 5.311910152435303
2025-04-17 13:30:41,970 - ***** Epoch: 76: Eval results *****
2025-04-17 13:30:41,970 -   train_loss = 5.3267412185668945
2025-04-17 13:30:42,580 - ***** Epoch: 77: Eval results *****
2025-04-17 13:30:42,581 -   train_loss = 5.312564849853516
2025-04-17 13:30:43,201 - ***** Epoch: 78: Eval results *****
2025-04-17 13:30:43,201 -   train_loss = 5.288864612579346
2025-04-17 13:30:43,831 - ***** Epoch: 79: Eval results *****
2025-04-17 13:30:43,832 -   train_loss = 5.279156684875488
2025-04-17 13:30:44,446 - ***** Epoch: 80: Eval results *****
2025-04-17 13:30:44,447 -   train_loss = 5.28031587600708
2025-04-17 13:30:45,072 - ***** Epoch: 81: Eval results *****
2025-04-17 13:30:45,072 -   train_loss = 5.258302211761475
2025-04-17 13:30:45,701 - ***** Epoch: 82: Eval results *****
2025-04-17 13:30:45,701 -   train_loss = 5.245954513549805
2025-04-17 13:30:46,316 - ***** Epoch: 83: Eval results *****
2025-04-17 13:30:46,317 -   train_loss = 5.242633819580078
2025-04-17 13:30:46,930 - ***** Epoch: 84: Eval results *****
2025-04-17 13:30:46,930 -   train_loss = 5.229357719421387
2025-04-17 13:30:47,541 - ***** Epoch: 85: Eval results *****
2025-04-17 13:30:47,541 -   train_loss = 5.229430675506592
2025-04-17 13:30:48,173 - ***** Epoch: 86: Eval results *****
2025-04-17 13:30:48,174 -   train_loss = 5.229952335357666
2025-04-17 13:30:48,787 - ***** Epoch: 87: Eval results *****
2025-04-17 13:30:48,787 -   train_loss = 5.22327995300293
2025-04-17 13:30:49,413 - ***** Epoch: 88: Eval results *****
2025-04-17 13:30:49,413 -   train_loss = 5.217942714691162
2025-04-17 13:30:50,040 - ***** Epoch: 89: Eval results *****
2025-04-17 13:30:50,040 -   train_loss = 5.211309432983398
2025-04-17 13:30:50,661 - ***** Epoch: 90: Eval results *****
2025-04-17 13:30:50,661 -   train_loss = 5.191834449768066
2025-04-17 13:30:51,272 - ***** Epoch: 91: Eval results *****
2025-04-17 13:30:51,272 -   train_loss = 5.17886209487915
2025-04-17 13:30:51,901 - ***** Epoch: 92: Eval results *****
2025-04-17 13:30:51,902 -   train_loss = 5.172194004058838
2025-04-17 13:30:52,524 - ***** Epoch: 93: Eval results *****
2025-04-17 13:30:52,524 -   train_loss = 5.148959636688232
2025-04-17 13:30:53,150 - ***** Epoch: 94: Eval results *****
2025-04-17 13:30:53,150 -   train_loss = 5.151980400085449
2025-04-17 13:30:53,766 - ***** Epoch: 95: Eval results *****
2025-04-17 13:30:53,767 -   train_loss = 5.142420291900635
2025-04-17 13:30:54,389 - ***** Epoch: 96: Eval results *****
2025-04-17 13:30:54,389 -   train_loss = 5.156586647033691
2025-04-17 13:30:55,006 - ***** Epoch: 97: Eval results *****
2025-04-17 13:30:55,006 -   train_loss = 5.155573844909668
2025-04-17 13:30:55,630 - ***** Epoch: 98: Eval results *****
2025-04-17 13:30:55,630 -   train_loss = 5.171754837036133
2025-04-17 13:30:56,263 - ***** Epoch: 99: Eval results *****
2025-04-17 13:30:56,263 -   train_loss = 5.127945899963379
2025-04-17 13:30:56,878 - ***** Epoch: 100: Eval results *****
2025-04-17 13:30:56,879 -   train_loss = 5.123586654663086
2025-04-17 13:30:58,455 - Pre-training finished...
2025-04-17 13:30:58,647 - Freeze all parameters but the last layer for efficiency
2025-04-17 13:30:58,656 - Multimodal Intent Recognition begins...
2025-04-17 13:30:58,656 - Training begins...
2025-04-17 13:31:09,504 - Initializing centroids with K-means++...
2025-04-17 13:31:09,611 - K-means++ used 0.11 s
2025-04-17 13:31:42,012 - K-means used 0.04 s
2025-04-17 13:31:43,143 - ***** Epoch: 1 *****
2025-04-17 13:31:43,143 - Supervised Training Loss: 5.251970
2025-04-17 13:31:43,143 - Unsupervised Training Loss: 5.811200
2025-04-17 13:32:11,712 - K-means used 0.13 s
2025-04-17 13:32:12,968 - ***** Epoch: 2 *****
2025-04-17 13:32:12,968 - Supervised Training Loss: 4.017650
2025-04-17 13:32:12,968 - Unsupervised Training Loss: 5.809400
2025-04-17 13:32:41,333 - K-means used 0.09 s
2025-04-17 13:32:42,741 - ***** Epoch: 3 *****
2025-04-17 13:32:42,741 - Supervised Training Loss: 5.374840
2025-04-17 13:32:42,741 - Unsupervised Training Loss: 5.586440
2025-04-17 13:33:12,813 - K-means used 0.12 s
2025-04-17 13:33:14,052 - ***** Epoch: 4 *****
2025-04-17 13:33:14,052 - Supervised Training Loss: 4.965770
2025-04-17 13:33:14,052 - Unsupervised Training Loss: 5.603640
2025-04-17 13:33:44,545 - K-means used 0.12 s
2025-04-17 13:33:46,004 - ***** Epoch: 5 *****
2025-04-17 13:33:46,004 - Supervised Training Loss: 4.542220
2025-04-17 13:33:46,005 - Unsupervised Training Loss: 5.613680
2025-04-17 13:34:14,427 - K-means used 0.03 s
2025-04-17 13:34:15,680 - ***** Epoch: 6 *****
2025-04-17 13:34:15,680 - Supervised Training Loss: 4.926170
2025-04-17 13:34:15,680 - Unsupervised Training Loss: 5.371290
2025-04-17 13:34:41,100 - K-means used 0.09 s
2025-04-17 13:34:42,870 - ***** Epoch: 7 *****
2025-04-17 13:34:42,870 - Supervised Training Loss: 4.777830
2025-04-17 13:34:42,870 - Unsupervised Training Loss: 5.495260
2025-04-17 13:35:13,205 - K-means used 0.12 s
2025-04-17 13:35:14,713 - ***** Epoch: 8 *****
2025-04-17 13:35:14,713 - Supervised Training Loss: 4.627860
2025-04-17 13:35:14,713 - Unsupervised Training Loss: 5.549280
2025-04-17 13:35:43,291 - K-means used 0.02 s
2025-04-17 13:35:44,786 - ***** Epoch: 9 *****
2025-04-17 13:35:44,786 - Supervised Training Loss: 4.830450
2025-04-17 13:35:44,786 - Unsupervised Training Loss: 5.582650
2025-04-17 13:36:10,162 - K-means used 0.04 s
2025-04-17 13:36:12,293 - ***** Epoch: 10 *****
2025-04-17 13:36:12,293 - Supervised Training Loss: 4.765700
2025-04-17 13:36:12,293 - Unsupervised Training Loss: 5.425630
2025-04-17 13:36:44,306 - K-means used 0.08 s
2025-04-17 13:36:46,466 - ***** Epoch: 11 *****
2025-04-17 13:36:46,466 - Supervised Training Loss: 4.663060
2025-04-17 13:36:46,466 - Unsupervised Training Loss: 5.505860
2025-04-17 13:37:15,621 - K-means used 0.02 s
2025-04-17 13:37:17,112 - ***** Epoch: 12 *****
2025-04-17 13:37:17,112 - Supervised Training Loss: 4.810040
2025-04-17 13:37:17,112 - Unsupervised Training Loss: 5.568880
2025-04-17 13:37:42,709 - K-means used 0.1 s
2025-04-17 13:37:45,053 - ***** Epoch: 13 *****
2025-04-17 13:37:45,054 - Supervised Training Loss: 4.761920
2025-04-17 13:37:45,054 - Unsupervised Training Loss: 5.299770
2025-04-17 13:38:13,110 - K-means used 0.02 s
2025-04-17 13:38:14,843 - ***** Epoch: 14 *****
2025-04-17 13:38:14,843 - Supervised Training Loss: 4.714100
2025-04-17 13:38:14,843 - Unsupervised Training Loss: 5.424730
2025-04-17 13:38:40,996 - K-means used 0.1 s
2025-04-17 13:38:43,796 - ***** Epoch: 15 *****
2025-04-17 13:38:43,797 - Supervised Training Loss: 4.555790
2025-04-17 13:38:43,797 - Unsupervised Training Loss: 5.525470
2025-04-17 13:39:11,516 - K-means used 0.02 s
2025-04-17 13:39:13,388 - ***** Epoch: 16 *****
2025-04-17 13:39:13,388 - Supervised Training Loss: 4.789910
2025-04-17 13:39:13,388 - Unsupervised Training Loss: 4.976940
2025-04-17 13:39:39,606 - K-means used 0.09 s
2025-04-17 13:39:42,417 - ***** Epoch: 17 *****
2025-04-17 13:39:42,417 - Supervised Training Loss: 4.764450
2025-04-17 13:39:42,417 - Unsupervised Training Loss: 5.191760
2025-04-17 13:40:00,945 - Training is finished...
2025-04-17 13:40:00,946 - Testing begins...
2025-04-17 13:40:09,296 - ***** Test results *****
2025-04-17 13:40:09,296 -   ACC = 20.0
2025-04-17 13:40:09,296 -   ARI = 4.83
2025-04-17 13:40:09,296 -   NMI = 26.07
2025-04-17 13:40:09,296 -   fmi = 10.99
2025-04-17 13:40:09,296 - Testing is finished...
2025-04-17 13:40:09,296 - Multimodal intent recognition is finished...
2025-04-17 13:40:09,296 - Results are saved in results/results_umc_pre.csv
2025-04-17 13:40:10,299 - Freeze all parameters but the last layer for efficiency
2025-04-17 13:40:10,338 - Pre-training start...
2025-04-17 13:40:10,985 - ***** Epoch: 1: Eval results *****
2025-04-17 13:40:10,985 -   train_loss = 5.684959411621094
2025-04-17 13:40:11,658 - ***** Epoch: 2: Eval results *****
2025-04-17 13:40:11,658 -   train_loss = 5.6839399337768555
2025-04-17 13:40:12,336 - ***** Epoch: 3: Eval results *****
2025-04-17 13:40:12,337 -   train_loss = 5.6862592697143555
2025-04-17 13:40:12,982 - ***** Epoch: 4: Eval results *****
2025-04-17 13:40:12,983 -   train_loss = 5.682140827178955
2025-04-17 13:40:13,632 - ***** Epoch: 5: Eval results *****
2025-04-17 13:40:13,632 -   train_loss = 5.688351631164551
2025-04-17 13:40:14,273 - ***** Epoch: 6: Eval results *****
2025-04-17 13:40:14,273 -   train_loss = 5.687184810638428
2025-04-17 13:40:14,923 - ***** Epoch: 7: Eval results *****
2025-04-17 13:40:14,923 -   train_loss = 5.681021213531494
2025-04-17 13:40:15,566 - ***** Epoch: 8: Eval results *****
2025-04-17 13:40:15,566 -   train_loss = 5.686790466308594
2025-04-17 13:40:16,221 - ***** Epoch: 9: Eval results *****
2025-04-17 13:40:16,221 -   train_loss = 5.685418605804443
2025-04-17 13:40:16,892 - ***** Epoch: 10: Eval results *****
2025-04-17 13:40:16,892 -   train_loss = 5.683069229125977
2025-04-17 13:40:17,552 - ***** Epoch: 11: Eval results *****
2025-04-17 13:40:17,553 -   train_loss = 5.685517311096191
2025-04-17 13:40:18,196 - ***** Epoch: 12: Eval results *****
2025-04-17 13:40:18,196 -   train_loss = 5.679208755493164
2025-04-17 13:40:18,838 - ***** Epoch: 13: Eval results *****
2025-04-17 13:40:18,839 -   train_loss = 5.68412446975708
2025-04-17 13:40:19,483 - ***** Epoch: 14: Eval results *****
2025-04-17 13:40:19,483 -   train_loss = 5.682031154632568
2025-04-17 13:40:20,135 - ***** Epoch: 15: Eval results *****
2025-04-17 13:40:20,135 -   train_loss = 5.684590816497803
2025-04-17 13:40:20,781 - ***** Epoch: 16: Eval results *****
2025-04-17 13:40:20,781 -   train_loss = 5.685431003570557
2025-04-17 13:40:21,424 - ***** Epoch: 17: Eval results *****
2025-04-17 13:40:21,424 -   train_loss = 5.683311462402344
2025-04-17 13:40:22,072 - ***** Epoch: 18: Eval results *****
2025-04-17 13:40:22,073 -   train_loss = 5.686985492706299
2025-04-17 13:40:22,719 - ***** Epoch: 19: Eval results *****
2025-04-17 13:40:22,719 -   train_loss = 5.686853408813477
2025-04-17 13:40:23,376 - ***** Epoch: 20: Eval results *****
2025-04-17 13:40:23,376 -   train_loss = 5.68442964553833
2025-04-17 13:40:24,021 - ***** Epoch: 21: Eval results *****
2025-04-17 13:40:24,022 -   train_loss = 5.681326389312744
2025-04-17 13:40:24,663 - ***** Epoch: 22: Eval results *****
2025-04-17 13:40:24,663 -   train_loss = 5.684263706207275
2025-04-17 13:40:25,303 - ***** Epoch: 23: Eval results *****
2025-04-17 13:40:25,304 -   train_loss = 5.6767730712890625
2025-04-17 13:40:25,954 - ***** Epoch: 24: Eval results *****
2025-04-17 13:40:25,954 -   train_loss = 5.684146404266357
2025-04-17 13:40:26,595 - ***** Epoch: 25: Eval results *****
2025-04-17 13:40:26,596 -   train_loss = 5.673524856567383
2025-04-17 13:40:27,234 - ***** Epoch: 26: Eval results *****
2025-04-17 13:40:27,234 -   train_loss = 5.677505016326904
2025-04-17 13:40:27,872 - ***** Epoch: 27: Eval results *****
2025-04-17 13:40:27,872 -   train_loss = 5.672075271606445
2025-04-17 13:40:28,522 - ***** Epoch: 28: Eval results *****
2025-04-17 13:40:28,523 -   train_loss = 5.675043106079102
2025-04-17 13:40:29,169 - ***** Epoch: 29: Eval results *****
2025-04-17 13:40:29,170 -   train_loss = 5.674526691436768
2025-04-17 13:40:29,814 - ***** Epoch: 30: Eval results *****
2025-04-17 13:40:29,814 -   train_loss = 5.66790771484375
2025-04-17 13:40:30,465 - ***** Epoch: 31: Eval results *****
2025-04-17 13:40:30,466 -   train_loss = 5.678749084472656
2025-04-17 13:40:31,115 - ***** Epoch: 32: Eval results *****
2025-04-17 13:40:31,115 -   train_loss = 5.666234970092773
2025-04-17 13:40:31,759 - ***** Epoch: 33: Eval results *****
2025-04-17 13:40:31,760 -   train_loss = 5.6719818115234375
2025-04-17 13:40:32,409 - ***** Epoch: 34: Eval results *****
2025-04-17 13:40:32,410 -   train_loss = 5.673658847808838
2025-04-17 13:40:33,053 - ***** Epoch: 35: Eval results *****
2025-04-17 13:40:33,053 -   train_loss = 5.6728291511535645
2025-04-17 13:40:33,694 - ***** Epoch: 36: Eval results *****
2025-04-17 13:40:33,694 -   train_loss = 5.662002086639404
2025-04-17 13:40:34,338 - ***** Epoch: 37: Eval results *****
2025-04-17 13:40:34,339 -   train_loss = 5.666430473327637
2025-04-17 13:40:34,985 - ***** Epoch: 38: Eval results *****
2025-04-17 13:40:34,986 -   train_loss = 5.670811176300049
2025-04-17 13:40:35,633 - ***** Epoch: 39: Eval results *****
2025-04-17 13:40:35,634 -   train_loss = 5.6585917472839355
2025-04-17 13:40:36,280 - ***** Epoch: 40: Eval results *****
2025-04-17 13:40:36,280 -   train_loss = 5.660174369812012
2025-04-17 13:40:36,924 - ***** Epoch: 41: Eval results *****
2025-04-17 13:40:36,924 -   train_loss = 5.66085958480835
2025-04-17 13:40:37,569 - ***** Epoch: 42: Eval results *****
2025-04-17 13:40:37,569 -   train_loss = 5.652063369750977
2025-04-17 13:40:38,285 - ***** Epoch: 43: Eval results *****
2025-04-17 13:40:38,286 -   train_loss = 5.654776573181152
2025-04-17 13:40:39,010 - ***** Epoch: 44: Eval results *****
2025-04-17 13:40:39,011 -   train_loss = 5.653146743774414
2025-04-17 13:40:39,750 - ***** Epoch: 45: Eval results *****
2025-04-17 13:40:39,750 -   train_loss = 5.641846179962158
2025-04-17 13:40:40,490 - ***** Epoch: 46: Eval results *****
2025-04-17 13:40:40,491 -   train_loss = 5.645751953125
2025-04-17 13:40:41,230 - ***** Epoch: 47: Eval results *****
2025-04-17 13:40:41,231 -   train_loss = 5.645055770874023
2025-04-17 13:40:41,969 - ***** Epoch: 48: Eval results *****
2025-04-17 13:40:41,970 -   train_loss = 5.638846397399902
2025-04-17 13:40:42,716 - ***** Epoch: 49: Eval results *****
2025-04-17 13:40:42,716 -   train_loss = 5.633754730224609
2025-04-17 13:40:43,514 - ***** Epoch: 50: Eval results *****
2025-04-17 13:40:43,515 -   train_loss = 5.636641979217529
2025-04-17 13:40:44,262 - ***** Epoch: 51: Eval results *****
2025-04-17 13:40:44,263 -   train_loss = 5.641447067260742
2025-04-17 13:40:45,156 - ***** Epoch: 52: Eval results *****
2025-04-17 13:40:45,156 -   train_loss = 5.6285810470581055
2025-04-17 13:40:45,895 - ***** Epoch: 53: Eval results *****
2025-04-17 13:40:45,896 -   train_loss = 5.627641201019287
2025-04-17 13:40:46,645 - ***** Epoch: 54: Eval results *****
2025-04-17 13:40:46,646 -   train_loss = 5.613532543182373
2025-04-17 13:40:47,397 - ***** Epoch: 55: Eval results *****
2025-04-17 13:40:47,398 -   train_loss = 5.6082234382629395
2025-04-17 13:40:48,140 - ***** Epoch: 56: Eval results *****
2025-04-17 13:40:48,141 -   train_loss = 5.615932941436768
2025-04-17 13:40:48,884 - ***** Epoch: 57: Eval results *****
2025-04-17 13:40:48,885 -   train_loss = 5.610271453857422
2025-04-17 13:40:49,633 - ***** Epoch: 58: Eval results *****
2025-04-17 13:40:49,634 -   train_loss = 5.60047721862793
2025-04-17 13:40:50,375 - ***** Epoch: 59: Eval results *****
2025-04-17 13:40:50,376 -   train_loss = 5.592167854309082
2025-04-17 13:40:51,114 - ***** Epoch: 60: Eval results *****
2025-04-17 13:40:51,115 -   train_loss = 5.585011959075928
2025-04-17 13:40:51,847 - ***** Epoch: 61: Eval results *****
2025-04-17 13:40:51,848 -   train_loss = 5.575732707977295
2025-04-17 13:40:52,576 - ***** Epoch: 62: Eval results *****
2025-04-17 13:40:52,576 -   train_loss = 5.5702595710754395
2025-04-17 13:40:53,292 - ***** Epoch: 63: Eval results *****
2025-04-17 13:40:53,293 -   train_loss = 5.5663909912109375
2025-04-17 13:40:54,025 - ***** Epoch: 64: Eval results *****
2025-04-17 13:40:54,026 -   train_loss = 5.56549596786499
2025-04-17 13:40:54,740 - ***** Epoch: 65: Eval results *****
2025-04-17 13:40:54,741 -   train_loss = 5.5515217781066895
2025-04-17 13:40:55,455 - ***** Epoch: 66: Eval results *****
2025-04-17 13:40:55,456 -   train_loss = 5.5427374839782715
2025-04-17 13:40:56,178 - ***** Epoch: 67: Eval results *****
2025-04-17 13:40:56,178 -   train_loss = 5.541882514953613
2025-04-17 13:40:56,910 - ***** Epoch: 68: Eval results *****
2025-04-17 13:40:56,910 -   train_loss = 5.529881000518799
2025-04-17 13:40:57,624 - ***** Epoch: 69: Eval results *****
2025-04-17 13:40:57,624 -   train_loss = 5.520898342132568
2025-04-17 13:40:58,360 - ***** Epoch: 70: Eval results *****
2025-04-17 13:40:58,360 -   train_loss = 5.5348124504089355
2025-04-17 13:40:59,087 - ***** Epoch: 71: Eval results *****
2025-04-17 13:40:59,088 -   train_loss = 5.521180152893066
2025-04-17 13:40:59,828 - ***** Epoch: 72: Eval results *****
2025-04-17 13:40:59,829 -   train_loss = 5.5037713050842285
2025-04-17 13:41:00,564 - ***** Epoch: 73: Eval results *****
2025-04-17 13:41:00,564 -   train_loss = 5.495495319366455
2025-04-17 13:41:01,298 - ***** Epoch: 74: Eval results *****
2025-04-17 13:41:01,299 -   train_loss = 5.473883628845215
2025-04-17 13:41:02,048 - ***** Epoch: 75: Eval results *****
2025-04-17 13:41:02,048 -   train_loss = 5.460743427276611
2025-04-17 13:41:02,773 - ***** Epoch: 76: Eval results *****
2025-04-17 13:41:02,774 -   train_loss = 5.468306064605713
2025-04-17 13:41:03,510 - ***** Epoch: 77: Eval results *****
2025-04-17 13:41:03,511 -   train_loss = 5.447656631469727
2025-04-17 13:41:04,241 - ***** Epoch: 78: Eval results *****
2025-04-17 13:41:04,241 -   train_loss = 5.4572625160217285
2025-04-17 13:41:04,973 - ***** Epoch: 79: Eval results *****
2025-04-17 13:41:04,973 -   train_loss = 5.44249963760376
2025-04-17 13:41:05,692 - ***** Epoch: 80: Eval results *****
2025-04-17 13:41:05,692 -   train_loss = 5.442196846008301
2025-04-17 13:41:06,409 - ***** Epoch: 81: Eval results *****
2025-04-17 13:41:06,410 -   train_loss = 5.427685737609863
2025-04-17 13:41:07,129 - ***** Epoch: 82: Eval results *****
2025-04-17 13:41:07,129 -   train_loss = 5.415224552154541
2025-04-17 13:41:07,850 - ***** Epoch: 83: Eval results *****
2025-04-17 13:41:07,850 -   train_loss = 5.406276226043701
2025-04-17 13:41:08,581 - ***** Epoch: 84: Eval results *****
2025-04-17 13:41:08,582 -   train_loss = 5.388379096984863
2025-04-17 13:41:09,309 - ***** Epoch: 85: Eval results *****
2025-04-17 13:41:09,309 -   train_loss = 5.389413833618164
2025-04-17 13:41:10,028 - ***** Epoch: 86: Eval results *****
2025-04-17 13:41:10,029 -   train_loss = 5.388903617858887
2025-04-17 13:41:10,747 - ***** Epoch: 87: Eval results *****
2025-04-17 13:41:10,748 -   train_loss = 5.383122444152832
2025-04-17 13:41:11,500 - ***** Epoch: 88: Eval results *****
2025-04-17 13:41:11,501 -   train_loss = 5.3524017333984375
2025-04-17 13:41:12,236 - ***** Epoch: 89: Eval results *****
2025-04-17 13:41:12,237 -   train_loss = 5.358279705047607
2025-04-17 13:41:12,968 - ***** Epoch: 90: Eval results *****
2025-04-17 13:41:12,969 -   train_loss = 5.338038444519043
2025-04-17 13:41:13,704 - ***** Epoch: 91: Eval results *****
2025-04-17 13:41:13,704 -   train_loss = 5.33243465423584
2025-04-17 13:41:14,411 - ***** Epoch: 92: Eval results *****
2025-04-17 13:41:14,412 -   train_loss = 5.3180413246154785
2025-04-17 13:41:15,136 - ***** Epoch: 93: Eval results *****
2025-04-17 13:41:15,137 -   train_loss = 5.318874835968018
2025-04-17 13:41:15,845 - ***** Epoch: 94: Eval results *****
2025-04-17 13:41:15,845 -   train_loss = 5.303767681121826
2025-04-17 13:41:16,539 - ***** Epoch: 95: Eval results *****
2025-04-17 13:41:16,539 -   train_loss = 5.2928571701049805
2025-04-17 13:41:17,262 - ***** Epoch: 96: Eval results *****
2025-04-17 13:41:17,263 -   train_loss = 5.293377876281738
2025-04-17 13:41:17,974 - ***** Epoch: 97: Eval results *****
2025-04-17 13:41:17,974 -   train_loss = 5.274877548217773
2025-04-17 13:41:18,624 - ***** Epoch: 98: Eval results *****
2025-04-17 13:41:18,625 -   train_loss = 5.262829303741455
2025-04-17 13:41:19,284 - ***** Epoch: 99: Eval results *****
2025-04-17 13:41:19,284 -   train_loss = 5.268977165222168
2025-04-17 13:41:19,942 - ***** Epoch: 100: Eval results *****
2025-04-17 13:41:19,943 -   train_loss = 5.251152515411377
2025-04-17 13:41:21,605 - Pre-training finished...
2025-04-17 13:41:21,926 - Freeze all parameters but the last layer for efficiency
2025-04-17 13:41:21,934 - Multimodal Intent Recognition begins...
2025-04-17 13:41:21,934 - Training begins...
2025-04-17 13:41:33,258 - Initializing centroids with K-means++...
2025-04-17 13:41:33,316 - K-means++ used 0.06 s
2025-04-17 13:42:02,207 - K-means used 0.13 s
2025-04-17 13:42:03,474 - ***** Epoch: 1 *****
2025-04-17 13:42:03,474 - Supervised Training Loss: 5.187940
2025-04-17 13:42:03,474 - Unsupervised Training Loss: 5.817500
2025-04-17 13:42:32,336 - K-means used 0.02 s
2025-04-17 13:42:33,584 - ***** Epoch: 2 *****
2025-04-17 13:42:33,584 - Supervised Training Loss: 4.024030
2025-04-17 13:42:33,584 - Unsupervised Training Loss: 5.788440
2025-04-17 13:42:58,823 - K-means used 0.02 s
2025-04-17 13:43:00,253 - ***** Epoch: 3 *****
2025-04-17 13:43:00,253 - Supervised Training Loss: 5.264360
2025-04-17 13:43:00,253 - Unsupervised Training Loss: 5.549640
2025-04-17 13:43:31,104 - K-means used 0.15 s
2025-04-17 13:43:32,446 - ***** Epoch: 4 *****
2025-04-17 13:43:32,446 - Supervised Training Loss: 4.890860
2025-04-17 13:43:32,446 - Unsupervised Training Loss: 5.568240
2025-04-17 13:44:02,140 - K-means used 0.02 s
2025-04-17 13:44:03,448 - ***** Epoch: 5 *****
2025-04-17 13:44:03,449 - Supervised Training Loss: 4.540160
2025-04-17 13:44:03,449 - Unsupervised Training Loss: 5.578710
2025-04-17 13:44:35,199 - K-means used 0.14 s
2025-04-17 13:44:36,684 - ***** Epoch: 6 *****
2025-04-17 13:44:36,684 - Supervised Training Loss: 4.884010
2025-04-17 13:44:36,684 - Unsupervised Training Loss: 5.356860
2025-04-17 13:45:06,826 - K-means used 0.03 s
2025-04-17 13:45:08,068 - ***** Epoch: 7 *****
2025-04-17 13:45:08,069 - Supervised Training Loss: 4.771270
2025-04-17 13:45:08,069 - Unsupervised Training Loss: 5.481550
2025-04-17 13:45:35,208 - K-means used 0.14 s
2025-04-17 13:45:36,827 - ***** Epoch: 8 *****
2025-04-17 13:45:36,828 - Supervised Training Loss: 4.620260
2025-04-17 13:45:36,828 - Unsupervised Training Loss: 5.530850
2025-04-17 13:46:06,726 - K-means used 0.08 s
2025-04-17 13:46:08,149 - ***** Epoch: 9 *****
2025-04-17 13:46:08,149 - Supervised Training Loss: 4.800460
2025-04-17 13:46:08,149 - Unsupervised Training Loss: 5.568570
2025-04-17 13:46:33,800 - K-means used 0.13 s
2025-04-17 13:46:35,770 - ***** Epoch: 10 *****
2025-04-17 13:46:35,770 - Supervised Training Loss: 4.716430
2025-04-17 13:46:35,771 - Unsupervised Training Loss: 5.392380
2025-04-17 13:47:03,993 - K-means used 0.02 s
2025-04-17 13:47:05,421 - ***** Epoch: 11 *****
2025-04-17 13:47:05,421 - Supervised Training Loss: 4.614570
2025-04-17 13:47:05,421 - Unsupervised Training Loss: 5.484890
2025-04-17 13:47:32,297 - K-means used 0.15 s
2025-04-17 13:47:34,361 - ***** Epoch: 12 *****
2025-04-17 13:47:34,361 - Supervised Training Loss: 4.743780
2025-04-17 13:47:34,361 - Unsupervised Training Loss: 5.553060
2025-04-17 13:48:04,699 - K-means used 0.13 s
2025-04-17 13:48:06,886 - ***** Epoch: 13 *****
2025-04-17 13:48:06,887 - Supervised Training Loss: 4.712010
2025-04-17 13:48:06,887 - Unsupervised Training Loss: 5.270890
2025-04-17 13:48:35,079 - K-means used 0.01 s
2025-04-17 13:48:36,708 - ***** Epoch: 14 *****
2025-04-17 13:48:36,709 - Supervised Training Loss: 4.660040
2025-04-17 13:48:36,709 - Unsupervised Training Loss: 5.408110
2025-04-17 13:49:04,096 - K-means used 0.07 s
2025-04-17 13:49:06,604 - ***** Epoch: 15 *****
2025-04-17 13:49:06,604 - Supervised Training Loss: 4.474540
2025-04-17 13:49:06,604 - Unsupervised Training Loss: 5.525860
2025-04-17 13:49:34,458 - K-means used 0.02 s
2025-04-17 13:49:36,342 - ***** Epoch: 16 *****
2025-04-17 13:49:36,342 - Supervised Training Loss: 4.730650
2025-04-17 13:49:36,342 - Unsupervised Training Loss: 4.978430
2025-04-17 13:50:02,809 - K-means used 0.1 s
2025-04-17 13:50:05,677 - ***** Epoch: 17 *****
2025-04-17 13:50:05,677 - Supervised Training Loss: 4.710920
2025-04-17 13:50:05,677 - Unsupervised Training Loss: 5.181650
2025-04-17 13:50:24,372 - Training is finished...
2025-04-17 13:50:24,372 - Testing begins...
2025-04-17 13:50:31,657 - ***** Test results *****
2025-04-17 13:50:31,657 -   ACC = 28.09
2025-04-17 13:50:31,657 -   ARI = 10.65
2025-04-17 13:50:31,657 -   NMI = 35.67
2025-04-17 13:50:31,657 -   fmi = 16.28
2025-04-17 13:50:31,657 - Testing is finished...
2025-04-17 13:50:31,658 - Multimodal intent recognition is finished...
2025-04-17 13:50:31,658 - Results are saved in results/results_umc_pre.csv
