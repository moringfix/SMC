2025-04-11 04:46:39,153 - ============================== Params ==============================
2025-04-11 04:46:39,153 - logger_name: umc_umc_bert-base-uncased_MIntRec_3
2025-04-11 04:46:39,153 - dataset: MIntRec
2025-04-11 04:46:39,153 - multimodal_method: umc
2025-04-11 04:46:39,153 - method: umc
2025-04-11 04:46:39,153 - text_backbone: bert-base-uncased
2025-04-11 04:46:39,153 - seed: 3
2025-04-11 04:46:39,153 - num_workers: 16
2025-04-11 04:46:39,153 - log_id: umc_umc_bert-base-uncased_MIntRec_3_2025-04-11-04-46-39
2025-04-11 04:46:39,153 - gpu_id: 0
2025-04-11 04:46:39,153 - data_path: /root/autodl-tmp/home/Share/Dataset/LZH
2025-04-11 04:46:39,153 - train: True
2025-04-11 04:46:39,153 - tune: True
2025-04-11 04:46:39,153 - save_model: True
2025-04-11 04:46:39,153 - save_results: True
2025-04-11 04:46:39,153 - log_path: logs
2025-04-11 04:46:39,153 - cache_path: cache
2025-04-11 04:46:39,154 - video_data_path: video_data
2025-04-11 04:46:39,154 - audio_data_path: audio_data
2025-04-11 04:46:39,154 - video_feats_path: swin_feats.pkl
2025-04-11 04:46:39,154 - audio_feats_path: wavlm_feats.pkl
2025-04-11 04:46:39,154 - results_path: results
2025-04-11 04:46:39,154 - output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/UMC/outputs/MIntRec
2025-04-11 04:46:39,154 - model_path: models
2025-04-11 04:46:39,154 - config_file_name: umc_MIntRec
2025-04-11 04:46:39,154 - results_file_name: results_umc.csv
2025-04-11 04:46:39,154 - text_pretrained_model: uncased_L-12_H-768_A-12
2025-04-11 04:46:39,154 - text_seq_len: 30
2025-04-11 04:46:39,154 - video_seq_len: 230
2025-04-11 04:46:39,154 - audio_seq_len: 480
2025-04-11 04:46:39,154 - text_feat_dim: 768
2025-04-11 04:46:39,154 - video_feat_dim: 1024
2025-04-11 04:46:39,154 - audio_feat_dim: 768
2025-04-11 04:46:39,154 - num_labels: 20
2025-04-11 04:46:39,154 - num_train_examples: 1779
2025-04-11 04:46:39,154 - pretrained_bert_model: uncased_L-12_H-768_A-12
2025-04-11 04:46:39,154 - pretrain_batch_size: 128
2025-04-11 04:46:39,154 - train_batch_size: 128
2025-04-11 04:46:39,154 - eval_batch_size: 128
2025-04-11 04:46:39,154 - test_batch_size: 128
2025-04-11 04:46:39,154 - num_pretrain_epochs: 100
2025-04-11 04:46:39,154 - num_train_epochs: 100
2025-04-11 04:46:39,154 - pretrain: [True]
2025-04-11 04:46:39,154 - aligned_method: ctc
2025-04-11 04:46:39,154 - need_aligned: False
2025-04-11 04:46:39,154 - freeze_pretrain_bert_parameters: [True]
2025-04-11 04:46:39,155 - freeze_train_bert_parameters: [True]
2025-04-11 04:46:39,155 - pretrain_temperature: [0.2]
2025-04-11 04:46:39,155 - train_temperature_sup: [1.4]
2025-04-11 04:46:39,155 - train_temperature_unsup: [1]
2025-04-11 04:46:39,155 - activation: tanh
2025-04-11 04:46:39,155 - lr_pre: 5e-06
2025-04-11 04:46:39,155 - lr: [0.0003]
2025-04-11 04:46:39,155 - delta: [0.05]
2025-04-11 04:46:39,155 - thres: [0.1]
2025-04-11 04:46:39,155 - topk: [5]
2025-04-11 04:46:39,155 - weight_decay: 0.01
2025-04-11 04:46:39,155 - feat_dim: 768
2025-04-11 04:46:39,155 - hidden_size: 768
2025-04-11 04:46:39,155 - grad_clip: -1.0
2025-04-11 04:46:39,155 - warmup_proportion: 0.5
2025-04-11 04:46:39,155 - hidden_dropout_prob: 0.1
2025-04-11 04:46:39,156 - weight: 1.0
2025-04-11 04:46:39,156 - loss_mode: rdrop
2025-04-11 04:46:39,156 - base_dim: 256
2025-04-11 04:46:39,156 - nheads: 8
2025-04-11 04:46:39,156 - attn_dropout: 0.1
2025-04-11 04:46:39,156 - relu_dropout: 0.1
2025-04-11 04:46:39,156 - embed_dropout: 0.1
2025-04-11 04:46:39,156 - res_dropout: 0.0
2025-04-11 04:46:39,156 - attn_mask: True
2025-04-11 04:46:39,156 - encoder_layers_1: 1
2025-04-11 04:46:39,156 - fusion_act: tanh
2025-04-11 04:46:39,156 - pred_output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/UMC/outputs/MIntRec/umc_umc_MIntRec_bert-base-uncased_3
2025-04-11 04:46:39,156 - model_output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/UMC/outputs/MIntRec/umc_umc_MIntRec_bert-base-uncased_3/models
2025-04-11 04:46:39,156 - ============================== End Params ==============================
2025-04-11 04:46:40,314 - Freeze all parameters but the last layer for efficiency
2025-04-11 04:46:40,349 - Pre-training start...
2025-04-11 04:46:55,455 - ***** Epoch: 1: Eval results *****
2025-04-11 04:46:55,456 -   train_loss = 5.937821558543614
2025-04-11 04:47:09,477 - ***** Epoch: 2: Eval results *****
2025-04-11 04:47:09,477 -   train_loss = 5.9393132754734586
2025-04-11 04:47:25,426 - ***** Epoch: 3: Eval results *****
2025-04-11 04:47:25,427 -   train_loss = 5.943385464804513
2025-04-11 04:47:41,598 - ***** Epoch: 4: Eval results *****
2025-04-11 04:47:41,598 -   train_loss = 5.940493140901838
2025-04-11 04:47:56,709 - ***** Epoch: 5: Eval results *****
2025-04-11 04:47:56,709 -   train_loss = 5.943325042724609
2025-04-11 04:48:12,704 - ***** Epoch: 6: Eval results *****
2025-04-11 04:48:12,704 -   train_loss = 5.94180154800415
2025-04-11 04:48:28,673 - ***** Epoch: 7: Eval results *****
2025-04-11 04:48:28,674 -   train_loss = 5.941987821034023
2025-04-11 04:48:44,731 - ***** Epoch: 8: Eval results *****
2025-04-11 04:48:44,732 -   train_loss = 5.943038122994559
2025-04-11 04:49:01,021 - ***** Epoch: 9: Eval results *****
2025-04-11 04:49:01,021 -   train_loss = 5.937992095947266
2025-04-11 04:49:17,302 - ***** Epoch: 10: Eval results *****
2025-04-11 04:49:17,302 -   train_loss = 5.9397350038800925
2025-04-11 04:49:33,346 - ***** Epoch: 11: Eval results *****
2025-04-11 04:49:33,347 -   train_loss = 5.941067184720721
2025-04-11 04:49:50,070 - ***** Epoch: 12: Eval results *****
2025-04-11 04:49:50,070 -   train_loss = 5.934883730752127
2025-04-11 04:50:06,439 - ***** Epoch: 13: Eval results *****
2025-04-11 04:50:06,439 -   train_loss = 5.93888521194458
2025-04-11 04:50:22,745 - ***** Epoch: 14: Eval results *****
2025-04-11 04:50:22,745 -   train_loss = 5.931131941931588
2025-04-11 04:50:39,473 - ***** Epoch: 15: Eval results *****
2025-04-11 04:50:39,473 -   train_loss = 5.927985395703997
2025-04-11 04:50:55,379 - ***** Epoch: 16: Eval results *****
2025-04-11 04:50:55,380 -   train_loss = 5.9340940202985495
2025-04-11 04:51:11,515 - ***** Epoch: 17: Eval results *****
2025-04-11 04:51:11,515 -   train_loss = 5.925230469022479
2025-04-11 04:51:27,369 - ***** Epoch: 18: Eval results *****
2025-04-11 04:51:27,370 -   train_loss = 5.918462072099958
2025-04-11 04:51:43,572 - ***** Epoch: 19: Eval results *****
2025-04-11 04:51:43,572 -   train_loss = 5.921144076756069
2025-04-11 04:51:59,790 - ***** Epoch: 20: Eval results *****
2025-04-11 04:51:59,790 -   train_loss = 5.917025327682495
2025-04-11 04:52:15,969 - ***** Epoch: 21: Eval results *****
2025-04-11 04:52:15,970 -   train_loss = 5.909182071685791
2025-04-11 04:52:32,117 - ***** Epoch: 22: Eval results *****
2025-04-11 04:52:32,118 -   train_loss = 5.896153926849365
2025-04-11 04:52:47,938 - ***** Epoch: 23: Eval results *****
2025-04-11 04:52:47,938 -   train_loss = 5.882523672921317
2025-04-11 04:53:04,179 - ***** Epoch: 24: Eval results *****
2025-04-11 04:53:04,180 -   train_loss = 5.869457721710205
2025-04-11 04:53:20,108 - ***** Epoch: 25: Eval results *****
2025-04-11 04:53:20,108 -   train_loss = 5.842216219220843
2025-04-11 04:53:35,615 - ***** Epoch: 26: Eval results *****
2025-04-11 04:53:35,615 -   train_loss = 5.812280723026821
2025-04-11 04:53:51,132 - ***** Epoch: 27: Eval results *****
2025-04-11 04:53:51,132 -   train_loss = 5.767275299344744
2025-04-11 04:54:06,970 - ***** Epoch: 28: Eval results *****
2025-04-11 04:54:06,970 -   train_loss = 5.702700410570417
2025-04-11 04:54:23,361 - ***** Epoch: 29: Eval results *****
2025-04-11 04:54:23,362 -   train_loss = 5.616892508098057
2025-04-11 04:54:39,654 - ***** Epoch: 30: Eval results *****
2025-04-11 04:54:39,654 -   train_loss = 5.497852666037423
2025-04-11 04:54:55,716 - ***** Epoch: 31: Eval results *****
2025-04-11 04:54:55,716 -   train_loss = 5.366437230791364
2025-04-11 04:55:12,229 - ***** Epoch: 32: Eval results *****
2025-04-11 04:55:12,229 -   train_loss = 5.236021620886667
2025-04-11 04:55:28,667 - ***** Epoch: 33: Eval results *****
2025-04-11 04:55:28,668 -   train_loss = 5.080021313258579
2025-04-11 04:55:44,803 - ***** Epoch: 34: Eval results *****
2025-04-11 04:55:44,803 -   train_loss = 4.96843079158238
2025-04-11 04:56:00,682 - ***** Epoch: 35: Eval results *****
2025-04-11 04:56:00,682 -   train_loss = 4.8521656308855325
2025-04-11 04:56:16,113 - ***** Epoch: 36: Eval results *****
2025-04-11 04:56:16,113 -   train_loss = 4.745799132755825
2025-04-11 04:56:31,778 - ***** Epoch: 37: Eval results *****
2025-04-11 04:56:31,778 -   train_loss = 4.643052067075457
2025-04-11 04:56:46,914 - ***** Epoch: 38: Eval results *****
2025-04-11 04:56:46,914 -   train_loss = 4.566123962402344
2025-04-11 04:57:03,926 - ***** Epoch: 39: Eval results *****
2025-04-11 04:57:03,927 -   train_loss = 4.479687690734863
2025-04-11 04:57:20,715 - ***** Epoch: 40: Eval results *****
2025-04-11 04:57:20,715 -   train_loss = 4.413159813199725
2025-04-11 04:57:37,683 - ***** Epoch: 41: Eval results *****
2025-04-11 04:57:37,684 -   train_loss = 4.328657831464495
2025-04-11 04:57:53,988 - ***** Epoch: 42: Eval results *****
2025-04-11 04:57:53,989 -   train_loss = 4.255688156400408
2025-04-11 04:58:10,881 - ***** Epoch: 43: Eval results *****
2025-04-11 04:58:10,881 -   train_loss = 4.17992775780814
2025-04-11 04:58:27,749 - ***** Epoch: 44: Eval results *****
2025-04-11 04:58:27,749 -   train_loss = 4.105998873710632
2025-04-11 04:58:44,761 - ***** Epoch: 45: Eval results *****
2025-04-11 04:58:44,761 -   train_loss = 4.0545936822891235
2025-04-11 04:59:01,027 - ***** Epoch: 46: Eval results *****
2025-04-11 04:59:01,027 -   train_loss = 3.988034623009818
2025-04-11 04:59:17,345 - ***** Epoch: 47: Eval results *****
2025-04-11 04:59:17,345 -   train_loss = 3.931699514389038
2025-04-11 04:59:33,642 - ***** Epoch: 48: Eval results *****
2025-04-11 04:59:33,643 -   train_loss = 3.881458503859384
2025-04-11 04:59:50,744 - ***** Epoch: 49: Eval results *****
2025-04-11 04:59:50,744 -   train_loss = 3.824226004736764
2025-04-11 05:00:07,618 - ***** Epoch: 50: Eval results *****
2025-04-11 05:00:07,620 -   train_loss = 3.7787449530192783
2025-04-11 05:00:25,008 - ***** Epoch: 51: Eval results *****
2025-04-11 05:00:25,008 -   train_loss = 3.730979016848973
2025-04-11 05:00:42,151 - ***** Epoch: 52: Eval results *****
2025-04-11 05:00:42,151 -   train_loss = 3.7084419216428484
2025-04-11 05:00:58,853 - ***** Epoch: 53: Eval results *****
2025-04-11 05:00:58,854 -   train_loss = 3.6685463190078735
2025-04-11 05:01:15,549 - ***** Epoch: 54: Eval results *****
2025-04-11 05:01:15,550 -   train_loss = 3.6302550520215715
2025-04-11 05:01:32,332 - ***** Epoch: 55: Eval results *****
2025-04-11 05:01:32,333 -   train_loss = 3.6113984414509366
2025-04-11 05:01:49,116 - ***** Epoch: 56: Eval results *****
2025-04-11 05:01:49,116 -   train_loss = 3.57200072492872
2025-04-11 05:02:06,554 - ***** Epoch: 57: Eval results *****
2025-04-11 05:02:06,554 -   train_loss = 3.5564394678388322
2025-04-11 05:02:24,326 - ***** Epoch: 58: Eval results *****
2025-04-11 05:02:24,326 -   train_loss = 3.532895428793771
2025-04-11 05:02:41,184 - ***** Epoch: 59: Eval results *****
2025-04-11 05:02:41,184 -   train_loss = 3.514082840510777
2025-04-11 05:02:57,467 - ***** Epoch: 60: Eval results *****
2025-04-11 05:02:57,467 -   train_loss = 3.4920198576790944
2025-04-11 05:03:14,265 - ***** Epoch: 61: Eval results *****
2025-04-11 05:03:14,266 -   train_loss = 3.48015068258558
2025-04-11 05:03:30,764 - ***** Epoch: 62: Eval results *****
2025-04-11 05:03:30,765 -   train_loss = 3.459546446800232
2025-04-11 05:03:47,571 - ***** Epoch: 63: Eval results *****
2025-04-11 05:03:47,571 -   train_loss = 3.4317459889820645
2025-04-11 05:04:04,163 - ***** Epoch: 64: Eval results *****
2025-04-11 05:04:04,164 -   train_loss = 3.415055070604597
2025-04-11 05:04:20,698 - ***** Epoch: 65: Eval results *****
2025-04-11 05:04:20,699 -   train_loss = 3.4157049315316335
2025-04-11 05:04:38,158 - ***** Epoch: 66: Eval results *****
2025-04-11 05:04:38,158 -   train_loss = 3.39908834866115
2025-04-11 05:04:55,373 - ***** Epoch: 67: Eval results *****
2025-04-11 05:04:55,374 -   train_loss = 3.3855989830834523
2025-04-11 05:05:11,978 - ***** Epoch: 68: Eval results *****
2025-04-11 05:05:11,979 -   train_loss = 3.3779279674802507
2025-04-11 05:05:28,621 - ***** Epoch: 69: Eval results *****
2025-04-11 05:05:28,621 -   train_loss = 3.3667660781315396
2025-04-11 05:05:45,529 - ***** Epoch: 70: Eval results *****
2025-04-11 05:05:45,530 -   train_loss = 3.3549500703811646
2025-04-11 05:06:02,051 - ***** Epoch: 71: Eval results *****
2025-04-11 05:06:02,051 -   train_loss = 3.3348871980394637
2025-04-11 05:06:18,217 - ***** Epoch: 72: Eval results *****
2025-04-11 05:06:18,217 -   train_loss = 3.334055645125253
2025-04-11 05:06:34,330 - ***** Epoch: 73: Eval results *****
2025-04-11 05:06:34,330 -   train_loss = 3.3174358095441545
2025-04-11 05:06:49,774 - ***** Epoch: 74: Eval results *****
2025-04-11 05:06:49,775 -   train_loss = 3.3103004353387013
2025-04-11 05:07:05,456 - ***** Epoch: 75: Eval results *****
2025-04-11 05:07:05,456 -   train_loss = 3.3274594375065396
2025-04-11 05:07:21,451 - ***** Epoch: 76: Eval results *****
2025-04-11 05:07:21,451 -   train_loss = 3.314460447856358
2025-04-11 05:07:36,781 - ***** Epoch: 77: Eval results *****
2025-04-11 05:07:36,781 -   train_loss = 3.2884001220975603
2025-04-11 05:07:52,083 - ***** Epoch: 78: Eval results *****
2025-04-11 05:07:52,083 -   train_loss = 3.2930374997002736
2025-04-11 05:08:07,921 - ***** Epoch: 79: Eval results *****
2025-04-11 05:08:07,921 -   train_loss = 3.2892033883503506
2025-04-11 05:08:24,957 - ***** Epoch: 80: Eval results *****
2025-04-11 05:08:24,957 -   train_loss = 3.286862322262355
2025-04-11 05:08:42,204 - ***** Epoch: 81: Eval results *****
2025-04-11 05:08:42,204 -   train_loss = 3.276580504008702
2025-04-11 05:08:59,150 - ***** Epoch: 82: Eval results *****
2025-04-11 05:08:59,151 -   train_loss = 3.2596204451152255
2025-04-11 05:09:16,326 - ***** Epoch: 83: Eval results *****
2025-04-11 05:09:16,326 -   train_loss = 3.2652111734662737
2025-04-11 05:09:33,605 - ***** Epoch: 84: Eval results *****
2025-04-11 05:09:33,605 -   train_loss = 3.258371216910226
2025-04-11 05:09:49,666 - ***** Epoch: 85: Eval results *****
2025-04-11 05:09:49,666 -   train_loss = 3.2685831444604054
2025-04-11 05:10:06,006 - ***** Epoch: 86: Eval results *****
2025-04-11 05:10:06,007 -   train_loss = 3.2609358515058244
2025-04-11 05:10:22,174 - ***** Epoch: 87: Eval results *****
2025-04-11 05:10:22,175 -   train_loss = 3.257926208632333
2025-04-11 05:10:38,573 - ***** Epoch: 88: Eval results *****
2025-04-11 05:10:38,573 -   train_loss = 3.25723397731781
2025-04-11 05:10:54,924 - ***** Epoch: 89: Eval results *****
2025-04-11 05:10:54,924 -   train_loss = 3.2495035443987166
2025-04-11 05:11:10,907 - ***** Epoch: 90: Eval results *****
2025-04-11 05:11:10,907 -   train_loss = 3.250448601586478
2025-04-11 05:11:26,927 - ***** Epoch: 91: Eval results *****
2025-04-11 05:11:26,928 -   train_loss = 3.252948726926531
2025-04-11 05:11:41,645 - ***** Epoch: 92: Eval results *****
2025-04-11 05:11:41,645 -   train_loss = 3.2433927399771556
2025-04-11 05:11:56,614 - ***** Epoch: 93: Eval results *****
2025-04-11 05:11:56,614 -   train_loss = 3.257072619029454
2025-04-11 05:12:12,037 - ***** Epoch: 94: Eval results *****
2025-04-11 05:12:12,037 -   train_loss = 3.2460080555507114
2025-04-11 05:12:27,565 - ***** Epoch: 95: Eval results *****
2025-04-11 05:12:27,565 -   train_loss = 3.230388675417219
2025-04-11 05:12:42,866 - ***** Epoch: 96: Eval results *****
2025-04-11 05:12:42,866 -   train_loss = 3.250078797340393
2025-04-11 05:12:58,657 - ***** Epoch: 97: Eval results *****
2025-04-11 05:12:58,657 -   train_loss = 3.248259884970529
2025-04-11 05:13:13,831 - ***** Epoch: 98: Eval results *****
2025-04-11 05:13:13,831 -   train_loss = 3.260951893670218
2025-04-11 05:13:29,329 - ***** Epoch: 99: Eval results *****
2025-04-11 05:13:29,329 -   train_loss = 3.2468481234141757
2025-04-11 05:13:45,025 - ***** Epoch: 100: Eval results *****
2025-04-11 05:13:45,025 -   train_loss = 3.2485176665442332
2025-04-11 05:13:45,590 - Pre-training finished...
2025-04-11 05:13:45,841 - Freeze all parameters but the last layer for efficiency
2025-04-11 05:13:45,850 - Multimodal Intent Recognition begins...
2025-04-11 05:13:45,850 - Training begins...
2025-04-11 05:14:02,255 - Initializing centroids with K-means++...
2025-04-11 05:14:02,408 - K-means++ used 0.15 s
2025-04-11 05:14:35,198 - K-means used 0.17 s
2025-04-11 05:14:36,670 - ***** Epoch: 1 *****
2025-04-11 05:14:36,670 - Supervised Training Loss: 4.889460
2025-04-11 05:14:36,671 - Unsupervised Training Loss: 5.185820
2025-04-11 05:15:11,619 - K-means used 0.03 s
2025-04-11 05:15:12,985 - ***** Epoch: 2 *****
2025-04-11 05:15:12,986 - Supervised Training Loss: 4.210180
2025-04-11 05:15:12,986 - Unsupervised Training Loss: 5.196740
2025-04-11 05:15:47,818 - K-means used 0.11 s
2025-04-11 05:15:49,259 - ***** Epoch: 3 *****
2025-04-11 05:15:49,260 - Supervised Training Loss: 5.347870
2025-04-11 05:15:49,260 - Unsupervised Training Loss: 5.048550
2025-04-11 05:16:18,732 - K-means used 0.02 s
2025-04-11 05:16:20,134 - ***** Epoch: 4 *****
2025-04-11 05:16:20,135 - Supervised Training Loss: 5.215470
2025-04-11 05:16:20,135 - Unsupervised Training Loss: 5.104360
2025-04-11 05:16:51,096 - K-means used 0.15 s
2025-04-11 05:16:52,523 - ***** Epoch: 5 *****
2025-04-11 05:16:52,524 - Supervised Training Loss: 4.941540
2025-04-11 05:16:52,524 - Unsupervised Training Loss: 5.138540
2025-04-11 05:17:22,316 - K-means used 0.02 s
2025-04-11 05:17:23,708 - ***** Epoch: 6 *****
2025-04-11 05:17:23,708 - Supervised Training Loss: 5.345750
2025-04-11 05:17:23,709 - Unsupervised Training Loss: 4.940430
2025-04-11 05:17:54,796 - K-means used 0.15 s
2025-04-11 05:17:56,449 - ***** Epoch: 7 *****
2025-04-11 05:17:56,450 - Supervised Training Loss: 5.260590
2025-04-11 05:17:56,450 - Unsupervised Training Loss: 5.045630
2025-04-11 05:18:26,675 - K-means used 0.02 s
2025-04-11 05:18:28,176 - ***** Epoch: 8 *****
2025-04-11 05:18:28,176 - Supervised Training Loss: 5.131520
2025-04-11 05:18:28,176 - Unsupervised Training Loss: 5.089350
2025-04-11 05:18:58,798 - K-means used 0.1 s
2025-04-11 05:19:00,632 - ***** Epoch: 9 *****
2025-04-11 05:19:00,632 - Supervised Training Loss: 5.344820
2025-04-11 05:19:00,632 - Unsupervised Training Loss: 5.131770
2025-04-11 05:19:29,308 - K-means used 0.06 s
2025-04-11 05:19:30,964 - ***** Epoch: 10 *****
2025-04-11 05:19:30,965 - Supervised Training Loss: 5.276860
2025-04-11 05:19:30,965 - Unsupervised Training Loss: 4.971660
2025-04-11 05:20:00,496 - K-means used 0.11 s
2025-04-11 05:20:02,722 - ***** Epoch: 11 *****
2025-04-11 05:20:02,722 - Supervised Training Loss: 5.190530
2025-04-11 05:20:02,722 - Unsupervised Training Loss: 5.038050
2025-04-11 05:20:32,406 - K-means used 0.07 s
2025-04-11 05:20:34,224 - ***** Epoch: 12 *****
2025-04-11 05:20:34,224 - Supervised Training Loss: 5.328490
2025-04-11 05:20:34,224 - Unsupervised Training Loss: 5.104630
2025-04-11 05:21:08,401 - K-means used 0.02 s
2025-04-11 05:21:10,613 - ***** Epoch: 13 *****
2025-04-11 05:21:10,613 - Supervised Training Loss: 5.288980
2025-04-11 05:21:10,614 - Unsupervised Training Loss: 4.819980
2025-04-11 05:21:42,105 - K-means used 0.04 s
2025-04-11 05:21:44,117 - ***** Epoch: 14 *****
2025-04-11 05:21:44,117 - Supervised Training Loss: 5.241780
2025-04-11 05:21:44,117 - Unsupervised Training Loss: 4.946910
2025-04-11 05:22:18,217 - K-means used 0.1 s
2025-04-11 05:22:20,921 - ***** Epoch: 15 *****
2025-04-11 05:22:20,922 - Supervised Training Loss: 5.074420
2025-04-11 05:22:20,922 - Unsupervised Training Loss: 5.058930
2025-04-11 05:22:50,224 - K-means used 0.02 s
2025-04-11 05:22:52,217 - ***** Epoch: 16 *****
2025-04-11 05:22:52,217 - Supervised Training Loss: 5.307790
2025-04-11 05:22:52,217 - Unsupervised Training Loss: 4.484830
2025-04-11 05:23:24,364 - K-means used 0.05 s
2025-04-11 05:23:27,353 - ***** Epoch: 17 *****
2025-04-11 05:23:27,353 - Supervised Training Loss: 5.272530
2025-04-11 05:23:27,354 - Unsupervised Training Loss: 4.731330
2025-04-11 05:23:46,944 - Training is finished...
2025-04-11 05:23:46,944 - Testing begins...
2025-04-11 05:23:54,308 - ***** Test results *****
2025-04-11 05:23:54,308 -   ACC = 36.85
2025-04-11 05:23:54,308 -   ARI = 19.04
2025-04-11 05:23:54,308 -   NMI = 41.13
2025-04-11 05:23:54,308 -   fmi = 24.46
2025-04-11 05:23:54,309 - Testing is finished...
2025-04-11 05:23:54,309 - Multimodal intent recognition is finished...
2025-04-11 05:23:54,309 - Results are saved in results/results_umc.csv
