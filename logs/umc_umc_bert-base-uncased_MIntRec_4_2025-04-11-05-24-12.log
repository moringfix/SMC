2025-04-11 05:24:12,369 - ============================== Params ==============================
2025-04-11 05:24:12,369 - logger_name: umc_umc_bert-base-uncased_MIntRec_4
2025-04-11 05:24:12,369 - dataset: MIntRec
2025-04-11 05:24:12,369 - multimodal_method: umc
2025-04-11 05:24:12,369 - method: umc
2025-04-11 05:24:12,369 - text_backbone: bert-base-uncased
2025-04-11 05:24:12,369 - seed: 4
2025-04-11 05:24:12,369 - num_workers: 16
2025-04-11 05:24:12,369 - log_id: umc_umc_bert-base-uncased_MIntRec_4_2025-04-11-05-24-12
2025-04-11 05:24:12,369 - gpu_id: 0
2025-04-11 05:24:12,369 - data_path: /root/autodl-tmp/home/Share/Dataset/LZH
2025-04-11 05:24:12,369 - train: True
2025-04-11 05:24:12,369 - tune: True
2025-04-11 05:24:12,369 - save_model: True
2025-04-11 05:24:12,369 - save_results: True
2025-04-11 05:24:12,370 - log_path: logs
2025-04-11 05:24:12,370 - cache_path: cache
2025-04-11 05:24:12,370 - video_data_path: video_data
2025-04-11 05:24:12,370 - audio_data_path: audio_data
2025-04-11 05:24:12,370 - video_feats_path: swin_feats.pkl
2025-04-11 05:24:12,370 - audio_feats_path: wavlm_feats.pkl
2025-04-11 05:24:12,370 - results_path: results
2025-04-11 05:24:12,370 - output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/UMC/outputs/MIntRec
2025-04-11 05:24:12,370 - model_path: models
2025-04-11 05:24:12,370 - config_file_name: umc_MIntRec
2025-04-11 05:24:12,370 - results_file_name: results_umc.csv
2025-04-11 05:24:12,370 - text_pretrained_model: uncased_L-12_H-768_A-12
2025-04-11 05:24:12,370 - text_seq_len: 30
2025-04-11 05:24:12,370 - video_seq_len: 230
2025-04-11 05:24:12,370 - audio_seq_len: 480
2025-04-11 05:24:12,370 - text_feat_dim: 768
2025-04-11 05:24:12,370 - video_feat_dim: 1024
2025-04-11 05:24:12,370 - audio_feat_dim: 768
2025-04-11 05:24:12,370 - num_labels: 20
2025-04-11 05:24:12,370 - num_train_examples: 1779
2025-04-11 05:24:12,370 - pretrained_bert_model: uncased_L-12_H-768_A-12
2025-04-11 05:24:12,370 - pretrain_batch_size: 128
2025-04-11 05:24:12,370 - train_batch_size: 128
2025-04-11 05:24:12,370 - eval_batch_size: 128
2025-04-11 05:24:12,370 - test_batch_size: 128
2025-04-11 05:24:12,370 - num_pretrain_epochs: 100
2025-04-11 05:24:12,370 - num_train_epochs: 100
2025-04-11 05:24:12,370 - pretrain: [True]
2025-04-11 05:24:12,370 - aligned_method: ctc
2025-04-11 05:24:12,370 - need_aligned: False
2025-04-11 05:24:12,370 - freeze_pretrain_bert_parameters: [True]
2025-04-11 05:24:12,371 - freeze_train_bert_parameters: [True]
2025-04-11 05:24:12,371 - pretrain_temperature: [0.2]
2025-04-11 05:24:12,371 - train_temperature_sup: [1.4]
2025-04-11 05:24:12,371 - train_temperature_unsup: [1]
2025-04-11 05:24:12,371 - activation: tanh
2025-04-11 05:24:12,371 - lr_pre: 5e-06
2025-04-11 05:24:12,371 - lr: [0.0003]
2025-04-11 05:24:12,371 - delta: [0.05]
2025-04-11 05:24:12,371 - thres: [0.1]
2025-04-11 05:24:12,371 - topk: [5]
2025-04-11 05:24:12,371 - weight_decay: 0.01
2025-04-11 05:24:12,371 - feat_dim: 768
2025-04-11 05:24:12,371 - hidden_size: 768
2025-04-11 05:24:12,371 - grad_clip: -1.0
2025-04-11 05:24:12,371 - warmup_proportion: 0.5
2025-04-11 05:24:12,372 - hidden_dropout_prob: 0.1
2025-04-11 05:24:12,372 - weight: 1.0
2025-04-11 05:24:12,372 - loss_mode: rdrop
2025-04-11 05:24:12,372 - base_dim: 256
2025-04-11 05:24:12,372 - nheads: 8
2025-04-11 05:24:12,372 - attn_dropout: 0.1
2025-04-11 05:24:12,372 - relu_dropout: 0.1
2025-04-11 05:24:12,372 - embed_dropout: 0.1
2025-04-11 05:24:12,372 - res_dropout: 0.0
2025-04-11 05:24:12,372 - attn_mask: True
2025-04-11 05:24:12,372 - encoder_layers_1: 1
2025-04-11 05:24:12,372 - fusion_act: tanh
2025-04-11 05:24:12,372 - pred_output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/UMC/outputs/MIntRec/umc_umc_MIntRec_bert-base-uncased_4
2025-04-11 05:24:12,372 - model_output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/UMC/outputs/MIntRec/umc_umc_MIntRec_bert-base-uncased_4/models
2025-04-11 05:24:12,372 - ============================== End Params ==============================
2025-04-11 05:24:13,492 - Freeze all parameters but the last layer for efficiency
2025-04-11 05:24:13,526 - Pre-training start...
2025-04-11 05:24:28,335 - ***** Epoch: 1: Eval results *****
2025-04-11 05:24:28,336 -   train_loss = 5.944475105830601
2025-04-11 05:24:42,010 - ***** Epoch: 2: Eval results *****
2025-04-11 05:24:42,010 -   train_loss = 5.94691344669887
2025-04-11 05:24:57,020 - ***** Epoch: 3: Eval results *****
2025-04-11 05:24:57,021 -   train_loss = 5.945452417646136
2025-04-11 05:25:12,538 - ***** Epoch: 4: Eval results *****
2025-04-11 05:25:12,538 -   train_loss = 5.943211623600551
2025-04-11 05:25:28,977 - ***** Epoch: 5: Eval results *****
2025-04-11 05:25:28,977 -   train_loss = 5.94326833316258
2025-04-11 05:25:45,438 - ***** Epoch: 6: Eval results *****
2025-04-11 05:25:45,438 -   train_loss = 5.945672512054443
2025-04-11 05:26:01,959 - ***** Epoch: 7: Eval results *****
2025-04-11 05:26:01,960 -   train_loss = 5.942196471350534
2025-04-11 05:26:18,367 - ***** Epoch: 8: Eval results *****
2025-04-11 05:26:18,367 -   train_loss = 5.945043870380947
2025-04-11 05:26:35,568 - ***** Epoch: 9: Eval results *****
2025-04-11 05:26:35,568 -   train_loss = 5.941270964486258
2025-04-11 05:26:52,241 - ***** Epoch: 10: Eval results *****
2025-04-11 05:26:52,242 -   train_loss = 5.9410853045327325
2025-04-11 05:27:08,556 - ***** Epoch: 11: Eval results *****
2025-04-11 05:27:08,556 -   train_loss = 5.9388278893062045
2025-04-11 05:27:24,946 - ***** Epoch: 12: Eval results *****
2025-04-11 05:27:24,947 -   train_loss = 5.938574348177228
2025-04-11 05:27:41,925 - ***** Epoch: 13: Eval results *****
2025-04-11 05:27:41,925 -   train_loss = 5.93994528906686
2025-04-11 05:27:58,550 - ***** Epoch: 14: Eval results *****
2025-04-11 05:27:58,550 -   train_loss = 5.93884403364999
2025-04-11 05:28:14,524 - ***** Epoch: 15: Eval results *****
2025-04-11 05:28:14,524 -   train_loss = 5.930973495755877
2025-04-11 05:28:31,269 - ***** Epoch: 16: Eval results *****
2025-04-11 05:28:31,270 -   train_loss = 5.934203216007778
2025-04-11 05:28:47,985 - ***** Epoch: 17: Eval results *****
2025-04-11 05:28:47,985 -   train_loss = 5.931423936571393
2025-04-11 05:29:03,645 - ***** Epoch: 18: Eval results *****
2025-04-11 05:29:03,646 -   train_loss = 5.925876787730625
2025-04-11 05:29:18,805 - ***** Epoch: 19: Eval results *****
2025-04-11 05:29:18,805 -   train_loss = 5.92727027620588
2025-04-11 05:29:34,441 - ***** Epoch: 20: Eval results *****
2025-04-11 05:29:34,442 -   train_loss = 5.922220536640713
2025-04-11 05:29:50,445 - ***** Epoch: 21: Eval results *****
2025-04-11 05:29:50,445 -   train_loss = 5.913496358054025
2025-04-11 05:30:06,392 - ***** Epoch: 22: Eval results *****
2025-04-11 05:30:06,392 -   train_loss = 5.911894355501447
2025-04-11 05:30:22,326 - ***** Epoch: 23: Eval results *****
2025-04-11 05:30:22,326 -   train_loss = 5.901870931897845
2025-04-11 05:30:38,470 - ***** Epoch: 24: Eval results *****
2025-04-11 05:30:38,470 -   train_loss = 5.893649339675903
2025-04-11 05:30:55,336 - ***** Epoch: 25: Eval results *****
2025-04-11 05:30:55,336 -   train_loss = 5.873649426868984
2025-04-11 05:31:12,272 - ***** Epoch: 26: Eval results *****
2025-04-11 05:31:12,273 -   train_loss = 5.852304765156338
2025-04-11 05:31:29,988 - ***** Epoch: 27: Eval results *****
2025-04-11 05:31:29,988 -   train_loss = 5.815871272768293
2025-04-11 05:31:46,061 - ***** Epoch: 28: Eval results *****
2025-04-11 05:31:46,061 -   train_loss = 5.775459357670376
2025-04-11 05:32:02,500 - ***** Epoch: 29: Eval results *****
2025-04-11 05:32:02,500 -   train_loss = 5.703692368098667
2025-04-11 05:32:17,837 - ***** Epoch: 30: Eval results *****
2025-04-11 05:32:17,837 -   train_loss = 5.616105828966413
2025-04-11 05:32:33,197 - ***** Epoch: 31: Eval results *****
2025-04-11 05:32:33,198 -   train_loss = 5.509714603424072
2025-04-11 05:32:48,425 - ***** Epoch: 32: Eval results *****
2025-04-11 05:32:48,425 -   train_loss = 5.39319566317967
2025-04-11 05:33:04,185 - ***** Epoch: 33: Eval results *****
2025-04-11 05:33:04,186 -   train_loss = 5.266740798950195
2025-04-11 05:33:20,158 - ***** Epoch: 34: Eval results *****
2025-04-11 05:33:20,158 -   train_loss = 5.135794912065778
2025-04-11 05:33:35,342 - ***** Epoch: 35: Eval results *****
2025-04-11 05:33:35,342 -   train_loss = 5.018417154039655
2025-04-11 05:33:51,126 - ***** Epoch: 36: Eval results *****
2025-04-11 05:33:51,126 -   train_loss = 4.891645090920584
2025-04-11 05:34:07,265 - ***** Epoch: 37: Eval results *****
2025-04-11 05:34:07,266 -   train_loss = 4.780818905149188
2025-04-11 05:34:23,125 - ***** Epoch: 38: Eval results *****
2025-04-11 05:34:23,125 -   train_loss = 4.649687051773071
2025-04-11 05:34:38,958 - ***** Epoch: 39: Eval results *****
2025-04-11 05:34:38,959 -   train_loss = 4.514290434973581
2025-04-11 05:34:55,064 - ***** Epoch: 40: Eval results *****
2025-04-11 05:34:55,064 -   train_loss = 4.414868116378784
2025-04-11 05:35:10,768 - ***** Epoch: 41: Eval results *****
2025-04-11 05:35:10,768 -   train_loss = 4.329908881868635
2025-04-11 05:35:26,514 - ***** Epoch: 42: Eval results *****
2025-04-11 05:35:26,515 -   train_loss = 4.257460594177246
2025-04-11 05:35:42,145 - ***** Epoch: 43: Eval results *****
2025-04-11 05:35:42,146 -   train_loss = 4.1795654296875
2025-04-11 05:35:58,924 - ***** Epoch: 44: Eval results *****
2025-04-11 05:35:58,924 -   train_loss = 4.097911545208523
2025-04-11 05:36:15,218 - ***** Epoch: 45: Eval results *****
2025-04-11 05:36:15,218 -   train_loss = 4.045510819980076
2025-04-11 05:36:31,608 - ***** Epoch: 46: Eval results *****
2025-04-11 05:36:31,608 -   train_loss = 3.9821852445602417
2025-04-11 05:36:48,084 - ***** Epoch: 47: Eval results *****
2025-04-11 05:36:48,084 -   train_loss = 3.915239793913705
2025-04-11 05:37:04,818 - ***** Epoch: 48: Eval results *****
2025-04-11 05:37:04,819 -   train_loss = 3.8701854263033186
2025-04-11 05:37:21,353 - ***** Epoch: 49: Eval results *****
2025-04-11 05:37:21,353 -   train_loss = 3.8105794872556413
2025-04-11 05:37:37,421 - ***** Epoch: 50: Eval results *****
2025-04-11 05:37:37,421 -   train_loss = 3.752066101346697
2025-04-11 05:37:53,238 - ***** Epoch: 51: Eval results *****
2025-04-11 05:37:53,238 -   train_loss = 3.7175508737564087
2025-04-11 05:38:09,758 - ***** Epoch: 52: Eval results *****
2025-04-11 05:38:09,758 -   train_loss = 3.681184325899397
2025-04-11 05:38:25,880 - ***** Epoch: 53: Eval results *****
2025-04-11 05:38:25,880 -   train_loss = 3.630714706012181
2025-04-11 05:38:42,224 - ***** Epoch: 54: Eval results *****
2025-04-11 05:38:42,224 -   train_loss = 3.59622665813991
2025-04-11 05:38:57,836 - ***** Epoch: 55: Eval results *****
2025-04-11 05:38:57,836 -   train_loss = 3.5503495761326382
2025-04-11 05:39:12,997 - ***** Epoch: 56: Eval results *****
2025-04-11 05:39:12,997 -   train_loss = 3.533481001853943
2025-04-11 05:39:28,276 - ***** Epoch: 57: Eval results *****
2025-04-11 05:39:28,276 -   train_loss = 3.509639654840742
2025-04-11 05:39:43,453 - ***** Epoch: 58: Eval results *****
2025-04-11 05:39:43,454 -   train_loss = 3.4839449610028947
2025-04-11 05:39:58,804 - ***** Epoch: 59: Eval results *****
2025-04-11 05:39:58,804 -   train_loss = 3.4719028302601407
2025-04-11 05:40:14,277 - ***** Epoch: 60: Eval results *****
2025-04-11 05:40:14,277 -   train_loss = 3.4467598029545377
2025-04-11 05:40:33,362 - ***** Epoch: 61: Eval results *****
2025-04-11 05:40:33,363 -   train_loss = 3.4195779051099504
2025-04-11 05:40:50,864 - ***** Epoch: 62: Eval results *****
2025-04-11 05:40:50,865 -   train_loss = 3.4077292680740356
2025-04-11 05:41:08,502 - ***** Epoch: 63: Eval results *****
2025-04-11 05:41:08,503 -   train_loss = 3.3907217298235213
2025-04-11 05:41:24,618 - ***** Epoch: 64: Eval results *****
2025-04-11 05:41:24,618 -   train_loss = 3.3730281250817433
2025-04-11 05:41:40,545 - ***** Epoch: 65: Eval results *****
2025-04-11 05:41:40,546 -   train_loss = 3.363771370479039
2025-04-11 05:41:57,532 - ***** Epoch: 66: Eval results *****
2025-04-11 05:41:57,532 -   train_loss = 3.34874473299299
2025-04-11 05:42:14,429 - ***** Epoch: 67: Eval results *****
2025-04-11 05:42:14,429 -   train_loss = 3.3469818319593156
2025-04-11 05:42:30,881 - ***** Epoch: 68: Eval results *****
2025-04-11 05:42:30,881 -   train_loss = 3.325729659625462
2025-04-11 05:42:46,331 - ***** Epoch: 69: Eval results *****
2025-04-11 05:42:46,331 -   train_loss = 3.312932082584926
2025-04-11 05:43:01,654 - ***** Epoch: 70: Eval results *****
2025-04-11 05:43:01,654 -   train_loss = 3.3108635459627425
2025-04-11 05:43:17,528 - ***** Epoch: 71: Eval results *****
2025-04-11 05:43:17,528 -   train_loss = 3.3036911487579346
2025-04-11 05:43:32,914 - ***** Epoch: 72: Eval results *****
2025-04-11 05:43:32,914 -   train_loss = 3.2976135866982594
2025-04-11 05:43:48,333 - ***** Epoch: 73: Eval results *****
2025-04-11 05:43:48,333 -   train_loss = 3.289468594959804
2025-04-11 05:44:04,544 - ***** Epoch: 74: Eval results *****
2025-04-11 05:44:04,544 -   train_loss = 3.295694555555071
2025-04-11 05:44:20,849 - ***** Epoch: 75: Eval results *****
2025-04-11 05:44:20,850 -   train_loss = 3.2791888202939714
2025-04-11 05:44:36,837 - ***** Epoch: 76: Eval results *****
2025-04-11 05:44:36,837 -   train_loss = 3.2753037214279175
2025-04-11 05:44:53,164 - ***** Epoch: 77: Eval results *****
2025-04-11 05:44:53,164 -   train_loss = 3.271685464041574
2025-04-11 05:45:09,625 - ***** Epoch: 78: Eval results *****
2025-04-11 05:45:09,626 -   train_loss = 3.269161173275539
2025-04-11 05:45:25,548 - ***** Epoch: 79: Eval results *****
2025-04-11 05:45:25,548 -   train_loss = 3.2627251829419817
2025-04-11 05:45:41,544 - ***** Epoch: 80: Eval results *****
2025-04-11 05:45:41,544 -   train_loss = 3.260238357952663
2025-04-11 05:45:57,525 - ***** Epoch: 81: Eval results *****
2025-04-11 05:45:57,525 -   train_loss = 3.248763050351824
2025-04-11 05:46:13,444 - ***** Epoch: 82: Eval results *****
2025-04-11 05:46:13,445 -   train_loss = 3.2558202743530273
2025-04-11 05:46:27,949 - ***** Epoch: 83: Eval results *****
2025-04-11 05:46:27,950 -   train_loss = 3.2559870992388045
2025-04-11 05:46:42,937 - ***** Epoch: 84: Eval results *****
2025-04-11 05:46:42,937 -   train_loss = 3.2427213191986084
2025-04-11 05:46:57,685 - ***** Epoch: 85: Eval results *****
2025-04-11 05:46:57,685 -   train_loss = 3.2455830233437672
2025-04-11 05:47:13,205 - ***** Epoch: 86: Eval results *****
2025-04-11 05:47:13,205 -   train_loss = 3.2419333457946777
2025-04-11 05:47:28,827 - ***** Epoch: 87: Eval results *****
2025-04-11 05:47:28,827 -   train_loss = 3.2364018133708408
2025-04-11 05:47:45,136 - ***** Epoch: 88: Eval results *****
2025-04-11 05:47:45,136 -   train_loss = 3.2311528410230363
2025-04-11 05:48:01,371 - ***** Epoch: 89: Eval results *****
2025-04-11 05:48:01,371 -   train_loss = 3.237997429711478
2025-04-11 05:48:17,589 - ***** Epoch: 90: Eval results *****
2025-04-11 05:48:17,590 -   train_loss = 3.2326090846742903
2025-04-11 05:48:33,104 - ***** Epoch: 91: Eval results *****
2025-04-11 05:48:33,104 -   train_loss = 3.2289165599005565
2025-04-11 05:48:47,922 - ***** Epoch: 92: Eval results *****
2025-04-11 05:48:47,923 -   train_loss = 3.229889920779637
2025-04-11 05:49:01,534 - ***** Epoch: 93: Eval results *****
2025-04-11 05:49:01,534 -   train_loss = 3.22516507761819
2025-04-11 05:49:16,246 - ***** Epoch: 94: Eval results *****
2025-04-11 05:49:16,246 -   train_loss = 3.2296028307506015
2025-04-11 05:49:32,037 - ***** Epoch: 95: Eval results *****
2025-04-11 05:49:32,037 -   train_loss = 3.2303323575428555
2025-04-11 05:49:47,666 - ***** Epoch: 96: Eval results *****
2025-04-11 05:49:47,666 -   train_loss = 3.2267840078898837
2025-04-11 05:50:02,873 - ***** Epoch: 97: Eval results *****
2025-04-11 05:50:02,873 -   train_loss = 3.237062965120588
2025-04-11 05:50:18,926 - ***** Epoch: 98: Eval results *****
2025-04-11 05:50:18,926 -   train_loss = 3.228524957384382
2025-04-11 05:50:34,886 - ***** Epoch: 99: Eval results *****
2025-04-11 05:50:34,886 -   train_loss = 3.231008001736232
2025-04-11 05:50:50,157 - ***** Epoch: 100: Eval results *****
2025-04-11 05:50:50,157 -   train_loss = 3.230844123022897
2025-04-11 05:50:50,701 - Pre-training finished...
2025-04-11 05:50:50,953 - Freeze all parameters but the last layer for efficiency
2025-04-11 05:50:50,963 - Multimodal Intent Recognition begins...
2025-04-11 05:50:50,964 - Training begins...
2025-04-11 05:51:07,243 - Initializing centroids with K-means++...
2025-04-11 05:51:07,399 - K-means++ used 0.16 s
2025-04-11 05:51:50,584 - K-means used 0.02 s
2025-04-11 05:51:52,037 - ***** Epoch: 1 *****
2025-04-11 05:51:52,038 - Supervised Training Loss: 4.896740
2025-04-11 05:51:52,039 - Unsupervised Training Loss: 5.185270
2025-04-11 05:52:26,333 - K-means used 0.09 s
2025-04-11 05:52:27,609 - ***** Epoch: 2 *****
2025-04-11 05:52:27,610 - Supervised Training Loss: 5.487600
2025-04-11 05:52:27,610 - Unsupervised Training Loss: 5.191410
2025-04-11 05:53:03,184 - K-means used 0.03 s
2025-04-11 05:53:04,543 - ***** Epoch: 3 *****
2025-04-11 05:53:04,543 - Supervised Training Loss: 5.341750
2025-04-11 05:53:04,543 - Unsupervised Training Loss: 5.041410
2025-04-11 05:53:35,639 - K-means used 0.08 s
2025-04-11 05:53:37,101 - ***** Epoch: 4 *****
2025-04-11 05:53:37,102 - Supervised Training Loss: 5.188030
2025-04-11 05:53:37,102 - Unsupervised Training Loss: 5.098360
2025-04-11 05:54:11,800 - K-means used 0.15 s
2025-04-11 05:54:13,785 - ***** Epoch: 5 *****
2025-04-11 05:54:13,786 - Supervised Training Loss: 4.954410
2025-04-11 05:54:13,786 - Unsupervised Training Loss: 5.120540
2025-04-11 05:54:50,201 - K-means used 0.02 s
2025-04-11 05:54:51,712 - ***** Epoch: 6 *****
2025-04-11 05:54:51,713 - Supervised Training Loss: 5.343690
2025-04-11 05:54:51,713 - Unsupervised Training Loss: 4.917030
2025-04-11 05:55:22,956 - K-means used 0.02 s
2025-04-11 05:55:24,344 - ***** Epoch: 7 *****
2025-04-11 05:55:24,344 - Supervised Training Loss: 5.257770
2025-04-11 05:55:24,344 - Unsupervised Training Loss: 5.026580
2025-04-11 05:55:53,700 - K-means used 0.02 s
2025-04-11 05:55:55,381 - ***** Epoch: 8 *****
2025-04-11 05:55:55,381 - Supervised Training Loss: 5.120920
2025-04-11 05:55:55,381 - Unsupervised Training Loss: 5.090000
2025-04-11 05:56:25,425 - K-means used 0.02 s
2025-04-11 05:56:26,981 - ***** Epoch: 9 *****
2025-04-11 05:56:26,982 - Supervised Training Loss: 5.336900
2025-04-11 05:56:26,982 - Unsupervised Training Loss: 5.120160
2025-04-11 05:56:56,427 - K-means used 0.03 s
2025-04-11 05:56:58,018 - ***** Epoch: 10 *****
2025-04-11 05:56:58,019 - Supervised Training Loss: 5.271060
2025-04-11 05:56:58,019 - Unsupervised Training Loss: 4.959200
2025-04-11 05:57:27,110 - K-means used 0.04 s
2025-04-11 05:57:28,707 - ***** Epoch: 11 *****
2025-04-11 05:57:28,708 - Supervised Training Loss: 5.191840
2025-04-11 05:57:28,708 - Unsupervised Training Loss: 5.030540
2025-04-11 05:57:58,101 - K-means used 0.02 s
2025-04-11 05:57:59,847 - ***** Epoch: 12 *****
2025-04-11 05:57:59,847 - Supervised Training Loss: 5.326440
2025-04-11 05:57:59,847 - Unsupervised Training Loss: 5.097460
2025-04-11 05:58:28,720 - K-means used 0.02 s
2025-04-11 05:58:30,573 - ***** Epoch: 13 *****
2025-04-11 05:58:30,573 - Supervised Training Loss: 5.285640
2025-04-11 05:58:30,574 - Unsupervised Training Loss: 4.815000
2025-04-11 05:58:58,997 - K-means used 0.08 s
2025-04-11 05:59:00,908 - ***** Epoch: 14 *****
2025-04-11 05:59:00,908 - Supervised Training Loss: 5.230620
2025-04-11 05:59:00,908 - Unsupervised Training Loss: 4.958050
2025-04-11 05:59:30,027 - K-means used 0.02 s
2025-04-11 05:59:31,942 - ***** Epoch: 15 *****
2025-04-11 05:59:31,942 - Supervised Training Loss: 5.110080
2025-04-11 05:59:31,942 - Unsupervised Training Loss: 5.054850
2025-04-11 06:00:00,640 - K-means used 0.03 s
2025-04-11 06:00:02,984 - ***** Epoch: 16 *****
2025-04-11 06:00:02,984 - Supervised Training Loss: 5.300210
2025-04-11 06:00:02,984 - Unsupervised Training Loss: 4.529240
2025-04-11 06:00:32,697 - K-means used 0.02 s
2025-04-11 06:00:34,824 - ***** Epoch: 17 *****
2025-04-11 06:00:34,825 - Supervised Training Loss: 5.264460
2025-04-11 06:00:34,825 - Unsupervised Training Loss: 4.746610
2025-04-11 06:00:52,457 - Training is finished...
2025-04-11 06:00:52,457 - Testing begins...
2025-04-11 06:01:02,001 - ***** Test results *****
2025-04-11 06:01:02,002 -   ACC = 35.96
2025-04-11 06:01:02,002 -   ARI = 17.52
2025-04-11 06:01:02,002 -   NMI = 40.06
2025-04-11 06:01:02,002 -   fmi = 22.85
2025-04-11 06:01:02,002 - Testing is finished...
2025-04-11 06:01:02,002 - Multimodal intent recognition is finished...
2025-04-11 06:01:02,002 - Results are saved in results/results_umc.csv
