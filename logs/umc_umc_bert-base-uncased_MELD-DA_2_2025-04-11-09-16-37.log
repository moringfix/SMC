2025-04-11 09:16:37,443 - ============================== Params ==============================
2025-04-11 09:16:37,444 - logger_name: umc_umc_bert-base-uncased_MELD-DA_2
2025-04-11 09:16:37,444 - dataset: MELD-DA
2025-04-11 09:16:37,444 - multimodal_method: umc
2025-04-11 09:16:37,444 - method: umc
2025-04-11 09:16:37,444 - text_backbone: bert-base-uncased
2025-04-11 09:16:37,444 - seed: 2
2025-04-11 09:16:37,444 - num_workers: 16
2025-04-11 09:16:37,444 - log_id: umc_umc_bert-base-uncased_MELD-DA_2_2025-04-11-09-16-37
2025-04-11 09:16:37,444 - gpu_id: 1
2025-04-11 09:16:37,444 - data_path: /root/autodl-tmp/home/Share/Dataset/LZH
2025-04-11 09:16:37,444 - train: True
2025-04-11 09:16:37,444 - tune: True
2025-04-11 09:16:37,444 - save_model: True
2025-04-11 09:16:37,444 - save_results: True
2025-04-11 09:16:37,444 - log_path: logs
2025-04-11 09:16:37,444 - cache_path: cache
2025-04-11 09:16:37,444 - video_data_path: video_data
2025-04-11 09:16:37,444 - audio_data_path: audio_data
2025-04-11 09:16:37,444 - video_feats_path: swin_feats.pkl
2025-04-11 09:16:37,444 - audio_feats_path: wavlm_feats.pkl
2025-04-11 09:16:37,444 - results_path: results
2025-04-11 09:16:37,444 - output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/UMC/outputs/MELD-DA
2025-04-11 09:16:37,444 - model_path: models
2025-04-11 09:16:37,444 - config_file_name: umc_MELD-DA
2025-04-11 09:16:37,445 - results_file_name: results_umc.csv
2025-04-11 09:16:37,445 - text_pretrained_model: uncased_L-12_H-768_A-12
2025-04-11 09:16:37,445 - text_seq_len: 70
2025-04-11 09:16:37,445 - video_seq_len: 250
2025-04-11 09:16:37,445 - audio_seq_len: 520
2025-04-11 09:16:37,445 - text_feat_dim: 768
2025-04-11 09:16:37,445 - video_feat_dim: 1024
2025-04-11 09:16:37,445 - audio_feat_dim: 768
2025-04-11 09:16:37,445 - num_labels: 12
2025-04-11 09:16:37,445 - num_train_examples: 7990
2025-04-11 09:16:37,445 - pretrained_bert_model: uncased_L-12_H-768_A-12
2025-04-11 09:16:37,445 - pretrain_batch_size: 128
2025-04-11 09:16:37,445 - train_batch_size: 128
2025-04-11 09:16:37,445 - eval_batch_size: 128
2025-04-11 09:16:37,445 - test_batch_size: 128
2025-04-11 09:16:37,445 - num_pretrain_epochs: [100]
2025-04-11 09:16:37,445 - num_train_epochs: [100]
2025-04-11 09:16:37,445 - pretrain: [True]
2025-04-11 09:16:37,445 - aligned_method: ctc
2025-04-11 09:16:37,445 - need_aligned: False
2025-04-11 09:16:37,445 - freeze_pretrain_bert_parameters: True
2025-04-11 09:16:37,445 - freeze_train_bert_parameters: True
2025-04-11 09:16:37,445 - pretrain_temperature: [0.2]
2025-04-11 09:16:37,445 - train_temperature_sup: [20]
2025-04-11 09:16:37,445 - train_temperature_unsup: [20]
2025-04-11 09:16:37,445 - activation: tanh
2025-04-11 09:16:37,445 - lr_pre: [5e-06]
2025-04-11 09:16:37,445 - lr: [0.0002]
2025-04-11 09:16:37,445 - delta: [0.05]
2025-04-11 09:16:37,445 - thres: [0.1]
2025-04-11 09:16:37,446 - topk: [5]
2025-04-11 09:16:37,446 - weight_decay: 0.01
2025-04-11 09:16:37,446 - feat_dim: 768
2025-04-11 09:16:37,446 - hidden_size: 768
2025-04-11 09:16:37,446 - grad_clip: [-1.0]
2025-04-11 09:16:37,446 - warmup_proportion: 0.5
2025-04-11 09:16:37,446 - hidden_dropout_prob: 0.1
2025-04-11 09:16:37,446 - weight: 1.0
2025-04-11 09:16:37,446 - loss_mode: rdrop
2025-04-11 09:16:37,446 - base_dim: [256]
2025-04-11 09:16:37,446 - nheads: 8
2025-04-11 09:16:37,446 - attn_dropout: 0.1
2025-04-11 09:16:37,446 - relu_dropout: 0.1
2025-04-11 09:16:37,446 - embed_dropout: 0.1
2025-04-11 09:16:37,446 - res_dropout: 0.0
2025-04-11 09:16:37,446 - attn_mask: True
2025-04-11 09:16:37,446 - encoder_layers_1: 1
2025-04-11 09:16:37,446 - fusion_act: tanh
2025-04-11 09:16:37,446 - pred_output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/UMC/outputs/MELD-DA/umc_umc_MELD-DA_bert-base-uncased_2
2025-04-11 09:16:37,446 - model_output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/UMC/outputs/MELD-DA/umc_umc_MELD-DA_bert-base-uncased_2/models
2025-04-11 09:16:37,446 - ============================== End Params ==============================
2025-04-11 09:16:38,675 - Freeze all parameters but the last layer for efficiency
2025-04-11 09:16:38,713 - Pre-training start...
2025-04-11 09:18:09,025 - ***** Epoch: 1: Eval results *****
2025-04-11 09:18:09,026 -   train_loss = 5.911912766713945
2025-04-11 09:19:38,980 - ***** Epoch: 2: Eval results *****
2025-04-11 09:19:38,980 -   train_loss = 5.91070162303864
2025-04-11 09:21:08,083 - ***** Epoch: 3: Eval results *****
2025-04-11 09:21:08,083 -   train_loss = 5.909051176101443
2025-04-11 09:22:42,712 - ***** Epoch: 4: Eval results *****
2025-04-11 09:22:42,713 -   train_loss = 5.902908870152065
2025-04-11 09:24:24,137 - ***** Epoch: 5: Eval results *****
2025-04-11 09:24:24,138 -   train_loss = 5.899889877864292
2025-04-11 09:26:07,951 - ***** Epoch: 6: Eval results *****
2025-04-11 09:26:07,952 -   train_loss = 5.896750737750341
2025-04-11 09:27:37,330 - ***** Epoch: 7: Eval results *****
2025-04-11 09:27:37,330 -   train_loss = 5.885332024286663
2025-04-11 09:29:05,738 - ***** Epoch: 8: Eval results *****
2025-04-11 09:29:05,738 -   train_loss = 5.869600583636571
2025-04-11 09:30:34,386 - ***** Epoch: 9: Eval results *****
2025-04-11 09:30:34,386 -   train_loss = 5.8452695740593805
2025-04-11 09:32:02,762 - ***** Epoch: 10: Eval results *****
2025-04-11 09:32:02,762 -   train_loss = 5.809592209165058
2025-04-11 09:33:30,684 - ***** Epoch: 11: Eval results *****
2025-04-11 09:33:30,684 -   train_loss = 5.743465272207109
2025-04-11 09:34:58,722 - ***** Epoch: 12: Eval results *****
2025-04-11 09:34:58,722 -   train_loss = 5.6442932477073064
2025-04-11 09:36:26,639 - ***** Epoch: 13: Eval results *****
2025-04-11 09:36:26,639 -   train_loss = 5.504233587355841
2025-04-11 09:37:54,222 - ***** Epoch: 14: Eval results *****
2025-04-11 09:37:54,222 -   train_loss = 5.33374852225894
2025-04-11 09:39:21,138 - ***** Epoch: 15: Eval results *****
2025-04-11 09:39:21,138 -   train_loss = 5.130833466847737
2025-04-11 09:40:48,148 - ***** Epoch: 16: Eval results *****
2025-04-11 09:40:48,149 -   train_loss = 4.897399633649796
2025-04-11 09:42:15,060 - ***** Epoch: 17: Eval results *****
2025-04-11 09:42:15,061 -   train_loss = 4.655210040864491
2025-04-11 09:43:42,373 - ***** Epoch: 18: Eval results *****
2025-04-11 09:43:42,373 -   train_loss = 4.449796487414647
2025-04-11 09:45:09,528 - ***** Epoch: 19: Eval results *****
2025-04-11 09:45:09,528 -   train_loss = 4.296021692336551
2025-04-11 09:46:37,227 - ***** Epoch: 20: Eval results *****
2025-04-11 09:46:37,227 -   train_loss = 4.175461167380924
2025-04-11 09:48:04,559 - ***** Epoch: 21: Eval results *****
2025-04-11 09:48:04,559 -   train_loss = 4.068097292430817
2025-04-11 09:49:30,932 - ***** Epoch: 22: Eval results *****
2025-04-11 09:49:30,933 -   train_loss = 3.9691241128104076
2025-04-11 09:50:57,607 - ***** Epoch: 23: Eval results *****
2025-04-11 09:50:57,608 -   train_loss = 3.8769078633141896
2025-04-11 09:52:24,170 - ***** Epoch: 24: Eval results *****
2025-04-11 09:52:24,170 -   train_loss = 3.774744643105401
2025-04-11 09:53:50,708 - ***** Epoch: 25: Eval results *****
2025-04-11 09:53:50,709 -   train_loss = 3.692384265718006
2025-04-11 09:55:17,124 - ***** Epoch: 26: Eval results *****
2025-04-11 09:55:17,125 -   train_loss = 3.620665364795261
2025-04-11 09:56:43,741 - ***** Epoch: 27: Eval results *****
2025-04-11 09:56:43,741 -   train_loss = 3.5580982594262984
2025-04-11 09:58:10,178 - ***** Epoch: 28: Eval results *****
2025-04-11 09:58:10,179 -   train_loss = 3.496294926083277
2025-04-11 09:59:36,344 - ***** Epoch: 29: Eval results *****
2025-04-11 09:59:36,344 -   train_loss = 3.4411008093092175
2025-04-11 10:01:02,629 - ***** Epoch: 30: Eval results *****
2025-04-11 10:01:02,629 -   train_loss = 3.396983574307154
2025-04-11 10:02:29,306 - ***** Epoch: 31: Eval results *****
2025-04-11 10:02:29,306 -   train_loss = 3.34964406679547
2025-04-11 10:03:56,541 - ***** Epoch: 32: Eval results *****
2025-04-11 10:03:56,541 -   train_loss = 3.3116101991562616
2025-04-11 10:05:23,187 - ***** Epoch: 33: Eval results *****
2025-04-11 10:05:23,188 -   train_loss = 3.2813427486116926
2025-04-11 10:06:49,918 - ***** Epoch: 34: Eval results *****
2025-04-11 10:06:49,919 -   train_loss = 3.2501779359484475
2025-04-11 10:08:16,527 - ***** Epoch: 35: Eval results *****
2025-04-11 10:08:16,527 -   train_loss = 3.2208427058325872
2025-04-11 10:09:43,556 - ***** Epoch: 36: Eval results *****
2025-04-11 10:09:43,556 -   train_loss = 3.2002494183797685
2025-04-11 10:11:09,658 - ***** Epoch: 37: Eval results *****
2025-04-11 10:11:09,658 -   train_loss = 3.170654607197595
2025-04-11 10:12:35,468 - ***** Epoch: 38: Eval results *****
2025-04-11 10:12:35,469 -   train_loss = 3.151128678094773
2025-04-11 10:14:01,819 - ***** Epoch: 39: Eval results *****
2025-04-11 10:14:01,819 -   train_loss = 3.125284993459308
2025-04-11 10:15:28,622 - ***** Epoch: 40: Eval results *****
2025-04-11 10:15:28,623 -   train_loss = 3.1001431222945923
2025-04-11 10:16:55,302 - ***** Epoch: 41: Eval results *****
2025-04-11 10:16:55,303 -   train_loss = 3.0760986199454656
2025-04-11 10:18:21,744 - ***** Epoch: 42: Eval results *****
2025-04-11 10:18:21,745 -   train_loss = 3.0554020518348333
2025-04-11 10:19:48,312 - ***** Epoch: 43: Eval results *****
2025-04-11 10:19:48,313 -   train_loss = 3.036784664032951
2025-04-11 10:21:15,179 - ***** Epoch: 44: Eval results *****
2025-04-11 10:21:15,179 -   train_loss = 3.015745231083461
2025-04-11 10:22:43,011 - ***** Epoch: 45: Eval results *****
2025-04-11 10:22:43,012 -   train_loss = 2.9942694580744185
2025-04-11 10:24:10,145 - ***** Epoch: 46: Eval results *****
2025-04-11 10:24:10,145 -   train_loss = 2.9765338746328203
2025-04-11 10:25:37,071 - ***** Epoch: 47: Eval results *****
2025-04-11 10:25:37,071 -   train_loss = 2.953895924583314
2025-04-11 10:27:04,201 - ***** Epoch: 48: Eval results *****
2025-04-11 10:27:04,202 -   train_loss = 2.937693304485745
2025-04-11 10:28:31,511 - ***** Epoch: 49: Eval results *****
2025-04-11 10:28:31,511 -   train_loss = 2.914064437624008
2025-04-11 10:29:58,013 - ***** Epoch: 50: Eval results *****
2025-04-11 10:29:58,013 -   train_loss = 2.9016035776289684
2025-04-11 10:31:24,654 - ***** Epoch: 51: Eval results *****
2025-04-11 10:31:24,654 -   train_loss = 2.8801766085246254
2025-04-11 10:32:51,351 - ***** Epoch: 52: Eval results *****
2025-04-11 10:32:51,351 -   train_loss = 2.8692863555181596
2025-04-11 10:34:18,386 - ***** Epoch: 53: Eval results *****
2025-04-11 10:34:18,386 -   train_loss = 2.8468788767617847
2025-04-11 10:35:45,127 - ***** Epoch: 54: Eval results *****
2025-04-11 10:35:45,128 -   train_loss = 2.843525591350737
2025-04-11 10:37:12,408 - ***** Epoch: 55: Eval results *****
2025-04-11 10:37:12,409 -   train_loss = 2.8196874346051897
2025-04-11 10:38:39,530 - ***** Epoch: 56: Eval results *****
2025-04-11 10:38:39,531 -   train_loss = 2.8102143151419505
2025-04-11 10:40:05,823 - ***** Epoch: 57: Eval results *****
2025-04-11 10:40:05,824 -   train_loss = 2.806275072551909
2025-04-11 10:41:32,476 - ***** Epoch: 58: Eval results *****
2025-04-11 10:41:32,477 -   train_loss = 2.7925537654331754
2025-04-11 10:42:59,346 - ***** Epoch: 59: Eval results *****
2025-04-11 10:42:59,347 -   train_loss = 2.7755638039301314
2025-04-11 10:44:26,092 - ***** Epoch: 60: Eval results *****
2025-04-11 10:44:26,092 -   train_loss = 2.7681551395900668
2025-04-11 10:45:52,754 - ***** Epoch: 61: Eval results *****
2025-04-11 10:45:52,754 -   train_loss = 2.758307625376989
2025-04-11 10:47:19,550 - ***** Epoch: 62: Eval results *****
2025-04-11 10:47:19,550 -   train_loss = 2.7500699758529663
2025-04-11 10:48:47,193 - ***** Epoch: 63: Eval results *****
2025-04-11 10:48:47,193 -   train_loss = 2.7415490074763222
2025-04-11 10:50:13,638 - ***** Epoch: 64: Eval results *****
2025-04-11 10:50:13,638 -   train_loss = 2.7372064136323475
2025-04-11 10:51:39,675 - ***** Epoch: 65: Eval results *****
2025-04-11 10:51:39,676 -   train_loss = 2.7252299369327604
2025-04-11 10:53:06,903 - ***** Epoch: 66: Eval results *****
2025-04-11 10:53:06,904 -   train_loss = 2.7155229742564853
2025-04-11 10:54:33,881 - ***** Epoch: 67: Eval results *****
2025-04-11 10:54:33,882 -   train_loss = 2.7120646938445074
2025-04-11 10:56:04,879 - ***** Epoch: 68: Eval results *****
2025-04-11 10:56:04,880 -   train_loss = 2.7007826093643432
2025-04-11 10:57:33,013 - ***** Epoch: 69: Eval results *****
2025-04-11 10:57:33,013 -   train_loss = 2.697764025794135
2025-04-11 10:59:05,417 - ***** Epoch: 70: Eval results *****
2025-04-11 10:59:05,418 -   train_loss = 2.6870626816673884
2025-04-11 11:00:41,656 - ***** Epoch: 71: Eval results *****
2025-04-11 11:00:41,657 -   train_loss = 2.684050949793013
2025-04-11 11:02:19,394 - ***** Epoch: 72: Eval results *****
2025-04-11 11:02:19,394 -   train_loss = 2.685857267606826
2025-04-11 11:03:58,700 - ***** Epoch: 73: Eval results *****
2025-04-11 11:03:58,701 -   train_loss = 2.6754142821781217
2025-04-11 11:05:37,790 - ***** Epoch: 74: Eval results *****
2025-04-11 11:05:37,790 -   train_loss = 2.6698668040926496
2025-04-11 11:07:16,145 - ***** Epoch: 75: Eval results *****
2025-04-11 11:07:16,145 -   train_loss = 2.6629964453833446
2025-04-11 11:08:53,758 - ***** Epoch: 76: Eval results *****
2025-04-11 11:08:53,758 -   train_loss = 2.6662424102662103
2025-04-11 11:10:32,392 - ***** Epoch: 77: Eval results *****
2025-04-11 11:10:32,392 -   train_loss = 2.6569723742348805
2025-04-11 11:12:07,429 - ***** Epoch: 78: Eval results *****
2025-04-11 11:12:07,429 -   train_loss = 2.6544592683277433
2025-04-11 11:13:42,460 - ***** Epoch: 79: Eval results *****
2025-04-11 11:13:42,461 -   train_loss = 2.643044394160074
2025-04-11 11:15:17,289 - ***** Epoch: 80: Eval results *****
2025-04-11 11:15:17,290 -   train_loss = 2.6434789877089244
2025-04-11 11:16:55,192 - ***** Epoch: 81: Eval results *****
2025-04-11 11:16:55,192 -   train_loss = 2.6457423879986717
2025-04-11 11:18:30,292 - ***** Epoch: 82: Eval results *****
2025-04-11 11:18:30,292 -   train_loss = 2.6397014458974204
2025-04-11 11:20:05,425 - ***** Epoch: 83: Eval results *****
2025-04-11 11:20:05,426 -   train_loss = 2.6359781291749744
2025-04-11 11:21:40,910 - ***** Epoch: 84: Eval results *****
2025-04-11 11:21:40,911 -   train_loss = 2.6334767190236894
2025-04-11 11:23:16,366 - ***** Epoch: 85: Eval results *****
2025-04-11 11:23:16,366 -   train_loss = 2.631568647566296
2025-04-11 11:24:52,711 - ***** Epoch: 86: Eval results *****
2025-04-11 11:24:52,711 -   train_loss = 2.629482602316236
2025-04-11 11:26:26,169 - ***** Epoch: 87: Eval results *****
2025-04-11 11:26:26,170 -   train_loss = 2.624901612599691
2025-04-11 11:28:01,891 - ***** Epoch: 88: Eval results *****
2025-04-11 11:28:01,891 -   train_loss = 2.623535284920344
2025-04-11 11:29:36,512 - ***** Epoch: 89: Eval results *****
2025-04-11 11:29:36,512 -   train_loss = 2.6237736675474377
2025-04-11 11:31:11,294 - ***** Epoch: 90: Eval results *****
2025-04-11 11:31:11,295 -   train_loss = 2.6246377873042275
2025-04-11 11:32:45,649 - ***** Epoch: 91: Eval results *****
2025-04-11 11:32:45,650 -   train_loss = 2.6170446399658447
2025-04-11 11:34:19,538 - ***** Epoch: 92: Eval results *****
2025-04-11 11:34:19,538 -   train_loss = 2.617681862815978
2025-04-11 11:35:52,030 - ***** Epoch: 93: Eval results *****
2025-04-11 11:35:52,031 -   train_loss = 2.6199915446932356
2025-04-11 11:37:27,827 - ***** Epoch: 94: Eval results *****
2025-04-11 11:37:27,828 -   train_loss = 2.614325351185269
2025-04-11 11:39:04,776 - ***** Epoch: 95: Eval results *****
2025-04-11 11:39:04,776 -   train_loss = 2.6208582700244962
2025-04-11 11:40:41,075 - ***** Epoch: 96: Eval results *****
2025-04-11 11:40:41,075 -   train_loss = 2.619164232223753
2025-04-11 11:42:17,196 - ***** Epoch: 97: Eval results *****
2025-04-11 11:42:17,196 -   train_loss = 2.6169927990625776
2025-04-11 11:43:53,365 - ***** Epoch: 98: Eval results *****
2025-04-11 11:43:53,366 -   train_loss = 2.611543990316845
2025-04-11 11:45:30,578 - ***** Epoch: 99: Eval results *****
2025-04-11 11:45:30,579 -   train_loss = 2.6107573414605763
2025-04-11 11:47:07,113 - ***** Epoch: 100: Eval results *****
2025-04-11 11:47:07,113 -   train_loss = 2.612885654918731
2025-04-11 11:47:07,682 - Pre-training finished...
2025-04-11 11:47:08,267 - Freeze all parameters but the last layer for efficiency
2025-04-11 11:47:08,277 - Multimodal Intent Recognition begins...
2025-04-11 11:47:08,277 - Training begins...
2025-04-11 11:47:57,556 - Initializing centroids with K-means++...
2025-04-11 11:47:57,820 - K-means++ used 0.26 s
2025-04-11 11:50:24,817 - K-means used 0.18 s
2025-04-11 11:50:28,690 - ***** Epoch: 1 *****
2025-04-11 11:50:28,690 - Supervised Training Loss: 5.683020
2025-04-11 11:50:28,692 - Unsupervised Training Loss: 5.879710
2025-04-11 11:52:54,509 - K-means used 0.17 s
2025-04-11 11:52:59,228 - ***** Epoch: 2 *****
2025-04-11 11:52:59,229 - Supervised Training Loss: 5.801980
2025-04-11 11:52:59,229 - Unsupervised Training Loss: 5.862000
2025-04-11 11:55:34,401 - K-means used 0.17 s
2025-04-11 11:55:39,944 - ***** Epoch: 3 *****
2025-04-11 11:55:39,945 - Supervised Training Loss: 5.846660
2025-04-11 11:55:39,945 - Unsupervised Training Loss: 5.902360
2025-04-11 11:58:18,233 - K-means used 0.19 s
2025-04-11 11:58:24,797 - ***** Epoch: 4 *****
2025-04-11 11:58:24,797 - Supervised Training Loss: 5.866150
2025-04-11 11:58:24,797 - Unsupervised Training Loss: 5.898180
2025-04-11 12:01:02,508 - K-means used 0.08 s
2025-04-11 12:01:10,210 - ***** Epoch: 5 *****
2025-04-11 12:01:10,211 - Supervised Training Loss: 5.879780
2025-04-11 12:01:10,211 - Unsupervised Training Loss: 5.894140
2025-04-11 12:03:48,729 - K-means used 0.16 s
2025-04-11 12:03:57,809 - ***** Epoch: 6 *****
2025-04-11 12:03:57,810 - Supervised Training Loss: 5.890000
2025-04-11 12:03:57,810 - Unsupervised Training Loss: 5.888800
2025-04-11 12:06:30,612 - K-means used 0.19 s
2025-04-11 12:06:40,412 - ***** Epoch: 7 *****
2025-04-11 12:06:40,413 - Supervised Training Loss: 5.896910
2025-04-11 12:06:40,413 - Unsupervised Training Loss: 5.881800
2025-04-11 12:09:07,756 - K-means used 0.25 s
2025-04-11 12:09:20,405 - ***** Epoch: 8 *****
2025-04-11 12:09:20,405 - Supervised Training Loss: 5.798090
2025-04-11 12:09:20,405 - Unsupervised Training Loss: 5.871150
2025-04-11 12:11:44,722 - K-means used 0.14 s
2025-04-11 12:12:01,253 - ***** Epoch: 9 *****
2025-04-11 12:12:01,253 - Supervised Training Loss: 5.845780
2025-04-11 12:12:01,253 - Unsupervised Training Loss: 5.855210
2025-04-11 12:14:25,713 - K-means used 0.06 s
2025-04-11 12:14:44,270 - ***** Epoch: 10 *****
2025-04-11 12:14:44,270 - Supervised Training Loss: 5.864010
2025-04-11 12:14:44,270 - Unsupervised Training Loss: 5.829420
2025-04-11 12:17:10,204 - K-means used 0.17 s
2025-04-11 12:17:31,409 - ***** Epoch: 11 *****
2025-04-11 12:17:31,409 - Supervised Training Loss: 5.876180
2025-04-11 12:17:31,409 - Unsupervised Training Loss: 5.699240
2025-04-11 12:19:56,032 - K-means used 0.07 s
2025-04-11 12:20:22,036 - ***** Epoch: 12 *****
2025-04-11 12:20:22,037 - Supervised Training Loss: 5.884350
2025-04-11 12:20:22,037 - Unsupervised Training Loss: 5.893980
2025-04-11 12:22:47,023 - K-means used 0.12 s
2025-04-11 12:23:12,552 - ***** Epoch: 13 *****
2025-04-11 12:23:12,553 - Supervised Training Loss: 5.889370
2025-04-11 12:23:12,553 - Unsupervised Training Loss: 5.886000
2025-04-11 12:25:37,004 - K-means used 0.07 s
2025-04-11 12:26:05,686 - ***** Epoch: 14 *****
2025-04-11 12:26:05,687 - Supervised Training Loss: 5.893710
2025-04-11 12:26:05,687 - Unsupervised Training Loss: 5.872280
2025-04-11 12:28:31,317 - K-means used 0.05 s
2025-04-11 12:29:03,210 - ***** Epoch: 15 *****
2025-04-11 12:29:03,210 - Supervised Training Loss: 5.897480
2025-04-11 12:29:03,210 - Unsupervised Training Loss: 5.847170
2025-04-11 12:31:29,305 - K-means used 0.08 s
2025-04-11 12:32:05,548 - ***** Epoch: 16 *****
2025-04-11 12:32:05,549 - Supervised Training Loss: 5.818890
2025-04-11 12:32:05,549 - Unsupervised Training Loss: 5.808970
2025-04-11 12:34:30,898 - K-means used 0.18 s
2025-04-11 12:35:09,413 - ***** Epoch: 17 *****
2025-04-11 12:35:09,413 - Supervised Training Loss: 5.865500
2025-04-11 12:35:09,414 - Unsupervised Training Loss: 5.713030
2025-04-11 12:36:49,318 - Training is finished...
2025-04-11 12:36:49,319 - Testing begins...
2025-04-11 12:37:22,418 - ***** Test results *****
2025-04-11 12:37:22,418 -   ACC = 34.73
2025-04-11 12:37:22,418 -   ARI = 21.99
2025-04-11 12:37:22,418 -   NMI = 22.07
2025-04-11 12:37:22,418 -   fmi = 34.2
2025-04-11 12:37:22,418 - Testing is finished...
2025-04-11 12:37:22,418 - Multimodal intent recognition is finished...
2025-04-11 12:37:22,418 - Results are saved in results/results_umc.csv
