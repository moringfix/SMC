2025-04-17 17:57:35,272 - 【无监督】进入了无监督的设定中, 加载数据集
2025-04-17 17:57:35,272 - data preparation...
2025-04-17 17:57:44,130 - Number of train samples = 1779
2025-04-17 17:57:44,130 - Number of testing samples = 445
2025-04-17 17:57:44,131 - data preparation...
2025-04-17 17:57:46,263 - num_train_examples = 1779
2025-04-17 17:57:46,264 - ============================== Params ==============================
2025-04-17 17:57:46,264 - logger_name: umc2_umc2_bert-base-uncased_MIntRec_0
2025-04-17 17:57:46,264 - dataset: MIntRec
2025-04-17 17:57:46,264 - multimodal_method: umc2
2025-04-17 17:57:46,264 - method: umc2
2025-04-17 17:57:46,264 - setting: unsupervised
2025-04-17 17:57:46,264 - merge_dev: False
2025-04-17 17:57:46,264 - text_backbone: bert-base-uncased
2025-04-17 17:57:46,264 - seed: 0
2025-04-17 17:57:46,264 - num_workers: 16
2025-04-17 17:57:46,264 - log_id: umc2_umc2_bert-base-uncased_MIntRec_0_2025-04-17-17-57-35
2025-04-17 17:57:46,264 - gpu_id: 1
2025-04-17 17:57:46,264 - data_path: /root/autodl-tmp/home/Share/Dataset/LZH
2025-04-17 17:57:46,264 - train: True
2025-04-17 17:57:46,264 - tune: True
2025-04-17 17:57:46,264 - save_model: True
2025-04-17 17:57:46,264 - save_results: True
2025-04-17 17:57:46,264 - log_path: logs
2025-04-17 17:57:46,264 - cache_path: cache
2025-04-17 17:57:46,264 - video_data_path: video_data
2025-04-17 17:57:46,264 - audio_data_path: audio_data
2025-04-17 17:57:46,264 - video_feats_path: swin_feats.pkl
2025-04-17 17:57:46,264 - audio_feats_path: wavlm_feats.pkl
2025-04-17 17:57:46,264 - results_path: results
2025-04-17 17:57:46,264 - output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/SMC/outputs_test2/MIntRec
2025-04-17 17:57:46,265 - model_path: models
2025-04-17 17:57:46,265 - config_file_name: umc2_MIntRec
2025-04-17 17:57:46,265 - results_file_name: results_umc2_pre.csv
2025-04-17 17:57:46,265 - text_pretrained_model: uncased_L-12_H-768_A-12
2025-04-17 17:57:46,265 - pretrained_bert_model: uncased_L-12_H-768_A-12
2025-04-17 17:57:46,265 - pretrain_batch_size: 128
2025-04-17 17:57:46,265 - train_batch_size: 128
2025-04-17 17:57:46,265 - eval_batch_size: 128
2025-04-17 17:57:46,265 - test_batch_size: 128
2025-04-17 17:57:46,265 - num_pretrain_epochs: 100
2025-04-17 17:57:46,265 - num_train_epochs: 100
2025-04-17 17:57:46,265 - pretrain: [True]
2025-04-17 17:57:46,265 - aligned_method: ctc
2025-04-17 17:57:46,265 - need_aligned: False
2025-04-17 17:57:46,265 - freeze_pretrain_bert_parameters: [True]
2025-04-17 17:57:46,265 - freeze_train_bert_parameters: [True]
2025-04-17 17:57:46,265 - pretrain_temperature: [0.1]
2025-04-17 17:57:46,265 - train_temperature_sup: [0.5]
2025-04-17 17:57:46,265 - train_temperature_unsup: [2]
2025-04-17 17:57:46,265 - activation: tanh
2025-04-17 17:57:46,265 - lr_pre: [1e-05]
2025-04-17 17:57:46,265 - lr: [5e-05]
2025-04-17 17:57:46,265 - delta: [0.05]
2025-04-17 17:57:46,265 - thres: [0.1]
2025-04-17 17:57:46,265 - topk: [5]
2025-04-17 17:57:46,265 - weight_decay: 0.01
2025-04-17 17:57:46,265 - feat_dim: 768
2025-04-17 17:57:46,265 - hidden_size: 768
2025-04-17 17:57:46,265 - grad_clip: -1.0
2025-04-17 17:57:46,266 - warmup_proportion: [0.1]
2025-04-17 17:57:46,266 - hidden_dropout_prob: 0.1
2025-04-17 17:57:46,266 - weight: 1.0
2025-04-17 17:57:46,266 - loss_mode: rdrop
2025-04-17 17:57:46,266 - base_dim: 256
2025-04-17 17:57:46,266 - nheads: 8
2025-04-17 17:57:46,266 - attn_dropout: 0.1
2025-04-17 17:57:46,266 - relu_dropout: 0.1
2025-04-17 17:57:46,266 - embed_dropout: 0.01
2025-04-17 17:57:46,266 - res_dropout: 0.0
2025-04-17 17:57:46,266 - attn_mask: True
2025-04-17 17:57:46,266 - encoder_layers_1: 1
2025-04-17 17:57:46,266 - fusion_act: tanh
2025-04-17 17:57:46,266 - pred_output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/SMC/outputs_test2/MIntRec/umc2_umc2_MIntRec_bert-base-uncased_0
2025-04-17 17:57:46,266 - model_output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/SMC/outputs_test2/MIntRec/umc2_umc2_MIntRec_bert-base-uncased_0/models
2025-04-17 17:57:46,266 - text_seq_len: 30
2025-04-17 17:57:46,266 - video_seq_len: 230
2025-04-17 17:57:46,266 - audio_seq_len: 480
2025-04-17 17:57:46,266 - text_feat_dim: 768
2025-04-17 17:57:46,266 - video_feat_dim: 1024
2025-04-17 17:57:46,266 - audio_feat_dim: 768
2025-04-17 17:57:46,266 - num_labels: 20
2025-04-17 17:57:46,266 - num_train_examples: 1779
2025-04-17 17:57:46,266 - ============================== End Params ==============================
2025-04-17 17:57:47,490 - Freeze all parameters but the last layer for efficiency
2025-04-17 17:57:47,524 - Pre-training start...
2025-04-17 17:58:06,540 - ***** Epoch: 1: Eval results *****
2025-04-17 17:58:06,540 -   train_loss = 5.94118366922651
2025-04-17 17:58:27,173 - ***** Epoch: 2: Eval results *****
2025-04-17 17:58:27,173 -   train_loss = 5.936119897024972
2025-04-17 17:58:48,143 - ***** Epoch: 3: Eval results *****
2025-04-17 17:58:48,143 -   train_loss = 5.892474481037685
2025-04-17 17:59:07,191 - ***** Epoch: 4: Eval results *****
2025-04-17 17:59:07,191 -   train_loss = 5.84357305935451
2025-04-17 17:59:28,150 - ***** Epoch: 5: Eval results *****
2025-04-17 17:59:28,151 -   train_loss = 5.732943568910871
2025-04-17 17:59:48,186 - ***** Epoch: 6: Eval results *****
2025-04-17 17:59:48,186 -   train_loss = 5.427707842418125
2025-04-17 18:00:09,528 - ***** Epoch: 7: Eval results *****
2025-04-17 18:00:09,528 -   train_loss = 4.830049003873553
2025-04-17 18:00:30,065 - ***** Epoch: 8: Eval results *****
2025-04-17 18:00:30,065 -   train_loss = 4.215932096753802
2025-04-17 18:00:50,398 - ***** Epoch: 9: Eval results *****
2025-04-17 18:00:50,398 -   train_loss = 3.685204795428685
2025-04-17 18:01:11,842 - ***** Epoch: 10: Eval results *****
2025-04-17 18:01:11,842 -   train_loss = 3.2771624326705933
2025-04-17 18:01:32,161 - ***** Epoch: 11: Eval results *****
2025-04-17 18:01:32,161 -   train_loss = 2.938228266579764
2025-04-17 18:01:52,563 - ***** Epoch: 12: Eval results *****
2025-04-17 18:01:52,564 -   train_loss = 2.6847919395991733
2025-04-17 18:02:16,746 - ***** Epoch: 13: Eval results *****
2025-04-17 18:02:16,746 -   train_loss = 2.4773466757365634
2025-04-17 18:02:38,274 - ***** Epoch: 14: Eval results *****
2025-04-17 18:02:38,274 -   train_loss = 2.317320874759129
2025-04-17 18:03:03,376 - ***** Epoch: 15: Eval results *****
2025-04-17 18:03:03,376 -   train_loss = 2.195733666419983
2025-04-17 18:03:27,054 - ***** Epoch: 16: Eval results *****
2025-04-17 18:03:27,054 -   train_loss = 2.0844816820962087
2025-04-17 18:03:51,106 - ***** Epoch: 17: Eval results *****
2025-04-17 18:03:51,107 -   train_loss = 1.9970881598336356
2025-04-17 18:04:14,377 - ***** Epoch: 18: Eval results *****
2025-04-17 18:04:14,377 -   train_loss = 1.9276525293077742
2025-04-17 18:04:37,158 - ***** Epoch: 19: Eval results *****
2025-04-17 18:04:37,159 -   train_loss = 1.8680890032223292
2025-04-17 18:05:00,961 - ***** Epoch: 20: Eval results *****
2025-04-17 18:05:00,961 -   train_loss = 1.8179490566253662
2025-04-17 18:05:22,644 - ***** Epoch: 21: Eval results *****
2025-04-17 18:05:22,644 -   train_loss = 1.767450783933912
2025-04-17 18:05:47,100 - ***** Epoch: 22: Eval results *****
2025-04-17 18:05:47,100 -   train_loss = 1.7299275398254395
2025-04-17 18:06:08,598 - ***** Epoch: 23: Eval results *****
2025-04-17 18:06:08,598 -   train_loss = 1.6997061456952776
2025-04-17 18:06:30,821 - ***** Epoch: 24: Eval results *****
2025-04-17 18:06:30,821 -   train_loss = 1.6415849498340063
2025-04-17 18:06:51,812 - ***** Epoch: 25: Eval results *****
2025-04-17 18:06:51,813 -   train_loss = 1.6259180733135767
2025-04-17 18:07:12,469 - ***** Epoch: 26: Eval results *****
2025-04-17 18:07:12,470 -   train_loss = 1.5991253767694746
2025-04-17 18:07:33,795 - ***** Epoch: 27: Eval results *****
2025-04-17 18:07:33,795 -   train_loss = 1.5800177540097917
2025-04-17 18:07:54,607 - ***** Epoch: 28: Eval results *****
2025-04-17 18:07:54,607 -   train_loss = 1.5663357547351293
2025-04-17 18:08:15,348 - ***** Epoch: 29: Eval results *****
2025-04-17 18:08:15,348 -   train_loss = 1.5285526599202837
2025-04-17 18:08:35,534 - ***** Epoch: 30: Eval results *****
2025-04-17 18:08:35,534 -   train_loss = 1.511474677494594
2025-04-17 18:08:56,436 - ***** Epoch: 31: Eval results *****
2025-04-17 18:08:56,437 -   train_loss = 1.4925504752567835
2025-04-17 18:09:17,740 - ***** Epoch: 32: Eval results *****
2025-04-17 18:09:17,741 -   train_loss = 1.4855277708598547
2025-04-17 18:09:38,440 - ***** Epoch: 33: Eval results *****
2025-04-17 18:09:38,440 -   train_loss = 1.4698939664023263
2025-04-17 18:09:58,373 - ***** Epoch: 34: Eval results *****
2025-04-17 18:09:58,373 -   train_loss = 1.4432050500597273
2025-04-17 18:10:19,632 - ***** Epoch: 35: Eval results *****
2025-04-17 18:10:19,633 -   train_loss = 1.443632755960737
2025-04-17 18:10:39,479 - ***** Epoch: 36: Eval results *****
2025-04-17 18:10:39,479 -   train_loss = 1.4212346758161272
2025-04-17 18:11:00,968 - ***** Epoch: 37: Eval results *****
2025-04-17 18:11:00,968 -   train_loss = 1.3967475550515311
2025-04-17 18:11:23,429 - ***** Epoch: 38: Eval results *****
2025-04-17 18:11:23,429 -   train_loss = 1.402789490563529
2025-04-17 18:11:45,123 - ***** Epoch: 39: Eval results *****
2025-04-17 18:11:45,124 -   train_loss = 1.3884212119238717
2025-04-17 18:12:06,154 - ***** Epoch: 40: Eval results *****
2025-04-17 18:12:06,155 -   train_loss = 1.3760483264923096
2025-04-17 18:12:26,133 - ***** Epoch: 41: Eval results *****
2025-04-17 18:12:26,134 -   train_loss = 1.375088563987187
2025-04-17 18:12:47,333 - ***** Epoch: 42: Eval results *****
2025-04-17 18:12:47,333 -   train_loss = 1.3638584613800049
2025-04-17 18:13:08,065 - ***** Epoch: 43: Eval results *****
2025-04-17 18:13:08,065 -   train_loss = 1.3418647732053484
2025-04-17 18:13:29,898 - ***** Epoch: 44: Eval results *****
2025-04-17 18:13:29,898 -   train_loss = 1.3602653230939592
2025-04-17 18:13:50,408 - ***** Epoch: 45: Eval results *****
2025-04-17 18:13:50,408 -   train_loss = 1.3375692112105233
2025-04-17 18:14:12,389 - ***** Epoch: 46: Eval results *****
2025-04-17 18:14:12,389 -   train_loss = 1.3419671143804277
2025-04-17 18:14:34,498 - ***** Epoch: 47: Eval results *****
2025-04-17 18:14:34,498 -   train_loss = 1.324587447302682
2025-04-17 18:14:55,487 - ***** Epoch: 48: Eval results *****
2025-04-17 18:14:55,487 -   train_loss = 1.3105544873646326
2025-04-17 18:15:17,400 - ***** Epoch: 49: Eval results *****
2025-04-17 18:15:17,400 -   train_loss = 1.3139585512025016
2025-04-17 18:15:39,278 - ***** Epoch: 50: Eval results *****
2025-04-17 18:15:39,278 -   train_loss = 1.300261207989284
2025-04-17 18:16:00,820 - ***** Epoch: 51: Eval results *****
2025-04-17 18:16:00,820 -   train_loss = 1.3122082182339259
2025-04-17 18:16:19,766 - ***** Epoch: 52: Eval results *****
2025-04-17 18:16:19,767 -   train_loss = 1.3000081096376692
2025-04-17 18:16:40,037 - ***** Epoch: 53: Eval results *****
2025-04-17 18:16:40,038 -   train_loss = 1.2865611740521021
2025-04-17 18:17:00,371 - ***** Epoch: 54: Eval results *****
2025-04-17 18:17:00,371 -   train_loss = 1.2915583338056291
2025-04-17 18:17:20,371 - ***** Epoch: 55: Eval results *****
2025-04-17 18:17:20,371 -   train_loss = 1.287426037447793
2025-04-17 18:17:41,129 - ***** Epoch: 56: Eval results *****
2025-04-17 18:17:41,129 -   train_loss = 1.2849500690187727
2025-04-17 18:18:01,405 - ***** Epoch: 57: Eval results *****
2025-04-17 18:18:01,405 -   train_loss = 1.2722652043615068
2025-04-17 18:18:22,376 - ***** Epoch: 58: Eval results *****
2025-04-17 18:18:22,376 -   train_loss = 1.269320317677089
2025-04-17 18:18:42,676 - ***** Epoch: 59: Eval results *****
2025-04-17 18:18:42,676 -   train_loss = 1.266488756452288
2025-04-17 18:19:03,326 - ***** Epoch: 60: Eval results *****
2025-04-17 18:19:03,326 -   train_loss = 1.2481660928045
2025-04-17 18:19:24,425 - ***** Epoch: 61: Eval results *****
2025-04-17 18:19:24,425 -   train_loss = 1.2593181133270264
2025-04-17 18:19:44,100 - ***** Epoch: 62: Eval results *****
2025-04-17 18:19:44,100 -   train_loss = 1.2497363771711076
2025-04-17 18:20:03,743 - ***** Epoch: 63: Eval results *****
2025-04-17 18:20:03,743 -   train_loss = 1.2414401258741106
2025-04-17 18:20:23,065 - ***** Epoch: 64: Eval results *****
2025-04-17 18:20:23,065 -   train_loss = 1.243129449231284
2025-04-17 18:20:43,544 - ***** Epoch: 65: Eval results *****
2025-04-17 18:20:43,544 -   train_loss = 1.2474905167307173
2025-04-17 18:21:05,827 - ***** Epoch: 66: Eval results *****
2025-04-17 18:21:05,827 -   train_loss = 1.2403318541390556
2025-04-17 18:21:25,740 - ***** Epoch: 67: Eval results *****
2025-04-17 18:21:25,740 -   train_loss = 1.2308058823857988
2025-04-17 18:21:46,430 - ***** Epoch: 68: Eval results *****
2025-04-17 18:21:46,430 -   train_loss = 1.2342467989240373
2025-04-17 18:22:06,403 - ***** Epoch: 69: Eval results *****
2025-04-17 18:22:06,404 -   train_loss = 1.2295780607632227
2025-04-17 18:22:26,137 - ***** Epoch: 70: Eval results *****
2025-04-17 18:22:26,137 -   train_loss = 1.2214538965906416
2025-04-17 18:22:46,370 - ***** Epoch: 71: Eval results *****
2025-04-17 18:22:46,370 -   train_loss = 1.2286927359444755
2025-04-17 18:23:06,146 - ***** Epoch: 72: Eval results *****
2025-04-17 18:23:06,146 -   train_loss = 1.2204806038311549
2025-04-17 18:23:26,061 - ***** Epoch: 73: Eval results *****
2025-04-17 18:23:26,061 -   train_loss = 1.2349882466452462
2025-04-17 18:23:46,640 - ***** Epoch: 74: Eval results *****
2025-04-17 18:23:46,640 -   train_loss = 1.2198764766965593
2025-04-17 18:24:07,304 - ***** Epoch: 75: Eval results *****
2025-04-17 18:24:07,305 -   train_loss = 1.2232184324945723
2025-04-17 18:24:26,739 - ***** Epoch: 76: Eval results *****
2025-04-17 18:24:26,740 -   train_loss = 1.2179557851382665
2025-04-17 18:24:45,304 - ***** Epoch: 77: Eval results *****
2025-04-17 18:24:45,304 -   train_loss = 1.2028349212237768
2025-04-17 18:25:05,712 - ***** Epoch: 78: Eval results *****
2025-04-17 18:25:05,713 -   train_loss = 1.2178228667804174
2025-04-17 18:25:26,202 - ***** Epoch: 79: Eval results *****
2025-04-17 18:25:26,202 -   train_loss = 1.2078884754862105
2025-04-17 18:25:45,390 - ***** Epoch: 80: Eval results *****
2025-04-17 18:25:45,390 -   train_loss = 1.202653706073761
2025-04-17 18:26:05,840 - ***** Epoch: 81: Eval results *****
2025-04-17 18:26:05,840 -   train_loss = 1.2160844802856445
2025-04-17 18:26:24,536 - ***** Epoch: 82: Eval results *****
2025-04-17 18:26:24,536 -   train_loss = 1.213218527180808
2025-04-17 18:26:45,772 - ***** Epoch: 83: Eval results *****
2025-04-17 18:26:45,772 -   train_loss = 1.214745921748025
2025-04-17 18:27:05,728 - ***** Epoch: 84: Eval results *****
2025-04-17 18:27:05,728 -   train_loss = 1.201535267489297
2025-04-17 18:27:25,333 - ***** Epoch: 85: Eval results *****
2025-04-17 18:27:25,333 -   train_loss = 1.2050124662263053
2025-04-17 18:27:44,151 - ***** Epoch: 86: Eval results *****
2025-04-17 18:27:44,152 -   train_loss = 1.2015478270394462
2025-04-17 18:28:04,738 - ***** Epoch: 87: Eval results *****
2025-04-17 18:28:04,738 -   train_loss = 1.2078647868973869
2025-04-17 18:28:24,437 - ***** Epoch: 88: Eval results *****
2025-04-17 18:28:24,437 -   train_loss = 1.2072305849620275
2025-04-17 18:28:44,497 - ***** Epoch: 89: Eval results *****
2025-04-17 18:28:44,497 -   train_loss = 1.1959583078111922
2025-04-17 18:29:05,134 - ***** Epoch: 90: Eval results *****
2025-04-17 18:29:05,135 -   train_loss = 1.2084018673215593
2025-04-17 18:29:25,854 - ***** Epoch: 91: Eval results *****
2025-04-17 18:29:25,854 -   train_loss = 1.2008220383099146
2025-04-17 18:29:46,322 - ***** Epoch: 92: Eval results *****
2025-04-17 18:29:46,323 -   train_loss = 1.195086087499346
2025-04-17 18:30:06,288 - ***** Epoch: 93: Eval results *****
2025-04-17 18:30:06,288 -   train_loss = 1.196711736066001
2025-04-17 18:30:27,652 - ***** Epoch: 94: Eval results *****
2025-04-17 18:30:27,652 -   train_loss = 1.1946528128215246
2025-04-17 18:30:47,999 - ***** Epoch: 95: Eval results *****
2025-04-17 18:30:48,000 -   train_loss = 1.2000490767615182
2025-04-17 18:31:08,124 - ***** Epoch: 96: Eval results *****
2025-04-17 18:31:08,124 -   train_loss = 1.2011844941547938
2025-04-17 18:31:27,741 - ***** Epoch: 97: Eval results *****
2025-04-17 18:31:27,741 -   train_loss = 1.192544434751783
2025-04-17 18:31:47,490 - ***** Epoch: 98: Eval results *****
2025-04-17 18:31:47,490 -   train_loss = 1.2119118571281433
2025-04-17 18:32:05,795 - ***** Epoch: 99: Eval results *****
2025-04-17 18:32:05,795 -   train_loss = 1.1991738847323827
2025-04-17 18:32:26,979 - ***** Epoch: 100: Eval results *****
2025-04-17 18:32:26,979 -   train_loss = 1.200210886342185
2025-04-17 18:32:27,450 - Pre-training finished...
2025-04-17 18:32:27,925 - Freeze all parameters but the last layer for efficiency
2025-04-17 18:32:27,934 - Multimodal Intent Recognition begins...
2025-04-17 18:32:27,935 - Training begins...
2025-04-17 18:32:42,711 - Initializing centroids with K-means++...
2025-04-17 18:32:42,804 - K-means++ used 0.09 s
2025-04-17 18:33:18,901 - K-means used 0.03 s
2025-04-17 18:33:19,950 - ***** Epoch: 1 *****
2025-04-17 18:33:19,950 - Supervised Training Loss: 4.397820
2025-04-17 18:33:19,951 - Unsupervised Training Loss: 5.506700
2025-04-17 18:33:52,997 - K-means used 0.03 s
2025-04-17 18:33:54,090 - ***** Epoch: 2 *****
2025-04-17 18:33:54,090 - Supervised Training Loss: 4.933410
2025-04-17 18:33:54,090 - Unsupervised Training Loss: 5.540830
2025-04-17 18:34:26,991 - K-means used 0.02 s
2025-04-17 18:34:28,058 - ***** Epoch: 3 *****
2025-04-17 18:34:28,058 - Supervised Training Loss: 4.619520
2025-04-17 18:34:28,058 - Unsupervised Training Loss: 5.404820
2025-04-17 18:35:01,619 - K-means used 0.02 s
2025-04-17 18:35:02,731 - ***** Epoch: 4 *****
2025-04-17 18:35:02,731 - Supervised Training Loss: 4.345610
2025-04-17 18:35:02,731 - Unsupervised Training Loss: 5.472310
2025-04-17 18:35:36,104 - K-means used 0.05 s
2025-04-17 18:35:37,325 - ***** Epoch: 5 *****
2025-04-17 18:35:37,326 - Supervised Training Loss: 4.100510
2025-04-17 18:35:37,326 - Unsupervised Training Loss: 5.513870
2025-04-17 18:36:12,075 - K-means used 0.03 s
2025-04-17 18:36:13,247 - ***** Epoch: 6 *****
2025-04-17 18:36:13,248 - Supervised Training Loss: 4.429200
2025-04-17 18:36:13,248 - Unsupervised Training Loss: 5.308950
2025-04-17 18:36:47,071 - K-means used 0.02 s
2025-04-17 18:36:48,398 - ***** Epoch: 7 *****
2025-04-17 18:36:48,398 - Supervised Training Loss: 4.324700
2025-04-17 18:36:48,398 - Unsupervised Training Loss: 5.427000
2025-04-17 18:37:21,372 - K-means used 0.02 s
2025-04-17 18:37:22,729 - ***** Epoch: 8 *****
2025-04-17 18:37:22,729 - Supervised Training Loss: 4.175650
2025-04-17 18:37:22,729 - Unsupervised Training Loss: 5.487150
2025-04-17 18:37:57,318 - K-means used 0.02 s
2025-04-17 18:37:58,632 - ***** Epoch: 9 *****
2025-04-17 18:37:58,632 - Supervised Training Loss: 4.383980
2025-04-17 18:37:58,632 - Unsupervised Training Loss: 5.521950
2025-04-17 18:38:31,436 - K-means used 0.03 s
2025-04-17 18:38:32,860 - ***** Epoch: 10 *****
2025-04-17 18:38:32,861 - Supervised Training Loss: 4.312340
2025-04-17 18:38:32,861 - Unsupervised Training Loss: 5.362000
2025-04-17 18:39:06,038 - K-means used 0.02 s
2025-04-17 18:39:07,818 - ***** Epoch: 11 *****
2025-04-17 18:39:07,818 - Supervised Training Loss: 4.242060
2025-04-17 18:39:07,818 - Unsupervised Training Loss: 5.441340
2025-04-17 18:39:42,638 - K-means used 0.02 s
2025-04-17 18:39:44,187 - ***** Epoch: 12 *****
2025-04-17 18:39:44,188 - Supervised Training Loss: 4.362920
2025-04-17 18:39:44,188 - Unsupervised Training Loss: 5.506860
2025-04-17 18:40:17,226 - K-means used 0.02 s
2025-04-17 18:40:18,944 - ***** Epoch: 13 *****
2025-04-17 18:40:18,944 - Supervised Training Loss: 4.334870
2025-04-17 18:40:18,944 - Unsupervised Training Loss: 5.213300
2025-04-17 18:40:52,105 - K-means used 0.03 s
2025-04-17 18:40:53,781 - ***** Epoch: 14 *****
2025-04-17 18:40:53,781 - Supervised Training Loss: 4.268950
2025-04-17 18:40:53,782 - Unsupervised Training Loss: 5.367550
2025-04-17 18:41:29,143 - K-means used 0.01 s
2025-04-17 18:41:31,258 - ***** Epoch: 15 *****
2025-04-17 18:41:31,258 - Supervised Training Loss: 4.158830
2025-04-17 18:41:31,258 - Unsupervised Training Loss: 5.456170
2025-04-17 18:42:08,105 - K-means used 0.01 s
2025-04-17 18:42:10,012 - ***** Epoch: 16 *****
2025-04-17 18:42:10,012 - Supervised Training Loss: 4.346010
2025-04-17 18:42:10,012 - Unsupervised Training Loss: 4.904290
2025-04-17 18:42:46,722 - K-means used 0.07 s
2025-04-17 18:42:48,646 - ***** Epoch: 17 *****
2025-04-17 18:42:48,646 - Supervised Training Loss: 4.324300
2025-04-17 18:42:48,646 - Unsupervised Training Loss: 5.141030
2025-04-17 18:43:13,184 - Training is finished...
2025-04-17 18:43:13,185 - Testing begins...
2025-04-17 18:43:20,123 - ***** Test results *****
2025-04-17 18:43:20,123 -   ACC = 34.16
2025-04-17 18:43:20,123 -   ARI = 13.19
2025-04-17 18:43:20,123 -   NMI = 37.54
2025-04-17 18:43:20,123 -   fmi = 18.99
2025-04-17 18:43:20,123 - Testing is finished...
2025-04-17 18:43:20,123 - Multimodal intent recognition is finished...
2025-04-17 18:43:20,123 - Results are saved in results/results_umc2_pre.csv
