2025-04-17 16:32:34,061 - 【无监督】进入了无监督的设定中, 加载数据集
2025-04-17 16:32:34,062 - data preparation...
2025-04-17 16:32:42,818 - Number of train samples = 1779
2025-04-17 16:32:42,819 - Number of testing samples = 445
2025-04-17 16:32:42,819 - data preparation...
2025-04-17 16:32:45,007 - num_train_examples = 1779
2025-04-17 16:32:45,008 - ============================== Params ==============================
2025-04-17 16:32:45,008 - logger_name: umc_umc_bert-base-uncased_MIntRec_0
2025-04-17 16:32:45,008 - dataset: MIntRec
2025-04-17 16:32:45,008 - multimodal_method: umc
2025-04-17 16:32:45,008 - method: umc
2025-04-17 16:32:45,008 - setting: unsupervised
2025-04-17 16:32:45,008 - merge_dev: False
2025-04-17 16:32:45,008 - text_backbone: bert-base-uncased
2025-04-17 16:32:45,008 - seed: 0
2025-04-17 16:32:45,008 - num_workers: 16
2025-04-17 16:32:45,008 - log_id: umc_umc_bert-base-uncased_MIntRec_0_2025-04-17-16-32-34
2025-04-17 16:32:45,008 - gpu_id: 1
2025-04-17 16:32:45,008 - data_path: /root/autodl-tmp/home/Share/Dataset/LZH
2025-04-17 16:32:45,008 - train: True
2025-04-17 16:32:45,008 - tune: True
2025-04-17 16:32:45,008 - save_model: True
2025-04-17 16:32:45,008 - save_results: True
2025-04-17 16:32:45,008 - log_path: logs
2025-04-17 16:32:45,008 - cache_path: cache
2025-04-17 16:32:45,008 - video_data_path: video_data
2025-04-17 16:32:45,008 - audio_data_path: audio_data
2025-04-17 16:32:45,009 - video_feats_path: swin_feats.pkl
2025-04-17 16:32:45,009 - audio_feats_path: wavlm_feats.pkl
2025-04-17 16:32:45,009 - results_path: results
2025-04-17 16:32:45,009 - output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/SMC/outputs_test2/MIntRec
2025-04-17 16:32:45,009 - model_path: models
2025-04-17 16:32:45,009 - config_file_name: umc_MIntRec
2025-04-17 16:32:45,009 - results_file_name: results_umc_pre.csv
2025-04-17 16:32:45,009 - text_pretrained_model: uncased_L-12_H-768_A-12
2025-04-17 16:32:45,009 - pretrained_bert_model: uncased_L-12_H-768_A-12
2025-04-17 16:32:45,009 - pretrain_batch_size: 128
2025-04-17 16:32:45,009 - train_batch_size: 128
2025-04-17 16:32:45,009 - eval_batch_size: 128
2025-04-17 16:32:45,009 - test_batch_size: 128
2025-04-17 16:32:45,009 - num_pretrain_epochs: 100
2025-04-17 16:32:45,009 - num_train_epochs: 100
2025-04-17 16:32:45,009 - pretrain: [True]
2025-04-17 16:32:45,009 - aligned_method: ctc
2025-04-17 16:32:45,009 - need_aligned: False
2025-04-17 16:32:45,009 - freeze_pretrain_bert_parameters: [True]
2025-04-17 16:32:45,009 - freeze_train_bert_parameters: [True]
2025-04-17 16:32:45,009 - pretrain_temperature: [0.08]
2025-04-17 16:32:45,009 - train_temperature_sup: [0.5]
2025-04-17 16:32:45,009 - train_temperature_unsup: [2]
2025-04-17 16:32:45,009 - activation: tanh
2025-04-17 16:32:45,009 - lr_pre: [1e-05]
2025-04-17 16:32:45,009 - lr: [5e-05]
2025-04-17 16:32:45,009 - delta: [0.05]
2025-04-17 16:32:45,009 - thres: [0.1]
2025-04-17 16:32:45,010 - topk: [5]
2025-04-17 16:32:45,010 - weight_decay: 0.01
2025-04-17 16:32:45,010 - feat_dim: 768
2025-04-17 16:32:45,010 - hidden_size: 768
2025-04-17 16:32:45,010 - grad_clip: -1.0
2025-04-17 16:32:45,010 - warmup_proportion: [0.1]
2025-04-17 16:32:45,010 - hidden_dropout_prob: 0.1
2025-04-17 16:32:45,010 - weight: 1.0
2025-04-17 16:32:45,010 - loss_mode: rdrop
2025-04-17 16:32:45,010 - base_dim: 256
2025-04-17 16:32:45,010 - nheads: 8
2025-04-17 16:32:45,010 - attn_dropout: 0.1
2025-04-17 16:32:45,010 - relu_dropout: 0.1
2025-04-17 16:32:45,010 - embed_dropout: 0.01
2025-04-17 16:32:45,010 - res_dropout: 0.0
2025-04-17 16:32:45,010 - attn_mask: True
2025-04-17 16:32:45,010 - encoder_layers_1: 1
2025-04-17 16:32:45,010 - fusion_act: tanh
2025-04-17 16:32:45,010 - pred_output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/SMC/outputs_test2/MIntRec/umc_umc_MIntRec_bert-base-uncased_0
2025-04-17 16:32:45,010 - model_output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/SMC/outputs_test2/MIntRec/umc_umc_MIntRec_bert-base-uncased_0/models
2025-04-17 16:32:45,010 - text_seq_len: 30
2025-04-17 16:32:45,010 - video_seq_len: 230
2025-04-17 16:32:45,010 - audio_seq_len: 480
2025-04-17 16:32:45,010 - text_feat_dim: 768
2025-04-17 16:32:45,010 - video_feat_dim: 1024
2025-04-17 16:32:45,010 - audio_feat_dim: 768
2025-04-17 16:32:45,010 - num_labels: 20
2025-04-17 16:32:45,010 - num_train_examples: 1779
2025-04-17 16:32:45,011 - ============================== End Params ==============================
2025-04-17 16:32:46,316 - Freeze all parameters but the last layer for efficiency
2025-04-17 16:32:46,350 - Pre-training start...
2025-04-17 16:33:02,297 - ***** Epoch: 1: Eval results *****
2025-04-17 16:33:02,298 -   train_loss = 5.967826638902936
2025-04-17 16:33:19,476 - ***** Epoch: 2: Eval results *****
2025-04-17 16:33:19,477 -   train_loss = 5.971589735576084
2025-04-17 16:33:37,214 - ***** Epoch: 3: Eval results *****
2025-04-17 16:33:37,215 -   train_loss = 5.949860777173724
2025-04-17 16:33:54,659 - ***** Epoch: 4: Eval results *****
2025-04-17 16:33:54,660 -   train_loss = 5.939929962158203
2025-04-17 16:34:12,188 - ***** Epoch: 5: Eval results *****
2025-04-17 16:34:12,189 -   train_loss = 5.922791310719082
2025-04-17 16:34:29,739 - ***** Epoch: 6: Eval results *****
2025-04-17 16:34:29,739 -   train_loss = 5.903789145605905
2025-04-17 16:34:46,614 - ***** Epoch: 7: Eval results *****
2025-04-17 16:34:46,614 -   train_loss = 5.868077448436192
2025-04-17 16:35:03,617 - ***** Epoch: 8: Eval results *****
2025-04-17 16:35:03,618 -   train_loss = 5.780516999108451
2025-04-17 16:35:20,581 - ***** Epoch: 9: Eval results *****
2025-04-17 16:35:20,582 -   train_loss = 5.588371651513236
2025-04-17 16:35:37,725 - ***** Epoch: 10: Eval results *****
2025-04-17 16:35:37,725 -   train_loss = 5.153501374380929
2025-04-17 16:35:54,590 - ***** Epoch: 11: Eval results *****
2025-04-17 16:35:54,590 -   train_loss = 4.619927099772862
2025-04-17 16:36:11,245 - ***** Epoch: 12: Eval results *****
2025-04-17 16:36:11,246 -   train_loss = 4.122914961406162
2025-04-17 16:36:27,136 - ***** Epoch: 13: Eval results *****
2025-04-17 16:36:27,136 -   train_loss = 3.7356801543916975
2025-04-17 16:36:43,341 - ***** Epoch: 14: Eval results *****
2025-04-17 16:36:43,341 -   train_loss = 3.4071628877094815
2025-04-17 16:36:59,218 - ***** Epoch: 15: Eval results *****
2025-04-17 16:36:59,218 -   train_loss = 3.1497167689459666
2025-04-17 16:37:15,534 - ***** Epoch: 16: Eval results *****
2025-04-17 16:37:15,535 -   train_loss = 2.877753802708217
2025-04-17 16:37:32,350 - ***** Epoch: 17: Eval results *****
2025-04-17 16:37:32,351 -   train_loss = 2.7021113634109497
2025-04-17 16:37:49,893 - ***** Epoch: 18: Eval results *****
2025-04-17 16:37:49,893 -   train_loss = 2.518162795475551
2025-04-17 16:38:06,938 - ***** Epoch: 19: Eval results *****
2025-04-17 16:38:06,938 -   train_loss = 2.405760748045785
2025-04-17 16:38:23,954 - ***** Epoch: 20: Eval results *****
2025-04-17 16:38:23,954 -   train_loss = 2.2781627689089095
2025-04-17 16:38:40,823 - ***** Epoch: 21: Eval results *****
2025-04-17 16:38:40,823 -   train_loss = 2.1891865049089705
2025-04-17 16:38:58,265 - ***** Epoch: 22: Eval results *****
2025-04-17 16:38:58,265 -   train_loss = 2.1028666155678883
2025-04-17 16:39:14,901 - ***** Epoch: 23: Eval results *****
2025-04-17 16:39:14,902 -   train_loss = 2.0492465836661204
2025-04-17 16:39:31,942 - ***** Epoch: 24: Eval results *****
2025-04-17 16:39:31,942 -   train_loss = 1.9714668818882533
2025-04-17 16:39:49,016 - ***** Epoch: 25: Eval results *****
2025-04-17 16:39:49,016 -   train_loss = 1.9248780948775155
2025-04-17 16:40:05,080 - ***** Epoch: 26: Eval results *****
2025-04-17 16:40:05,081 -   train_loss = 1.873549222946167
2025-04-17 16:40:22,015 - ***** Epoch: 27: Eval results *****
2025-04-17 16:40:22,016 -   train_loss = 1.8267416954040527
2025-04-17 16:40:38,293 - ***** Epoch: 28: Eval results *****
2025-04-17 16:40:38,294 -   train_loss = 1.775515956538064
2025-04-17 16:40:55,319 - ***** Epoch: 29: Eval results *****
2025-04-17 16:40:55,319 -   train_loss = 1.7537591116768974
2025-04-17 16:41:12,512 - ***** Epoch: 30: Eval results *****
2025-04-17 16:41:12,513 -   train_loss = 1.7100726195744105
2025-04-17 16:41:29,734 - ***** Epoch: 31: Eval results *****
2025-04-17 16:41:29,735 -   train_loss = 1.6806158678872245
2025-04-17 16:41:46,693 - ***** Epoch: 32: Eval results *****
2025-04-17 16:41:46,694 -   train_loss = 1.659295277936118
2025-04-17 16:42:03,199 - ***** Epoch: 33: Eval results *****
2025-04-17 16:42:03,199 -   train_loss = 1.6262785962649755
2025-04-17 16:42:20,869 - ***** Epoch: 34: Eval results *****
2025-04-17 16:42:20,870 -   train_loss = 1.6045626997947693
2025-04-17 16:42:38,511 - ***** Epoch: 35: Eval results *****
2025-04-17 16:42:38,511 -   train_loss = 1.5992527263505119
2025-04-17 16:42:56,000 - ***** Epoch: 36: Eval results *****
2025-04-17 16:42:56,000 -   train_loss = 1.5664472579956055
2025-04-17 16:43:13,519 - ***** Epoch: 37: Eval results *****
2025-04-17 16:43:13,520 -   train_loss = 1.5327130811555045
2025-04-17 16:43:31,027 - ***** Epoch: 38: Eval results *****
2025-04-17 16:43:31,027 -   train_loss = 1.5097572548048837
2025-04-17 16:43:48,265 - ***** Epoch: 39: Eval results *****
2025-04-17 16:43:48,265 -   train_loss = 1.5068307774407523
2025-04-17 16:44:05,480 - ***** Epoch: 40: Eval results *****
2025-04-17 16:44:05,480 -   train_loss = 1.4934091908591134
2025-04-17 16:44:22,617 - ***** Epoch: 41: Eval results *****
2025-04-17 16:44:22,618 -   train_loss = 1.4774795004299708
2025-04-17 16:44:39,674 - ***** Epoch: 42: Eval results *****
2025-04-17 16:44:39,674 -   train_loss = 1.4801364541053772
2025-04-17 16:44:56,674 - ***** Epoch: 43: Eval results *****
2025-04-17 16:44:56,674 -   train_loss = 1.4486418536731176
2025-04-17 16:45:13,619 - ***** Epoch: 44: Eval results *****
2025-04-17 16:45:13,619 -   train_loss = 1.445319311959403
2025-04-17 16:45:30,930 - ***** Epoch: 45: Eval results *****
2025-04-17 16:45:30,930 -   train_loss = 1.4379086324146815
2025-04-17 16:45:48,860 - ***** Epoch: 46: Eval results *****
2025-04-17 16:45:48,861 -   train_loss = 1.4199219175747462
2025-04-17 16:46:06,517 - ***** Epoch: 47: Eval results *****
2025-04-17 16:46:06,518 -   train_loss = 1.4129304374967302
2025-04-17 16:46:23,868 - ***** Epoch: 48: Eval results *****
2025-04-17 16:46:23,869 -   train_loss = 1.3989219324929374
2025-04-17 16:46:41,594 - ***** Epoch: 49: Eval results *****
2025-04-17 16:46:41,594 -   train_loss = 1.393708484513419
2025-04-17 16:46:58,881 - ***** Epoch: 50: Eval results *****
2025-04-17 16:46:58,881 -   train_loss = 1.3745861223765783
2025-04-17 16:47:15,984 - ***** Epoch: 51: Eval results *****
2025-04-17 16:47:15,985 -   train_loss = 1.3859705754688807
2025-04-17 16:47:33,413 - ***** Epoch: 52: Eval results *****
2025-04-17 16:47:33,414 -   train_loss = 1.370119299207415
2025-04-17 16:47:50,415 - ***** Epoch: 53: Eval results *****
2025-04-17 16:47:50,415 -   train_loss = 1.3686991333961487
2025-04-17 16:48:07,266 - ***** Epoch: 54: Eval results *****
2025-04-17 16:48:07,266 -   train_loss = 1.3757227318627494
2025-04-17 16:48:24,075 - ***** Epoch: 55: Eval results *****
2025-04-17 16:48:24,075 -   train_loss = 1.351050283227648
2025-04-17 16:48:40,780 - ***** Epoch: 56: Eval results *****
2025-04-17 16:48:40,780 -   train_loss = 1.3409660373415266
2025-04-17 16:48:57,261 - ***** Epoch: 57: Eval results *****
2025-04-17 16:48:57,261 -   train_loss = 1.3233257617269243
2025-04-17 16:49:13,857 - ***** Epoch: 58: Eval results *****
2025-04-17 16:49:13,857 -   train_loss = 1.3361597231456213
2025-04-17 16:49:30,164 - ***** Epoch: 59: Eval results *****
2025-04-17 16:49:30,164 -   train_loss = 1.3159545063972473
2025-04-17 16:49:46,288 - ***** Epoch: 60: Eval results *****
2025-04-17 16:49:46,288 -   train_loss = 1.3161584224019731
2025-04-17 16:50:03,224 - ***** Epoch: 61: Eval results *****
2025-04-17 16:50:03,224 -   train_loss = 1.3183655738830566
2025-04-17 16:50:20,627 - ***** Epoch: 62: Eval results *****
2025-04-17 16:50:20,627 -   train_loss = 1.310696073940822
2025-04-17 16:50:36,476 - ***** Epoch: 63: Eval results *****
2025-04-17 16:50:36,476 -   train_loss = 1.3129978009632655
2025-04-17 16:50:53,021 - ***** Epoch: 64: Eval results *****
2025-04-17 16:50:53,021 -   train_loss = 1.288249066897801
2025-04-17 16:51:09,379 - ***** Epoch: 65: Eval results *****
2025-04-17 16:51:09,379 -   train_loss = 1.2983562009675162
2025-04-17 16:51:26,329 - ***** Epoch: 66: Eval results *****
2025-04-17 16:51:26,329 -   train_loss = 1.288483704839434
2025-04-17 16:51:43,179 - ***** Epoch: 67: Eval results *****
2025-04-17 16:51:43,179 -   train_loss = 1.2752152000154768
2025-04-17 16:51:58,799 - ***** Epoch: 68: Eval results *****
2025-04-17 16:51:58,799 -   train_loss = 1.2740111776760645
2025-04-17 16:52:15,336 - ***** Epoch: 69: Eval results *****
2025-04-17 16:52:15,336 -   train_loss = 1.2728354930877686
2025-04-17 16:52:31,823 - ***** Epoch: 70: Eval results *****
2025-04-17 16:52:31,824 -   train_loss = 1.2826504026140486
2025-04-17 16:52:48,600 - ***** Epoch: 71: Eval results *****
2025-04-17 16:52:48,601 -   train_loss = 1.269807415349143
2025-04-17 16:53:05,443 - ***** Epoch: 72: Eval results *****
2025-04-17 16:53:05,443 -   train_loss = 1.2861388666289193
2025-04-17 16:53:21,572 - ***** Epoch: 73: Eval results *****
2025-04-17 16:53:21,572 -   train_loss = 1.2752713305609567
2025-04-17 16:53:37,688 - ***** Epoch: 74: Eval results *****
2025-04-17 16:53:37,689 -   train_loss = 1.2711861218724931
2025-04-17 16:53:53,968 - ***** Epoch: 75: Eval results *****
2025-04-17 16:53:53,968 -   train_loss = 1.2753633175577437
2025-04-17 16:54:10,846 - ***** Epoch: 76: Eval results *****
2025-04-17 16:54:10,846 -   train_loss = 1.2669901507241386
2025-04-17 16:54:27,871 - ***** Epoch: 77: Eval results *****
2025-04-17 16:54:27,871 -   train_loss = 1.2517858573368617
2025-04-17 16:54:44,284 - ***** Epoch: 78: Eval results *****
2025-04-17 16:54:44,285 -   train_loss = 1.2558418767792838
2025-04-17 16:55:01,040 - ***** Epoch: 79: Eval results *****
2025-04-17 16:55:01,040 -   train_loss = 1.2604527047702245
2025-04-17 16:55:17,608 - ***** Epoch: 80: Eval results *****
2025-04-17 16:55:17,608 -   train_loss = 1.2514207022530692
2025-04-17 16:55:34,225 - ***** Epoch: 81: Eval results *****
2025-04-17 16:55:34,225 -   train_loss = 1.257742702960968
2025-04-17 16:55:50,807 - ***** Epoch: 82: Eval results *****
2025-04-17 16:55:50,807 -   train_loss = 1.2518826808248247
2025-04-17 16:56:07,368 - ***** Epoch: 83: Eval results *****
2025-04-17 16:56:07,368 -   train_loss = 1.2684046881539481
2025-04-17 16:56:23,947 - ***** Epoch: 84: Eval results *****
2025-04-17 16:56:23,947 -   train_loss = 1.2517233490943909
2025-04-17 16:56:40,442 - ***** Epoch: 85: Eval results *****
2025-04-17 16:56:40,442 -   train_loss = 1.2504224692072188
2025-04-17 16:56:57,965 - ***** Epoch: 86: Eval results *****
2025-04-17 16:56:57,965 -   train_loss = 1.253894329071045
