2025-04-11 11:34:44,936 - ============================== Params ==============================
2025-04-11 11:34:44,937 - logger_name: umc_umc_bert-base-uncased_MIntRec_1
2025-04-11 11:34:44,937 - dataset: MIntRec
2025-04-11 11:34:44,937 - multimodal_method: umc
2025-04-11 11:34:44,937 - method: umc
2025-04-11 11:34:44,937 - text_backbone: bert-base-uncased
2025-04-11 11:34:44,937 - seed: 1
2025-04-11 11:34:44,937 - num_workers: 16
2025-04-11 11:34:44,937 - log_id: umc_umc_bert-base-uncased_MIntRec_1_2025-04-11-11-34-44
2025-04-11 11:34:44,937 - gpu_id: 0
2025-04-11 11:34:44,937 - data_path: /root/autodl-tmp/home/Share/Dataset/LZH
2025-04-11 11:34:44,937 - train: True
2025-04-11 11:34:44,937 - tune: True
2025-04-11 11:34:44,937 - save_model: True
2025-04-11 11:34:44,937 - save_results: True
2025-04-11 11:34:44,937 - log_path: logs
2025-04-11 11:34:44,937 - cache_path: cache
2025-04-11 11:34:44,937 - video_data_path: video_data
2025-04-11 11:34:44,937 - audio_data_path: audio_data
2025-04-11 11:34:44,937 - video_feats_path: swin_feats.pkl
2025-04-11 11:34:44,937 - audio_feats_path: wavlm_feats.pkl
2025-04-11 11:34:44,937 - results_path: results
2025-04-11 11:34:44,937 - output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/UMC/outputs/MIntRec
2025-04-11 11:34:44,937 - model_path: models
2025-04-11 11:34:44,937 - config_file_name: umc_MIntRec
2025-04-11 11:34:44,938 - results_file_name: results_umc.csv
2025-04-11 11:34:44,938 - text_pretrained_model: uncased_L-12_H-768_A-12
2025-04-11 11:34:44,938 - text_seq_len: 30
2025-04-11 11:34:44,938 - video_seq_len: 230
2025-04-11 11:34:44,938 - audio_seq_len: 480
2025-04-11 11:34:44,938 - text_feat_dim: 768
2025-04-11 11:34:44,938 - video_feat_dim: 1024
2025-04-11 11:34:44,938 - audio_feat_dim: 768
2025-04-11 11:34:44,938 - num_labels: 20
2025-04-11 11:34:44,938 - num_train_examples: 1779
2025-04-11 11:34:44,938 - pretrained_bert_model: uncased_L-12_H-768_A-12
2025-04-11 11:34:44,938 - pretrain_batch_size: 128
2025-04-11 11:34:44,938 - train_batch_size: 128
2025-04-11 11:34:44,938 - eval_batch_size: 128
2025-04-11 11:34:44,938 - test_batch_size: 128
2025-04-11 11:34:44,938 - num_pretrain_epochs: 100
2025-04-11 11:34:44,938 - num_train_epochs: 100
2025-04-11 11:34:44,938 - pretrain: [True]
2025-04-11 11:34:44,938 - aligned_method: ctc
2025-04-11 11:34:44,938 - need_aligned: False
2025-04-11 11:34:44,938 - freeze_pretrain_bert_parameters: [True]
2025-04-11 11:34:44,938 - freeze_train_bert_parameters: [True]
2025-04-11 11:34:44,938 - pretrain_temperature: [0.2]
2025-04-11 11:34:44,938 - train_temperature_sup: [1.4]
2025-04-11 11:34:44,938 - train_temperature_unsup: [1]
2025-04-11 11:34:44,938 - activation: tanh
2025-04-11 11:34:44,938 - lr_pre: 1e-05
2025-04-11 11:34:44,938 - lr: [0.0003]
2025-04-11 11:34:44,938 - delta: [0.05]
2025-04-11 11:34:44,939 - thres: [0.1]
2025-04-11 11:34:44,939 - topk: [5]
2025-04-11 11:34:44,939 - weight_decay: 0.01
2025-04-11 11:34:44,939 - feat_dim: 768
2025-04-11 11:34:44,939 - hidden_size: 768
2025-04-11 11:34:44,939 - grad_clip: -1.0
2025-04-11 11:34:44,939 - warmup_proportion: 0.5
2025-04-11 11:34:44,939 - hidden_dropout_prob: 0.1
2025-04-11 11:34:44,939 - weight: 1.0
2025-04-11 11:34:44,939 - loss_mode: rdrop
2025-04-11 11:34:44,939 - base_dim: 256
2025-04-11 11:34:44,939 - nheads: 8
2025-04-11 11:34:44,939 - attn_dropout: 0.1
2025-04-11 11:34:44,939 - relu_dropout: 0.1
2025-04-11 11:34:44,939 - embed_dropout: 0.1
2025-04-11 11:34:44,939 - res_dropout: 0.0
2025-04-11 11:34:44,939 - attn_mask: True
2025-04-11 11:34:44,939 - encoder_layers_1: 1
2025-04-11 11:34:44,939 - fusion_act: tanh
2025-04-11 11:34:44,940 - pred_output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/UMC/outputs/MIntRec/umc_umc_MIntRec_bert-base-uncased_1
2025-04-11 11:34:44,940 - model_output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/UMC/outputs/MIntRec/umc_umc_MIntRec_bert-base-uncased_1/models
2025-04-11 11:34:44,940 - ============================== End Params ==============================
2025-04-11 11:34:46,038 - Freeze all parameters but the last layer for efficiency
2025-04-11 11:34:46,073 - Pre-training start...
2025-04-11 11:35:01,050 - ***** Epoch: 1: Eval results *****
2025-04-11 11:35:01,050 -   train_loss = 5.941777331488473
2025-04-11 11:35:14,676 - ***** Epoch: 2: Eval results *****
2025-04-11 11:35:14,676 -   train_loss = 5.943211725779942
2025-04-11 11:35:29,561 - ***** Epoch: 3: Eval results *****
2025-04-11 11:35:29,562 -   train_loss = 5.940015247889927
2025-04-11 11:35:44,319 - ***** Epoch: 4: Eval results *****
2025-04-11 11:35:44,319 -   train_loss = 5.941359383719308
2025-04-11 11:35:59,237 - ***** Epoch: 5: Eval results *****
2025-04-11 11:35:59,237 -   train_loss = 5.944060121263776
2025-04-11 11:36:14,853 - ***** Epoch: 6: Eval results *****
2025-04-11 11:36:14,853 -   train_loss = 5.94230900491987
2025-04-11 11:36:30,274 - ***** Epoch: 7: Eval results *****
2025-04-11 11:36:30,274 -   train_loss = 5.941468681607928
2025-04-11 11:36:45,799 - ***** Epoch: 8: Eval results *****
2025-04-11 11:36:45,800 -   train_loss = 5.935379368918283
2025-04-11 11:37:01,723 - ***** Epoch: 9: Eval results *****
2025-04-11 11:37:01,724 -   train_loss = 5.937350443431309
2025-04-11 11:37:17,590 - ***** Epoch: 10: Eval results *****
2025-04-11 11:37:17,590 -   train_loss = 5.934865474700928
2025-04-11 11:37:33,293 - ***** Epoch: 11: Eval results *****
2025-04-11 11:37:33,294 -   train_loss = 5.931551456451416
2025-04-11 11:37:49,912 - ***** Epoch: 12: Eval results *****
2025-04-11 11:37:49,912 -   train_loss = 5.929231132779803
2025-04-11 11:38:05,953 - ***** Epoch: 13: Eval results *****
2025-04-11 11:38:05,954 -   train_loss = 5.925913095474243
2025-04-11 11:38:21,830 - ***** Epoch: 14: Eval results *****
2025-04-11 11:38:21,830 -   train_loss = 5.92258037839617
2025-04-11 11:38:38,695 - ***** Epoch: 15: Eval results *****
2025-04-11 11:38:38,695 -   train_loss = 5.918372767312186
2025-04-11 11:38:55,493 - ***** Epoch: 16: Eval results *****
2025-04-11 11:38:55,493 -   train_loss = 5.90510756628854
2025-04-11 11:39:11,901 - ***** Epoch: 17: Eval results *****
2025-04-11 11:39:11,902 -   train_loss = 5.893785033907209
2025-04-11 11:39:27,890 - ***** Epoch: 18: Eval results *****
2025-04-11 11:39:27,890 -   train_loss = 5.876230069569179
2025-04-11 11:39:44,447 - ***** Epoch: 19: Eval results *****
2025-04-11 11:39:44,448 -   train_loss = 5.851647104535784
2025-04-11 11:39:59,784 - ***** Epoch: 20: Eval results *****
2025-04-11 11:39:59,784 -   train_loss = 5.8090643882751465
2025-04-11 11:40:16,072 - ***** Epoch: 21: Eval results *****
2025-04-11 11:40:16,072 -   train_loss = 5.736606291362217
2025-04-11 11:40:32,726 - ***** Epoch: 22: Eval results *****
2025-04-11 11:40:32,726 -   train_loss = 5.631619385310581
2025-04-11 11:40:49,712 - ***** Epoch: 23: Eval results *****
2025-04-11 11:40:49,712 -   train_loss = 5.471328565052578
2025-04-11 11:41:06,681 - ***** Epoch: 24: Eval results *****
2025-04-11 11:41:06,681 -   train_loss = 5.277060031890869
2025-04-11 11:41:22,174 - ***** Epoch: 25: Eval results *****
2025-04-11 11:41:22,174 -   train_loss = 5.089137928826468
2025-04-11 11:41:37,825 - ***** Epoch: 26: Eval results *****
2025-04-11 11:41:37,825 -   train_loss = 4.9175887789045065
2025-04-11 11:41:53,419 - ***** Epoch: 27: Eval results *****
2025-04-11 11:41:53,420 -   train_loss = 4.7359960079193115
2025-04-11 11:42:09,024 - ***** Epoch: 28: Eval results *****
2025-04-11 11:42:09,025 -   train_loss = 4.578444651194981
2025-04-11 11:42:24,748 - ***** Epoch: 29: Eval results *****
2025-04-11 11:42:24,749 -   train_loss = 4.421654939651489
2025-04-11 11:42:40,050 - ***** Epoch: 30: Eval results *****
2025-04-11 11:42:40,050 -   train_loss = 4.3127171993255615
2025-04-11 11:42:56,517 - ***** Epoch: 31: Eval results *****
2025-04-11 11:42:56,517 -   train_loss = 4.226478746959141
2025-04-11 11:43:12,547 - ***** Epoch: 32: Eval results *****
2025-04-11 11:43:12,548 -   train_loss = 4.114404610225132
2025-04-11 11:43:27,840 - ***** Epoch: 33: Eval results *****
2025-04-11 11:43:27,840 -   train_loss = 4.033272385597229
2025-04-11 11:43:43,187 - ***** Epoch: 34: Eval results *****
2025-04-11 11:43:43,187 -   train_loss = 3.9383056334086826
2025-04-11 11:43:58,939 - ***** Epoch: 35: Eval results *****
2025-04-11 11:43:58,940 -   train_loss = 3.872098445892334
2025-04-11 11:44:14,408 - ***** Epoch: 36: Eval results *****
2025-04-11 11:44:14,409 -   train_loss = 3.8076287508010864
2025-04-11 11:44:30,695 - ***** Epoch: 37: Eval results *****
2025-04-11 11:44:30,696 -   train_loss = 3.7358149800981795
2025-04-11 11:44:47,324 - ***** Epoch: 38: Eval results *****
2025-04-11 11:44:47,324 -   train_loss = 3.6755588224955966
2025-04-11 11:45:04,893 - ***** Epoch: 39: Eval results *****
2025-04-11 11:45:04,893 -   train_loss = 3.613843100411551
2025-04-11 11:45:22,085 - ***** Epoch: 40: Eval results *****
2025-04-11 11:45:22,085 -   train_loss = 3.573365330696106
2025-04-11 11:45:39,511 - ***** Epoch: 41: Eval results *****
2025-04-11 11:45:39,512 -   train_loss = 3.523865359170096
2025-04-11 11:45:56,038 - ***** Epoch: 42: Eval results *****
2025-04-11 11:45:56,038 -   train_loss = 3.472627111843654
2025-04-11 11:46:13,341 - ***** Epoch: 43: Eval results *****
2025-04-11 11:46:13,341 -   train_loss = 3.423253263745989
2025-04-11 11:46:29,762 - ***** Epoch: 44: Eval results *****
2025-04-11 11:46:29,763 -   train_loss = 3.38187769481114
2025-04-11 11:46:45,882 - ***** Epoch: 45: Eval results *****
2025-04-11 11:46:45,882 -   train_loss = 3.3669522489820207
2025-04-11 11:47:02,447 - ***** Epoch: 46: Eval results *****
2025-04-11 11:47:02,448 -   train_loss = 3.3253520216260637
2025-04-11 11:47:17,645 - ***** Epoch: 47: Eval results *****
2025-04-11 11:47:17,646 -   train_loss = 3.290763327053615
2025-04-11 11:47:33,001 - ***** Epoch: 48: Eval results *****
2025-04-11 11:47:33,001 -   train_loss = 3.2713433844702586
2025-04-11 11:47:47,953 - ***** Epoch: 49: Eval results *****
2025-04-11 11:47:47,953 -   train_loss = 3.2487626927239552
2025-04-11 11:48:03,814 - ***** Epoch: 50: Eval results *****
2025-04-11 11:48:03,814 -   train_loss = 3.2045520884650096
2025-04-11 11:48:19,734 - ***** Epoch: 51: Eval results *****
2025-04-11 11:48:19,734 -   train_loss = 3.1893087455204556
2025-04-11 11:48:35,774 - ***** Epoch: 52: Eval results *****
2025-04-11 11:48:35,774 -   train_loss = 3.1605567932128906
2025-04-11 11:48:52,437 - ***** Epoch: 53: Eval results *****
2025-04-11 11:48:52,437 -   train_loss = 3.157367774418422
2025-04-11 11:49:08,525 - ***** Epoch: 54: Eval results *****
2025-04-11 11:49:08,525 -   train_loss = 3.1342001983097623
2025-04-11 11:49:24,749 - ***** Epoch: 55: Eval results *****
2025-04-11 11:49:24,750 -   train_loss = 3.1002323797770908
2025-04-11 11:49:40,749 - ***** Epoch: 56: Eval results *****
2025-04-11 11:49:40,749 -   train_loss = 3.0900677612849643
2025-04-11 11:49:55,300 - ***** Epoch: 57: Eval results *****
2025-04-11 11:49:55,300 -   train_loss = 3.070037143571036
2025-04-11 11:50:11,033 - ***** Epoch: 58: Eval results *****
2025-04-11 11:50:11,034 -   train_loss = 3.067110436303275
2025-04-11 11:50:26,419 - ***** Epoch: 59: Eval results *****
2025-04-11 11:50:26,420 -   train_loss = 3.0513739245278493
2025-04-11 11:50:43,034 - ***** Epoch: 60: Eval results *****
2025-04-11 11:50:43,035 -   train_loss = 3.038637672151838
2025-04-11 11:50:59,487 - ***** Epoch: 61: Eval results *****
2025-04-11 11:50:59,487 -   train_loss = 3.032252720424107
2025-04-11 11:51:16,048 - ***** Epoch: 62: Eval results *****
2025-04-11 11:51:16,049 -   train_loss = 3.017311249460493
2025-04-11 11:51:35,824 - ***** Epoch: 63: Eval results *****
2025-04-11 11:51:35,825 -   train_loss = 3.0020889725003923
2025-04-11 11:51:56,403 - ***** Epoch: 64: Eval results *****
2025-04-11 11:51:56,404 -   train_loss = 2.994274377822876
2025-04-11 11:52:13,776 - ***** Epoch: 65: Eval results *****
2025-04-11 11:52:13,777 -   train_loss = 2.9883795976638794
2025-04-11 11:52:28,111 - ***** Epoch: 66: Eval results *****
2025-04-11 11:52:28,114 -   train_loss = 2.968860251562936
2025-04-11 11:52:45,082 - ***** Epoch: 67: Eval results *****
2025-04-11 11:52:45,082 -   train_loss = 2.9607382672173634
2025-04-11 11:53:01,602 - ***** Epoch: 68: Eval results *****
2025-04-11 11:53:01,602 -   train_loss = 2.9548771381378174
2025-04-11 11:53:18,697 - ***** Epoch: 69: Eval results *****
2025-04-11 11:53:18,698 -   train_loss = 2.9351753337042674
2025-04-11 11:53:35,159 - ***** Epoch: 70: Eval results *****
2025-04-11 11:53:35,159 -   train_loss = 2.9342627695628574
2025-04-11 11:53:52,019 - ***** Epoch: 71: Eval results *****
2025-04-11 11:53:52,020 -   train_loss = 2.9382831028529575
2025-04-11 11:54:09,002 - ***** Epoch: 72: Eval results *****
2025-04-11 11:54:09,002 -   train_loss = 2.925552725791931
2025-04-11 11:54:25,326 - ***** Epoch: 73: Eval results *****
2025-04-11 11:54:25,326 -   train_loss = 2.920672961643764
2025-04-11 11:54:41,480 - ***** Epoch: 74: Eval results *****
2025-04-11 11:54:41,481 -   train_loss = 2.9137140001569475
2025-04-11 11:54:56,508 - ***** Epoch: 75: Eval results *****
2025-04-11 11:54:56,509 -   train_loss = 2.908368570463998
2025-04-11 11:55:12,468 - ***** Epoch: 76: Eval results *****
2025-04-11 11:55:12,468 -   train_loss = 2.9014247996466502
2025-04-11 11:55:28,076 - ***** Epoch: 77: Eval results *****
2025-04-11 11:55:28,076 -   train_loss = 2.891826476369585
2025-04-11 11:55:44,174 - ***** Epoch: 78: Eval results *****
2025-04-11 11:55:44,174 -   train_loss = 2.8890299456460133
2025-04-11 11:56:00,389 - ***** Epoch: 79: Eval results *****
2025-04-11 11:56:00,390 -   train_loss = 2.88466739654541
2025-04-11 11:56:16,341 - ***** Epoch: 80: Eval results *****
2025-04-11 11:56:16,341 -   train_loss = 2.8902816772460938
2025-04-11 11:56:32,604 - ***** Epoch: 81: Eval results *****
2025-04-11 11:56:32,604 -   train_loss = 2.8742143426622664
2025-04-11 11:56:48,504 - ***** Epoch: 82: Eval results *****
2025-04-11 11:56:48,504 -   train_loss = 2.888072303363255
2025-04-11 11:57:03,880 - ***** Epoch: 83: Eval results *****
2025-04-11 11:57:03,880 -   train_loss = 2.873855539730617
2025-04-11 11:57:18,690 - ***** Epoch: 84: Eval results *****
2025-04-11 11:57:18,691 -   train_loss = 2.8668184791292464
2025-04-11 11:57:32,830 - ***** Epoch: 85: Eval results *****
2025-04-11 11:57:32,830 -   train_loss = 2.8872878892081126
2025-04-11 11:57:45,874 - ***** Epoch: 86: Eval results *****
2025-04-11 11:57:45,875 -   train_loss = 2.8709714072091237
2025-04-11 11:58:00,990 - ***** Epoch: 87: Eval results *****
2025-04-11 11:58:00,990 -   train_loss = 2.87093676839556
2025-04-11 11:58:15,778 - ***** Epoch: 88: Eval results *****
2025-04-11 11:58:15,779 -   train_loss = 2.8744402612958635
2025-04-11 11:58:31,905 - ***** Epoch: 89: Eval results *****
2025-04-11 11:58:31,905 -   train_loss = 2.86205450126103
2025-04-11 11:58:48,145 - ***** Epoch: 90: Eval results *****
2025-04-11 11:58:48,145 -   train_loss = 2.873543756348746
2025-04-11 11:59:03,548 - ***** Epoch: 91: Eval results *****
2025-04-11 11:59:03,549 -   train_loss = 2.879704066685268
2025-04-11 11:59:18,801 - ***** Epoch: 92: Eval results *****
2025-04-11 11:59:18,802 -   train_loss = 2.8610128675188338
2025-04-11 11:59:33,634 - ***** Epoch: 93: Eval results *****
2025-04-11 11:59:33,634 -   train_loss = 2.8740088088171825
2025-04-11 11:59:47,794 - ***** Epoch: 94: Eval results *****
2025-04-11 11:59:47,794 -   train_loss = 2.853189843041556
2025-04-11 12:00:02,388 - ***** Epoch: 95: Eval results *****
2025-04-11 12:00:02,388 -   train_loss = 2.8652324846812656
2025-04-11 12:00:16,160 - ***** Epoch: 96: Eval results *****
2025-04-11 12:00:16,160 -   train_loss = 2.856000746999468
2025-04-11 12:00:30,173 - ***** Epoch: 97: Eval results *****
2025-04-11 12:00:30,174 -   train_loss = 2.860323565346854
2025-04-11 12:00:46,105 - ***** Epoch: 98: Eval results *****
2025-04-11 12:00:46,105 -   train_loss = 2.865483437265669
2025-04-11 12:01:01,186 - ***** Epoch: 99: Eval results *****
2025-04-11 12:01:01,186 -   train_loss = 2.8606609276362827
2025-04-11 12:01:17,698 - ***** Epoch: 100: Eval results *****
2025-04-11 12:01:17,698 -   train_loss = 2.8694399765559604
2025-04-11 12:01:19,419 - Pre-training finished...
2025-04-11 12:01:19,723 - Freeze all parameters but the last layer for efficiency
2025-04-11 12:01:19,736 - Multimodal Intent Recognition begins...
2025-04-11 12:01:19,736 - Training begins...
2025-04-11 12:01:35,565 - Initializing centroids with K-means++...
2025-04-11 12:01:35,702 - K-means++ used 0.14 s
2025-04-11 12:02:05,685 - K-means used 0.03 s
2025-04-11 12:02:07,136 - ***** Epoch: 1 *****
2025-04-11 12:02:07,137 - Supervised Training Loss: 4.891570
2025-04-11 12:02:07,138 - Unsupervised Training Loss: 5.127080
2025-04-11 12:02:35,736 - K-means used 0.02 s
2025-04-11 12:02:36,957 - ***** Epoch: 2 *****
2025-04-11 12:02:36,957 - Supervised Training Loss: 3.879510
2025-04-11 12:02:36,958 - Unsupervised Training Loss: 5.150860
2025-04-11 12:03:05,352 - K-means used 0.03 s
2025-04-11 12:03:06,515 - ***** Epoch: 3 *****
2025-04-11 12:03:06,516 - Supervised Training Loss: 5.354040
2025-04-11 12:03:06,516 - Unsupervised Training Loss: 5.004260
2025-04-11 12:03:44,979 - K-means used 0.02 s
2025-04-11 12:03:46,530 - ***** Epoch: 4 *****
2025-04-11 12:03:46,530 - Supervised Training Loss: 5.212760
2025-04-11 12:03:46,530 - Unsupervised Training Loss: 5.076700
2025-04-11 12:04:14,024 - K-means used 0.03 s
2025-04-11 12:04:15,339 - ***** Epoch: 5 *****
2025-04-11 12:04:15,339 - Supervised Training Loss: 4.925060
2025-04-11 12:04:15,340 - Unsupervised Training Loss: 5.111330
2025-04-11 12:04:42,000 - K-means used 0.07 s
2025-04-11 12:04:43,408 - ***** Epoch: 6 *****
2025-04-11 12:04:43,408 - Supervised Training Loss: 5.345510
2025-04-11 12:04:43,408 - Unsupervised Training Loss: 4.903710
2025-04-11 12:05:10,049 - K-means used 0.02 s
2025-04-11 12:05:11,648 - ***** Epoch: 7 *****
2025-04-11 12:05:11,648 - Supervised Training Loss: 5.247380
2025-04-11 12:05:11,648 - Unsupervised Training Loss: 5.020050
2025-04-11 12:05:39,625 - K-means used 0.03 s
2025-04-11 12:05:41,361 - ***** Epoch: 8 *****
2025-04-11 12:05:41,361 - Supervised Training Loss: 5.100860
2025-04-11 12:05:41,361 - Unsupervised Training Loss: 5.073350
2025-04-11 12:06:07,304 - K-means used 0.15 s
2025-04-11 12:06:09,796 - ***** Epoch: 9 *****
2025-04-11 12:06:09,796 - Supervised Training Loss: 5.333450
2025-04-11 12:06:09,796 - Unsupervised Training Loss: 5.098940
2025-04-11 12:06:38,199 - K-means used 0.02 s
2025-04-11 12:06:39,841 - ***** Epoch: 10 *****
2025-04-11 12:06:39,841 - Supervised Training Loss: 5.259800
2025-04-11 12:06:39,841 - Unsupervised Training Loss: 4.944500
2025-04-11 12:07:08,263 - K-means used 0.02 s
2025-04-11 12:07:10,109 - ***** Epoch: 11 *****
2025-04-11 12:07:10,109 - Supervised Training Loss: 5.184420
2025-04-11 12:07:10,109 - Unsupervised Training Loss: 5.021520
2025-04-11 12:07:37,797 - K-means used 0.04 s
2025-04-11 12:07:39,554 - ***** Epoch: 12 *****
2025-04-11 12:07:39,555 - Supervised Training Loss: 5.318360
2025-04-11 12:07:39,555 - Unsupervised Training Loss: 5.083910
2025-04-11 12:08:07,504 - K-means used 0.06 s
2025-04-11 12:08:09,499 - ***** Epoch: 13 *****
2025-04-11 12:08:09,499 - Supervised Training Loss: 5.279590
2025-04-11 12:08:09,499 - Unsupervised Training Loss: 4.815650
2025-04-11 12:08:36,722 - K-means used 0.02 s
2025-04-11 12:08:38,616 - ***** Epoch: 14 *****
2025-04-11 12:08:38,617 - Supervised Training Loss: 5.229510
2025-04-11 12:08:38,617 - Unsupervised Training Loss: 4.941560
2025-04-11 12:09:09,578 - K-means used 0.02 s
2025-04-11 12:09:11,511 - ***** Epoch: 15 *****
2025-04-11 12:09:11,512 - Supervised Training Loss: 5.084980
2025-04-11 12:09:11,512 - Unsupervised Training Loss: 5.039980
2025-04-11 12:09:41,515 - K-means used 0.02 s
2025-04-11 12:09:43,690 - ***** Epoch: 16 *****
2025-04-11 12:09:43,691 - Supervised Training Loss: 5.293240
2025-04-11 12:09:43,691 - Unsupervised Training Loss: 4.510090
2025-04-11 12:10:15,335 - K-means used 0.02 s
2025-04-11 12:10:17,999 - ***** Epoch: 17 *****
2025-04-11 12:10:17,999 - Supervised Training Loss: 5.260370
2025-04-11 12:10:17,999 - Unsupervised Training Loss: 4.731690
2025-04-11 12:10:39,500 - Training is finished...
2025-04-11 12:10:39,501 - Testing begins...
2025-04-11 12:10:47,759 - ***** Test results *****
2025-04-11 12:10:47,760 -   ACC = 40.0
2025-04-11 12:10:47,760 -   ARI = 19.78
2025-04-11 12:10:47,760 -   NMI = 43.81
2025-04-11 12:10:47,760 -   fmi = 24.85
2025-04-11 12:10:47,760 - Testing is finished...
2025-04-11 12:10:47,760 - Multimodal intent recognition is finished...
2025-04-11 12:10:47,760 - Results are saved in results/results_umc.csv
