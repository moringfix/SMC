2025-04-11 16:08:07,339 - ============================== Params ==============================
2025-04-11 16:08:07,339 - logger_name: umc_umc_bert-base-uncased_MELD-DA_4
2025-04-11 16:08:07,339 - dataset: MELD-DA
2025-04-11 16:08:07,340 - multimodal_method: umc
2025-04-11 16:08:07,340 - method: umc
2025-04-11 16:08:07,340 - text_backbone: bert-base-uncased
2025-04-11 16:08:07,340 - seed: 4
2025-04-11 16:08:07,340 - num_workers: 16
2025-04-11 16:08:07,340 - log_id: umc_umc_bert-base-uncased_MELD-DA_4_2025-04-11-16-08-07
2025-04-11 16:08:07,340 - gpu_id: 1
2025-04-11 16:08:07,340 - data_path: /root/autodl-tmp/home/Share/Dataset/LZH
2025-04-11 16:08:07,340 - train: True
2025-04-11 16:08:07,340 - tune: True
2025-04-11 16:08:07,340 - save_model: True
2025-04-11 16:08:07,340 - save_results: True
2025-04-11 16:08:07,340 - log_path: logs
2025-04-11 16:08:07,340 - cache_path: cache
2025-04-11 16:08:07,340 - video_data_path: video_data
2025-04-11 16:08:07,340 - audio_data_path: audio_data
2025-04-11 16:08:07,340 - video_feats_path: swin_feats.pkl
2025-04-11 16:08:07,340 - audio_feats_path: wavlm_feats.pkl
2025-04-11 16:08:07,340 - results_path: results
2025-04-11 16:08:07,340 - output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/UMC/outputs/MELD-DA
2025-04-11 16:08:07,340 - model_path: models
2025-04-11 16:08:07,340 - config_file_name: umc_MELD-DA
2025-04-11 16:08:07,340 - results_file_name: results_umc.csv
2025-04-11 16:08:07,340 - text_pretrained_model: uncased_L-12_H-768_A-12
2025-04-11 16:08:07,340 - text_seq_len: 70
2025-04-11 16:08:07,340 - video_seq_len: 250
2025-04-11 16:08:07,340 - audio_seq_len: 520
2025-04-11 16:08:07,340 - text_feat_dim: 768
2025-04-11 16:08:07,341 - video_feat_dim: 1024
2025-04-11 16:08:07,341 - audio_feat_dim: 768
2025-04-11 16:08:07,341 - num_labels: 12
2025-04-11 16:08:07,341 - num_train_examples: 7990
2025-04-11 16:08:07,341 - pretrained_bert_model: uncased_L-12_H-768_A-12
2025-04-11 16:08:07,341 - pretrain_batch_size: 128
2025-04-11 16:08:07,341 - train_batch_size: 128
2025-04-11 16:08:07,341 - eval_batch_size: 128
2025-04-11 16:08:07,341 - test_batch_size: 128
2025-04-11 16:08:07,341 - num_pretrain_epochs: [100]
2025-04-11 16:08:07,341 - num_train_epochs: [100]
2025-04-11 16:08:07,341 - pretrain: [True]
2025-04-11 16:08:07,341 - aligned_method: ctc
2025-04-11 16:08:07,341 - need_aligned: False
2025-04-11 16:08:07,341 - freeze_pretrain_bert_parameters: True
2025-04-11 16:08:07,341 - freeze_train_bert_parameters: True
2025-04-11 16:08:07,341 - pretrain_temperature: [0.2]
2025-04-11 16:08:07,341 - train_temperature_sup: [20]
2025-04-11 16:08:07,341 - train_temperature_unsup: [20]
2025-04-11 16:08:07,341 - activation: tanh
2025-04-11 16:08:07,341 - lr_pre: [5e-06]
2025-04-11 16:08:07,341 - lr: [0.0002]
2025-04-11 16:08:07,341 - delta: [0.05]
2025-04-11 16:08:07,341 - thres: [0.1]
2025-04-11 16:08:07,341 - topk: [5]
2025-04-11 16:08:07,341 - weight_decay: 0.01
2025-04-11 16:08:07,341 - feat_dim: 768
2025-04-11 16:08:07,341 - hidden_size: 768
2025-04-11 16:08:07,341 - grad_clip: [-1.0]
2025-04-11 16:08:07,342 - warmup_proportion: 0.5
2025-04-11 16:08:07,342 - hidden_dropout_prob: 0.1
2025-04-11 16:08:07,342 - weight: 1.0
2025-04-11 16:08:07,342 - loss_mode: rdrop
2025-04-11 16:08:07,342 - base_dim: [256]
2025-04-11 16:08:07,342 - nheads: 8
2025-04-11 16:08:07,342 - attn_dropout: 0.1
2025-04-11 16:08:07,342 - relu_dropout: 0.1
2025-04-11 16:08:07,342 - embed_dropout: 0.1
2025-04-11 16:08:07,342 - res_dropout: 0.0
2025-04-11 16:08:07,342 - attn_mask: True
2025-04-11 16:08:07,342 - encoder_layers_1: 1
2025-04-11 16:08:07,342 - fusion_act: tanh
2025-04-11 16:08:07,342 - pred_output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/UMC/outputs/MELD-DA/umc_umc_MELD-DA_bert-base-uncased_4
2025-04-11 16:08:07,342 - model_output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/UMC/outputs/MELD-DA/umc_umc_MELD-DA_bert-base-uncased_4/models
2025-04-11 16:08:07,342 - ============================== End Params ==============================
2025-04-11 16:08:08,503 - Freeze all parameters but the last layer for efficiency
2025-04-11 16:08:08,539 - Pre-training start...
2025-04-11 16:09:34,398 - ***** Epoch: 1: Eval results *****
2025-04-11 16:09:34,399 -   train_loss = 5.917299172234913
2025-04-11 16:11:03,946 - ***** Epoch: 2: Eval results *****
2025-04-11 16:11:03,947 -   train_loss = 5.916966302054269
2025-04-11 16:12:33,707 - ***** Epoch: 3: Eval results *****
2025-04-11 16:12:33,709 -   train_loss = 5.914501470232767
2025-04-11 16:14:03,733 - ***** Epoch: 4: Eval results *****
2025-04-11 16:14:03,733 -   train_loss = 5.910299104357523
2025-04-11 16:15:32,877 - ***** Epoch: 5: Eval results *****
2025-04-11 16:15:32,878 -   train_loss = 5.907734916323707
2025-04-11 16:17:03,194 - ***** Epoch: 6: Eval results *****
2025-04-11 16:17:03,195 -   train_loss = 5.8991798597668845
2025-04-11 16:18:33,388 - ***** Epoch: 7: Eval results *****
2025-04-11 16:18:33,388 -   train_loss = 5.889333096761552
2025-04-11 16:20:03,201 - ***** Epoch: 8: Eval results *****
2025-04-11 16:20:03,202 -   train_loss = 5.873597220769004
2025-04-11 16:21:33,169 - ***** Epoch: 9: Eval results *****
2025-04-11 16:21:33,169 -   train_loss = 5.845621381487165
2025-04-11 16:23:03,265 - ***** Epoch: 10: Eval results *****
2025-04-11 16:23:03,266 -   train_loss = 5.792992523738316
2025-04-11 16:24:33,862 - ***** Epoch: 11: Eval results *****
2025-04-11 16:24:33,862 -   train_loss = 5.7036998309786355
2025-04-11 16:26:04,498 - ***** Epoch: 12: Eval results *****
2025-04-11 16:26:04,499 -   train_loss = 5.57655528235057
2025-04-11 16:27:34,162 - ***** Epoch: 13: Eval results *****
2025-04-11 16:27:34,163 -   train_loss = 5.418547970908029
2025-04-11 16:29:03,990 - ***** Epoch: 14: Eval results *****
2025-04-11 16:29:03,990 -   train_loss = 5.265654314131964
2025-04-11 16:30:33,388 - ***** Epoch: 15: Eval results *****
2025-04-11 16:30:33,388 -   train_loss = 5.11956256533426
2025-04-11 16:32:03,058 - ***** Epoch: 16: Eval results *****
2025-04-11 16:32:03,059 -   train_loss = 4.971993809654599
2025-04-11 16:33:33,481 - ***** Epoch: 17: Eval results *****
2025-04-11 16:33:33,481 -   train_loss = 4.796508792846922
2025-04-11 16:35:04,092 - ***** Epoch: 18: Eval results *****
2025-04-11 16:35:04,093 -   train_loss = 4.6008938569871205
2025-04-11 16:36:34,001 - ***** Epoch: 19: Eval results *****
2025-04-11 16:36:34,002 -   train_loss = 4.394108102435157
2025-04-11 16:38:03,782 - ***** Epoch: 20: Eval results *****
2025-04-11 16:38:03,782 -   train_loss = 4.2117363763233975
2025-04-11 16:39:34,228 - ***** Epoch: 21: Eval results *****
2025-04-11 16:39:34,228 -   train_loss = 4.064660166937207
2025-04-11 16:41:04,587 - ***** Epoch: 22: Eval results *****
2025-04-11 16:41:04,588 -   train_loss = 3.9583654933505588
2025-04-11 16:42:34,994 - ***** Epoch: 23: Eval results *****
2025-04-11 16:42:34,995 -   train_loss = 3.847936229100303
2025-04-11 16:44:04,615 - ***** Epoch: 24: Eval results *****
2025-04-11 16:44:04,616 -   train_loss = 3.758841385917058
2025-04-11 16:45:35,045 - ***** Epoch: 25: Eval results *****
2025-04-11 16:45:35,046 -   train_loss = 3.673437826217167
2025-04-11 16:47:05,333 - ***** Epoch: 26: Eval results *****
2025-04-11 16:47:05,333 -   train_loss = 3.6043211543370806
2025-04-11 16:48:35,568 - ***** Epoch: 27: Eval results *****
2025-04-11 16:48:35,568 -   train_loss = 3.5408661895328097
2025-04-11 16:50:05,364 - ***** Epoch: 28: Eval results *****
2025-04-11 16:50:05,364 -   train_loss = 3.4878279292394243
2025-04-11 16:51:35,298 - ***** Epoch: 29: Eval results *****
2025-04-11 16:51:35,299 -   train_loss = 3.432232073375157
2025-04-11 16:53:05,034 - ***** Epoch: 30: Eval results *****
2025-04-11 16:53:05,035 -   train_loss = 3.3883876611316013
2025-04-11 16:54:34,699 - ***** Epoch: 31: Eval results *****
2025-04-11 16:54:34,699 -   train_loss = 3.3491735344841365
2025-04-11 16:56:04,548 - ***** Epoch: 32: Eval results *****
2025-04-11 16:56:04,548 -   train_loss = 3.3118074470096164
2025-04-11 16:57:34,508 - ***** Epoch: 33: Eval results *****
2025-04-11 16:57:34,509 -   train_loss = 3.269974174953642
2025-04-11 16:59:04,648 - ***** Epoch: 34: Eval results *****
2025-04-11 16:59:04,648 -   train_loss = 3.2361903001391696
2025-04-11 17:00:34,346 - ***** Epoch: 35: Eval results *****
2025-04-11 17:00:34,346 -   train_loss = 3.203032190837557
2025-04-11 17:02:03,593 - ***** Epoch: 36: Eval results *****
2025-04-11 17:02:03,593 -   train_loss = 3.1750205509246343
2025-04-11 17:03:33,674 - ***** Epoch: 37: Eval results *****
2025-04-11 17:03:33,675 -   train_loss = 3.139730941681635
2025-04-11 17:05:04,161 - ***** Epoch: 38: Eval results *****
2025-04-11 17:05:04,162 -   train_loss = 3.115698704643855
2025-04-11 17:06:34,402 - ***** Epoch: 39: Eval results *****
2025-04-11 17:06:34,402 -   train_loss = 3.086101554688953
2025-04-11 17:08:04,541 - ***** Epoch: 40: Eval results *****
2025-04-11 17:08:04,541 -   train_loss = 3.0649496827806746
2025-04-11 17:09:35,006 - ***** Epoch: 41: Eval results *****
2025-04-11 17:09:35,006 -   train_loss = 3.0396277563912526
2025-04-11 17:11:05,261 - ***** Epoch: 42: Eval results *****
2025-04-11 17:11:05,261 -   train_loss = 3.012011410698058
2025-04-11 17:12:35,375 - ***** Epoch: 43: Eval results *****
2025-04-11 17:12:35,375 -   train_loss = 2.988983120237078
2025-04-11 17:14:05,174 - ***** Epoch: 44: Eval results *****
2025-04-11 17:14:05,174 -   train_loss = 2.967515226394411
2025-04-11 17:15:36,524 - ***** Epoch: 45: Eval results *****
2025-04-11 17:15:36,525 -   train_loss = 2.9512262912023637
2025-04-11 17:17:08,069 - ***** Epoch: 46: Eval results *****
2025-04-11 17:17:08,070 -   train_loss = 2.9316524967314703
2025-04-11 17:18:44,749 - ***** Epoch: 47: Eval results *****
2025-04-11 17:18:44,750 -   train_loss = 2.909292815223573
2025-04-11 17:20:15,749 - ***** Epoch: 48: Eval results *****
2025-04-11 17:20:15,749 -   train_loss = 2.8973207398066445
2025-04-11 17:21:52,565 - ***** Epoch: 49: Eval results *****
2025-04-11 17:21:52,566 -   train_loss = 2.8762033099219915
2025-04-11 17:23:24,688 - ***** Epoch: 50: Eval results *****
2025-04-11 17:23:24,688 -   train_loss = 2.8610248225075856
2025-04-11 17:24:55,261 - ***** Epoch: 51: Eval results *****
2025-04-11 17:24:55,261 -   train_loss = 2.849106709162394
2025-04-11 17:26:26,177 - ***** Epoch: 52: Eval results *****
2025-04-11 17:26:26,178 -   train_loss = 2.8350839198581754
2025-04-11 17:27:57,282 - ***** Epoch: 53: Eval results *****
2025-04-11 17:27:57,283 -   train_loss = 2.8211941491989863
2025-04-11 17:29:28,295 - ***** Epoch: 54: Eval results *****
2025-04-11 17:29:28,296 -   train_loss = 2.8120594365256175
2025-04-11 17:30:58,912 - ***** Epoch: 55: Eval results *****
2025-04-11 17:30:58,912 -   train_loss = 2.798507803962344
2025-04-11 17:32:29,837 - ***** Epoch: 56: Eval results *****
2025-04-11 17:32:29,838 -   train_loss = 2.7864251439533536
2025-04-11 17:34:00,701 - ***** Epoch: 57: Eval results *****
2025-04-11 17:34:00,701 -   train_loss = 2.7808158965337846
2025-04-11 17:35:31,430 - ***** Epoch: 58: Eval results *****
2025-04-11 17:35:31,430 -   train_loss = 2.766429412932623
2025-04-11 17:37:02,898 - ***** Epoch: 59: Eval results *****
2025-04-11 17:37:02,898 -   train_loss = 2.7567162286667597
2025-04-11 17:38:33,977 - ***** Epoch: 60: Eval results *****
2025-04-11 17:38:33,977 -   train_loss = 2.7518374503604948
2025-04-11 17:40:05,010 - ***** Epoch: 61: Eval results *****
2025-04-11 17:40:05,010 -   train_loss = 2.736808114581638
2025-04-11 17:41:35,848 - ***** Epoch: 62: Eval results *****
2025-04-11 17:41:35,848 -   train_loss = 2.7343869739108615
2025-04-11 17:43:06,593 - ***** Epoch: 63: Eval results *****
2025-04-11 17:43:06,594 -   train_loss = 2.7215525082179477
2025-04-11 17:44:36,697 - ***** Epoch: 64: Eval results *****
2025-04-11 17:44:36,698 -   train_loss = 2.715913598499601
2025-04-11 17:46:06,626 - ***** Epoch: 65: Eval results *****
2025-04-11 17:46:06,626 -   train_loss = 2.709038085407681
2025-04-11 17:47:36,944 - ***** Epoch: 66: Eval results *****
2025-04-11 17:47:36,944 -   train_loss = 2.700014911000691
2025-04-11 17:49:07,632 - ***** Epoch: 67: Eval results *****
2025-04-11 17:49:07,633 -   train_loss = 2.6913280676281643
2025-04-11 17:50:38,525 - ***** Epoch: 68: Eval results *****
2025-04-11 17:50:38,525 -   train_loss = 2.6895055657341365
2025-04-11 17:52:09,458 - ***** Epoch: 69: Eval results *****
2025-04-11 17:52:09,458 -   train_loss = 2.6869304520743236
2025-04-11 17:53:40,010 - ***** Epoch: 70: Eval results *****
2025-04-11 17:53:40,010 -   train_loss = 2.677512078058152
2025-04-11 17:55:10,824 - ***** Epoch: 71: Eval results *****
2025-04-11 17:55:10,825 -   train_loss = 2.671131832259042
2025-04-11 17:56:41,586 - ***** Epoch: 72: Eval results *****
2025-04-11 17:56:41,586 -   train_loss = 2.6671078148342313
2025-04-11 17:58:12,779 - ***** Epoch: 73: Eval results *****
2025-04-11 17:58:12,780 -   train_loss = 2.6641990760016063
2025-04-11 17:59:42,734 - ***** Epoch: 74: Eval results *****
2025-04-11 17:59:42,734 -   train_loss = 2.6576355014528548
2025-04-11 18:01:13,232 - ***** Epoch: 75: Eval results *****
2025-04-11 18:01:13,232 -   train_loss = 2.6583564697750033
2025-04-11 18:02:43,773 - ***** Epoch: 76: Eval results *****
2025-04-11 18:02:43,773 -   train_loss = 2.6485452916887073
2025-04-11 18:04:14,418 - ***** Epoch: 77: Eval results *****
2025-04-11 18:04:14,419 -   train_loss = 2.654559078670683
2025-04-11 18:05:45,587 - ***** Epoch: 78: Eval results *****
2025-04-11 18:05:45,588 -   train_loss = 2.6493974488879006
2025-04-11 18:07:15,565 - ***** Epoch: 79: Eval results *****
2025-04-11 18:07:15,565 -   train_loss = 2.6367510367953586
2025-04-11 18:08:45,982 - ***** Epoch: 80: Eval results *****
2025-04-11 18:08:45,983 -   train_loss = 2.636236752782549
2025-04-11 18:10:17,067 - ***** Epoch: 81: Eval results *****
2025-04-11 18:10:17,067 -   train_loss = 2.6355479312321495
2025-04-11 18:11:47,969 - ***** Epoch: 82: Eval results *****
2025-04-11 18:11:47,969 -   train_loss = 2.6299665390499056
2025-04-11 18:13:18,499 - ***** Epoch: 83: Eval results *****
2025-04-11 18:13:18,500 -   train_loss = 2.6279183285576955
2025-04-11 18:14:49,001 - ***** Epoch: 84: Eval results *****
2025-04-11 18:14:49,002 -   train_loss = 2.6289794009829324
2025-04-11 18:16:19,153 - ***** Epoch: 85: Eval results *****
2025-04-11 18:16:19,153 -   train_loss = 2.6270230327333723
2025-04-11 18:17:48,776 - ***** Epoch: 86: Eval results *****
2025-04-11 18:17:48,777 -   train_loss = 2.6217230236719526
2025-04-11 18:19:18,578 - ***** Epoch: 87: Eval results *****
2025-04-11 18:19:18,578 -   train_loss = 2.618828012829735
2025-04-11 18:20:48,757 - ***** Epoch: 88: Eval results *****
2025-04-11 18:20:48,758 -   train_loss = 2.6137016898109797
2025-04-11 18:22:18,970 - ***** Epoch: 89: Eval results *****
2025-04-11 18:22:18,971 -   train_loss = 2.6174778332785955
2025-04-11 18:23:48,548 - ***** Epoch: 90: Eval results *****
2025-04-11 18:23:48,549 -   train_loss = 2.6124505845327226
2025-04-11 18:25:18,721 - ***** Epoch: 91: Eval results *****
2025-04-11 18:25:18,722 -   train_loss = 2.6176795051211403
2025-04-11 18:26:48,900 - ***** Epoch: 92: Eval results *****
2025-04-11 18:26:48,900 -   train_loss = 2.6114762397039506
2025-04-11 18:28:19,880 - ***** Epoch: 93: Eval results *****
2025-04-11 18:28:19,880 -   train_loss = 2.6108890752943736
2025-04-11 18:29:50,056 - ***** Epoch: 94: Eval results *****
2025-04-11 18:29:50,056 -   train_loss = 2.6136770324101524
2025-04-11 18:31:20,592 - ***** Epoch: 95: Eval results *****
2025-04-11 18:31:20,593 -   train_loss = 2.6038996075826977
2025-04-11 18:32:51,475 - ***** Epoch: 96: Eval results *****
2025-04-11 18:32:51,475 -   train_loss = 2.607195061350626
2025-04-11 18:34:21,221 - ***** Epoch: 97: Eval results *****
2025-04-11 18:34:21,222 -   train_loss = 2.6063977725922114
2025-04-11 18:35:51,727 - ***** Epoch: 98: Eval results *****
2025-04-11 18:35:51,728 -   train_loss = 2.6093669429657953
2025-04-11 18:37:21,929 - ***** Epoch: 99: Eval results *****
2025-04-11 18:37:21,930 -   train_loss = 2.6067415835365417
2025-04-11 18:38:51,889 - ***** Epoch: 100: Eval results *****
2025-04-11 18:38:51,889 -   train_loss = 2.608202368494064
2025-04-11 18:38:52,435 - Pre-training finished...
2025-04-11 18:38:52,784 - Freeze all parameters but the last layer for efficiency
2025-04-11 18:38:52,793 - Multimodal Intent Recognition begins...
2025-04-11 18:38:52,794 - Training begins...
2025-04-11 18:39:36,984 - Initializing centroids with K-means++...
2025-04-11 18:39:37,319 - K-means++ used 0.33 s
2025-04-11 18:41:55,102 - K-means used 0.07 s
2025-04-11 18:41:58,834 - ***** Epoch: 1 *****
2025-04-11 18:41:58,834 - Supervised Training Loss: 5.688110
2025-04-11 18:41:58,835 - Unsupervised Training Loss: 5.879170
2025-04-11 18:44:12,105 - K-means used 0.08 s
2025-04-11 18:44:16,532 - ***** Epoch: 2 *****
2025-04-11 18:44:16,532 - Supervised Training Loss: 5.803650
2025-04-11 18:44:16,532 - Unsupervised Training Loss: 5.860610
2025-04-11 18:46:32,197 - K-means used 0.14 s
2025-04-11 18:46:37,074 - ***** Epoch: 3 *****
2025-04-11 18:46:37,074 - Supervised Training Loss: 5.847900
2025-04-11 18:46:37,074 - Unsupervised Training Loss: 5.902320
2025-04-11 18:48:48,109 - K-means used 0.08 s
2025-04-11 18:48:54,188 - ***** Epoch: 4 *****
2025-04-11 18:48:54,189 - Supervised Training Loss: 5.867270
2025-04-11 18:48:54,189 - Unsupervised Training Loss: 5.898180
2025-04-11 18:51:07,365 - K-means used 0.05 s
2025-04-11 18:51:14,587 - ***** Epoch: 5 *****
2025-04-11 18:51:14,587 - Supervised Training Loss: 5.880500
2025-04-11 18:51:14,587 - Unsupervised Training Loss: 5.893930
2025-04-11 18:53:27,152 - K-means used 0.06 s
2025-04-11 18:53:36,203 - ***** Epoch: 6 *****
2025-04-11 18:53:36,203 - Supervised Training Loss: 5.890260
2025-04-11 18:53:36,203 - Unsupervised Training Loss: 5.888460
2025-04-11 18:55:49,097 - K-means used 0.06 s
2025-04-11 18:55:59,276 - ***** Epoch: 7 *****
2025-04-11 18:55:59,277 - Supervised Training Loss: 5.896320
2025-04-11 18:55:59,277 - Unsupervised Training Loss: 5.882000
2025-04-11 18:58:12,522 - K-means used 0.07 s
2025-04-11 18:58:25,202 - ***** Epoch: 8 *****
2025-04-11 18:58:25,203 - Supervised Training Loss: 5.792590
2025-04-11 18:58:25,203 - Unsupervised Training Loss: 5.871670
2025-04-11 19:00:38,541 - K-means used 0.05 s
2025-04-11 19:00:54,431 - ***** Epoch: 9 *****
2025-04-11 19:00:54,432 - Supervised Training Loss: 5.848280
2025-04-11 19:00:54,432 - Unsupervised Training Loss: 5.852920
2025-04-11 19:03:08,036 - K-means used 0.06 s
2025-04-11 19:03:27,332 - ***** Epoch: 10 *****
2025-04-11 19:03:27,332 - Supervised Training Loss: 5.864600
2025-04-11 19:03:27,332 - Unsupervised Training Loss: 5.827520
2025-04-11 19:05:41,900 - K-means used 0.06 s
2025-04-11 19:06:04,010 - ***** Epoch: 11 *****
2025-04-11 19:06:04,010 - Supervised Training Loss: 5.876020
2025-04-11 19:06:04,010 - Unsupervised Training Loss: 5.699230
2025-04-11 19:08:20,002 - K-means used 0.19 s
2025-04-11 19:08:44,231 - ***** Epoch: 12 *****
2025-04-11 19:08:44,231 - Supervised Training Loss: 5.883860
2025-04-11 19:08:44,231 - Unsupervised Training Loss: 5.894230
2025-04-11 19:10:58,349 - K-means used 0.04 s
2025-04-11 19:11:24,912 - ***** Epoch: 13 *****
2025-04-11 19:11:24,913 - Supervised Training Loss: 5.889580
2025-04-11 19:11:24,913 - Unsupervised Training Loss: 5.885230
2025-04-11 19:13:50,242 - K-means used 0.06 s
2025-04-11 19:14:41,921 - ***** Epoch: 14 *****
2025-04-11 19:14:41,921 - Supervised Training Loss: 5.894010
2025-04-11 19:14:41,922 - Unsupervised Training Loss: 5.871180
2025-04-11 19:17:14,317 - K-means used 0.09 s
2025-04-11 19:17:53,491 - ***** Epoch: 15 *****
2025-04-11 19:17:53,491 - Supervised Training Loss: 5.897320
2025-04-11 19:17:53,491 - Unsupervised Training Loss: 5.847000
2025-04-11 19:20:44,368 - K-means used 0.08 s
2025-04-11 19:21:37,731 - ***** Epoch: 16 *****
2025-04-11 19:21:37,731 - Supervised Training Loss: 5.828040
2025-04-11 19:21:37,731 - Unsupervised Training Loss: 5.806920
2025-04-11 19:23:54,176 - K-means used 0.05 s
2025-04-11 19:24:38,610 - ***** Epoch: 17 *****
2025-04-11 19:24:38,611 - Supervised Training Loss: 5.863460
2025-04-11 19:24:38,611 - Unsupervised Training Loss: 5.720860
2025-04-11 19:26:31,590 - Training is finished...
2025-04-11 19:26:31,592 - Testing begins...
2025-04-11 19:27:10,519 - ***** Test results *****
2025-04-11 19:27:10,519 -   ACC = 32.58
2025-04-11 19:27:10,519 -   ARI = 15.02
2025-04-11 19:27:10,520 -   NMI = 19.35
2025-04-11 19:27:10,520 -   fmi = 30.01
2025-04-11 19:27:10,520 - Testing is finished...
2025-04-11 19:27:10,520 - Multimodal intent recognition is finished...
2025-04-11 19:27:10,520 - Results are saved in results/results_umc.csv
