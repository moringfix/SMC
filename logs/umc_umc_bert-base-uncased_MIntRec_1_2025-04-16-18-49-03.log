2025-04-16 18:49:03,649 - 【无监督】进入了无监督的设定中, 加载数据集
2025-04-16 18:49:03,649 - data preparation...
2025-04-16 18:49:12,917 - Number of train samples = 1779
2025-04-16 18:49:12,918 - Number of testing samples = 445
2025-04-16 18:49:12,918 - data preparation...
2025-04-16 18:49:15,039 - num_train_examples = 1779
2025-04-16 18:49:15,039 - ============================== Params ==============================
2025-04-16 18:49:15,040 - logger_name: umc_umc_bert-base-uncased_MIntRec_1
2025-04-16 18:49:15,040 - dataset: MIntRec
2025-04-16 18:49:15,040 - multimodal_method: umc
2025-04-16 18:49:15,040 - method: umc
2025-04-16 18:49:15,040 - setting: unsupervised
2025-04-16 18:49:15,040 - text_backbone: bert-base-uncased
2025-04-16 18:49:15,040 - seed: 1
2025-04-16 18:49:15,040 - num_workers: 16
2025-04-16 18:49:15,040 - log_id: umc_umc_bert-base-uncased_MIntRec_1_2025-04-16-18-49-03
2025-04-16 18:49:15,040 - gpu_id: 1
2025-04-16 18:49:15,040 - data_path: /root/autodl-tmp/home/Share/Dataset/LZH
2025-04-16 18:49:15,040 - train: True
2025-04-16 18:49:15,040 - tune: True
2025-04-16 18:49:15,040 - save_model: True
2025-04-16 18:49:15,040 - save_results: True
2025-04-16 18:49:15,040 - log_path: logs
2025-04-16 18:49:15,040 - cache_path: cache
2025-04-16 18:49:15,040 - video_data_path: video_data
2025-04-16 18:49:15,040 - audio_data_path: audio_data
2025-04-16 18:49:15,040 - video_feats_path: swin_feats.pkl
2025-04-16 18:49:15,040 - audio_feats_path: wavlm_feats.pkl
2025-04-16 18:49:15,040 - results_path: results
2025-04-16 18:49:15,040 - output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/SMC/outputs_test2/MIntRec
2025-04-16 18:49:15,040 - model_path: models
2025-04-16 18:49:15,041 - config_file_name: umc_MIntRec
2025-04-16 18:49:15,041 - results_file_name: results_umc.csv
2025-04-16 18:49:15,041 - text_pretrained_model: uncased_L-12_H-768_A-12
2025-04-16 18:49:15,041 - pretrained_bert_model: uncased_L-12_H-768_A-12
2025-04-16 18:49:15,041 - pretrain_batch_size: 128
2025-04-16 18:49:15,041 - train_batch_size: 128
2025-04-16 18:49:15,041 - eval_batch_size: 128
2025-04-16 18:49:15,041 - test_batch_size: 128
2025-04-16 18:49:15,041 - num_pretrain_epochs: 100
2025-04-16 18:49:15,041 - num_train_epochs: 100
2025-04-16 18:49:15,041 - pretrain: [True]
2025-04-16 18:49:15,041 - aligned_method: ctc
2025-04-16 18:49:15,041 - need_aligned: False
2025-04-16 18:49:15,041 - freeze_pretrain_bert_parameters: [True]
2025-04-16 18:49:15,041 - freeze_train_bert_parameters: [True]
2025-04-16 18:49:15,041 - pretrain_temperature: [0.1]
2025-04-16 18:49:15,041 - train_temperature_sup: [0.5]
2025-04-16 18:49:15,041 - train_temperature_unsup: [2]
2025-04-16 18:49:15,041 - activation: tanh
2025-04-16 18:49:15,041 - lr_pre: [5e-06]
2025-04-16 18:49:15,041 - lr: [5e-05]
2025-04-16 18:49:15,042 - delta: [0.05]
2025-04-16 18:49:15,042 - thres: [0.1]
2025-04-16 18:49:15,042 - topk: [5]
2025-04-16 18:49:15,042 - weight_decay: 0.01
2025-04-16 18:49:15,042 - feat_dim: 768
2025-04-16 18:49:15,042 - hidden_size: 768
2025-04-16 18:49:15,042 - grad_clip: -1.0
2025-04-16 18:49:15,042 - warmup_proportion: [0.1]
2025-04-16 18:49:15,042 - hidden_dropout_prob: 0.1
2025-04-16 18:49:15,042 - weight: 1.0
2025-04-16 18:49:15,042 - loss_mode: rdrop
2025-04-16 18:49:15,042 - base_dim: 256
2025-04-16 18:49:15,042 - nheads: 8
2025-04-16 18:49:15,042 - attn_dropout: 0.1
2025-04-16 18:49:15,042 - relu_dropout: 0.1
2025-04-16 18:49:15,042 - embed_dropout: 0.01
2025-04-16 18:49:15,042 - res_dropout: 0.0
2025-04-16 18:49:15,042 - attn_mask: True
2025-04-16 18:49:15,042 - encoder_layers_1: 1
2025-04-16 18:49:15,042 - fusion_act: tanh
2025-04-16 18:49:15,042 - pred_output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/SMC/outputs_test2/MIntRec/umc_umc_MIntRec_bert-base-uncased_1
2025-04-16 18:49:15,042 - model_output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/SMC/outputs_test2/MIntRec/umc_umc_MIntRec_bert-base-uncased_1/models
2025-04-16 18:49:15,042 - text_seq_len: 30
2025-04-16 18:49:15,042 - video_seq_len: 230
2025-04-16 18:49:15,042 - audio_seq_len: 480
2025-04-16 18:49:15,043 - text_feat_dim: 768
2025-04-16 18:49:15,043 - video_feat_dim: 1024
2025-04-16 18:49:15,043 - audio_feat_dim: 768
2025-04-16 18:49:15,043 - num_labels: 20
2025-04-16 18:49:15,043 - num_train_examples: 1779
2025-04-16 18:49:15,043 - ============================== End Params ==============================
2025-04-16 18:49:16,526 - Freeze all parameters but the last layer for efficiency
2025-04-16 18:49:16,564 - Pre-training start...
2025-04-16 18:49:35,513 - ***** Epoch: 1: Eval results *****
2025-04-16 18:49:35,514 -   train_loss = 5.965276990618024
2025-04-16 18:49:57,293 - ***** Epoch: 2: Eval results *****
2025-04-16 18:49:57,294 -   train_loss = 5.9638722624097555
2025-04-16 18:50:20,554 - ***** Epoch: 3: Eval results *****
2025-04-16 18:50:20,554 -   train_loss = 5.953319992337908
2025-04-16 18:50:43,529 - ***** Epoch: 4: Eval results *****
2025-04-16 18:50:43,530 -   train_loss = 5.952804020472935
2025-04-16 18:51:07,486 - ***** Epoch: 5: Eval results *****
2025-04-16 18:51:07,486 -   train_loss = 5.947339466639927
2025-04-16 18:51:28,082 - ***** Epoch: 6: Eval results *****
2025-04-16 18:51:28,082 -   train_loss = 5.945943968636649
2025-04-16 18:51:49,675 - ***** Epoch: 7: Eval results *****
2025-04-16 18:51:49,676 -   train_loss = 5.9289699622562955
2025-04-16 18:52:11,633 - ***** Epoch: 8: Eval results *****
2025-04-16 18:52:11,634 -   train_loss = 5.914437328066144
2025-04-16 18:52:33,765 - ***** Epoch: 9: Eval results *****
2025-04-16 18:52:33,765 -   train_loss = 5.90280818939209
2025-04-16 18:52:54,966 - ***** Epoch: 10: Eval results *****
2025-04-16 18:52:54,967 -   train_loss = 5.871819155556815
2025-04-16 18:53:15,368 - ***** Epoch: 11: Eval results *****
2025-04-16 18:53:15,369 -   train_loss = 5.8121450287955145
2025-04-16 18:53:36,675 - ***** Epoch: 12: Eval results *****
2025-04-16 18:53:36,675 -   train_loss = 5.717460053307669
2025-04-16 18:53:57,388 - ***** Epoch: 13: Eval results *****
2025-04-16 18:53:57,388 -   train_loss = 5.576301881245205
2025-04-16 18:54:20,588 - ***** Epoch: 14: Eval results *****
2025-04-16 18:54:20,588 -   train_loss = 5.377404962267194
2025-04-16 18:54:42,166 - ***** Epoch: 15: Eval results *****
2025-04-16 18:54:42,167 -   train_loss = 5.118437222072056
2025-04-16 18:55:05,865 - ***** Epoch: 16: Eval results *****
2025-04-16 18:55:05,865 -   train_loss = 4.84194278717041
2025-04-16 18:55:26,824 - ***** Epoch: 17: Eval results *****
2025-04-16 18:55:26,824 -   train_loss = 4.602931942258563
2025-04-16 18:55:46,539 - ***** Epoch: 18: Eval results *****
2025-04-16 18:55:46,540 -   train_loss = 4.392217227390835
2025-04-16 18:56:07,866 - ***** Epoch: 19: Eval results *****
2025-04-16 18:56:07,867 -   train_loss = 4.1908939225333075
2025-04-16 18:56:29,756 - ***** Epoch: 20: Eval results *****
2025-04-16 18:56:29,757 -   train_loss = 4.01606890133449
2025-04-16 18:56:50,829 - ***** Epoch: 21: Eval results *****
2025-04-16 18:56:50,830 -   train_loss = 3.8745177813938687
2025-04-16 18:57:14,312 - ***** Epoch: 22: Eval results *****
2025-04-16 18:57:14,313 -   train_loss = 3.7394834416253224
2025-04-16 18:57:36,994 - ***** Epoch: 23: Eval results *****
2025-04-16 18:57:36,994 -   train_loss = 3.6163961717060635
2025-04-16 18:57:57,875 - ***** Epoch: 24: Eval results *****
2025-04-16 18:57:57,875 -   train_loss = 3.503630893571036
2025-04-16 18:58:19,554 - ***** Epoch: 25: Eval results *****
2025-04-16 18:58:19,554 -   train_loss = 3.404741048812866
2025-04-16 18:58:40,420 - ***** Epoch: 26: Eval results *****
2025-04-16 18:58:40,420 -   train_loss = 3.318168418748038
2025-04-16 18:59:01,789 - ***** Epoch: 27: Eval results *****
2025-04-16 18:59:01,789 -   train_loss = 3.2271537951060703
2025-04-16 18:59:22,118 - ***** Epoch: 28: Eval results *****
2025-04-16 18:59:22,118 -   train_loss = 3.1536055973597934
2025-04-16 18:59:41,915 - ***** Epoch: 29: Eval results *****
2025-04-16 18:59:41,915 -   train_loss = 3.054607476506914
2025-04-16 19:00:03,748 - ***** Epoch: 30: Eval results *****
2025-04-16 19:00:03,749 -   train_loss = 3.015426584652492
2025-04-16 19:00:25,210 - ***** Epoch: 31: Eval results *****
2025-04-16 19:00:25,210 -   train_loss = 2.9592926842825755
2025-04-16 19:00:48,213 - ***** Epoch: 32: Eval results *****
2025-04-16 19:00:48,213 -   train_loss = 2.8850090503692627
2025-04-16 19:01:10,969 - ***** Epoch: 33: Eval results *****
2025-04-16 19:01:10,969 -   train_loss = 2.8252631596156528
2025-04-16 19:01:32,190 - ***** Epoch: 34: Eval results *****
2025-04-16 19:01:32,190 -   train_loss = 2.770853246961321
2025-04-16 19:01:52,313 - ***** Epoch: 35: Eval results *****
2025-04-16 19:01:52,313 -   train_loss = 2.7364994968686784
2025-04-16 19:02:12,970 - ***** Epoch: 36: Eval results *****
2025-04-16 19:02:12,971 -   train_loss = 2.696085146495274
2025-04-16 19:02:34,561 - ***** Epoch: 37: Eval results *****
2025-04-16 19:02:34,561 -   train_loss = 2.644527997289385
2025-04-16 19:02:55,370 - ***** Epoch: 38: Eval results *****
2025-04-16 19:02:55,371 -   train_loss = 2.614642313548497
2025-04-16 19:03:16,744 - ***** Epoch: 39: Eval results *****
2025-04-16 19:03:16,744 -   train_loss = 2.5736693484442577
2025-04-16 19:03:38,735 - ***** Epoch: 40: Eval results *****
2025-04-16 19:03:38,736 -   train_loss = 2.556516204561506
2025-04-16 19:03:59,941 - ***** Epoch: 41: Eval results *****
2025-04-16 19:03:59,941 -   train_loss = 2.5233668088912964
2025-04-16 19:04:21,974 - ***** Epoch: 42: Eval results *****
2025-04-16 19:04:21,974 -   train_loss = 2.490437490599496
2025-04-16 19:04:44,238 - ***** Epoch: 43: Eval results *****
2025-04-16 19:04:44,238 -   train_loss = 2.4449860198157176
2025-04-16 19:05:04,776 - ***** Epoch: 44: Eval results *****
2025-04-16 19:05:04,777 -   train_loss = 2.407676271029881
2025-04-16 19:05:25,760 - ***** Epoch: 45: Eval results *****
2025-04-16 19:05:25,761 -   train_loss = 2.4082696437835693
2025-04-16 19:05:47,188 - ***** Epoch: 46: Eval results *****
2025-04-16 19:05:47,188 -   train_loss = 2.370133263724191
2025-04-16 19:06:08,542 - ***** Epoch: 47: Eval results *****
2025-04-16 19:06:08,543 -   train_loss = 2.354788269315447
2025-04-16 19:06:30,787 - ***** Epoch: 48: Eval results *****
2025-04-16 19:06:30,788 -   train_loss = 2.341225096157619
2025-04-16 19:06:52,252 - ***** Epoch: 49: Eval results *****
2025-04-16 19:06:52,253 -   train_loss = 2.3141038758414134
2025-04-16 19:07:13,508 - ***** Epoch: 50: Eval results *****
2025-04-16 19:07:13,508 -   train_loss = 2.274487410272871
2025-04-16 19:07:37,357 - ***** Epoch: 51: Eval results *****
2025-04-16 19:07:37,357 -   train_loss = 2.2704522780009677
2025-04-16 19:07:59,295 - ***** Epoch: 52: Eval results *****
2025-04-16 19:07:59,295 -   train_loss = 2.250315683228629
2025-04-16 19:08:18,751 - ***** Epoch: 53: Eval results *****
2025-04-16 19:08:18,751 -   train_loss = 2.2453504289899553
2025-04-16 19:08:39,735 - ***** Epoch: 54: Eval results *****
2025-04-16 19:08:39,736 -   train_loss = 2.2306556020464217
2025-04-16 19:09:01,898 - ***** Epoch: 55: Eval results *****
2025-04-16 19:09:01,898 -   train_loss = 2.193375519343785
2025-04-16 19:09:22,646 - ***** Epoch: 56: Eval results *****
2025-04-16 19:09:22,646 -   train_loss = 2.1775727612631663
2025-04-16 19:09:43,193 - ***** Epoch: 57: Eval results *****
2025-04-16 19:09:43,193 -   train_loss = 2.1655257599694386
2025-04-16 19:10:05,064 - ***** Epoch: 58: Eval results *****
2025-04-16 19:10:05,064 -   train_loss = 2.1690672295434132
2025-04-16 19:10:26,391 - ***** Epoch: 59: Eval results *****
2025-04-16 19:10:26,392 -   train_loss = 2.1572888578687395
2025-04-16 19:10:49,411 - ***** Epoch: 60: Eval results *****
2025-04-16 19:10:49,411 -   train_loss = 2.1437003782817294
2025-04-16 19:11:13,043 - ***** Epoch: 61: Eval results *****
2025-04-16 19:11:13,043 -   train_loss = 2.1269927535738264
2025-04-16 19:11:34,458 - ***** Epoch: 62: Eval results *****
2025-04-16 19:11:34,458 -   train_loss = 2.1150167669568742
2025-04-16 19:11:53,399 - ***** Epoch: 63: Eval results *****
2025-04-16 19:11:53,399 -   train_loss = 2.1026491778237477
2025-04-16 19:12:13,430 - ***** Epoch: 64: Eval results *****
2025-04-16 19:12:13,430 -   train_loss = 2.1039364337921143
2025-04-16 19:12:34,961 - ***** Epoch: 65: Eval results *****
2025-04-16 19:12:34,961 -   train_loss = 2.0948800018855502
2025-04-16 19:12:56,719 - ***** Epoch: 66: Eval results *****
2025-04-16 19:12:56,720 -   train_loss = 2.0906699981008257
2025-04-16 19:13:18,327 - ***** Epoch: 67: Eval results *****
2025-04-16 19:13:18,327 -   train_loss = 2.058399021625519
2025-04-16 19:13:41,001 - ***** Epoch: 68: Eval results *****
2025-04-16 19:13:41,001 -   train_loss = 2.0563115988458907
2025-04-16 19:14:01,815 - ***** Epoch: 69: Eval results *****
2025-04-16 19:14:01,815 -   train_loss = 2.0304174593516757
2025-04-16 19:14:27,958 - ***** Epoch: 70: Eval results *****
2025-04-16 19:14:27,958 -   train_loss = 2.0394578320639476
2025-04-16 19:14:49,100 - ***** Epoch: 71: Eval results *****
2025-04-16 19:14:49,100 -   train_loss = 2.0429679325648715
2025-04-16 19:15:09,740 - ***** Epoch: 72: Eval results *****
2025-04-16 19:15:09,740 -   train_loss = 2.0315183912004744
2025-04-16 19:15:31,150 - ***** Epoch: 73: Eval results *****
2025-04-16 19:15:31,151 -   train_loss = 2.0226871371269226
2025-04-16 19:15:51,561 - ***** Epoch: 74: Eval results *****
2025-04-16 19:15:51,561 -   train_loss = 2.0159408705575124
2025-04-16 19:16:13,923 - ***** Epoch: 75: Eval results *****
2025-04-16 19:16:13,923 -   train_loss = 2.022389761039189
2025-04-16 19:16:35,277 - ***** Epoch: 76: Eval results *****
2025-04-16 19:16:35,277 -   train_loss = 2.0139742153031484
2025-04-16 19:16:57,561 - ***** Epoch: 77: Eval results *****
2025-04-16 19:16:57,562 -   train_loss = 1.9988624623843603
2025-04-16 19:17:19,310 - ***** Epoch: 78: Eval results *****
2025-04-16 19:17:19,310 -   train_loss = 1.9987514444759913
2025-04-16 19:17:43,747 - ***** Epoch: 79: Eval results *****
2025-04-16 19:17:43,748 -   train_loss = 1.9934538858277457
2025-04-16 19:18:05,273 - ***** Epoch: 80: Eval results *****
2025-04-16 19:18:05,273 -   train_loss = 1.9842167156083244
2025-04-16 19:18:25,144 - ***** Epoch: 81: Eval results *****
2025-04-16 19:18:25,144 -   train_loss = 1.9747895768710546
2025-04-16 19:18:44,847 - ***** Epoch: 82: Eval results *****
2025-04-16 19:18:44,847 -   train_loss = 1.9889768362045288
2025-04-16 19:19:06,621 - ***** Epoch: 83: Eval results *****
2025-04-16 19:19:06,621 -   train_loss = 1.984918372971671
2025-04-16 19:19:28,086 - ***** Epoch: 84: Eval results *****
2025-04-16 19:19:28,086 -   train_loss = 1.9679183619362968
2025-04-16 19:19:48,475 - ***** Epoch: 85: Eval results *****
2025-04-16 19:19:48,476 -   train_loss = 1.994575023651123
2025-04-16 19:20:10,516 - ***** Epoch: 86: Eval results *****
2025-04-16 19:20:10,516 -   train_loss = 1.9786314879144942
2025-04-16 19:20:31,723 - ***** Epoch: 87: Eval results *****
2025-04-16 19:20:31,723 -   train_loss = 1.978026705128806
2025-04-16 19:20:56,753 - ***** Epoch: 88: Eval results *****
2025-04-16 19:20:56,753 -   train_loss = 1.9758660197257996
2025-04-16 19:21:18,349 - ***** Epoch: 89: Eval results *****
2025-04-16 19:21:18,349 -   train_loss = 1.9690552864755904
2025-04-16 19:21:37,038 - ***** Epoch: 90: Eval results *****
2025-04-16 19:21:37,039 -   train_loss = 1.9803532872881209
2025-04-16 19:21:58,142 - ***** Epoch: 91: Eval results *****
2025-04-16 19:21:58,142 -   train_loss = 1.9867091519492013
2025-04-16 19:22:18,176 - ***** Epoch: 92: Eval results *****
2025-04-16 19:22:18,177 -   train_loss = 1.9679686852863856
2025-04-16 19:22:39,165 - ***** Epoch: 93: Eval results *****
2025-04-16 19:22:39,165 -   train_loss = 1.9770138008253915
2025-04-16 19:23:00,682 - ***** Epoch: 94: Eval results *****
2025-04-16 19:23:00,683 -   train_loss = 1.958351390702384
2025-04-16 19:23:20,700 - ***** Epoch: 95: Eval results *****
2025-04-16 19:23:20,700 -   train_loss = 1.973576009273529
2025-04-16 19:23:42,565 - ***** Epoch: 96: Eval results *****
2025-04-16 19:23:42,566 -   train_loss = 1.9514347399984087
2025-04-16 19:24:07,760 - ***** Epoch: 97: Eval results *****
2025-04-16 19:24:07,761 -   train_loss = 1.9536740950175695
2025-04-16 19:24:28,285 - ***** Epoch: 98: Eval results *****
2025-04-16 19:24:28,285 -   train_loss = 1.9760888304029192
2025-04-16 19:24:50,079 - ***** Epoch: 99: Eval results *****
2025-04-16 19:24:50,080 -   train_loss = 1.9607510992458888
2025-04-16 19:25:12,008 - ***** Epoch: 100: Eval results *****
2025-04-16 19:25:12,008 -   train_loss = 1.9736021331378393
2025-04-16 19:25:13,694 - Pre-training finished...
2025-04-16 19:25:14,052 - Freeze all parameters but the last layer for efficiency
2025-04-16 19:25:14,061 - Multimodal Intent Recognition begins...
2025-04-16 19:25:14,061 - Training begins...
2025-04-16 19:25:30,437 - Initializing centroids with K-means++...
2025-04-16 19:25:30,528 - K-means++ used 0.09 s
2025-04-16 19:26:05,161 - K-means used 0.03 s
2025-04-16 19:26:06,578 - ***** Epoch: 1 *****
2025-04-16 19:26:06,578 - Supervised Training Loss: 4.398470
2025-04-16 19:26:06,578 - Unsupervised Training Loss: 5.571330
2025-04-16 19:26:38,640 - K-means used 0.03 s
2025-04-16 19:26:39,909 - ***** Epoch: 2 *****
2025-04-16 19:26:39,909 - Supervised Training Loss: 4.978860
2025-04-16 19:26:39,909 - Unsupervised Training Loss: 5.589240
2025-04-16 19:27:14,604 - K-means used 0.03 s
2025-04-16 19:27:16,328 - ***** Epoch: 3 *****
2025-04-16 19:27:16,328 - Supervised Training Loss: 4.780110
2025-04-16 19:27:16,328 - Unsupervised Training Loss: 5.434040
2025-04-16 19:27:54,554 - K-means used 0.02 s
2025-04-16 19:27:56,151 - ***** Epoch: 4 *****
2025-04-16 19:27:56,152 - Supervised Training Loss: 4.574330
2025-04-16 19:27:56,152 - Unsupervised Training Loss: 5.500930
2025-04-16 19:28:28,632 - K-means used 0.02 s
2025-04-16 19:28:29,861 - ***** Epoch: 5 *****
2025-04-16 19:28:29,861 - Supervised Training Loss: 4.288870
2025-04-16 19:28:29,862 - Unsupervised Training Loss: 5.536730
2025-04-16 19:29:03,337 - K-means used 0.02 s
2025-04-16 19:29:05,519 - ***** Epoch: 6 *****
2025-04-16 19:29:05,519 - Supervised Training Loss: 4.678730
2025-04-16 19:29:05,519 - Unsupervised Training Loss: 5.327510
2025-04-16 19:29:39,600 - K-means used 0.05 s
2025-04-16 19:29:41,271 - ***** Epoch: 7 *****
2025-04-16 19:29:41,271 - Supervised Training Loss: 4.578600
2025-04-16 19:29:41,271 - Unsupervised Training Loss: 5.449080
2025-04-16 19:30:13,539 - K-means used 0.02 s
2025-04-16 19:30:15,665 - ***** Epoch: 8 *****
2025-04-16 19:30:15,666 - Supervised Training Loss: 4.426350
2025-04-16 19:30:15,666 - Unsupervised Training Loss: 5.508690
2025-04-16 19:30:49,682 - K-means used 0.02 s
2025-04-16 19:30:51,151 - ***** Epoch: 9 *****
2025-04-16 19:30:51,151 - Supervised Training Loss: 4.666090
2025-04-16 19:30:51,151 - Unsupervised Training Loss: 5.544350
2025-04-16 19:31:26,031 - K-means used 0.02 s
2025-04-16 19:31:27,754 - ***** Epoch: 10 *****
2025-04-16 19:31:27,754 - Supervised Training Loss: 4.595600
2025-04-16 19:31:27,754 - Unsupervised Training Loss: 5.388120
2025-04-16 19:32:00,037 - K-means used 0.02 s
2025-04-16 19:32:02,498 - ***** Epoch: 11 *****
2025-04-16 19:32:02,498 - Supervised Training Loss: 4.514010
2025-04-16 19:32:02,498 - Unsupervised Training Loss: 5.466710
2025-04-16 19:32:36,872 - K-means used 0.03 s
2025-04-16 19:32:39,061 - ***** Epoch: 12 *****
2025-04-16 19:32:39,062 - Supervised Training Loss: 4.646000
2025-04-16 19:32:39,062 - Unsupervised Training Loss: 5.540560
2025-04-16 19:33:13,513 - K-means used 0.02 s
2025-04-16 19:33:15,652 - ***** Epoch: 13 *****
2025-04-16 19:33:15,652 - Supervised Training Loss: 4.612920
2025-04-16 19:33:15,652 - Unsupervised Training Loss: 5.265630
2025-04-16 19:33:51,950 - K-means used 0.02 s
2025-04-16 19:33:54,046 - ***** Epoch: 14 *****
2025-04-16 19:33:54,046 - Supervised Training Loss: 4.561080
2025-04-16 19:33:54,047 - Unsupervised Training Loss: 5.399700
2025-04-16 19:34:29,802 - K-means used 0.03 s
2025-04-16 19:34:32,236 - ***** Epoch: 15 *****
2025-04-16 19:34:32,236 - Supervised Training Loss: 4.417040
2025-04-16 19:34:32,237 - Unsupervised Training Loss: 5.496040
2025-04-16 19:35:06,738 - K-means used 0.02 s
2025-04-16 19:35:08,896 - ***** Epoch: 16 *****
2025-04-16 19:35:08,897 - Supervised Training Loss: 4.666930
2025-04-16 19:35:08,897 - Unsupervised Training Loss: 4.902150
2025-04-16 19:35:44,186 - K-means used 0.01 s
2025-04-16 19:35:46,257 - ***** Epoch: 17 *****
2025-04-16 19:35:46,257 - Supervised Training Loss: 4.644920
2025-04-16 19:35:46,257 - Unsupervised Training Loss: 5.177660
2025-04-16 19:36:09,741 - Training is finished...
2025-04-16 19:36:09,742 - Testing begins...
2025-04-16 19:36:17,260 - ***** Test results *****
2025-04-16 19:36:17,260 -   ACC = 40.45
2025-04-16 19:36:17,260 -   ARI = 20.22
2025-04-16 19:36:17,260 -   NMI = 45.13
2025-04-16 19:36:17,260 -   fmi = 25.27
2025-04-16 19:36:17,260 - Testing is finished...
2025-04-16 19:36:17,260 - Multimodal intent recognition is finished...
2025-04-16 19:36:17,260 - Results are saved in results/results_umc.csv
