2025-04-15 22:44:56,964 - 进入了无监督的设定中, 加载数据集
2025-04-15 22:44:56,969 - data preparation...
2025-04-15 22:45:06,921 - Number of train samples = 1779
2025-04-15 22:45:06,923 - Number of testing samples = 445
2025-04-15 22:45:06,923 - data preparation...
2025-04-15 22:45:09,094 - ============================== Params ==============================
2025-04-15 22:45:09,094 - logger_name: umc_umc_bert-base-uncased_MIntRec_1
2025-04-15 22:45:09,094 - dataset: MIntRec
2025-04-15 22:45:09,094 - multimodal_method: umc
2025-04-15 22:45:09,094 - method: umc
2025-04-15 22:45:09,094 - setting: unsupervised
2025-04-15 22:45:09,094 - text_backbone: bert-base-uncased
2025-04-15 22:45:09,095 - seed: 1
2025-04-15 22:45:09,095 - num_workers: 16
2025-04-15 22:45:09,095 - log_id: umc_umc_bert-base-uncased_MIntRec_1_2025-04-15-22-44-56
2025-04-15 22:45:09,095 - gpu_id: 1
2025-04-15 22:45:09,095 - data_path: /root/autodl-tmp/home/Share/Dataset/LZH
2025-04-15 22:45:09,095 - train: True
2025-04-15 22:45:09,095 - tune: True
2025-04-15 22:45:09,095 - save_model: True
2025-04-15 22:45:09,095 - save_results: True
2025-04-15 22:45:09,095 - log_path: logs
2025-04-15 22:45:09,095 - cache_path: cache
2025-04-15 22:45:09,095 - video_data_path: video_data
2025-04-15 22:45:09,095 - audio_data_path: audio_data
2025-04-15 22:45:09,095 - video_feats_path: swin_feats.pkl
2025-04-15 22:45:09,095 - audio_feats_path: wavlm_feats.pkl
2025-04-15 22:45:09,095 - results_path: results
2025-04-15 22:45:09,095 - output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/SMC/outputs_test/MIntRec
2025-04-15 22:45:09,095 - model_path: models
2025-04-15 22:45:09,095 - config_file_name: umc_MIntRec
2025-04-15 22:45:09,095 - results_file_name: results_umc.csv
2025-04-15 22:45:09,096 - text_pretrained_model: uncased_L-12_H-768_A-12
2025-04-15 22:45:09,096 - pretrained_bert_model: uncased_L-12_H-768_A-12
2025-04-15 22:45:09,096 - pretrain_batch_size: 128
2025-04-15 22:45:09,096 - train_batch_size: 128
2025-04-15 22:45:09,096 - eval_batch_size: 128
2025-04-15 22:45:09,096 - test_batch_size: 128
2025-04-15 22:45:09,096 - num_pretrain_epochs: 100
2025-04-15 22:45:09,096 - num_train_epochs: 100
2025-04-15 22:45:09,096 - pretrain: [True]
2025-04-15 22:45:09,096 - aligned_method: ctc
2025-04-15 22:45:09,096 - need_aligned: False
2025-04-15 22:45:09,096 - freeze_pretrain_bert_parameters: [True]
2025-04-15 22:45:09,096 - freeze_train_bert_parameters: [True]
2025-04-15 22:45:09,096 - pretrain_temperature: [0.1]
2025-04-15 22:45:09,096 - train_temperature_sup: [0.5, 1, 2, 4, 6, 8]
2025-04-15 22:45:09,096 - train_temperature_unsup: [0.5, 1, 2, 4, 6, 8]
2025-04-15 22:45:09,096 - activation: tanh
2025-04-15 22:45:09,096 - lr_pre: 1e-05
2025-04-15 22:45:09,096 - lr: [0.0001]
2025-04-15 22:45:09,096 - delta: [0.05]
2025-04-15 22:45:09,096 - thres: [0.1]
2025-04-15 22:45:09,096 - topk: [5]
2025-04-15 22:45:09,096 - weight_decay: 0.01
2025-04-15 22:45:09,096 - feat_dim: 768
2025-04-15 22:45:09,096 - hidden_size: 768
2025-04-15 22:45:09,096 - grad_clip: -1.0
2025-04-15 22:45:09,096 - warmup_proportion: 0.5
2025-04-15 22:45:09,096 - hidden_dropout_prob: 0.1
2025-04-15 22:45:09,097 - weight: 1.0
2025-04-15 22:45:09,097 - loss_mode: rdrop
2025-04-15 22:45:09,097 - base_dim: 256
2025-04-15 22:45:09,097 - nheads: 8
2025-04-15 22:45:09,097 - attn_dropout: 0.1
2025-04-15 22:45:09,097 - relu_dropout: 0.1
2025-04-15 22:45:09,097 - embed_dropout: 0.01
2025-04-15 22:45:09,097 - res_dropout: 0.0
2025-04-15 22:45:09,097 - attn_mask: True
2025-04-15 22:45:09,097 - encoder_layers_1: 1
2025-04-15 22:45:09,097 - fusion_act: tanh
2025-04-15 22:45:09,097 - pred_output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/SMC/outputs_test/MIntRec/umc_umc_MIntRec_bert-base-uncased_1
2025-04-15 22:45:09,097 - model_output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/SMC/outputs_test/MIntRec/umc_umc_MIntRec_bert-base-uncased_1/models
2025-04-15 22:45:09,097 - text_seq_len: 30
2025-04-15 22:45:09,097 - video_seq_len: 230
2025-04-15 22:45:09,097 - audio_seq_len: 480
2025-04-15 22:45:09,097 - text_feat_dim: 768
2025-04-15 22:45:09,097 - video_feat_dim: 1024
2025-04-15 22:45:09,097 - audio_feat_dim: 768
2025-04-15 22:45:09,097 - num_train_examples: 1779
2025-04-15 22:45:09,097 - ============================== End Params ==============================
2025-04-15 22:45:10,339 - Freeze all parameters but the last layer for efficiency
2025-04-15 22:45:10,373 - Pre-training start...
2025-04-15 22:45:33,416 - ***** Epoch: 1: Eval results *****
2025-04-15 22:45:33,416 -   train_loss = 5.965466294969831
2025-04-15 22:45:58,600 - ***** Epoch: 2: Eval results *****
2025-04-15 22:45:58,600 -   train_loss = 5.965345893587385
2025-04-15 22:46:25,798 - ***** Epoch: 3: Eval results *****
2025-04-15 22:46:25,799 -   train_loss = 5.95721299307687
2025-04-15 22:46:54,169 - ***** Epoch: 4: Eval results *****
2025-04-15 22:46:54,169 -   train_loss = 5.960200548171997
2025-04-15 22:47:21,336 - ***** Epoch: 5: Eval results *****
2025-04-15 22:47:21,337 -   train_loss = 5.9588868618011475
2025-04-15 22:47:49,174 - ***** Epoch: 6: Eval results *****
2025-04-15 22:47:49,174 -   train_loss = 5.962545803615025
2025-04-15 22:48:16,649 - ***** Epoch: 7: Eval results *****
2025-04-15 22:48:16,650 -   train_loss = 5.951046126229422
2025-04-15 22:48:46,305 - ***** Epoch: 8: Eval results *****
2025-04-15 22:48:46,306 -   train_loss = 5.947066852024624
2025-04-15 22:49:15,528 - ***** Epoch: 9: Eval results *****
2025-04-15 22:49:15,528 -   train_loss = 5.94837440763201
2025-04-15 22:49:42,696 - ***** Epoch: 10: Eval results *****
2025-04-15 22:49:42,697 -   train_loss = 5.938637018203735
2025-04-15 22:50:11,338 - ***** Epoch: 11: Eval results *****
2025-04-15 22:50:11,338 -   train_loss = 5.927142926624843
2025-04-15 22:50:41,304 - ***** Epoch: 12: Eval results *****
2025-04-15 22:50:41,305 -   train_loss = 5.918137550354004
2025-04-15 22:51:15,711 - ***** Epoch: 13: Eval results *****
2025-04-15 22:51:15,712 -   train_loss = 5.903786693300519
2025-04-15 22:51:43,898 - ***** Epoch: 14: Eval results *****
2025-04-15 22:51:43,898 -   train_loss = 5.897359848022461
2025-04-15 22:52:10,633 - ***** Epoch: 15: Eval results *****
2025-04-15 22:52:10,634 -   train_loss = 5.882296664374215
2025-04-15 22:52:37,508 - ***** Epoch: 16: Eval results *****
2025-04-15 22:52:37,509 -   train_loss = 5.843610933848789
2025-04-15 22:53:04,610 - ***** Epoch: 17: Eval results *****
2025-04-15 22:53:04,610 -   train_loss = 5.803824595042637
2025-04-15 22:53:33,690 - ***** Epoch: 18: Eval results *****
2025-04-15 22:53:33,691 -   train_loss = 5.7354958057403564
2025-04-15 22:54:00,114 - ***** Epoch: 19: Eval results *****
2025-04-15 22:54:00,115 -   train_loss = 5.634575571332659
2025-04-15 22:54:24,597 - ***** Epoch: 20: Eval results *****
2025-04-15 22:54:24,597 -   train_loss = 5.46269839150565
2025-04-15 22:54:54,610 - ***** Epoch: 21: Eval results *****
2025-04-15 22:54:54,611 -   train_loss = 5.243681771414621
2025-04-15 22:55:18,908 - ***** Epoch: 22: Eval results *****
2025-04-15 22:55:18,908 -   train_loss = 4.989411456244333
2025-04-15 22:55:48,211 - ***** Epoch: 23: Eval results *****
2025-04-15 22:55:48,212 -   train_loss = 4.719662427902222
2025-04-15 22:56:14,738 - ***** Epoch: 24: Eval results *****
2025-04-15 22:56:14,738 -   train_loss = 4.457946130207607
2025-04-15 22:56:39,802 - ***** Epoch: 25: Eval results *****
2025-04-15 22:56:39,803 -   train_loss = 4.218876276697431
2025-04-15 22:57:07,818 - ***** Epoch: 26: Eval results *****
2025-04-15 22:57:07,819 -   train_loss = 4.006240810666766
2025-04-15 22:57:32,199 - ***** Epoch: 27: Eval results *****
2025-04-15 22:57:32,200 -   train_loss = 3.80300315788814
2025-04-15 22:57:59,713 - ***** Epoch: 28: Eval results *****
2025-04-15 22:57:59,714 -   train_loss = 3.63109598840986
2025-04-15 22:58:25,905 - ***** Epoch: 29: Eval results *****
2025-04-15 22:58:25,905 -   train_loss = 3.431739398411342
2025-04-15 22:58:51,046 - ***** Epoch: 30: Eval results *****
2025-04-15 22:58:51,047 -   train_loss = 3.3063933679035733
2025-04-15 22:59:17,633 - ***** Epoch: 31: Eval results *****
2025-04-15 22:59:17,634 -   train_loss = 3.171513097626822
2025-04-15 22:59:46,819 - ***** Epoch: 32: Eval results *****
2025-04-15 22:59:46,820 -   train_loss = 3.0125469309943065
2025-04-15 23:00:13,394 - ***** Epoch: 33: Eval results *****
2025-04-15 23:00:13,395 -   train_loss = 2.885493210383824
2025-04-15 23:00:38,608 - ***** Epoch: 34: Eval results *****
2025-04-15 23:00:38,608 -   train_loss = 2.7635891267231534
2025-04-15 23:01:04,220 - ***** Epoch: 35: Eval results *****
2025-04-15 23:01:04,220 -   train_loss = 2.673182334218706
2025-04-15 23:01:29,884 - ***** Epoch: 36: Eval results *****
2025-04-15 23:01:29,885 -   train_loss = 2.5842822108949934
2025-04-15 23:01:56,506 - ***** Epoch: 37: Eval results *****
2025-04-15 23:01:56,506 -   train_loss = 2.4890136889048984
2025-04-15 23:02:22,477 - ***** Epoch: 38: Eval results *****
2025-04-15 23:02:22,477 -   train_loss = 2.4154596499034335
2025-04-15 23:02:46,973 - ***** Epoch: 39: Eval results *****
2025-04-15 23:02:46,973 -   train_loss = 2.3401195321764265
2025-04-15 23:03:14,399 - ***** Epoch: 40: Eval results *****
2025-04-15 23:03:14,400 -   train_loss = 2.285885316984994
2025-04-15 23:03:39,711 - ***** Epoch: 41: Eval results *****
2025-04-15 23:03:39,712 -   train_loss = 2.2227776050567627
2025-04-15 23:04:10,106 - ***** Epoch: 42: Eval results *****
2025-04-15 23:04:10,106 -   train_loss = 2.155966196741377
2025-04-15 23:04:37,101 - ***** Epoch: 43: Eval results *****
2025-04-15 23:04:37,102 -   train_loss = 2.0905475446156094
2025-04-15 23:05:05,008 - ***** Epoch: 44: Eval results *****
2025-04-15 23:05:05,008 -   train_loss = 2.0315012080328807
2025-04-15 23:05:30,129 - ***** Epoch: 45: Eval results *****
2025-04-15 23:05:30,130 -   train_loss = 2.0016123482159207
2025-04-15 23:05:58,011 - ***** Epoch: 46: Eval results *****
2025-04-15 23:05:58,012 -   train_loss = 1.9516273822103227
2025-04-15 23:06:25,381 - ***** Epoch: 47: Eval results *****
2025-04-15 23:06:25,381 -   train_loss = 1.9159231441361564
2025-04-15 23:06:51,678 - ***** Epoch: 48: Eval results *****
2025-04-15 23:06:51,678 -   train_loss = 1.8904192873409815
2025-04-15 23:07:19,568 - ***** Epoch: 49: Eval results *****
2025-04-15 23:07:19,568 -   train_loss = 1.851384494985853
2025-04-15 23:07:46,108 - ***** Epoch: 50: Eval results *****
2025-04-15 23:07:46,108 -   train_loss = 1.8020550778933935
2025-04-15 23:08:14,587 - ***** Epoch: 51: Eval results *****
2025-04-15 23:08:14,588 -   train_loss = 1.7827449866703577
2025-04-15 23:08:40,080 - ***** Epoch: 52: Eval results *****
2025-04-15 23:08:40,081 -   train_loss = 1.7569181748798914
2025-04-15 23:09:04,313 - ***** Epoch: 53: Eval results *****
2025-04-15 23:09:04,314 -   train_loss = 1.7399866666112627
2025-04-15 23:09:35,012 - ***** Epoch: 54: Eval results *****
2025-04-15 23:09:35,013 -   train_loss = 1.722646747316633
2025-04-15 23:10:01,309 - ***** Epoch: 55: Eval results *****
2025-04-15 23:10:01,309 -   train_loss = 1.690345014844622
2025-04-15 23:10:27,630 - ***** Epoch: 56: Eval results *****
2025-04-15 23:10:27,630 -   train_loss = 1.6723674620900835
2025-04-15 23:10:54,416 - ***** Epoch: 57: Eval results *****
2025-04-15 23:10:54,417 -   train_loss = 1.6590171796934945
2025-04-15 23:11:22,395 - ***** Epoch: 58: Eval results *****
2025-04-15 23:11:22,395 -   train_loss = 1.6610261457306998
2025-04-15 23:11:50,376 - ***** Epoch: 59: Eval results *****
2025-04-15 23:11:50,377 -   train_loss = 1.637637266090938
2025-04-15 23:12:17,335 - ***** Epoch: 60: Eval results *****
2025-04-15 23:12:17,336 -   train_loss = 1.6260476452963692
2025-04-15 23:12:47,699 - ***** Epoch: 61: Eval results *****
2025-04-15 23:12:47,700 -   train_loss = 1.6107598202569144
2025-04-15 23:13:13,317 - ***** Epoch: 62: Eval results *****
2025-04-15 23:13:13,318 -   train_loss = 1.5909374696867806
2025-04-15 23:13:43,198 - ***** Epoch: 63: Eval results *****
2025-04-15 23:13:43,199 -   train_loss = 1.5827550206865584
2025-04-15 23:14:10,720 - ***** Epoch: 64: Eval results *****
2025-04-15 23:14:10,721 -   train_loss = 1.576135584286281
2025-04-15 23:14:39,198 - ***** Epoch: 65: Eval results *****
2025-04-15 23:14:39,199 -   train_loss = 1.5694381424358912
2025-04-15 23:15:04,920 - ***** Epoch: 66: Eval results *****
2025-04-15 23:15:04,920 -   train_loss = 1.5743322798183985
2025-04-15 23:15:32,721 - ***** Epoch: 67: Eval results *****
2025-04-15 23:15:32,721 -   train_loss = 1.5471838542393275
2025-04-15 23:15:58,775 - ***** Epoch: 68: Eval results *****
2025-04-15 23:15:58,775 -   train_loss = 1.5389817697661263
2025-04-15 23:16:24,704 - ***** Epoch: 69: Eval results *****
2025-04-15 23:16:24,704 -   train_loss = 1.52009551014219
2025-04-15 23:16:53,313 - ***** Epoch: 70: Eval results *****
2025-04-15 23:16:53,314 -   train_loss = 1.5251017383166723
2025-04-15 23:17:16,260 - ***** Epoch: 71: Eval results *****
2025-04-15 23:17:16,260 -   train_loss = 1.5232263803482056
2025-04-15 23:17:43,912 - ***** Epoch: 72: Eval results *****
2025-04-15 23:17:43,913 -   train_loss = 1.5161983966827393
2025-04-15 23:18:11,136 - ***** Epoch: 73: Eval results *****
2025-04-15 23:18:11,136 -   train_loss = 1.5092132432120187
2025-04-15 23:18:37,110 - ***** Epoch: 74: Eval results *****
2025-04-15 23:18:37,111 -   train_loss = 1.5032913599695479
2025-04-15 23:19:03,198 - ***** Epoch: 75: Eval results *****
2025-04-15 23:19:03,198 -   train_loss = 1.506056479045323
2025-04-15 23:19:28,269 - ***** Epoch: 76: Eval results *****
2025-04-15 23:19:28,270 -   train_loss = 1.5020357881273543
2025-04-15 23:19:54,309 - ***** Epoch: 77: Eval results *****
2025-04-15 23:19:54,309 -   train_loss = 1.4920177715165275
2025-04-15 23:20:20,516 - ***** Epoch: 78: Eval results *****
2025-04-15 23:20:20,517 -   train_loss = 1.4898055110658919
2025-04-15 23:20:50,913 - ***** Epoch: 79: Eval results *****
2025-04-15 23:20:50,913 -   train_loss = 1.4788446937288557
2025-04-15 23:21:17,103 - ***** Epoch: 80: Eval results *****
2025-04-15 23:21:17,103 -   train_loss = 1.4795292019844055
2025-04-15 23:21:42,698 - ***** Epoch: 81: Eval results *****
2025-04-15 23:21:42,699 -   train_loss = 1.4671854717390878
2025-04-15 23:22:09,676 - ***** Epoch: 82: Eval results *****
2025-04-15 23:22:09,677 -   train_loss = 1.4778798392840795
2025-04-15 23:22:36,794 - ***** Epoch: 83: Eval results *****
2025-04-15 23:22:36,795 -   train_loss = 1.4684524280684335
2025-04-15 23:23:04,233 - ***** Epoch: 84: Eval results *****
2025-04-15 23:23:04,233 -   train_loss = 1.4628453935895647
2025-04-15 23:23:29,557 - ***** Epoch: 85: Eval results *****
2025-04-15 23:23:29,558 -   train_loss = 1.4872464452471053
2025-04-15 23:23:52,517 - ***** Epoch: 86: Eval results *****
2025-04-15 23:23:52,517 -   train_loss = 1.4723889912877763
2025-04-15 23:24:19,111 - ***** Epoch: 87: Eval results *****
2025-04-15 23:24:19,111 -   train_loss = 1.4696228163582938
2025-04-15 23:24:45,496 - ***** Epoch: 88: Eval results *****
2025-04-15 23:24:45,497 -   train_loss = 1.4671505859919958
2025-04-15 23:25:15,713 - ***** Epoch: 89: Eval results *****
2025-04-15 23:25:15,713 -   train_loss = 1.454234744821276
2025-04-15 23:25:41,525 - ***** Epoch: 90: Eval results *****
2025-04-15 23:25:41,526 -   train_loss = 1.4663633278438024
2025-04-15 23:26:07,686 - ***** Epoch: 91: Eval results *****
2025-04-15 23:26:07,686 -   train_loss = 1.471615024975368
2025-04-15 23:26:31,195 - ***** Epoch: 92: Eval results *****
2025-04-15 23:26:31,195 -   train_loss = 1.4679123163223267
2025-04-15 23:26:55,258 - ***** Epoch: 93: Eval results *****
2025-04-15 23:26:55,259 -   train_loss = 1.4704045908791679
2025-04-15 23:27:19,920 - ***** Epoch: 94: Eval results *****
2025-04-15 23:27:19,921 -   train_loss = 1.4568239195006234
2025-04-15 23:27:44,022 - ***** Epoch: 95: Eval results *****
2025-04-15 23:27:44,022 -   train_loss = 1.4624989032745361
2025-04-15 23:28:09,878 - ***** Epoch: 96: Eval results *****
2025-04-15 23:28:09,878 -   train_loss = 1.455000707081386
2025-04-15 23:28:34,954 - ***** Epoch: 97: Eval results *****
2025-04-15 23:28:34,954 -   train_loss = 1.4548651831490653
2025-04-15 23:28:57,450 - ***** Epoch: 98: Eval results *****
2025-04-15 23:28:57,450 -   train_loss = 1.4679394108908517
2025-04-15 23:29:23,899 - ***** Epoch: 99: Eval results *****
2025-04-15 23:29:23,900 -   train_loss = 1.4554633583341325
2025-04-15 23:29:47,504 - ***** Epoch: 100: Eval results *****
2025-04-15 23:29:47,505 -   train_loss = 1.4603660702705383
2025-04-15 23:29:48,406 - Pre-training finished...
