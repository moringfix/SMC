2025-04-15 22:44:56,964 - 进入了无监督的设定中, 加载数据集
2025-04-15 22:44:56,969 - data preparation...
2025-04-15 22:45:06,921 - Number of train samples = 1779
2025-04-15 22:45:06,923 - Number of testing samples = 445
2025-04-15 22:45:06,923 - data preparation...
2025-04-15 22:45:09,094 - ============================== Params ==============================
2025-04-15 22:45:09,094 - logger_name: umc_umc_bert-base-uncased_MIntRec_1
2025-04-15 22:45:09,094 - dataset: MIntRec
2025-04-15 22:45:09,094 - multimodal_method: umc
2025-04-15 22:45:09,094 - method: umc
2025-04-15 22:45:09,094 - setting: unsupervised
2025-04-15 22:45:09,094 - text_backbone: bert-base-uncased
2025-04-15 22:45:09,095 - seed: 1
2025-04-15 22:45:09,095 - num_workers: 16
2025-04-15 22:45:09,095 - log_id: umc_umc_bert-base-uncased_MIntRec_1_2025-04-15-22-44-56
2025-04-15 22:45:09,095 - gpu_id: 1
2025-04-15 22:45:09,095 - data_path: /root/autodl-tmp/home/Share/Dataset/LZH
2025-04-15 22:45:09,095 - train: True
2025-04-15 22:45:09,095 - tune: True
2025-04-15 22:45:09,095 - save_model: True
2025-04-15 22:45:09,095 - save_results: True
2025-04-15 22:45:09,095 - log_path: logs
2025-04-15 22:45:09,095 - cache_path: cache
2025-04-15 22:45:09,095 - video_data_path: video_data
2025-04-15 22:45:09,095 - audio_data_path: audio_data
2025-04-15 22:45:09,095 - video_feats_path: swin_feats.pkl
2025-04-15 22:45:09,095 - audio_feats_path: wavlm_feats.pkl
2025-04-15 22:45:09,095 - results_path: results
2025-04-15 22:45:09,095 - output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/SMC/outputs_test/MIntRec
2025-04-15 22:45:09,095 - model_path: models
2025-04-15 22:45:09,095 - config_file_name: umc_MIntRec
2025-04-15 22:45:09,095 - results_file_name: results_umc.csv
2025-04-15 22:45:09,096 - text_pretrained_model: uncased_L-12_H-768_A-12
2025-04-15 22:45:09,096 - pretrained_bert_model: uncased_L-12_H-768_A-12
2025-04-15 22:45:09,096 - pretrain_batch_size: 128
2025-04-15 22:45:09,096 - train_batch_size: 128
2025-04-15 22:45:09,096 - eval_batch_size: 128
2025-04-15 22:45:09,096 - test_batch_size: 128
2025-04-15 22:45:09,096 - num_pretrain_epochs: 100
2025-04-15 22:45:09,096 - num_train_epochs: 100
2025-04-15 22:45:09,096 - pretrain: [True]
2025-04-15 22:45:09,096 - aligned_method: ctc
2025-04-15 22:45:09,096 - need_aligned: False
2025-04-15 22:45:09,096 - freeze_pretrain_bert_parameters: [True]
2025-04-15 22:45:09,096 - freeze_train_bert_parameters: [True]
2025-04-15 22:45:09,096 - pretrain_temperature: [0.1]
2025-04-15 22:45:09,096 - train_temperature_sup: [0.5, 1, 2, 4, 6, 8]
2025-04-15 22:45:09,096 - train_temperature_unsup: [0.5, 1, 2, 4, 6, 8]
2025-04-15 22:45:09,096 - activation: tanh
2025-04-15 22:45:09,096 - lr_pre: 1e-05
2025-04-15 22:45:09,096 - lr: [0.0001]
2025-04-15 22:45:09,096 - delta: [0.05]
2025-04-15 22:45:09,096 - thres: [0.1]
2025-04-15 22:45:09,096 - topk: [5]
2025-04-15 22:45:09,096 - weight_decay: 0.01
2025-04-15 22:45:09,096 - feat_dim: 768
2025-04-15 22:45:09,096 - hidden_size: 768
2025-04-15 22:45:09,096 - grad_clip: -1.0
2025-04-15 22:45:09,096 - warmup_proportion: 0.5
2025-04-15 22:45:09,096 - hidden_dropout_prob: 0.1
2025-04-15 22:45:09,097 - weight: 1.0
2025-04-15 22:45:09,097 - loss_mode: rdrop
2025-04-15 22:45:09,097 - base_dim: 256
2025-04-15 22:45:09,097 - nheads: 8
2025-04-15 22:45:09,097 - attn_dropout: 0.1
2025-04-15 22:45:09,097 - relu_dropout: 0.1
2025-04-15 22:45:09,097 - embed_dropout: 0.01
2025-04-15 22:45:09,097 - res_dropout: 0.0
2025-04-15 22:45:09,097 - attn_mask: True
2025-04-15 22:45:09,097 - encoder_layers_1: 1
2025-04-15 22:45:09,097 - fusion_act: tanh
2025-04-15 22:45:09,097 - pred_output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/SMC/outputs_test/MIntRec/umc_umc_MIntRec_bert-base-uncased_1
2025-04-15 22:45:09,097 - model_output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/SMC/outputs_test/MIntRec/umc_umc_MIntRec_bert-base-uncased_1/models
2025-04-15 22:45:09,097 - text_seq_len: 30
2025-04-15 22:45:09,097 - video_seq_len: 230
2025-04-15 22:45:09,097 - audio_seq_len: 480
2025-04-15 22:45:09,097 - text_feat_dim: 768
2025-04-15 22:45:09,097 - video_feat_dim: 1024
2025-04-15 22:45:09,097 - audio_feat_dim: 768
2025-04-15 22:45:09,097 - num_train_examples: 1779
2025-04-15 22:45:09,097 - ============================== End Params ==============================
2025-04-15 22:45:10,339 - Freeze all parameters but the last layer for efficiency
2025-04-15 22:45:10,373 - Pre-training start...
2025-04-15 22:45:33,416 - ***** Epoch: 1: Eval results *****
2025-04-15 22:45:33,416 -   train_loss = 5.965466294969831
2025-04-15 22:45:58,600 - ***** Epoch: 2: Eval results *****
2025-04-15 22:45:58,600 -   train_loss = 5.965345893587385
2025-04-15 22:46:25,798 - ***** Epoch: 3: Eval results *****
2025-04-15 22:46:25,799 -   train_loss = 5.95721299307687
2025-04-15 22:46:54,169 - ***** Epoch: 4: Eval results *****
2025-04-15 22:46:54,169 -   train_loss = 5.960200548171997
2025-04-15 22:47:21,336 - ***** Epoch: 5: Eval results *****
2025-04-15 22:47:21,337 -   train_loss = 5.9588868618011475
2025-04-15 22:47:49,174 - ***** Epoch: 6: Eval results *****
2025-04-15 22:47:49,174 -   train_loss = 5.962545803615025
2025-04-15 22:48:16,649 - ***** Epoch: 7: Eval results *****
2025-04-15 22:48:16,650 -   train_loss = 5.951046126229422
2025-04-15 22:48:46,305 - ***** Epoch: 8: Eval results *****
2025-04-15 22:48:46,306 -   train_loss = 5.947066852024624
2025-04-15 22:49:15,528 - ***** Epoch: 9: Eval results *****
2025-04-15 22:49:15,528 -   train_loss = 5.94837440763201
2025-04-15 22:49:42,696 - ***** Epoch: 10: Eval results *****
2025-04-15 22:49:42,697 -   train_loss = 5.938637018203735
2025-04-15 22:50:11,338 - ***** Epoch: 11: Eval results *****
2025-04-15 22:50:11,338 -   train_loss = 5.927142926624843
2025-04-15 22:50:41,304 - ***** Epoch: 12: Eval results *****
2025-04-15 22:50:41,305 -   train_loss = 5.918137550354004
