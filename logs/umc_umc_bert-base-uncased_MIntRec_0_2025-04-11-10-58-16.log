2025-04-11 10:58:16,452 - ============================== Params ==============================
2025-04-11 10:58:16,452 - logger_name: umc_umc_bert-base-uncased_MIntRec_0
2025-04-11 10:58:16,452 - dataset: MIntRec
2025-04-11 10:58:16,452 - multimodal_method: umc
2025-04-11 10:58:16,452 - method: umc
2025-04-11 10:58:16,452 - text_backbone: bert-base-uncased
2025-04-11 10:58:16,452 - seed: 0
2025-04-11 10:58:16,452 - num_workers: 16
2025-04-11 10:58:16,452 - log_id: umc_umc_bert-base-uncased_MIntRec_0_2025-04-11-10-58-16
2025-04-11 10:58:16,452 - gpu_id: 0
2025-04-11 10:58:16,452 - data_path: /root/autodl-tmp/home/Share/Dataset/LZH
2025-04-11 10:58:16,452 - train: True
2025-04-11 10:58:16,452 - tune: True
2025-04-11 10:58:16,452 - save_model: True
2025-04-11 10:58:16,452 - save_results: True
2025-04-11 10:58:16,453 - log_path: logs
2025-04-11 10:58:16,453 - cache_path: cache
2025-04-11 10:58:16,453 - video_data_path: video_data
2025-04-11 10:58:16,453 - audio_data_path: audio_data
2025-04-11 10:58:16,453 - video_feats_path: swin_feats.pkl
2025-04-11 10:58:16,453 - audio_feats_path: wavlm_feats.pkl
2025-04-11 10:58:16,453 - results_path: results
2025-04-11 10:58:16,453 - output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/UMC/outputs/MIntRec
2025-04-11 10:58:16,453 - model_path: models
2025-04-11 10:58:16,453 - config_file_name: umc_MIntRec
2025-04-11 10:58:16,453 - results_file_name: results_umc.csv
2025-04-11 10:58:16,453 - text_pretrained_model: uncased_L-12_H-768_A-12
2025-04-11 10:58:16,453 - text_seq_len: 30
2025-04-11 10:58:16,453 - video_seq_len: 230
2025-04-11 10:58:16,453 - audio_seq_len: 480
2025-04-11 10:58:16,453 - text_feat_dim: 768
2025-04-11 10:58:16,453 - video_feat_dim: 1024
2025-04-11 10:58:16,453 - audio_feat_dim: 768
2025-04-11 10:58:16,453 - num_labels: 20
2025-04-11 10:58:16,453 - num_train_examples: 1779
2025-04-11 10:58:16,453 - pretrained_bert_model: uncased_L-12_H-768_A-12
2025-04-11 10:58:16,453 - pretrain_batch_size: 128
2025-04-11 10:58:16,453 - train_batch_size: 128
2025-04-11 10:58:16,453 - eval_batch_size: 128
2025-04-11 10:58:16,453 - test_batch_size: 128
2025-04-11 10:58:16,453 - num_pretrain_epochs: 100
2025-04-11 10:58:16,453 - num_train_epochs: 100
2025-04-11 10:58:16,453 - pretrain: [True]
2025-04-11 10:58:16,453 - aligned_method: ctc
2025-04-11 10:58:16,454 - need_aligned: False
2025-04-11 10:58:16,454 - freeze_pretrain_bert_parameters: [True]
2025-04-11 10:58:16,454 - freeze_train_bert_parameters: [True]
2025-04-11 10:58:16,454 - pretrain_temperature: [0.2]
2025-04-11 10:58:16,454 - train_temperature_sup: [1.4]
2025-04-11 10:58:16,454 - train_temperature_unsup: [1]
2025-04-11 10:58:16,454 - activation: tanh
2025-04-11 10:58:16,454 - lr_pre: 1e-05
2025-04-11 10:58:16,454 - lr: [0.0003]
2025-04-11 10:58:16,454 - delta: [0.05]
2025-04-11 10:58:16,454 - thres: [0.1]
2025-04-11 10:58:16,454 - topk: [5]
2025-04-11 10:58:16,454 - weight_decay: 0.01
2025-04-11 10:58:16,454 - feat_dim: 768
2025-04-11 10:58:16,454 - hidden_size: 768
2025-04-11 10:58:16,454 - grad_clip: -1.0
2025-04-11 10:58:16,454 - warmup_proportion: 0.5
2025-04-11 10:58:16,454 - hidden_dropout_prob: 0.1
2025-04-11 10:58:16,454 - weight: 1.0
2025-04-11 10:58:16,454 - loss_mode: rdrop
2025-04-11 10:58:16,454 - base_dim: 256
2025-04-11 10:58:16,454 - nheads: 8
2025-04-11 10:58:16,454 - attn_dropout: 0.1
2025-04-11 10:58:16,454 - relu_dropout: 0.1
2025-04-11 10:58:16,454 - embed_dropout: 0.1
2025-04-11 10:58:16,454 - res_dropout: 0.0
2025-04-11 10:58:16,454 - attn_mask: True
2025-04-11 10:58:16,454 - encoder_layers_1: 1
2025-04-11 10:58:16,454 - fusion_act: tanh
2025-04-11 10:58:16,455 - pred_output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/UMC/outputs/MIntRec/umc_umc_MIntRec_bert-base-uncased_0
2025-04-11 10:58:16,455 - model_output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/UMC/outputs/MIntRec/umc_umc_MIntRec_bert-base-uncased_0/models
2025-04-11 10:58:16,455 - ============================== End Params ==============================
2025-04-11 10:58:17,569 - Freeze all parameters but the last layer for efficiency
2025-04-11 10:58:17,605 - Pre-training start...
2025-04-11 10:58:32,802 - ***** Epoch: 1: Eval results *****
2025-04-11 10:58:32,803 -   train_loss = 5.938590356281826
2025-04-11 10:58:47,484 - ***** Epoch: 2: Eval results *****
2025-04-11 10:58:47,484 -   train_loss = 5.939079114368984
2025-04-11 10:59:04,879 - ***** Epoch: 3: Eval results *****
2025-04-11 10:59:04,880 -   train_loss = 5.937030826296125
2025-04-11 10:59:22,412 - ***** Epoch: 4: Eval results *****
2025-04-11 10:59:22,412 -   train_loss = 5.93860353742327
2025-04-11 10:59:39,506 - ***** Epoch: 5: Eval results *****
2025-04-11 10:59:39,506 -   train_loss = 5.933631386075701
2025-04-11 10:59:56,048 - ***** Epoch: 6: Eval results *****
2025-04-11 10:59:56,048 -   train_loss = 5.937811238425119
2025-04-11 11:00:12,437 - ***** Epoch: 7: Eval results *****
2025-04-11 11:00:12,437 -   train_loss = 5.935423271996634
2025-04-11 11:00:28,905 - ***** Epoch: 8: Eval results *****
2025-04-11 11:00:28,906 -   train_loss = 5.931890998567853
2025-04-11 11:00:44,289 - ***** Epoch: 9: Eval results *****
2025-04-11 11:00:44,290 -   train_loss = 5.933904307229178
2025-04-11 11:01:00,571 - ***** Epoch: 10: Eval results *****
2025-04-11 11:01:00,572 -   train_loss = 5.929786954607282
2025-04-11 11:01:18,410 - ***** Epoch: 11: Eval results *****
2025-04-11 11:01:18,410 -   train_loss = 5.929440328053066
2025-04-11 11:01:35,562 - ***** Epoch: 12: Eval results *****
2025-04-11 11:01:35,563 -   train_loss = 5.921934229987008
2025-04-11 11:01:51,572 - ***** Epoch: 13: Eval results *****
2025-04-11 11:01:51,572 -   train_loss = 5.919466631753104
2025-04-11 11:02:07,450 - ***** Epoch: 14: Eval results *****
2025-04-11 11:02:07,451 -   train_loss = 5.9140748637063165
2025-04-11 11:02:23,579 - ***** Epoch: 15: Eval results *****
2025-04-11 11:02:23,580 -   train_loss = 5.9100300925118585
2025-04-11 11:02:39,635 - ***** Epoch: 16: Eval results *****
2025-04-11 11:02:39,636 -   train_loss = 5.897755486624582
2025-04-11 11:02:56,354 - ***** Epoch: 17: Eval results *****
2025-04-11 11:02:56,354 -   train_loss = 5.880706208092826
2025-04-11 11:03:13,658 - ***** Epoch: 18: Eval results *****
2025-04-11 11:03:13,659 -   train_loss = 5.852950607027326
2025-04-11 11:03:31,954 - ***** Epoch: 19: Eval results *****
2025-04-11 11:03:31,955 -   train_loss = 5.817711932318551
2025-04-11 11:03:49,140 - ***** Epoch: 20: Eval results *****
2025-04-11 11:03:49,140 -   train_loss = 5.749179431370327
2025-04-11 11:04:06,229 - ***** Epoch: 21: Eval results *****
2025-04-11 11:04:06,229 -   train_loss = 5.652810675757272
2025-04-11 11:04:22,608 - ***** Epoch: 22: Eval results *****
2025-04-11 11:04:22,609 -   train_loss = 5.503366606576102
2025-04-11 11:04:38,579 - ***** Epoch: 23: Eval results *****
2025-04-11 11:04:38,579 -   train_loss = 5.3321350642613
2025-04-11 11:04:55,108 - ***** Epoch: 24: Eval results *****
2025-04-11 11:04:55,108 -   train_loss = 5.138067041124616
2025-04-11 11:05:10,991 - ***** Epoch: 25: Eval results *****
2025-04-11 11:05:10,991 -   train_loss = 4.955983536584037
2025-04-11 11:05:28,411 - ***** Epoch: 26: Eval results *****
2025-04-11 11:05:28,411 -   train_loss = 4.796024833406721
2025-04-11 11:05:45,905 - ***** Epoch: 27: Eval results *****
2025-04-11 11:05:45,906 -   train_loss = 4.657538277762277
2025-04-11 11:06:02,633 - ***** Epoch: 28: Eval results *****
2025-04-11 11:06:02,634 -   train_loss = 4.527082102639334
2025-04-11 11:06:18,731 - ***** Epoch: 29: Eval results *****
2025-04-11 11:06:18,732 -   train_loss = 4.408154385430472
2025-04-11 11:06:34,735 - ***** Epoch: 30: Eval results *****
2025-04-11 11:06:34,735 -   train_loss = 4.308071919849941
2025-04-11 11:06:50,546 - ***** Epoch: 31: Eval results *****
2025-04-11 11:06:50,546 -   train_loss = 4.206461531775338
2025-04-11 11:07:06,973 - ***** Epoch: 32: Eval results *****
2025-04-11 11:07:06,973 -   train_loss = 4.1220561265945435
2025-04-11 11:07:24,712 - ***** Epoch: 33: Eval results *****
2025-04-11 11:07:24,713 -   train_loss = 4.033419626099723
2025-04-11 11:07:42,491 - ***** Epoch: 34: Eval results *****
2025-04-11 11:07:42,492 -   train_loss = 3.954611676079886
2025-04-11 11:07:59,026 - ***** Epoch: 35: Eval results *****
2025-04-11 11:07:59,027 -   train_loss = 3.85954635483878
2025-04-11 11:08:14,853 - ***** Epoch: 36: Eval results *****
2025-04-11 11:08:14,854 -   train_loss = 3.77406907081604
2025-04-11 11:08:31,263 - ***** Epoch: 37: Eval results *****
2025-04-11 11:08:31,263 -   train_loss = 3.692713805607387
2025-04-11 11:08:47,340 - ***** Epoch: 38: Eval results *****
2025-04-11 11:08:47,340 -   train_loss = 3.630051323345729
2025-04-11 11:09:03,745 - ***** Epoch: 39: Eval results *****
2025-04-11 11:09:03,745 -   train_loss = 3.582845517567226
2025-04-11 11:09:20,279 - ***** Epoch: 40: Eval results *****
2025-04-11 11:09:20,280 -   train_loss = 3.530004824910845
2025-04-11 11:09:37,068 - ***** Epoch: 41: Eval results *****
2025-04-11 11:09:37,068 -   train_loss = 3.4941924469811574
2025-04-11 11:09:54,219 - ***** Epoch: 42: Eval results *****
2025-04-11 11:09:54,220 -   train_loss = 3.4553745814732144
2025-04-11 11:10:09,945 - ***** Epoch: 43: Eval results *****
2025-04-11 11:10:09,945 -   train_loss = 3.4115745510373796
2025-04-11 11:10:25,795 - ***** Epoch: 44: Eval results *****
2025-04-11 11:10:25,795 -   train_loss = 3.3742649725505283
2025-04-11 11:10:42,208 - ***** Epoch: 45: Eval results *****
2025-04-11 11:10:42,209 -   train_loss = 3.341618912560599
2025-04-11 11:10:57,578 - ***** Epoch: 46: Eval results *****
2025-04-11 11:10:57,578 -   train_loss = 3.307855044092451
2025-04-11 11:11:13,038 - ***** Epoch: 47: Eval results *****
2025-04-11 11:11:13,038 -   train_loss = 3.2877112797328403
2025-04-11 11:11:28,628 - ***** Epoch: 48: Eval results *****
2025-04-11 11:11:28,628 -   train_loss = 3.2591572318758284
2025-04-11 11:11:44,509 - ***** Epoch: 49: Eval results *****
2025-04-11 11:11:44,510 -   train_loss = 3.229689802442278
2025-04-11 11:12:00,090 - ***** Epoch: 50: Eval results *****
2025-04-11 11:12:00,091 -   train_loss = 3.2044173989977156
2025-04-11 11:12:16,156 - ***** Epoch: 51: Eval results *****
2025-04-11 11:12:16,156 -   train_loss = 3.2003913606916154
2025-04-11 11:12:31,865 - ***** Epoch: 52: Eval results *****
2025-04-11 11:12:31,865 -   train_loss = 3.1665001256125316
2025-04-11 11:12:47,165 - ***** Epoch: 53: Eval results *****
2025-04-11 11:12:47,166 -   train_loss = 3.1534115076065063
2025-04-11 11:13:02,771 - ***** Epoch: 54: Eval results *****
2025-04-11 11:13:02,772 -   train_loss = 3.1426447119031633
2025-04-11 11:13:18,066 - ***** Epoch: 55: Eval results *****
2025-04-11 11:13:18,066 -   train_loss = 3.1242318834577287
2025-04-11 11:13:33,684 - ***** Epoch: 56: Eval results *****
2025-04-11 11:13:33,684 -   train_loss = 3.102156843457903
2025-04-11 11:13:49,005 - ***** Epoch: 57: Eval results *****
2025-04-11 11:13:49,005 -   train_loss = 3.083751286779131
2025-04-11 11:14:04,210 - ***** Epoch: 58: Eval results *****
2025-04-11 11:14:04,211 -   train_loss = 3.0682320594787598
2025-04-11 11:14:19,834 - ***** Epoch: 59: Eval results *****
2025-04-11 11:14:19,835 -   train_loss = 3.0551025015967235
2025-04-11 11:14:36,102 - ***** Epoch: 60: Eval results *****
2025-04-11 11:14:36,103 -   train_loss = 3.038638608796256
2025-04-11 11:14:51,835 - ***** Epoch: 61: Eval results *****
2025-04-11 11:14:51,835 -   train_loss = 3.0369648592812672
2025-04-11 11:15:07,459 - ***** Epoch: 62: Eval results *****
2025-04-11 11:15:07,460 -   train_loss = 3.0282566206795827
2025-04-11 11:15:22,969 - ***** Epoch: 63: Eval results *****
2025-04-11 11:15:22,970 -   train_loss = 3.0221914052963257
2025-04-11 11:15:38,952 - ***** Epoch: 64: Eval results *****
2025-04-11 11:15:38,953 -   train_loss = 2.9954280853271484
2025-04-11 11:15:54,389 - ***** Epoch: 65: Eval results *****
2025-04-11 11:15:54,389 -   train_loss = 3.002741915839059
2025-04-11 11:16:10,126 - ***** Epoch: 66: Eval results *****
2025-04-11 11:16:10,126 -   train_loss = 2.988651820591518
2025-04-11 11:16:25,104 - ***** Epoch: 67: Eval results *****
2025-04-11 11:16:25,105 -   train_loss = 2.9686285087040494
2025-04-11 11:16:41,370 - ***** Epoch: 68: Eval results *****
2025-04-11 11:16:41,370 -   train_loss = 2.971214226314
2025-04-11 11:16:56,962 - ***** Epoch: 69: Eval results *****
2025-04-11 11:16:56,963 -   train_loss = 2.9614021437508717
2025-04-11 11:17:12,178 - ***** Epoch: 70: Eval results *****
2025-04-11 11:17:12,178 -   train_loss = 2.966693435396467
2025-04-11 11:17:27,813 - ***** Epoch: 71: Eval results *****
2025-04-11 11:17:27,813 -   train_loss = 2.9655962330954417
2025-04-11 11:17:42,512 - ***** Epoch: 72: Eval results *****
2025-04-11 11:17:42,512 -   train_loss = 2.955580609185355
2025-04-11 11:17:57,720 - ***** Epoch: 73: Eval results *****
2025-04-11 11:17:57,721 -   train_loss = 2.9510693720408847
2025-04-11 11:18:12,693 - ***** Epoch: 74: Eval results *****
2025-04-11 11:18:12,693 -   train_loss = 2.9466740914753506
2025-04-11 11:18:27,989 - ***** Epoch: 75: Eval results *****
2025-04-11 11:18:27,990 -   train_loss = 2.9472978115081787
2025-04-11 11:18:43,261 - ***** Epoch: 76: Eval results *****
2025-04-11 11:18:43,261 -   train_loss = 2.929393938609532
2025-04-11 11:18:58,433 - ***** Epoch: 77: Eval results *****
2025-04-11 11:18:58,434 -   train_loss = 2.917530196053641
2025-04-11 11:19:13,606 - ***** Epoch: 78: Eval results *****
2025-04-11 11:19:13,606 -   train_loss = 2.9191045590809415
2025-04-11 11:19:28,730 - ***** Epoch: 79: Eval results *****
2025-04-11 11:19:28,730 -   train_loss = 2.9178291729518344
2025-04-11 11:19:43,774 - ***** Epoch: 80: Eval results *****
2025-04-11 11:19:43,774 -   train_loss = 2.9134331260408675
2025-04-11 11:19:58,720 - ***** Epoch: 81: Eval results *****
2025-04-11 11:19:58,720 -   train_loss = 2.9077014412198747
2025-04-11 11:20:13,905 - ***** Epoch: 82: Eval results *****
2025-04-11 11:20:13,906 -   train_loss = 2.908088598932539
2025-04-11 11:20:29,671 - ***** Epoch: 83: Eval results *****
2025-04-11 11:20:29,671 -   train_loss = 2.9191722188677107
2025-04-11 11:20:45,951 - ***** Epoch: 84: Eval results *****
2025-04-11 11:20:45,951 -   train_loss = 2.900795187268938
2025-04-11 11:21:02,012 - ***** Epoch: 85: Eval results *****
2025-04-11 11:21:02,012 -   train_loss = 2.9050216334206715
2025-04-11 11:21:17,493 - ***** Epoch: 86: Eval results *****
2025-04-11 11:21:17,493 -   train_loss = 2.902312994003296
2025-04-11 11:21:33,136 - ***** Epoch: 87: Eval results *****
2025-04-11 11:21:33,137 -   train_loss = 2.892526422228132
2025-04-11 11:21:48,388 - ***** Epoch: 88: Eval results *****
2025-04-11 11:21:48,388 -   train_loss = 2.894523416246687
2025-04-11 11:22:04,225 - ***** Epoch: 89: Eval results *****
2025-04-11 11:22:04,225 -   train_loss = 2.8959390265601024
2025-04-11 11:22:20,020 - ***** Epoch: 90: Eval results *****
2025-04-11 11:22:20,020 -   train_loss = 2.894098707607814
2025-04-11 11:22:35,244 - ***** Epoch: 91: Eval results *****
2025-04-11 11:22:35,244 -   train_loss = 2.8840131078447615
2025-04-11 11:22:50,426 - ***** Epoch: 92: Eval results *****
2025-04-11 11:22:50,426 -   train_loss = 2.8859222616468156
2025-04-11 11:23:05,746 - ***** Epoch: 93: Eval results *****
2025-04-11 11:23:05,746 -   train_loss = 2.888626285961696
2025-04-11 11:23:21,876 - ***** Epoch: 94: Eval results *****
2025-04-11 11:23:21,876 -   train_loss = 2.8887894494192943
2025-04-11 11:23:37,956 - ***** Epoch: 95: Eval results *****
2025-04-11 11:23:37,956 -   train_loss = 2.8916430984224593
2025-04-11 11:23:54,323 - ***** Epoch: 96: Eval results *****
2025-04-11 11:23:54,324 -   train_loss = 2.891456263405936
2025-04-11 11:24:10,182 - ***** Epoch: 97: Eval results *****
2025-04-11 11:24:10,182 -   train_loss = 2.890963315963745
2025-04-11 11:24:27,025 - ***** Epoch: 98: Eval results *****
2025-04-11 11:24:27,026 -   train_loss = 2.89900381224496
2025-04-11 11:24:43,685 - ***** Epoch: 99: Eval results *****
2025-04-11 11:24:43,685 -   train_loss = 2.883169855390276
2025-04-11 11:24:59,958 - ***** Epoch: 100: Eval results *****
2025-04-11 11:24:59,958 -   train_loss = 2.892158423151289
2025-04-11 11:25:01,565 - Pre-training finished...
2025-04-11 11:25:01,835 - Freeze all parameters but the last layer for efficiency
2025-04-11 11:25:01,844 - Multimodal Intent Recognition begins...
2025-04-11 11:25:01,845 - Training begins...
2025-04-11 11:25:17,737 - Initializing centroids with K-means++...
2025-04-11 11:25:17,825 - K-means++ used 0.09 s
2025-04-11 11:25:46,303 - K-means used 0.1 s
2025-04-11 11:25:47,357 - ***** Epoch: 1 *****
2025-04-11 11:25:47,357 - Supervised Training Loss: 4.886880
2025-04-11 11:25:47,357 - Unsupervised Training Loss: 5.124890
2025-04-11 11:26:14,425 - K-means used 0.02 s
2025-04-11 11:26:15,850 - ***** Epoch: 2 *****
2025-04-11 11:26:15,851 - Supervised Training Loss: 3.877720
2025-04-11 11:26:15,851 - Unsupervised Training Loss: 5.148560
2025-04-11 11:26:44,578 - K-means used 0.03 s
2025-04-11 11:26:45,983 - ***** Epoch: 3 *****
2025-04-11 11:26:45,983 - Supervised Training Loss: 5.341780
2025-04-11 11:26:45,984 - Unsupervised Training Loss: 5.011680
2025-04-11 11:27:15,629 - K-means used 0.02 s
2025-04-11 11:27:17,064 - ***** Epoch: 4 *****
2025-04-11 11:27:17,064 - Supervised Training Loss: 5.217300
2025-04-11 11:27:17,064 - Unsupervised Training Loss: 5.079310
2025-04-11 11:27:47,504 - K-means used 0.03 s
2025-04-11 11:27:48,958 - ***** Epoch: 5 *****
2025-04-11 11:27:48,958 - Supervised Training Loss: 4.950560
2025-04-11 11:27:48,959 - Unsupervised Training Loss: 5.114930
2025-04-11 11:28:19,570 - K-means used 0.04 s
2025-04-11 11:28:21,002 - ***** Epoch: 6 *****
2025-04-11 11:28:21,002 - Supervised Training Loss: 5.344130
2025-04-11 11:28:21,002 - Unsupervised Training Loss: 4.906920
2025-04-11 11:28:50,207 - K-means used 0.05 s
2025-04-11 11:28:51,667 - ***** Epoch: 7 *****
2025-04-11 11:28:51,668 - Supervised Training Loss: 5.262240
2025-04-11 11:28:51,668 - Unsupervised Training Loss: 5.019900
2025-04-11 11:29:21,225 - K-means used 0.03 s
2025-04-11 11:29:22,814 - ***** Epoch: 8 *****
2025-04-11 11:29:22,815 - Supervised Training Loss: 5.093610
2025-04-11 11:29:22,815 - Unsupervised Training Loss: 5.072060
2025-04-11 11:29:52,417 - K-means used 0.03 s
2025-04-11 11:29:54,022 - ***** Epoch: 9 *****
2025-04-11 11:29:54,022 - Supervised Training Loss: 5.327110
2025-04-11 11:29:54,022 - Unsupervised Training Loss: 5.113680
2025-04-11 11:30:22,916 - K-means used 0.03 s
2025-04-11 11:30:24,554 - ***** Epoch: 10 *****
2025-04-11 11:30:24,554 - Supervised Training Loss: 5.265780
2025-04-11 11:30:24,554 - Unsupervised Training Loss: 4.959660
2025-04-11 11:30:53,206 - K-means used 0.02 s
2025-04-11 11:30:55,037 - ***** Epoch: 11 *****
2025-04-11 11:30:55,037 - Supervised Training Loss: 5.189210
2025-04-11 11:30:55,038 - Unsupervised Training Loss: 5.022480
2025-04-11 11:31:24,526 - K-means used 0.03 s
2025-04-11 11:31:26,327 - ***** Epoch: 12 *****
2025-04-11 11:31:26,327 - Supervised Training Loss: 5.315510
2025-04-11 11:31:26,327 - Unsupervised Training Loss: 5.080700
2025-04-11 11:31:54,679 - K-means used 0.02 s
2025-04-11 11:31:56,675 - ***** Epoch: 13 *****
2025-04-11 11:31:56,676 - Supervised Training Loss: 5.279050
2025-04-11 11:31:56,676 - Unsupervised Training Loss: 4.796350
2025-04-11 11:32:25,832 - K-means used 0.02 s
2025-04-11 11:32:27,944 - ***** Epoch: 14 *****
2025-04-11 11:32:27,944 - Supervised Training Loss: 5.228600
2025-04-11 11:32:27,944 - Unsupervised Training Loss: 4.925520
2025-04-11 11:32:56,812 - K-means used 0.02 s
2025-04-11 11:32:59,110 - ***** Epoch: 15 *****
2025-04-11 11:32:59,111 - Supervised Training Loss: 5.089260
2025-04-11 11:32:59,111 - Unsupervised Training Loss: 5.037470
2025-04-11 11:33:27,514 - K-means used 0.07 s
2025-04-11 11:33:29,654 - ***** Epoch: 16 *****
2025-04-11 11:33:29,654 - Supervised Training Loss: 5.290810
2025-04-11 11:33:29,654 - Unsupervised Training Loss: 4.484810
2025-04-11 11:33:58,427 - K-means used 0.02 s
2025-04-11 11:34:00,734 - ***** Epoch: 17 *****
2025-04-11 11:34:00,735 - Supervised Training Loss: 5.258760
2025-04-11 11:34:00,735 - Unsupervised Training Loss: 4.706650
2025-04-11 11:34:19,379 - Training is finished...
2025-04-11 11:34:19,380 - Testing begins...
2025-04-11 11:34:26,556 - ***** Test results *****
2025-04-11 11:34:26,556 -   ACC = 38.88
2025-04-11 11:34:26,556 -   ARI = 20.27
2025-04-11 11:34:26,556 -   NMI = 45.2
2025-04-11 11:34:26,556 -   fmi = 25.45
2025-04-11 11:34:26,557 - Testing is finished...
2025-04-11 11:34:26,557 - Multimodal intent recognition is finished...
2025-04-11 11:34:26,557 - Results are saved in results/results_umc.csv
