2025-04-14 16:30:50,154 - ============================== Params ==============================
2025-04-14 16:30:50,154 - logger_name: umc_umc_bert-base-uncased_MIntRec_1
2025-04-14 16:30:50,154 - dataset: MIntRec
2025-04-14 16:30:50,154 - multimodal_method: umc
2025-04-14 16:30:50,155 - method: umc
2025-04-14 16:30:50,155 - text_backbone: bert-base-uncased
2025-04-14 16:30:50,155 - seed: 1
2025-04-14 16:30:50,155 - num_workers: 16
2025-04-14 16:30:50,155 - log_id: umc_umc_bert-base-uncased_MIntRec_1_2025-04-14-16-30-50
2025-04-14 16:30:50,155 - gpu_id: 0
2025-04-14 16:30:50,155 - data_path: /root/autodl-tmp/home/Share/Dataset/LZH
2025-04-14 16:30:50,155 - train: True
2025-04-14 16:30:50,155 - tune: True
2025-04-14 16:30:50,155 - save_model: True
2025-04-14 16:30:50,155 - save_results: True
2025-04-14 16:30:50,155 - log_path: logs
2025-04-14 16:30:50,155 - cache_path: cache
2025-04-14 16:30:50,155 - video_data_path: video_data
2025-04-14 16:30:50,155 - audio_data_path: audio_data
2025-04-14 16:30:50,155 - video_feats_path: swin_feats.pkl
2025-04-14 16:30:50,155 - audio_feats_path: wavlm_feats.pkl
2025-04-14 16:30:50,156 - results_path: results
2025-04-14 16:30:50,156 - output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/UMC/outputs/MIntRec
2025-04-14 16:30:50,156 - model_path: models
2025-04-14 16:30:50,156 - config_file_name: umc_MIntRec
2025-04-14 16:30:50,156 - results_file_name: results_umc.csv
2025-04-14 16:30:50,156 - text_pretrained_model: uncased_L-12_H-768_A-12
2025-04-14 16:30:50,156 - text_seq_len: 30
2025-04-14 16:30:50,156 - video_seq_len: 230
2025-04-14 16:30:50,156 - audio_seq_len: 480
2025-04-14 16:30:50,156 - text_feat_dim: 768
2025-04-14 16:30:50,156 - video_feat_dim: 1024
2025-04-14 16:30:50,156 - audio_feat_dim: 768
2025-04-14 16:30:50,156 - num_labels: 20
2025-04-14 16:30:50,156 - num_train_examples: 1779
2025-04-14 16:30:50,156 - pretrained_bert_model: uncased_L-12_H-768_A-12
2025-04-14 16:30:50,156 - pretrain_batch_size: 128
2025-04-14 16:30:50,156 - train_batch_size: 128
2025-04-14 16:30:50,156 - eval_batch_size: 128
2025-04-14 16:30:50,156 - test_batch_size: 128
2025-04-14 16:30:50,156 - num_pretrain_epochs: 100
2025-04-14 16:30:50,156 - num_train_epochs: 100
2025-04-14 16:30:50,156 - pretrain: [True]
2025-04-14 16:30:50,156 - aligned_method: ctc
2025-04-14 16:30:50,156 - need_aligned: False
2025-04-14 16:30:50,156 - freeze_pretrain_bert_parameters: [True]
2025-04-14 16:30:50,156 - freeze_train_bert_parameters: [True]
2025-04-14 16:30:50,156 - pretrain_temperature: [0.1]
2025-04-14 16:30:50,156 - train_temperature_sup: [7.6]
2025-04-14 16:30:50,156 - train_temperature_unsup: [0.9]
2025-04-14 16:30:50,156 - activation: tanh
2025-04-14 16:30:50,157 - lr_pre: 1e-05
2025-04-14 16:30:50,157 - lr: [0.0003]
2025-04-14 16:30:50,157 - delta: [0.05]
2025-04-14 16:30:50,157 - thres: [0.1]
2025-04-14 16:30:50,157 - topk: [5]
2025-04-14 16:30:50,157 - weight_decay: 0.01
2025-04-14 16:30:50,157 - feat_dim: 768
2025-04-14 16:30:50,157 - hidden_size: 768
2025-04-14 16:30:50,157 - grad_clip: -1.0
2025-04-14 16:30:50,157 - warmup_proportion: 0.5
2025-04-14 16:30:50,157 - hidden_dropout_prob: 0.1
2025-04-14 16:30:50,157 - weight: 1.0
2025-04-14 16:30:50,157 - loss_mode: rdrop
2025-04-14 16:30:50,157 - base_dim: 256
2025-04-14 16:30:50,157 - nheads: 8
2025-04-14 16:30:50,157 - attn_dropout: 0.1
2025-04-14 16:30:50,157 - relu_dropout: 0.1
2025-04-14 16:30:50,157 - embed_dropout: 0.01
2025-04-14 16:30:50,157 - res_dropout: 0.0
2025-04-14 16:30:50,157 - attn_mask: True
2025-04-14 16:30:50,157 - encoder_layers_1: 1
2025-04-14 16:30:50,157 - fusion_act: tanh
2025-04-14 16:30:50,157 - pred_output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/UMC/outputs/MIntRec/umc_umc_MIntRec_bert-base-uncased_1
2025-04-14 16:30:50,157 - model_output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/UMC/outputs/MIntRec/umc_umc_MIntRec_bert-base-uncased_1/models
2025-04-14 16:30:50,157 - ============================== End Params ==============================
2025-04-14 16:30:51,447 - Freeze all parameters but the last layer for efficiency
2025-04-14 16:30:51,481 - Pre-training start...
2025-04-14 16:31:06,229 - ***** Epoch: 1: Eval results *****
2025-04-14 16:31:06,230 -   train_loss = 5.965466294969831
2025-04-14 16:31:20,094 - ***** Epoch: 2: Eval results *****
2025-04-14 16:31:20,094 -   train_loss = 5.965345893587385
2025-04-14 16:31:35,350 - ***** Epoch: 3: Eval results *****
2025-04-14 16:31:35,350 -   train_loss = 5.95721299307687
2025-04-14 16:31:50,697 - ***** Epoch: 4: Eval results *****
2025-04-14 16:31:50,698 -   train_loss = 5.960200548171997
2025-04-14 16:32:06,880 - ***** Epoch: 5: Eval results *****
2025-04-14 16:32:06,880 -   train_loss = 5.9588868618011475
2025-04-14 16:32:22,810 - ***** Epoch: 6: Eval results *****
2025-04-14 16:32:22,810 -   train_loss = 5.962545803615025
2025-04-14 16:32:38,848 - ***** Epoch: 7: Eval results *****
2025-04-14 16:32:38,849 -   train_loss = 5.951046126229422
2025-04-14 16:32:53,848 - ***** Epoch: 8: Eval results *****
2025-04-14 16:32:53,848 -   train_loss = 5.947066852024624
2025-04-14 16:33:09,086 - ***** Epoch: 9: Eval results *****
2025-04-14 16:33:09,086 -   train_loss = 5.94837440763201
2025-04-14 16:33:24,172 - ***** Epoch: 10: Eval results *****
2025-04-14 16:33:24,172 -   train_loss = 5.938637018203735
2025-04-14 16:33:39,750 - ***** Epoch: 11: Eval results *****
2025-04-14 16:33:39,750 -   train_loss = 5.927142926624843
2025-04-14 16:33:55,266 - ***** Epoch: 12: Eval results *****
2025-04-14 16:33:55,266 -   train_loss = 5.918137550354004
2025-04-14 16:34:10,735 - ***** Epoch: 13: Eval results *****
2025-04-14 16:34:10,735 -   train_loss = 5.903786693300519
2025-04-14 16:34:26,198 - ***** Epoch: 14: Eval results *****
2025-04-14 16:34:26,198 -   train_loss = 5.897359848022461
2025-04-14 16:34:41,333 - ***** Epoch: 15: Eval results *****
2025-04-14 16:34:41,334 -   train_loss = 5.882296664374215
2025-04-14 16:34:56,363 - ***** Epoch: 16: Eval results *****
2025-04-14 16:34:56,364 -   train_loss = 5.843610933848789
2025-04-14 16:35:11,569 - ***** Epoch: 17: Eval results *****
2025-04-14 16:35:11,570 -   train_loss = 5.803824595042637
2025-04-14 16:35:26,585 - ***** Epoch: 18: Eval results *****
2025-04-14 16:35:26,585 -   train_loss = 5.7354958057403564
2025-04-14 16:35:42,157 - ***** Epoch: 19: Eval results *****
2025-04-14 16:35:42,158 -   train_loss = 5.634575571332659
2025-04-14 16:35:56,819 - ***** Epoch: 20: Eval results *****
2025-04-14 16:35:56,819 -   train_loss = 5.46269839150565
2025-04-14 16:36:11,736 - ***** Epoch: 21: Eval results *****
2025-04-14 16:36:11,736 -   train_loss = 5.243681771414621
2025-04-14 16:36:26,557 - ***** Epoch: 22: Eval results *****
2025-04-14 16:36:26,557 -   train_loss = 4.989411456244333
2025-04-14 16:36:41,810 - ***** Epoch: 23: Eval results *****
2025-04-14 16:36:41,810 -   train_loss = 4.719662427902222
2025-04-14 16:36:57,014 - ***** Epoch: 24: Eval results *****
2025-04-14 16:36:57,014 -   train_loss = 4.457946130207607
2025-04-14 16:37:12,113 - ***** Epoch: 25: Eval results *****
2025-04-14 16:37:12,114 -   train_loss = 4.218876276697431
2025-04-14 16:37:27,688 - ***** Epoch: 26: Eval results *****
2025-04-14 16:37:27,688 -   train_loss = 4.006240810666766
2025-04-14 16:37:43,457 - ***** Epoch: 27: Eval results *****
2025-04-14 16:37:43,458 -   train_loss = 3.80300315788814
2025-04-14 16:37:59,360 - ***** Epoch: 28: Eval results *****
2025-04-14 16:37:59,360 -   train_loss = 3.63109598840986
2025-04-14 16:38:14,750 - ***** Epoch: 29: Eval results *****
2025-04-14 16:38:14,750 -   train_loss = 3.431739398411342
2025-04-14 16:38:30,521 - ***** Epoch: 30: Eval results *****
2025-04-14 16:38:30,521 -   train_loss = 3.3063933679035733
2025-04-14 16:38:45,801 - ***** Epoch: 31: Eval results *****
2025-04-14 16:38:45,801 -   train_loss = 3.171513097626822
2025-04-14 16:39:01,981 - ***** Epoch: 32: Eval results *****
2025-04-14 16:39:01,981 -   train_loss = 3.0125469309943065
2025-04-14 16:39:17,044 - ***** Epoch: 33: Eval results *****
2025-04-14 16:39:17,044 -   train_loss = 2.885493210383824
2025-04-14 16:39:33,004 - ***** Epoch: 34: Eval results *****
2025-04-14 16:39:33,004 -   train_loss = 2.7635891267231534
2025-04-14 16:39:49,160 - ***** Epoch: 35: Eval results *****
2025-04-14 16:39:49,160 -   train_loss = 2.673182334218706
2025-04-14 16:40:04,555 - ***** Epoch: 36: Eval results *****
2025-04-14 16:40:04,556 -   train_loss = 2.5842822108949934
2025-04-14 16:40:20,654 - ***** Epoch: 37: Eval results *****
2025-04-14 16:40:20,654 -   train_loss = 2.4890136889048984
2025-04-14 16:40:36,309 - ***** Epoch: 38: Eval results *****
2025-04-14 16:40:36,309 -   train_loss = 2.4154596499034335
2025-04-14 16:40:52,101 - ***** Epoch: 39: Eval results *****
2025-04-14 16:40:52,102 -   train_loss = 2.3401195321764265
2025-04-14 16:41:07,654 - ***** Epoch: 40: Eval results *****
2025-04-14 16:41:07,654 -   train_loss = 2.285885316984994
2025-04-14 16:41:22,846 - ***** Epoch: 41: Eval results *****
2025-04-14 16:41:22,847 -   train_loss = 2.2227776050567627
2025-04-14 16:41:38,118 - ***** Epoch: 42: Eval results *****
2025-04-14 16:41:38,118 -   train_loss = 2.155966196741377
2025-04-14 16:41:53,130 - ***** Epoch: 43: Eval results *****
2025-04-14 16:41:53,130 -   train_loss = 2.0905475446156094
2025-04-14 16:42:08,728 - ***** Epoch: 44: Eval results *****
2025-04-14 16:42:08,728 -   train_loss = 2.0315012080328807
2025-04-14 16:42:24,561 - ***** Epoch: 45: Eval results *****
2025-04-14 16:42:24,561 -   train_loss = 2.0016123482159207
2025-04-14 16:42:39,784 - ***** Epoch: 46: Eval results *****
2025-04-14 16:42:39,784 -   train_loss = 1.9516273822103227
2025-04-14 16:42:55,604 - ***** Epoch: 47: Eval results *****
2025-04-14 16:42:55,605 -   train_loss = 1.9159231441361564
2025-04-14 16:43:10,254 - ***** Epoch: 48: Eval results *****
2025-04-14 16:43:10,255 -   train_loss = 1.8904192873409815
2025-04-14 16:43:25,920 - ***** Epoch: 49: Eval results *****
2025-04-14 16:43:25,921 -   train_loss = 1.851384494985853
2025-04-14 16:43:40,925 - ***** Epoch: 50: Eval results *****
2025-04-14 16:43:40,926 -   train_loss = 1.8020550778933935
2025-04-14 16:43:55,936 - ***** Epoch: 51: Eval results *****
2025-04-14 16:43:55,936 -   train_loss = 1.7827449866703577
2025-04-14 16:44:10,659 - ***** Epoch: 52: Eval results *****
2025-04-14 16:44:10,659 -   train_loss = 1.7569181748798914
2025-04-14 16:44:25,821 - ***** Epoch: 53: Eval results *****
2025-04-14 16:44:25,821 -   train_loss = 1.7399866666112627
2025-04-14 16:44:40,785 - ***** Epoch: 54: Eval results *****
2025-04-14 16:44:40,785 -   train_loss = 1.722646747316633
2025-04-14 16:44:56,662 - ***** Epoch: 55: Eval results *****
2025-04-14 16:44:56,662 -   train_loss = 1.690345014844622
2025-04-14 16:45:12,748 - ***** Epoch: 56: Eval results *****
2025-04-14 16:45:12,748 -   train_loss = 1.6723674620900835
2025-04-14 16:45:28,852 - ***** Epoch: 57: Eval results *****
2025-04-14 16:45:28,853 -   train_loss = 1.6590171796934945
2025-04-14 16:45:44,850 - ***** Epoch: 58: Eval results *****
2025-04-14 16:45:44,850 -   train_loss = 1.6610261457306998
2025-04-14 16:46:01,081 - ***** Epoch: 59: Eval results *****
2025-04-14 16:46:01,082 -   train_loss = 1.637637266090938
2025-04-14 16:46:16,680 - ***** Epoch: 60: Eval results *****
2025-04-14 16:46:16,680 -   train_loss = 1.6260476452963692
2025-04-14 16:46:32,334 - ***** Epoch: 61: Eval results *****
2025-04-14 16:46:32,335 -   train_loss = 1.6107598202569144
2025-04-14 16:46:48,121 - ***** Epoch: 62: Eval results *****
2025-04-14 16:46:48,122 -   train_loss = 1.5909374696867806
2025-04-14 16:47:03,775 - ***** Epoch: 63: Eval results *****
2025-04-14 16:47:03,775 -   train_loss = 1.5827550206865584
2025-04-14 16:47:19,983 - ***** Epoch: 64: Eval results *****
2025-04-14 16:47:19,983 -   train_loss = 1.576135584286281
2025-04-14 16:47:36,243 - ***** Epoch: 65: Eval results *****
2025-04-14 16:47:36,244 -   train_loss = 1.5694381424358912
2025-04-14 16:47:51,473 - ***** Epoch: 66: Eval results *****
2025-04-14 16:47:51,474 -   train_loss = 1.5743322798183985
2025-04-14 16:48:07,533 - ***** Epoch: 67: Eval results *****
2025-04-14 16:48:07,533 -   train_loss = 1.5471838542393275
2025-04-14 16:48:22,764 - ***** Epoch: 68: Eval results *****
2025-04-14 16:48:22,764 -   train_loss = 1.5389817697661263
2025-04-14 16:48:38,619 - ***** Epoch: 69: Eval results *****
2025-04-14 16:48:38,620 -   train_loss = 1.52009551014219
2025-04-14 16:48:54,383 - ***** Epoch: 70: Eval results *****
2025-04-14 16:48:54,384 -   train_loss = 1.5251017383166723
2025-04-14 16:49:10,291 - ***** Epoch: 71: Eval results *****
2025-04-14 16:49:10,291 -   train_loss = 1.5232263803482056
2025-04-14 16:49:26,559 - ***** Epoch: 72: Eval results *****
2025-04-14 16:49:26,560 -   train_loss = 1.5161983966827393
2025-04-14 16:49:42,409 - ***** Epoch: 73: Eval results *****
2025-04-14 16:49:42,409 -   train_loss = 1.5092132432120187
2025-04-14 16:49:58,253 - ***** Epoch: 74: Eval results *****
2025-04-14 16:49:58,254 -   train_loss = 1.5032913599695479
2025-04-14 16:50:14,718 - ***** Epoch: 75: Eval results *****
2025-04-14 16:50:14,719 -   train_loss = 1.506056479045323
2025-04-14 16:50:30,446 - ***** Epoch: 76: Eval results *****
2025-04-14 16:50:30,446 -   train_loss = 1.5020357881273543
2025-04-14 16:50:46,207 - ***** Epoch: 77: Eval results *****
2025-04-14 16:50:46,208 -   train_loss = 1.4920177715165275
2025-04-14 16:51:01,770 - ***** Epoch: 78: Eval results *****
2025-04-14 16:51:01,770 -   train_loss = 1.4898055110658919
2025-04-14 16:51:17,292 - ***** Epoch: 79: Eval results *****
2025-04-14 16:51:17,293 -   train_loss = 1.4788446937288557
2025-04-14 16:51:34,253 - ***** Epoch: 80: Eval results *****
2025-04-14 16:51:34,253 -   train_loss = 1.4795292019844055
2025-04-14 16:51:51,428 - ***** Epoch: 81: Eval results *****
2025-04-14 16:51:51,428 -   train_loss = 1.4671854717390878
2025-04-14 16:52:10,366 - ***** Epoch: 82: Eval results *****
2025-04-14 16:52:10,366 -   train_loss = 1.4778798392840795
2025-04-14 16:52:27,553 - ***** Epoch: 83: Eval results *****
2025-04-14 16:52:27,553 -   train_loss = 1.4684524280684335
2025-04-14 16:52:46,017 - ***** Epoch: 84: Eval results *****
2025-04-14 16:52:46,017 -   train_loss = 1.4628453935895647
2025-04-14 16:53:02,902 - ***** Epoch: 85: Eval results *****
2025-04-14 16:53:02,902 -   train_loss = 1.4872464452471053
2025-04-14 16:53:19,450 - ***** Epoch: 86: Eval results *****
2025-04-14 16:53:19,450 -   train_loss = 1.4723889912877763
2025-04-14 16:53:35,985 - ***** Epoch: 87: Eval results *****
2025-04-14 16:53:35,985 -   train_loss = 1.4696228163582938
2025-04-14 16:53:52,167 - ***** Epoch: 88: Eval results *****
2025-04-14 16:53:52,168 -   train_loss = 1.4671505859919958
2025-04-14 16:54:08,148 - ***** Epoch: 89: Eval results *****
2025-04-14 16:54:08,148 -   train_loss = 1.454234744821276
2025-04-14 16:54:24,313 - ***** Epoch: 90: Eval results *****
2025-04-14 16:54:24,313 -   train_loss = 1.4663633278438024
2025-04-14 16:54:40,300 - ***** Epoch: 91: Eval results *****
2025-04-14 16:54:40,300 -   train_loss = 1.471615024975368
2025-04-14 16:54:56,060 - ***** Epoch: 92: Eval results *****
2025-04-14 16:54:56,060 -   train_loss = 1.4679123163223267
2025-04-14 16:55:12,345 - ***** Epoch: 93: Eval results *****
2025-04-14 16:55:12,346 -   train_loss = 1.4704045908791679
2025-04-14 16:55:28,783 - ***** Epoch: 94: Eval results *****
2025-04-14 16:55:28,783 -   train_loss = 1.4568239195006234
2025-04-14 16:55:44,662 - ***** Epoch: 95: Eval results *****
2025-04-14 16:55:44,663 -   train_loss = 1.4624989032745361
2025-04-14 16:56:00,570 - ***** Epoch: 96: Eval results *****
2025-04-14 16:56:00,570 -   train_loss = 1.455000707081386
2025-04-14 16:56:15,909 - ***** Epoch: 97: Eval results *****
2025-04-14 16:56:15,910 -   train_loss = 1.4548651831490653
2025-04-14 16:56:31,296 - ***** Epoch: 98: Eval results *****
2025-04-14 16:56:31,297 -   train_loss = 1.4679394108908517
2025-04-14 16:56:46,536 - ***** Epoch: 99: Eval results *****
2025-04-14 16:56:46,537 -   train_loss = 1.4554633583341325
2025-04-14 16:57:02,039 - ***** Epoch: 100: Eval results *****
2025-04-14 16:57:02,039 -   train_loss = 1.4603660702705383
2025-04-14 16:57:03,673 - Pre-training finished...
2025-04-14 16:57:03,933 - Freeze all parameters but the last layer for efficiency
2025-04-14 16:57:03,943 - Multimodal Intent Recognition begins...
2025-04-14 16:57:03,943 - Training begins...
2025-04-14 16:57:19,719 - Initializing centroids with K-means++...
2025-04-14 16:57:19,805 - K-means++ used 0.09 s
2025-04-14 16:57:49,748 - K-means used 0.03 s
2025-04-14 16:57:51,119 - ***** Epoch: 1 *****
2025-04-14 16:57:51,120 - Supervised Training Loss: 5.298980
2025-04-14 16:57:51,120 - Unsupervised Training Loss: 5.086350
2025-04-14 16:58:19,765 - K-means used 0.02 s
2025-04-14 16:58:21,202 - ***** Epoch: 2 *****
2025-04-14 16:58:21,202 - Supervised Training Loss: 4.148500
2025-04-14 16:58:21,202 - Unsupervised Training Loss: 5.102810
2025-04-14 16:58:49,694 - K-means used 0.02 s
2025-04-14 16:58:51,190 - ***** Epoch: 3 *****
2025-04-14 16:58:51,190 - Supervised Training Loss: 5.769540
2025-04-14 16:58:51,191 - Unsupervised Training Loss: 4.941440
2025-04-14 16:59:19,972 - K-means used 0.02 s
2025-04-14 16:59:21,482 - ***** Epoch: 4 *****
2025-04-14 16:59:21,483 - Supervised Training Loss: 5.655710
2025-04-14 16:59:21,483 - Unsupervised Training Loss: 5.011890
2025-04-14 16:59:49,456 - K-means used 0.03 s
2025-04-14 16:59:51,104 - ***** Epoch: 5 *****
2025-04-14 16:59:51,104 - Supervised Training Loss: 5.386160
2025-04-14 16:59:51,104 - Unsupervised Training Loss: 5.053970
2025-04-14 17:00:20,128 - K-means used 0.02 s
2025-04-14 17:00:21,522 - ***** Epoch: 6 *****
2025-04-14 17:00:21,522 - Supervised Training Loss: 5.814920
2025-04-14 17:00:21,522 - Unsupervised Training Loss: 4.838200
2025-04-14 17:00:50,217 - K-means used 0.06 s
2025-04-14 17:00:51,840 - ***** Epoch: 7 *****
2025-04-14 17:00:51,841 - Supervised Training Loss: 5.739120
2025-04-14 17:00:51,841 - Unsupervised Training Loss: 4.985190
2025-04-14 17:01:21,749 - K-means used 0.03 s
2025-04-14 17:01:23,473 - ***** Epoch: 8 *****
2025-04-14 17:01:23,474 - Supervised Training Loss: 5.610790
2025-04-14 17:01:23,474 - Unsupervised Training Loss: 5.031300
2025-04-14 17:01:52,996 - K-means used 0.04 s
2025-04-14 17:01:54,842 - ***** Epoch: 9 *****
2025-04-14 17:01:54,843 - Supervised Training Loss: 5.839220
2025-04-14 17:01:54,843 - Unsupervised Training Loss: 5.055890
2025-04-14 17:02:29,392 - K-means used 0.03 s
2025-04-14 17:02:31,045 - ***** Epoch: 10 *****
2025-04-14 17:02:31,045 - Supervised Training Loss: 5.782310
2025-04-14 17:02:31,045 - Unsupervised Training Loss: 4.889650
2025-04-14 17:03:02,387 - K-means used 0.02 s
2025-04-14 17:03:04,055 - ***** Epoch: 11 *****
2025-04-14 17:03:04,055 - Supervised Training Loss: 5.703120
2025-04-14 17:03:04,055 - Unsupervised Training Loss: 4.959270
2025-04-14 17:03:33,720 - K-means used 0.02 s
2025-04-14 17:03:35,534 - ***** Epoch: 12 *****
2025-04-14 17:03:35,534 - Supervised Training Loss: 5.841800
2025-04-14 17:03:35,534 - Unsupervised Training Loss: 5.018310
2025-04-14 17:04:05,416 - K-means used 0.02 s
2025-04-14 17:04:07,249 - ***** Epoch: 13 *****
2025-04-14 17:04:07,249 - Supervised Training Loss: 5.805710
2025-04-14 17:04:07,250 - Unsupervised Training Loss: 4.738610
2025-04-14 17:04:35,763 - K-means used 0.02 s
2025-04-14 17:04:37,650 - ***** Epoch: 14 *****
2025-04-14 17:04:37,650 - Supervised Training Loss: 5.749570
2025-04-14 17:04:37,651 - Unsupervised Training Loss: 4.897200
2025-04-14 17:05:06,017 - K-means used 0.09 s
2025-04-14 17:05:08,054 - ***** Epoch: 15 *****
2025-04-14 17:05:08,054 - Supervised Training Loss: 5.628050
2025-04-14 17:05:08,054 - Unsupervised Training Loss: 4.959350
2025-04-14 17:05:36,441 - K-means used 0.01 s
2025-04-14 17:05:38,468 - ***** Epoch: 16 *****
2025-04-14 17:05:38,468 - Supervised Training Loss: 5.817880
2025-04-14 17:05:38,469 - Unsupervised Training Loss: 4.424090
2025-04-14 17:06:08,906 - K-means used 0.05 s
2025-04-14 17:06:11,105 - ***** Epoch: 17 *****
2025-04-14 17:06:11,105 - Supervised Training Loss: 5.781960
2025-04-14 17:06:11,105 - Unsupervised Training Loss: 4.626540
2025-04-14 17:06:30,763 - Training is finished...
2025-04-14 17:06:30,764 - Testing begins...
2025-04-14 17:06:37,939 - ***** Test results *****
2025-04-14 17:06:37,939 -   ACC = 37.75
2025-04-14 17:06:37,939 -   ARI = 20.17
2025-04-14 17:06:37,939 -   NMI = 45.91
2025-04-14 17:06:37,939 -   fmi = 25.12
2025-04-14 17:06:37,939 - Testing is finished...
2025-04-14 17:06:37,940 - Multimodal intent recognition is finished...
2025-04-14 17:06:37,940 - Results are saved in results/results_umc.csv
