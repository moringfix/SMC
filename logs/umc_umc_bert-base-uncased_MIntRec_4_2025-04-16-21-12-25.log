2025-04-16 21:12:25,390 - 【无监督】进入了无监督的设定中, 加载数据集
2025-04-16 21:12:25,390 - data preparation...
2025-04-16 21:12:34,602 - Number of train samples = 1779
2025-04-16 21:12:34,602 - Number of testing samples = 445
2025-04-16 21:12:34,602 - data preparation...
2025-04-16 21:12:36,825 - num_train_examples = 1779
2025-04-16 21:12:36,826 - ============================== Params ==============================
2025-04-16 21:12:36,826 - logger_name: umc_umc_bert-base-uncased_MIntRec_4
2025-04-16 21:12:36,826 - dataset: MIntRec
2025-04-16 21:12:36,826 - multimodal_method: umc
2025-04-16 21:12:36,826 - method: umc
2025-04-16 21:12:36,826 - setting: unsupervised
2025-04-16 21:12:36,826 - text_backbone: bert-base-uncased
2025-04-16 21:12:36,826 - seed: 4
2025-04-16 21:12:36,826 - num_workers: 16
2025-04-16 21:12:36,826 - log_id: umc_umc_bert-base-uncased_MIntRec_4_2025-04-16-21-12-25
2025-04-16 21:12:36,826 - gpu_id: 1
2025-04-16 21:12:36,826 - data_path: /root/autodl-tmp/home/Share/Dataset/LZH
2025-04-16 21:12:36,826 - train: True
2025-04-16 21:12:36,826 - tune: True
2025-04-16 21:12:36,826 - save_model: True
2025-04-16 21:12:36,826 - save_results: True
2025-04-16 21:12:36,826 - log_path: logs
2025-04-16 21:12:36,826 - cache_path: cache
2025-04-16 21:12:36,826 - video_data_path: video_data
2025-04-16 21:12:36,826 - audio_data_path: audio_data
2025-04-16 21:12:36,826 - video_feats_path: swin_feats.pkl
2025-04-16 21:12:36,827 - audio_feats_path: wavlm_feats.pkl
2025-04-16 21:12:36,827 - results_path: results
2025-04-16 21:12:36,827 - output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/SMC/outputs_test2/MIntRec
2025-04-16 21:12:36,827 - model_path: models
2025-04-16 21:12:36,827 - config_file_name: umc_MIntRec
2025-04-16 21:12:36,827 - results_file_name: results_umc.csv
2025-04-16 21:12:36,827 - text_pretrained_model: uncased_L-12_H-768_A-12
2025-04-16 21:12:36,827 - pretrained_bert_model: uncased_L-12_H-768_A-12
2025-04-16 21:12:36,827 - pretrain_batch_size: 128
2025-04-16 21:12:36,827 - train_batch_size: 128
2025-04-16 21:12:36,827 - eval_batch_size: 128
2025-04-16 21:12:36,827 - test_batch_size: 128
2025-04-16 21:12:36,827 - num_pretrain_epochs: 100
2025-04-16 21:12:36,827 - num_train_epochs: 100
2025-04-16 21:12:36,827 - pretrain: [True]
2025-04-16 21:12:36,827 - aligned_method: ctc
2025-04-16 21:12:36,827 - need_aligned: False
2025-04-16 21:12:36,828 - freeze_pretrain_bert_parameters: [True]
2025-04-16 21:12:36,828 - freeze_train_bert_parameters: [True]
2025-04-16 21:12:36,828 - pretrain_temperature: [0.1]
2025-04-16 21:12:36,828 - train_temperature_sup: [0.5]
2025-04-16 21:12:36,828 - train_temperature_unsup: [2]
2025-04-16 21:12:36,828 - activation: tanh
2025-04-16 21:12:36,828 - lr_pre: [5e-06]
2025-04-16 21:12:36,828 - lr: [5e-05]
2025-04-16 21:12:36,828 - delta: [0.05]
2025-04-16 21:12:36,828 - thres: [0.1]
2025-04-16 21:12:36,828 - topk: [5]
2025-04-16 21:12:36,828 - weight_decay: 0.01
2025-04-16 21:12:36,828 - feat_dim: 768
2025-04-16 21:12:36,828 - hidden_size: 768
2025-04-16 21:12:36,828 - grad_clip: -1.0
2025-04-16 21:12:36,828 - warmup_proportion: [0.1]
2025-04-16 21:12:36,828 - hidden_dropout_prob: 0.1
2025-04-16 21:12:36,828 - weight: 1.0
2025-04-16 21:12:36,828 - loss_mode: rdrop
2025-04-16 21:12:36,828 - base_dim: 256
2025-04-16 21:12:36,828 - nheads: 8
2025-04-16 21:12:36,828 - attn_dropout: 0.1
2025-04-16 21:12:36,828 - relu_dropout: 0.1
2025-04-16 21:12:36,828 - embed_dropout: 0.01
2025-04-16 21:12:36,828 - res_dropout: 0.0
2025-04-16 21:12:36,828 - attn_mask: True
2025-04-16 21:12:36,828 - encoder_layers_1: 1
2025-04-16 21:12:36,828 - fusion_act: tanh
2025-04-16 21:12:36,829 - pred_output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/SMC/outputs_test2/MIntRec/umc_umc_MIntRec_bert-base-uncased_4
2025-04-16 21:12:36,829 - model_output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/SMC/outputs_test2/MIntRec/umc_umc_MIntRec_bert-base-uncased_4/models
2025-04-16 21:12:36,829 - text_seq_len: 30
2025-04-16 21:12:36,829 - video_seq_len: 230
2025-04-16 21:12:36,829 - audio_seq_len: 480
2025-04-16 21:12:36,829 - text_feat_dim: 768
2025-04-16 21:12:36,829 - video_feat_dim: 1024
2025-04-16 21:12:36,829 - audio_feat_dim: 768
2025-04-16 21:12:36,829 - num_labels: 20
2025-04-16 21:12:36,829 - num_train_examples: 1779
2025-04-16 21:12:36,829 - ============================== End Params ==============================
2025-04-16 21:12:38,064 - Freeze all parameters but the last layer for efficiency
2025-04-16 21:12:38,099 - Pre-training start...
2025-04-16 21:12:58,911 - ***** Epoch: 1: Eval results *****
2025-04-16 21:12:58,912 -   train_loss = 5.970492499215262
2025-04-16 21:13:20,227 - ***** Epoch: 2: Eval results *****
2025-04-16 21:13:20,227 -   train_loss = 5.965209177562168
2025-04-16 21:13:39,934 - ***** Epoch: 3: Eval results *****
2025-04-16 21:13:39,935 -   train_loss = 5.962076119014195
2025-04-16 21:13:59,738 - ***** Epoch: 4: Eval results *****
2025-04-16 21:13:59,738 -   train_loss = 5.95509968485151
2025-04-16 21:14:22,517 - ***** Epoch: 5: Eval results *****
2025-04-16 21:14:22,517 -   train_loss = 5.953247649329049
2025-04-16 21:14:42,761 - ***** Epoch: 6: Eval results *****
2025-04-16 21:14:42,761 -   train_loss = 5.950912271227155
2025-04-16 21:15:05,032 - ***** Epoch: 7: Eval results *****
2025-04-16 21:15:05,032 -   train_loss = 5.937949010304043
2025-04-16 21:15:26,974 - ***** Epoch: 8: Eval results *****
2025-04-16 21:15:26,975 -   train_loss = 5.927582161767142
2025-04-16 21:15:49,446 - ***** Epoch: 9: Eval results *****
2025-04-16 21:15:49,447 -   train_loss = 5.909050975527082
2025-04-16 21:16:11,061 - ***** Epoch: 10: Eval results *****
2025-04-16 21:16:11,061 -   train_loss = 5.884311301367624
2025-04-16 21:16:32,175 - ***** Epoch: 11: Eval results *****
2025-04-16 21:16:32,175 -   train_loss = 5.836780684334891
2025-04-16 21:16:53,567 - ***** Epoch: 12: Eval results *****
2025-04-16 21:16:53,568 -   train_loss = 5.753293888909476
2025-04-16 21:17:15,642 - ***** Epoch: 13: Eval results *****
2025-04-16 21:17:15,643 -   train_loss = 5.608691453933716
2025-04-16 21:17:40,663 - ***** Epoch: 14: Eval results *****
2025-04-16 21:17:40,664 -   train_loss = 5.3897881507873535
2025-04-16 21:18:03,216 - ***** Epoch: 15: Eval results *****
2025-04-16 21:18:03,217 -   train_loss = 5.105509996414185
2025-04-16 21:18:25,701 - ***** Epoch: 16: Eval results *****
2025-04-16 21:18:25,702 -   train_loss = 4.84176778793335
2025-04-16 21:18:46,208 - ***** Epoch: 17: Eval results *****
2025-04-16 21:18:46,208 -   train_loss = 4.603118760245187
2025-04-16 21:19:07,764 - ***** Epoch: 18: Eval results *****
2025-04-16 21:19:07,765 -   train_loss = 4.343575409480503
2025-04-16 21:19:27,120 - ***** Epoch: 19: Eval results *****
2025-04-16 21:19:27,121 -   train_loss = 4.154952372823443
2025-04-16 21:19:48,920 - ***** Epoch: 20: Eval results *****
2025-04-16 21:19:48,920 -   train_loss = 3.9608861207962036
2025-04-16 21:20:09,746 - ***** Epoch: 21: Eval results *****
2025-04-16 21:20:09,746 -   train_loss = 3.797640323638916
2025-04-16 21:20:31,127 - ***** Epoch: 22: Eval results *****
2025-04-16 21:20:31,128 -   train_loss = 3.6376326765332903
2025-04-16 21:20:54,316 - ***** Epoch: 23: Eval results *****
2025-04-16 21:20:54,316 -   train_loss = 3.509148529597691
2025-04-16 21:21:17,370 - ***** Epoch: 24: Eval results *****
2025-04-16 21:21:17,370 -   train_loss = 3.409634692328317
2025-04-16 21:21:37,653 - ***** Epoch: 25: Eval results *****
2025-04-16 21:21:37,653 -   train_loss = 3.2658360174724033
2025-04-16 21:21:59,178 - ***** Epoch: 26: Eval results *****
2025-04-16 21:21:59,179 -   train_loss = 3.197974136897496
2025-04-16 21:22:19,712 - ***** Epoch: 27: Eval results *****
2025-04-16 21:22:19,713 -   train_loss = 3.1294440031051636
2025-04-16 21:22:40,487 - ***** Epoch: 28: Eval results *****
2025-04-16 21:22:40,488 -   train_loss = 3.0489678723471507
2025-04-16 21:23:01,465 - ***** Epoch: 29: Eval results *****
2025-04-16 21:23:01,465 -   train_loss = 2.980319159371512
2025-04-16 21:23:23,364 - ***** Epoch: 30: Eval results *****
2025-04-16 21:23:23,365 -   train_loss = 2.912715366908482
2025-04-16 21:23:45,676 - ***** Epoch: 31: Eval results *****
2025-04-16 21:23:45,677 -   train_loss = 2.8482721022197177
2025-04-16 21:24:06,619 - ***** Epoch: 32: Eval results *****
2025-04-16 21:24:06,619 -   train_loss = 2.794135536466326
2025-04-16 21:24:26,175 - ***** Epoch: 33: Eval results *****
2025-04-16 21:24:26,176 -   train_loss = 2.746960605893816
2025-04-16 21:24:51,147 - ***** Epoch: 34: Eval results *****
2025-04-16 21:24:51,147 -   train_loss = 2.6967215878622874
2025-04-16 21:25:11,782 - ***** Epoch: 35: Eval results *****
2025-04-16 21:25:11,783 -   train_loss = 2.643981831414359
2025-04-16 21:25:32,798 - ***** Epoch: 36: Eval results *****
2025-04-16 21:25:32,798 -   train_loss = 2.5941962684903825
2025-04-16 21:25:54,313 - ***** Epoch: 37: Eval results *****
2025-04-16 21:25:54,314 -   train_loss = 2.5745887756347656
2025-04-16 21:26:17,111 - ***** Epoch: 38: Eval results *****
2025-04-16 21:26:17,111 -   train_loss = 2.5277776888438632
2025-04-16 21:26:39,060 - ***** Epoch: 39: Eval results *****
2025-04-16 21:26:39,060 -   train_loss = 2.4790617568152293
2025-04-16 21:27:00,460 - ***** Epoch: 40: Eval results *****
2025-04-16 21:27:00,460 -   train_loss = 2.468992437635149
2025-04-16 21:27:21,474 - ***** Epoch: 41: Eval results *****
2025-04-16 21:27:21,475 -   train_loss = 2.444402047566005
2025-04-16 21:27:43,198 - ***** Epoch: 42: Eval results *****
2025-04-16 21:27:43,198 -   train_loss = 2.4276827573776245
2025-04-16 21:28:06,553 - ***** Epoch: 43: Eval results *****
2025-04-16 21:28:06,554 -   train_loss = 2.3814880677631924
2025-04-16 21:28:27,719 - ***** Epoch: 44: Eval results *****
2025-04-16 21:28:27,719 -   train_loss = 2.359793390546526
2025-04-16 21:28:49,209 - ***** Epoch: 45: Eval results *****
2025-04-16 21:28:49,209 -   train_loss = 2.350848742893764
2025-04-16 21:29:10,144 - ***** Epoch: 46: Eval results *****
2025-04-16 21:29:10,145 -   train_loss = 2.330718517303467
2025-04-16 21:29:31,711 - ***** Epoch: 47: Eval results *****
2025-04-16 21:29:31,711 -   train_loss = 2.293642282485962
2025-04-16 21:29:51,551 - ***** Epoch: 48: Eval results *****
2025-04-16 21:29:51,552 -   train_loss = 2.2835492406572615
2025-04-16 21:30:14,137 - ***** Epoch: 49: Eval results *****
2025-04-16 21:30:14,137 -   train_loss = 2.251434871128627
2025-04-16 21:30:35,794 - ***** Epoch: 50: Eval results *****
2025-04-16 21:30:35,794 -   train_loss = 2.242251362119402
2025-04-16 21:30:58,175 - ***** Epoch: 51: Eval results *****
2025-04-16 21:30:58,175 -   train_loss = 2.2375426973615373
2025-04-16 21:31:23,143 - ***** Epoch: 52: Eval results *****
2025-04-16 21:31:23,144 -   train_loss = 2.205269660268511
2025-04-16 21:31:45,701 - ***** Epoch: 53: Eval results *****
2025-04-16 21:31:45,701 -   train_loss = 2.1924054622650146
2025-04-16 21:32:06,802 - ***** Epoch: 54: Eval results *****
2025-04-16 21:32:06,802 -   train_loss = 2.1883017676217213
2025-04-16 21:32:27,066 - ***** Epoch: 55: Eval results *****
2025-04-16 21:32:27,066 -   train_loss = 2.1512197085789273
2025-04-16 21:32:48,167 - ***** Epoch: 56: Eval results *****
2025-04-16 21:32:48,168 -   train_loss = 2.161570038114275
2025-04-16 21:33:08,110 - ***** Epoch: 57: Eval results *****
2025-04-16 21:33:08,110 -   train_loss = 2.152472768511091
2025-04-16 21:33:29,127 - ***** Epoch: 58: Eval results *****
2025-04-16 21:33:29,127 -   train_loss = 2.1353069373539517
2025-04-16 21:33:48,470 - ***** Epoch: 59: Eval results *****
2025-04-16 21:33:48,470 -   train_loss = 2.133424690791539
2025-04-16 21:34:09,853 - ***** Epoch: 60: Eval results *****
2025-04-16 21:34:09,854 -   train_loss = 2.1182000126157488
2025-04-16 21:34:31,539 - ***** Epoch: 61: Eval results *****
2025-04-16 21:34:31,540 -   train_loss = 2.09684727873121
2025-04-16 21:34:51,892 - ***** Epoch: 62: Eval results *****
2025-04-16 21:34:51,892 -   train_loss = 2.106715508869716
2025-04-16 21:35:14,318 - ***** Epoch: 63: Eval results *****
2025-04-16 21:35:14,318 -   train_loss = 2.0876896721976146
2025-04-16 21:35:35,880 - ***** Epoch: 64: Eval results *****
2025-04-16 21:35:35,880 -   train_loss = 2.0636363540376936
2025-04-16 21:35:58,579 - ***** Epoch: 65: Eval results *****
2025-04-16 21:35:58,579 -   train_loss = 2.0549474954605103
2025-04-16 21:36:18,410 - ***** Epoch: 66: Eval results *****
2025-04-16 21:36:18,411 -   train_loss = 2.053007347243173
2025-04-16 21:36:40,598 - ***** Epoch: 67: Eval results *****
2025-04-16 21:36:40,598 -   train_loss = 2.0557437794549123
2025-04-16 21:37:02,852 - ***** Epoch: 68: Eval results *****
2025-04-16 21:37:02,852 -   train_loss = 2.033019491604396
2025-04-16 21:37:23,762 - ***** Epoch: 69: Eval results *****
2025-04-16 21:37:23,762 -   train_loss = 2.0131176028932845
2025-04-16 21:37:45,270 - ***** Epoch: 70: Eval results *****
2025-04-16 21:37:45,270 -   train_loss = 2.021917232445308
2025-04-16 21:38:08,915 - ***** Epoch: 71: Eval results *****
2025-04-16 21:38:08,916 -   train_loss = 2.0190981881959096
2025-04-16 21:38:31,326 - ***** Epoch: 72: Eval results *****
2025-04-16 21:38:31,327 -   train_loss = 2.0156400544302806
2025-04-16 21:38:51,304 - ***** Epoch: 73: Eval results *****
2025-04-16 21:38:51,305 -   train_loss = 2.011071562767029
2025-04-16 21:39:12,062 - ***** Epoch: 74: Eval results *****
2025-04-16 21:39:12,062 -   train_loss = 2.0200221793992177
2025-04-16 21:39:33,782 - ***** Epoch: 75: Eval results *****
2025-04-16 21:39:33,782 -   train_loss = 2.0056227275303433
2025-04-16 21:39:56,262 - ***** Epoch: 76: Eval results *****
2025-04-16 21:39:56,262 -   train_loss = 2.0049539378711154
2025-04-16 21:40:17,427 - ***** Epoch: 77: Eval results *****
2025-04-16 21:40:17,427 -   train_loss = 2.0045540843691145
2025-04-16 21:40:38,386 - ***** Epoch: 78: Eval results *****
2025-04-16 21:40:38,387 -   train_loss = 1.994531239782061
2025-04-16 21:41:00,283 - ***** Epoch: 79: Eval results *****
2025-04-16 21:41:00,283 -   train_loss = 1.9899477703230721
2025-04-16 21:41:23,581 - ***** Epoch: 80: Eval results *****
2025-04-16 21:41:23,581 -   train_loss = 1.9850624118532454
2025-04-16 21:41:47,865 - ***** Epoch: 81: Eval results *****
2025-04-16 21:41:47,865 -   train_loss = 1.9783231105123247
2025-04-16 21:42:09,008 - ***** Epoch: 82: Eval results *****
2025-04-16 21:42:09,008 -   train_loss = 1.9775481564658028
2025-04-16 21:42:30,439 - ***** Epoch: 83: Eval results *****
2025-04-16 21:42:30,440 -   train_loss = 1.9824637174606323
2025-04-16 21:42:51,410 - ***** Epoch: 84: Eval results *****
2025-04-16 21:42:51,411 -   train_loss = 1.9669067093304224
2025-04-16 21:43:13,453 - ***** Epoch: 85: Eval results *****
2025-04-16 21:43:13,453 -   train_loss = 1.9751635364123754
2025-04-16 21:43:34,598 - ***** Epoch: 86: Eval results *****
2025-04-16 21:43:34,599 -   train_loss = 1.9617008822304862
2025-04-16 21:43:56,030 - ***** Epoch: 87: Eval results *****
2025-04-16 21:43:56,030 -   train_loss = 1.959186111177717
2025-04-16 21:44:17,876 - ***** Epoch: 88: Eval results *****
2025-04-16 21:44:17,876 -   train_loss = 1.9695776786123003
2025-04-16 21:44:38,399 - ***** Epoch: 89: Eval results *****
2025-04-16 21:44:38,399 -   train_loss = 1.9695226550102234
2025-04-16 21:45:03,384 - ***** Epoch: 90: Eval results *****
2025-04-16 21:45:03,384 -   train_loss = 1.9597067066601344
2025-04-16 21:45:25,361 - ***** Epoch: 91: Eval results *****
2025-04-16 21:45:25,362 -   train_loss = 1.9474780218941825
2025-04-16 21:45:46,054 - ***** Epoch: 92: Eval results *****
2025-04-16 21:45:46,054 -   train_loss = 1.9599587661879403
2025-04-16 21:46:05,307 - ***** Epoch: 93: Eval results *****
2025-04-16 21:46:05,308 -   train_loss = 1.9551181282315935
2025-04-16 21:46:27,259 - ***** Epoch: 94: Eval results *****
2025-04-16 21:46:27,260 -   train_loss = 1.9616342782974243
2025-04-16 21:46:48,213 - ***** Epoch: 95: Eval results *****
2025-04-16 21:46:48,213 -   train_loss = 1.9603155936513628
2025-04-16 21:47:08,597 - ***** Epoch: 96: Eval results *****
2025-04-16 21:47:08,597 -   train_loss = 1.9519513079098292
2025-04-16 21:47:28,650 - ***** Epoch: 97: Eval results *****
2025-04-16 21:47:28,650 -   train_loss = 1.9718050701277596
2025-04-16 21:47:49,249 - ***** Epoch: 98: Eval results *****
2025-04-16 21:47:49,249 -   train_loss = 1.9518023559025355
2025-04-16 21:48:14,673 - ***** Epoch: 99: Eval results *****
2025-04-16 21:48:14,673 -   train_loss = 1.9629438093730383
2025-04-16 21:48:35,584 - ***** Epoch: 100: Eval results *****
2025-04-16 21:48:35,584 -   train_loss = 1.9601359707968575
2025-04-16 21:48:36,250 - Pre-training finished...
2025-04-16 21:48:36,662 - Freeze all parameters but the last layer for efficiency
2025-04-16 21:48:36,672 - Multimodal Intent Recognition begins...
2025-04-16 21:48:36,672 - Training begins...
2025-04-16 21:48:54,088 - Initializing centroids with K-means++...
2025-04-16 21:48:54,206 - K-means++ used 0.12 s
2025-04-16 21:49:30,203 - K-means used 0.03 s
2025-04-16 21:49:31,538 - ***** Epoch: 1 *****
2025-04-16 21:49:31,538 - Supervised Training Loss: 4.401880
2025-04-16 21:49:31,539 - Unsupervised Training Loss: 5.571050
2025-04-16 21:50:06,706 - K-means used 0.03 s
2025-04-16 21:50:07,879 - ***** Epoch: 2 *****
2025-04-16 21:50:07,880 - Supervised Training Loss: 4.959040
2025-04-16 21:50:07,880 - Unsupervised Training Loss: 5.589070
2025-04-16 21:50:41,744 - K-means used 0.02 s
2025-04-16 21:50:43,210 - ***** Epoch: 3 *****
2025-04-16 21:50:43,210 - Supervised Training Loss: 4.789480
2025-04-16 21:50:43,210 - Unsupervised Training Loss: 5.435230
2025-04-16 21:51:19,409 - K-means used 0.07 s
2025-04-16 21:51:21,330 - ***** Epoch: 4 *****
2025-04-16 21:51:21,330 - Supervised Training Loss: 4.575480
2025-04-16 21:51:21,330 - Unsupervised Training Loss: 5.502730
2025-04-16 21:51:56,201 - K-means used 0.02 s
2025-04-16 21:51:57,634 - ***** Epoch: 5 *****
2025-04-16 21:51:57,634 - Supervised Training Loss: 4.261570
2025-04-16 21:51:57,634 - Unsupervised Training Loss: 5.540010
2025-04-16 21:52:31,519 - K-means used 0.02 s
2025-04-16 21:52:34,008 - ***** Epoch: 6 *****
2025-04-16 21:52:34,009 - Supervised Training Loss: 4.690760
2025-04-16 21:52:34,009 - Unsupervised Training Loss: 5.324410
2025-04-16 21:53:07,438 - K-means used 0.03 s
2025-04-16 21:53:09,169 - ***** Epoch: 7 *****
2025-04-16 21:53:09,169 - Supervised Training Loss: 4.592720
2025-04-16 21:53:09,169 - Unsupervised Training Loss: 5.446080
2025-04-16 21:53:44,443 - K-means used 0.02 s
2025-04-16 21:53:46,271 - ***** Epoch: 8 *****
2025-04-16 21:53:46,271 - Supervised Training Loss: 4.442400
2025-04-16 21:53:46,271 - Unsupervised Training Loss: 5.512180
2025-04-16 21:54:19,665 - K-means used 0.02 s
2025-04-16 21:54:21,357 - ***** Epoch: 9 *****
2025-04-16 21:54:21,358 - Supervised Training Loss: 4.677280
2025-04-16 21:54:21,358 - Unsupervised Training Loss: 5.546400
2025-04-16 21:54:58,041 - K-means used 0.02 s
2025-04-16 21:54:59,859 - ***** Epoch: 10 *****
2025-04-16 21:54:59,860 - Supervised Training Loss: 4.607080
2025-04-16 21:54:59,860 - Unsupervised Training Loss: 5.392730
2025-04-16 21:55:35,896 - K-means used 0.04 s
2025-04-16 21:55:37,756 - ***** Epoch: 11 *****
2025-04-16 21:55:37,756 - Supervised Training Loss: 4.528560
2025-04-16 21:55:37,756 - Unsupervised Training Loss: 5.468610
2025-04-16 21:56:10,448 - K-means used 0.02 s
2025-04-16 21:56:12,326 - ***** Epoch: 12 *****
2025-04-16 21:56:12,327 - Supervised Training Loss: 4.682520
2025-04-16 21:56:12,327 - Unsupervised Training Loss: 5.528730
2025-04-16 21:56:46,118 - K-means used 0.02 s
2025-04-16 21:56:48,457 - ***** Epoch: 13 *****
2025-04-16 21:56:48,458 - Supervised Training Loss: 4.644630
2025-04-16 21:56:48,458 - Unsupervised Training Loss: 5.247600
2025-04-16 21:57:23,564 - K-means used 0.03 s
2025-04-16 21:57:25,596 - ***** Epoch: 14 *****
2025-04-16 21:57:25,596 - Supervised Training Loss: 4.592530
2025-04-16 21:57:25,597 - Unsupervised Training Loss: 5.397990
2025-04-16 21:58:02,614 - K-means used 0.02 s
2025-04-16 21:58:04,739 - ***** Epoch: 15 *****
2025-04-16 21:58:04,740 - Supervised Training Loss: 4.472090
2025-04-16 21:58:04,740 - Unsupervised Training Loss: 5.495280
2025-04-16 21:58:40,804 - K-means used 0.02 s
2025-04-16 21:58:43,773 - ***** Epoch: 16 *****
2025-04-16 21:58:43,774 - Supervised Training Loss: 4.693040
2025-04-16 21:58:43,774 - Unsupervised Training Loss: 4.933220
2025-04-16 21:59:19,401 - K-means used 0.04 s
2025-04-16 21:59:22,200 - ***** Epoch: 17 *****
2025-04-16 21:59:22,200 - Supervised Training Loss: 4.676970
2025-04-16 21:59:22,200 - Unsupervised Training Loss: 5.162690
2025-04-16 21:59:44,970 - Training is finished...
2025-04-16 21:59:44,971 - Testing begins...
2025-04-16 21:59:52,802 - ***** Test results *****
2025-04-16 21:59:52,802 -   ACC = 35.06
2025-04-16 21:59:52,802 -   ARI = 16.28
2025-04-16 21:59:52,802 -   NMI = 43.38
2025-04-16 21:59:52,802 -   fmi = 21.52
2025-04-16 21:59:52,802 - Testing is finished...
2025-04-16 21:59:52,802 - Multimodal intent recognition is finished...
2025-04-16 21:59:52,802 - Results are saved in results/results_umc.csv
