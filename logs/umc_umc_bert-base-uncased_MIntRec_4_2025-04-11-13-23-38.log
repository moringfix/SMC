2025-04-11 13:23:38,590 - ============================== Params ==============================
2025-04-11 13:23:38,590 - logger_name: umc_umc_bert-base-uncased_MIntRec_4
2025-04-11 13:23:38,590 - dataset: MIntRec
2025-04-11 13:23:38,590 - multimodal_method: umc
2025-04-11 13:23:38,591 - method: umc
2025-04-11 13:23:38,591 - text_backbone: bert-base-uncased
2025-04-11 13:23:38,591 - seed: 4
2025-04-11 13:23:38,591 - num_workers: 16
2025-04-11 13:23:38,591 - log_id: umc_umc_bert-base-uncased_MIntRec_4_2025-04-11-13-23-38
2025-04-11 13:23:38,591 - gpu_id: 0
2025-04-11 13:23:38,591 - data_path: /root/autodl-tmp/home/Share/Dataset/LZH
2025-04-11 13:23:38,591 - train: True
2025-04-11 13:23:38,591 - tune: True
2025-04-11 13:23:38,591 - save_model: True
2025-04-11 13:23:38,591 - save_results: True
2025-04-11 13:23:38,591 - log_path: logs
2025-04-11 13:23:38,591 - cache_path: cache
2025-04-11 13:23:38,591 - video_data_path: video_data
2025-04-11 13:23:38,591 - audio_data_path: audio_data
2025-04-11 13:23:38,591 - video_feats_path: swin_feats.pkl
2025-04-11 13:23:38,591 - audio_feats_path: wavlm_feats.pkl
2025-04-11 13:23:38,591 - results_path: results
2025-04-11 13:23:38,592 - output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/UMC/outputs/MIntRec
2025-04-11 13:23:38,592 - model_path: models
2025-04-11 13:23:38,592 - config_file_name: umc_MIntRec
2025-04-11 13:23:38,592 - results_file_name: results_umc.csv
2025-04-11 13:23:38,592 - text_pretrained_model: uncased_L-12_H-768_A-12
2025-04-11 13:23:38,592 - text_seq_len: 30
2025-04-11 13:23:38,592 - video_seq_len: 230
2025-04-11 13:23:38,592 - audio_seq_len: 480
2025-04-11 13:23:38,592 - text_feat_dim: 768
2025-04-11 13:23:38,592 - video_feat_dim: 1024
2025-04-11 13:23:38,592 - audio_feat_dim: 768
2025-04-11 13:23:38,592 - num_labels: 20
2025-04-11 13:23:38,592 - num_train_examples: 1779
2025-04-11 13:23:38,592 - pretrained_bert_model: uncased_L-12_H-768_A-12
2025-04-11 13:23:38,592 - pretrain_batch_size: 128
2025-04-11 13:23:38,592 - train_batch_size: 128
2025-04-11 13:23:38,592 - eval_batch_size: 128
2025-04-11 13:23:38,592 - test_batch_size: 128
2025-04-11 13:23:38,592 - num_pretrain_epochs: 100
2025-04-11 13:23:38,592 - num_train_epochs: 100
2025-04-11 13:23:38,592 - pretrain: [True]
2025-04-11 13:23:38,592 - aligned_method: ctc
2025-04-11 13:23:38,592 - need_aligned: False
2025-04-11 13:23:38,592 - freeze_pretrain_bert_parameters: [True]
2025-04-11 13:23:38,592 - freeze_train_bert_parameters: [True]
2025-04-11 13:23:38,592 - pretrain_temperature: [0.2]
2025-04-11 13:23:38,592 - train_temperature_sup: [1.4]
2025-04-11 13:23:38,592 - train_temperature_unsup: [1]
2025-04-11 13:23:38,592 - activation: tanh
2025-04-11 13:23:38,593 - lr_pre: 1e-05
2025-04-11 13:23:38,593 - lr: [0.0003]
2025-04-11 13:23:38,593 - delta: [0.05]
2025-04-11 13:23:38,593 - thres: [0.1]
2025-04-11 13:23:38,593 - topk: [5]
2025-04-11 13:23:38,593 - weight_decay: 0.01
2025-04-11 13:23:38,593 - feat_dim: 768
2025-04-11 13:23:38,593 - hidden_size: 768
2025-04-11 13:23:38,593 - grad_clip: -1.0
2025-04-11 13:23:38,593 - warmup_proportion: 0.5
2025-04-11 13:23:38,593 - hidden_dropout_prob: 0.1
2025-04-11 13:23:38,593 - weight: 1.0
2025-04-11 13:23:38,593 - loss_mode: rdrop
2025-04-11 13:23:38,593 - base_dim: 256
2025-04-11 13:23:38,593 - nheads: 8
2025-04-11 13:23:38,593 - attn_dropout: 0.1
2025-04-11 13:23:38,593 - relu_dropout: 0.1
2025-04-11 13:23:38,593 - embed_dropout: 0.1
2025-04-11 13:23:38,593 - res_dropout: 0.0
2025-04-11 13:23:38,593 - attn_mask: True
2025-04-11 13:23:38,593 - encoder_layers_1: 1
2025-04-11 13:23:38,593 - fusion_act: tanh
2025-04-11 13:23:38,593 - pred_output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/UMC/outputs/MIntRec/umc_umc_MIntRec_bert-base-uncased_4
2025-04-11 13:23:38,593 - model_output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/UMC/outputs/MIntRec/umc_umc_MIntRec_bert-base-uncased_4/models
2025-04-11 13:23:38,593 - ============================== End Params ==============================
2025-04-11 13:23:39,693 - Freeze all parameters but the last layer for efficiency
2025-04-11 13:23:39,728 - Pre-training start...
2025-04-11 13:23:54,646 - ***** Epoch: 1: Eval results *****
2025-04-11 13:23:54,646 -   train_loss = 5.944462129047939
2025-04-11 13:24:08,656 - ***** Epoch: 2: Eval results *****
2025-04-11 13:24:08,656 -   train_loss = 5.946808746882847
2025-04-11 13:24:23,874 - ***** Epoch: 3: Eval results *****
2025-04-11 13:24:23,874 -   train_loss = 5.945162330354963
2025-04-11 13:24:39,730 - ***** Epoch: 4: Eval results *****
2025-04-11 13:24:39,731 -   train_loss = 5.942648104258946
2025-04-11 13:24:56,208 - ***** Epoch: 5: Eval results *****
2025-04-11 13:24:56,209 -   train_loss = 5.942367655890329
2025-04-11 13:25:12,255 - ***** Epoch: 6: Eval results *****
2025-04-11 13:25:12,256 -   train_loss = 5.944362163543701
2025-04-11 13:25:27,888 - ***** Epoch: 7: Eval results *****
2025-04-11 13:25:27,889 -   train_loss = 5.940333162035261
2025-04-11 13:25:43,486 - ***** Epoch: 8: Eval results *****
2025-04-11 13:25:43,486 -   train_loss = 5.942641292299543
2025-04-11 13:25:58,464 - ***** Epoch: 9: Eval results *****
2025-04-11 13:25:58,464 -   train_loss = 5.93805057661874
2025-04-11 13:26:14,649 - ***** Epoch: 10: Eval results *****
2025-04-11 13:26:14,649 -   train_loss = 5.936690160206386
2025-04-11 13:26:31,193 - ***** Epoch: 11: Eval results *****
2025-04-11 13:26:31,193 -   train_loss = 5.933799982070923
2025-04-11 13:26:46,756 - ***** Epoch: 12: Eval results *****
2025-04-11 13:26:46,756 -   train_loss = 5.931793349129813
2025-04-11 13:27:02,843 - ***** Epoch: 13: Eval results *****
2025-04-11 13:27:02,844 -   train_loss = 5.930988345827375
2025-04-11 13:27:22,243 - ***** Epoch: 14: Eval results *****
2025-04-11 13:27:22,243 -   train_loss = 5.9267240933009555
2025-04-11 13:27:40,039 - ***** Epoch: 15: Eval results *****
2025-04-11 13:27:40,039 -   train_loss = 5.9140782696860175
2025-04-11 13:27:58,524 - ***** Epoch: 16: Eval results *****
2025-04-11 13:27:58,525 -   train_loss = 5.911146913255964
2025-04-11 13:28:17,286 - ***** Epoch: 17: Eval results *****
2025-04-11 13:28:17,286 -   train_loss = 5.896145616258893
2025-04-11 13:28:35,846 - ***** Epoch: 18: Eval results *****
2025-04-11 13:28:35,846 -   train_loss = 5.872024604252407
2025-04-11 13:28:54,356 - ***** Epoch: 19: Eval results *****
2025-04-11 13:28:54,356 -   train_loss = 5.844306298664638
2025-04-11 13:29:12,324 - ***** Epoch: 20: Eval results *****
2025-04-11 13:29:12,324 -   train_loss = 5.794231312615531
2025-04-11 13:29:29,882 - ***** Epoch: 21: Eval results *****
2025-04-11 13:29:29,883 -   train_loss = 5.709695407322475
2025-04-11 13:29:46,879 - ***** Epoch: 22: Eval results *****
2025-04-11 13:29:46,879 -   train_loss = 5.5906936781747
2025-04-11 13:30:03,798 - ***** Epoch: 23: Eval results *****
2025-04-11 13:30:03,798 -   train_loss = 5.432221003941128
2025-04-11 13:30:21,035 - ***** Epoch: 24: Eval results *****
2025-04-11 13:30:21,036 -   train_loss = 5.263125215257917
2025-04-11 13:30:37,930 - ***** Epoch: 25: Eval results *****
2025-04-11 13:30:37,930 -   train_loss = 5.0651160308292935
2025-04-11 13:30:55,204 - ***** Epoch: 26: Eval results *****
2025-04-11 13:30:55,204 -   train_loss = 4.887816054480417
2025-04-11 13:31:11,786 - ***** Epoch: 27: Eval results *****
2025-04-11 13:31:11,786 -   train_loss = 4.714941603796823
2025-04-11 13:31:28,648 - ***** Epoch: 28: Eval results *****
2025-04-11 13:31:28,649 -   train_loss = 4.5473485333578925
2025-04-11 13:31:44,998 - ***** Epoch: 29: Eval results *****
2025-04-11 13:31:44,998 -   train_loss = 4.389583076749529
2025-04-11 13:32:01,053 - ***** Epoch: 30: Eval results *****
2025-04-11 13:32:01,053 -   train_loss = 4.256070409502302
2025-04-11 13:32:17,429 - ***** Epoch: 31: Eval results *****
2025-04-11 13:32:17,429 -   train_loss = 4.156435353415353
2025-04-11 13:32:33,454 - ***** Epoch: 32: Eval results *****
2025-04-11 13:32:33,454 -   train_loss = 4.060999086924961
2025-04-11 13:32:49,216 - ***** Epoch: 33: Eval results *****
2025-04-11 13:32:49,217 -   train_loss = 3.9825601066861833
2025-04-11 13:33:05,321 - ***** Epoch: 34: Eval results *****
2025-04-11 13:33:05,322 -   train_loss = 3.8926306452069963
2025-04-11 13:33:22,726 - ***** Epoch: 35: Eval results *****
2025-04-11 13:33:22,726 -   train_loss = 3.8200635399137224
2025-04-11 13:33:39,898 - ***** Epoch: 36: Eval results *****
2025-04-11 13:33:39,899 -   train_loss = 3.7382150377546037
2025-04-11 13:33:57,438 - ***** Epoch: 37: Eval results *****
2025-04-11 13:33:57,438 -   train_loss = 3.689525212560381
2025-04-11 13:34:14,856 - ***** Epoch: 38: Eval results *****
2025-04-11 13:34:14,856 -   train_loss = 3.6290066923413957
2025-04-11 13:34:32,224 - ***** Epoch: 39: Eval results *****
2025-04-11 13:34:32,224 -   train_loss = 3.552366988999503
2025-04-11 13:34:48,735 - ***** Epoch: 40: Eval results *****
2025-04-11 13:34:48,735 -   train_loss = 3.5125188316617693
2025-04-11 13:35:04,757 - ***** Epoch: 41: Eval results *****
2025-04-11 13:35:04,757 -   train_loss = 3.463498217718942
2025-04-11 13:35:21,193 - ***** Epoch: 42: Eval results *****
2025-04-11 13:35:21,193 -   train_loss = 3.4266694613865445
2025-04-11 13:35:37,774 - ***** Epoch: 43: Eval results *****
2025-04-11 13:35:37,774 -   train_loss = 3.376215968813215
2025-04-11 13:35:54,345 - ***** Epoch: 44: Eval results *****
2025-04-11 13:35:54,346 -   train_loss = 3.339448264666966
2025-04-11 13:36:11,205 - ***** Epoch: 45: Eval results *****
2025-04-11 13:36:11,205 -   train_loss = 3.311823674610683
2025-04-11 13:36:27,019 - ***** Epoch: 46: Eval results *****
2025-04-11 13:36:27,020 -   train_loss = 3.2916576862335205
2025-04-11 13:36:42,839 - ***** Epoch: 47: Eval results *****
2025-04-11 13:36:42,839 -   train_loss = 3.2555165461131503
2025-04-11 13:36:58,890 - ***** Epoch: 48: Eval results *****
2025-04-11 13:36:58,890 -   train_loss = 3.2387914657592773
2025-04-11 13:37:14,402 - ***** Epoch: 49: Eval results *****
2025-04-11 13:37:14,403 -   train_loss = 3.206095916884286
2025-04-11 13:37:30,278 - ***** Epoch: 50: Eval results *****
2025-04-11 13:37:30,278 -   train_loss = 3.1804226636886597
2025-04-11 13:37:47,313 - ***** Epoch: 51: Eval results *****
2025-04-11 13:37:47,313 -   train_loss = 3.1600988592420305
2025-04-11 13:38:03,742 - ***** Epoch: 52: Eval results *****
2025-04-11 13:38:03,742 -   train_loss = 3.139701179095677
2025-04-11 13:38:19,720 - ***** Epoch: 53: Eval results *****
2025-04-11 13:38:19,720 -   train_loss = 3.112144112586975
2025-04-11 13:38:35,654 - ***** Epoch: 54: Eval results *****
2025-04-11 13:38:35,654 -   train_loss = 3.0970653976712907
2025-04-11 13:38:51,529 - ***** Epoch: 55: Eval results *****
2025-04-11 13:38:51,530 -   train_loss = 3.066202299935477
2025-04-11 13:39:07,032 - ***** Epoch: 56: Eval results *****
2025-04-11 13:39:07,033 -   train_loss = 3.065292409488133
2025-04-11 13:39:22,463 - ***** Epoch: 57: Eval results *****
2025-04-11 13:39:22,463 -   train_loss = 3.049652303968157
2025-04-11 13:39:38,333 - ***** Epoch: 58: Eval results *****
2025-04-11 13:39:38,333 -   train_loss = 3.034049851553781
2025-04-11 13:39:53,701 - ***** Epoch: 59: Eval results *****
2025-04-11 13:39:53,702 -   train_loss = 3.0255151305879866
2025-04-11 13:40:08,220 - ***** Epoch: 60: Eval results *****
2025-04-11 13:40:08,221 -   train_loss = 3.0139836413519725
2025-04-11 13:40:23,716 - ***** Epoch: 61: Eval results *****
2025-04-11 13:40:23,717 -   train_loss = 2.994198305266244
2025-04-11 13:40:38,423 - ***** Epoch: 62: Eval results *****
2025-04-11 13:40:38,423 -   train_loss = 2.9967447008405412
2025-04-11 13:40:53,761 - ***** Epoch: 63: Eval results *****
2025-04-11 13:40:53,762 -   train_loss = 2.9804854903902327
2025-04-11 13:41:09,162 - ***** Epoch: 64: Eval results *****
2025-04-11 13:41:09,163 -   train_loss = 2.9667180606297086
2025-04-11 13:41:24,335 - ***** Epoch: 65: Eval results *****
2025-04-11 13:41:24,335 -   train_loss = 2.960431218147278
2025-04-11 13:41:39,960 - ***** Epoch: 66: Eval results *****
2025-04-11 13:41:39,960 -   train_loss = 2.952286260468619
2025-04-11 13:41:54,577 - ***** Epoch: 67: Eval results *****
2025-04-11 13:41:54,578 -   train_loss = 2.953443033354623
2025-04-11 13:42:09,912 - ***** Epoch: 68: Eval results *****
2025-04-11 13:42:09,912 -   train_loss = 2.934723666736058
2025-04-11 13:42:24,394 - ***** Epoch: 69: Eval results *****
2025-04-11 13:42:24,394 -   train_loss = 2.921208620071411
2025-04-11 13:42:39,353 - ***** Epoch: 70: Eval results *****
2025-04-11 13:42:39,354 -   train_loss = 2.9228300877979825
2025-04-11 13:42:54,826 - ***** Epoch: 71: Eval results *****
2025-04-11 13:42:54,826 -   train_loss = 2.922303489276341
2025-04-11 13:43:10,089 - ***** Epoch: 72: Eval results *****
2025-04-11 13:43:10,089 -   train_loss = 2.9218647480010986
2025-04-11 13:43:25,898 - ***** Epoch: 73: Eval results *****
2025-04-11 13:43:25,898 -   train_loss = 2.919681429862976
2025-04-11 13:43:41,612 - ***** Epoch: 74: Eval results *****
2025-04-11 13:43:41,612 -   train_loss = 2.92161226272583
2025-04-11 13:43:57,542 - ***** Epoch: 75: Eval results *****
2025-04-11 13:43:57,542 -   train_loss = 2.9100864103862216
2025-04-11 13:44:13,601 - ***** Epoch: 76: Eval results *****
2025-04-11 13:44:13,601 -   train_loss = 2.9107356582369124
2025-04-11 13:44:29,196 - ***** Epoch: 77: Eval results *****
2025-04-11 13:44:29,196 -   train_loss = 2.909331747463771
2025-04-11 13:44:44,205 - ***** Epoch: 78: Eval results *****
2025-04-11 13:44:44,205 -   train_loss = 2.9070763758250644
2025-04-11 13:44:59,519 - ***** Epoch: 79: Eval results *****
2025-04-11 13:44:59,520 -   train_loss = 2.901034780911037
2025-04-11 13:45:15,377 - ***** Epoch: 80: Eval results *****
2025-04-11 13:45:15,378 -   train_loss = 2.8983151401792253
2025-04-11 13:45:31,500 - ***** Epoch: 81: Eval results *****
2025-04-11 13:45:31,500 -   train_loss = 2.8940113953181674
2025-04-11 13:45:47,628 - ***** Epoch: 82: Eval results *****
2025-04-11 13:45:47,629 -   train_loss = 2.8950691393443515
2025-04-11 13:46:04,044 - ***** Epoch: 83: Eval results *****
2025-04-11 13:46:04,045 -   train_loss = 2.890187178339277
2025-04-11 13:46:20,748 - ***** Epoch: 84: Eval results *****
2025-04-11 13:46:20,748 -   train_loss = 2.884812389101301
2025-04-11 13:46:37,513 - ***** Epoch: 85: Eval results *****
2025-04-11 13:46:37,513 -   train_loss = 2.8847546918051585
2025-04-11 13:46:54,738 - ***** Epoch: 86: Eval results *****
2025-04-11 13:46:54,738 -   train_loss = 2.8813613482884
2025-04-11 13:47:11,734 - ***** Epoch: 87: Eval results *****
2025-04-11 13:47:11,734 -   train_loss = 2.8779849665505544
2025-04-11 13:47:28,593 - ***** Epoch: 88: Eval results *****
2025-04-11 13:47:28,594 -   train_loss = 2.8739513839994157
2025-04-11 13:47:45,748 - ***** Epoch: 89: Eval results *****
2025-04-11 13:47:45,748 -   train_loss = 2.8778929029192244
2025-04-11 13:48:02,590 - ***** Epoch: 90: Eval results *****
2025-04-11 13:48:02,590 -   train_loss = 2.87301618712289
2025-04-11 13:48:18,979 - ***** Epoch: 91: Eval results *****
2025-04-11 13:48:18,979 -   train_loss = 2.869024702480861
2025-04-11 13:48:35,998 - ***** Epoch: 92: Eval results *****
2025-04-11 13:48:35,998 -   train_loss = 2.8762381758008684
2025-04-11 13:48:52,806 - ***** Epoch: 93: Eval results *****
2025-04-11 13:48:52,806 -   train_loss = 2.8721337488719394
2025-04-11 13:49:09,542 - ***** Epoch: 94: Eval results *****
2025-04-11 13:49:09,543 -   train_loss = 2.8741519451141357
2025-04-11 13:49:25,749 - ***** Epoch: 95: Eval results *****
2025-04-11 13:49:25,750 -   train_loss = 2.8753393036978587
2025-04-11 13:49:41,388 - ***** Epoch: 96: Eval results *****
2025-04-11 13:49:41,388 -   train_loss = 2.8699887820652554
2025-04-11 13:49:56,972 - ***** Epoch: 97: Eval results *****
2025-04-11 13:49:56,972 -   train_loss = 2.8751193625586375
2025-04-11 13:50:13,141 - ***** Epoch: 98: Eval results *****
2025-04-11 13:50:13,141 -   train_loss = 2.871646523475647
2025-04-11 13:50:29,317 - ***** Epoch: 99: Eval results *****
2025-04-11 13:50:29,317 -   train_loss = 2.8788931369781494
2025-04-11 13:50:45,808 - ***** Epoch: 100: Eval results *****
2025-04-11 13:50:45,808 -   train_loss = 2.8800152369907925
2025-04-11 13:50:47,513 - Pre-training finished...
2025-04-11 13:50:47,789 - Freeze all parameters but the last layer for efficiency
2025-04-11 13:50:47,798 - Multimodal Intent Recognition begins...
2025-04-11 13:50:47,799 - Training begins...
2025-04-11 13:51:02,944 - Initializing centroids with K-means++...
2025-04-11 13:51:03,108 - K-means++ used 0.16 s
2025-04-11 13:51:36,400 - K-means used 0.05 s
2025-04-11 13:51:37,798 - ***** Epoch: 1 *****
2025-04-11 13:51:37,799 - Supervised Training Loss: 4.901240
2025-04-11 13:51:37,800 - Unsupervised Training Loss: 5.122910
2025-04-11 13:52:08,538 - K-means used 0.02 s
2025-04-11 13:52:09,984 - ***** Epoch: 2 *****
2025-04-11 13:52:09,985 - Supervised Training Loss: 4.206000
2025-04-11 13:52:09,985 - Unsupervised Training Loss: 5.149880
2025-04-11 13:52:40,312 - K-means used 0.02 s
2025-04-11 13:52:41,715 - ***** Epoch: 3 *****
2025-04-11 13:52:41,715 - Supervised Training Loss: 5.355940
2025-04-11 13:52:41,715 - Unsupervised Training Loss: 5.013510
2025-04-11 13:53:13,538 - K-means used 0.02 s
2025-04-11 13:53:14,976 - ***** Epoch: 4 *****
2025-04-11 13:53:14,976 - Supervised Training Loss: 5.236230
2025-04-11 13:53:14,976 - Unsupervised Training Loss: 5.082760
2025-04-11 13:53:47,019 - K-means used 0.07 s
2025-04-11 13:53:48,425 - ***** Epoch: 5 *****
2025-04-11 13:53:48,425 - Supervised Training Loss: 4.970440
2025-04-11 13:53:48,425 - Unsupervised Training Loss: 5.111290
2025-04-11 13:54:18,521 - K-means used 0.02 s
2025-04-11 13:54:19,850 - ***** Epoch: 6 *****
2025-04-11 13:54:19,850 - Supervised Training Loss: 5.346210
2025-04-11 13:54:19,850 - Unsupervised Training Loss: 4.913030
2025-04-11 13:54:49,599 - K-means used 0.05 s
2025-04-11 13:54:51,115 - ***** Epoch: 7 *****
2025-04-11 13:54:51,115 - Supervised Training Loss: 5.268860
2025-04-11 13:54:51,115 - Unsupervised Training Loss: 5.016170
2025-04-11 13:55:23,404 - K-means used 0.02 s
2025-04-11 13:55:25,072 - ***** Epoch: 8 *****
2025-04-11 13:55:25,072 - Supervised Training Loss: 5.115390
2025-04-11 13:55:25,072 - Unsupervised Training Loss: 5.076600
2025-04-11 13:55:56,623 - K-means used 0.07 s
2025-04-11 13:55:58,221 - ***** Epoch: 9 *****
2025-04-11 13:55:58,221 - Supervised Training Loss: 5.341800
2025-04-11 13:55:58,222 - Unsupervised Training Loss: 5.115610
2025-04-11 13:56:28,548 - K-means used 0.02 s
2025-04-11 13:56:30,251 - ***** Epoch: 10 *****
2025-04-11 13:56:30,251 - Supervised Training Loss: 5.274750
2025-04-11 13:56:30,251 - Unsupervised Training Loss: 4.946800
2025-04-11 13:57:00,861 - K-means used 0.02 s
2025-04-11 13:57:02,630 - ***** Epoch: 11 *****
2025-04-11 13:57:02,630 - Supervised Training Loss: 5.199750
2025-04-11 13:57:02,630 - Unsupervised Training Loss: 5.017910
2025-04-11 13:57:34,151 - K-means used 0.02 s
2025-04-11 13:57:35,891 - ***** Epoch: 12 *****
2025-04-11 13:57:35,891 - Supervised Training Loss: 5.322910
2025-04-11 13:57:35,891 - Unsupervised Training Loss: 5.088250
2025-04-11 13:58:05,917 - K-means used 0.02 s
2025-04-11 13:58:07,920 - ***** Epoch: 13 *****
2025-04-11 13:58:07,921 - Supervised Training Loss: 5.289210
2025-04-11 13:58:07,921 - Unsupervised Training Loss: 4.801650
2025-04-11 13:58:36,455 - K-means used 0.02 s
2025-04-11 13:58:38,325 - ***** Epoch: 14 *****
2025-04-11 13:58:38,325 - Supervised Training Loss: 5.233100
2025-04-11 13:58:38,325 - Unsupervised Training Loss: 4.944850
2025-04-11 13:59:07,312 - K-means used 0.01 s
2025-04-11 13:59:09,245 - ***** Epoch: 15 *****
2025-04-11 13:59:09,245 - Supervised Training Loss: 5.092950
2025-04-11 13:59:09,245 - Unsupervised Training Loss: 5.048780
2025-04-11 13:59:37,724 - K-means used 0.02 s
2025-04-11 13:59:39,593 - ***** Epoch: 16 *****
2025-04-11 13:59:39,593 - Supervised Training Loss: 5.304520
2025-04-11 13:59:39,593 - Unsupervised Training Loss: 4.492420
2025-04-11 14:00:09,715 - K-means used 0.02 s
2025-04-11 14:00:11,735 - ***** Epoch: 17 *****
2025-04-11 14:00:11,735 - Supervised Training Loss: 5.272370
2025-04-11 14:00:11,735 - Unsupervised Training Loss: 4.721540
2025-04-11 14:00:30,327 - Training is finished...
2025-04-11 14:00:30,327 - Testing begins...
2025-04-11 14:00:38,121 - ***** Test results *****
2025-04-11 14:00:38,121 -   ACC = 35.28
2025-04-11 14:00:38,121 -   ARI = 16.9
2025-04-11 14:00:38,121 -   NMI = 41.63
2025-04-11 14:00:38,121 -   fmi = 22.19
2025-04-11 14:00:38,121 - Testing is finished...
2025-04-11 14:00:38,121 - Multimodal intent recognition is finished...
2025-04-11 14:00:38,121 - Results are saved in results/results_umc.csv
