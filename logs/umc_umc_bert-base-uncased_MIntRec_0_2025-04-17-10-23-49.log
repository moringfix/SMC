2025-04-17 10:23:49,472 - 【无监督】进入了无监督的设定中, 加载数据集
2025-04-17 10:23:49,472 - data preparation...
2025-04-17 10:23:58,142 - Number of train samples = 1779
2025-04-17 10:23:58,143 - Number of testing samples = 445
2025-04-17 10:23:58,143 - data preparation...
2025-04-17 10:24:00,464 - num_train_examples = 1779
2025-04-17 10:24:00,464 - ============================== Params ==============================
2025-04-17 10:24:00,464 - logger_name: umc_umc_bert-base-uncased_MIntRec_0
2025-04-17 10:24:00,465 - dataset: MIntRec
2025-04-17 10:24:00,465 - multimodal_method: umc
2025-04-17 10:24:00,465 - method: umc
2025-04-17 10:24:00,465 - setting: unsupervised
2025-04-17 10:24:00,465 - text_backbone: bert-base-uncased
2025-04-17 10:24:00,465 - seed: 0
2025-04-17 10:24:00,465 - num_workers: 16
2025-04-17 10:24:00,465 - log_id: umc_umc_bert-base-uncased_MIntRec_0_2025-04-17-10-23-49
2025-04-17 10:24:00,465 - gpu_id: 1
2025-04-17 10:24:00,465 - data_path: /root/autodl-tmp/home/Share/Dataset/LZH
2025-04-17 10:24:00,465 - train: True
2025-04-17 10:24:00,465 - tune: True
2025-04-17 10:24:00,465 - save_model: True
2025-04-17 10:24:00,465 - save_results: True
2025-04-17 10:24:00,465 - log_path: logs
2025-04-17 10:24:00,465 - cache_path: cache
2025-04-17 10:24:00,465 - video_data_path: video_data
2025-04-17 10:24:00,465 - audio_data_path: audio_data
2025-04-17 10:24:00,465 - video_feats_path: swin_feats.pkl
2025-04-17 10:24:00,465 - audio_feats_path: wavlm_feats.pkl
2025-04-17 10:24:00,465 - results_path: results
2025-04-17 10:24:00,465 - output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/SMC/outputs_test2/MIntRec
2025-04-17 10:24:00,465 - model_path: models
2025-04-17 10:24:00,465 - config_file_name: umc_MIntRec
2025-04-17 10:24:00,465 - results_file_name: results_umc_pre.csv
2025-04-17 10:24:00,465 - text_pretrained_model: uncased_L-12_H-768_A-12
2025-04-17 10:24:00,465 - pretrained_bert_model: uncased_L-12_H-768_A-12
2025-04-17 10:24:00,465 - pretrain_batch_size: 128
2025-04-17 10:24:00,465 - train_batch_size: 128
2025-04-17 10:24:00,466 - eval_batch_size: 128
2025-04-17 10:24:00,466 - test_batch_size: 128
2025-04-17 10:24:00,466 - num_pretrain_epochs: 100
2025-04-17 10:24:00,466 - num_train_epochs: 100
2025-04-17 10:24:00,466 - pretrain: [True]
2025-04-17 10:24:00,466 - aligned_method: ctc
2025-04-17 10:24:00,466 - need_aligned: False
2025-04-17 10:24:00,466 - freeze_pretrain_bert_parameters: [True]
2025-04-17 10:24:00,466 - freeze_train_bert_parameters: [True]
2025-04-17 10:24:00,466 - pretrain_temperature: [0.1, 0.2, 0.4, 0.5]
2025-04-17 10:24:00,466 - train_temperature_sup: [0.5]
2025-04-17 10:24:00,466 - train_temperature_unsup: [2]
2025-04-17 10:24:00,466 - activation: tanh
2025-04-17 10:24:00,466 - lr_pre: [1e-05]
2025-04-17 10:24:00,466 - lr: [5e-05]
2025-04-17 10:24:00,466 - delta: [0.05]
2025-04-17 10:24:00,466 - thres: [0.1]
2025-04-17 10:24:00,466 - topk: [5]
2025-04-17 10:24:00,466 - weight_decay: 0.01
2025-04-17 10:24:00,466 - feat_dim: 768
2025-04-17 10:24:00,466 - hidden_size: 768
2025-04-17 10:24:00,466 - grad_clip: -1.0
2025-04-17 10:24:00,466 - warmup_proportion: [0.1]
2025-04-17 10:24:00,466 - hidden_dropout_prob: 0.1
2025-04-17 10:24:00,466 - weight: 1.0
2025-04-17 10:24:00,466 - loss_mode: rdrop
2025-04-17 10:24:00,466 - base_dim: 256
2025-04-17 10:24:00,466 - nheads: 8
2025-04-17 10:24:00,466 - attn_dropout: 0.1
2025-04-17 10:24:00,466 - relu_dropout: 0.1
2025-04-17 10:24:00,467 - embed_dropout: 0.01
2025-04-17 10:24:00,467 - res_dropout: 0.0
2025-04-17 10:24:00,467 - attn_mask: True
2025-04-17 10:24:00,467 - encoder_layers_1: 1
2025-04-17 10:24:00,467 - fusion_act: tanh
2025-04-17 10:24:00,467 - pred_output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/SMC/outputs_test2/MIntRec/umc_umc_MIntRec_bert-base-uncased_0
2025-04-17 10:24:00,467 - model_output_path: /root/autodl-tmp/home/lizhuohang/reaserch/EMNLP/SMC/outputs_test2/MIntRec/umc_umc_MIntRec_bert-base-uncased_0/models
2025-04-17 10:24:00,467 - text_seq_len: 30
2025-04-17 10:24:00,467 - video_seq_len: 230
2025-04-17 10:24:00,467 - audio_seq_len: 480
2025-04-17 10:24:00,467 - text_feat_dim: 768
2025-04-17 10:24:00,467 - video_feat_dim: 1024
2025-04-17 10:24:00,467 - audio_feat_dim: 768
2025-04-17 10:24:00,467 - num_labels: 20
2025-04-17 10:24:00,467 - num_train_examples: 1779
2025-04-17 10:24:00,467 - ============================== End Params ==============================
2025-04-17 10:24:01,673 - Freeze all parameters but the last layer for efficiency
2025-04-17 10:24:01,707 - Pre-training start...
2025-04-17 10:24:17,696 - ***** Epoch: 1: Eval results *****
2025-04-17 10:24:17,696 -   train_loss = 5.949193477630615
2025-04-17 10:24:33,628 - ***** Epoch: 2: Eval results *****
2025-04-17 10:24:33,628 -   train_loss = 5.952265739440918
2025-04-17 10:24:53,730 - ***** Epoch: 3: Eval results *****
2025-04-17 10:24:53,730 -   train_loss = 5.935606479644775
2025-04-17 10:25:11,168 - ***** Epoch: 4: Eval results *****
2025-04-17 10:25:11,169 -   train_loss = 5.927751336778913
2025-04-17 10:25:30,259 - ***** Epoch: 5: Eval results *****
2025-04-17 10:25:30,260 -   train_loss = 5.913497652326312
2025-04-17 10:25:51,146 - ***** Epoch: 6: Eval results *****
2025-04-17 10:25:51,146 -   train_loss = 5.89586785861424
2025-04-17 10:26:10,959 - ***** Epoch: 7: Eval results *****
2025-04-17 10:26:10,959 -   train_loss = 5.859759432928903
2025-04-17 10:26:29,934 - ***** Epoch: 8: Eval results *****
2025-04-17 10:26:29,934 -   train_loss = 5.767020191465106
2025-04-17 10:26:48,651 - ***** Epoch: 9: Eval results *****
2025-04-17 10:26:48,652 -   train_loss = 5.558987549373081
2025-04-17 10:27:06,489 - ***** Epoch: 10: Eval results *****
2025-04-17 10:27:06,490 -   train_loss = 5.152538878577096
2025-04-17 10:27:24,041 - ***** Epoch: 11: Eval results *****
2025-04-17 10:27:24,041 -   train_loss = 4.676499843597412
2025-04-17 10:27:41,077 - ***** Epoch: 12: Eval results *****
2025-04-17 10:27:41,077 -   train_loss = 4.232026815414429
2025-04-17 10:27:57,866 - ***** Epoch: 13: Eval results *****
2025-04-17 10:27:57,866 -   train_loss = 3.88461126599993
2025-04-17 10:28:13,984 - ***** Epoch: 14: Eval results *****
2025-04-17 10:28:13,984 -   train_loss = 3.5916838305337087
2025-04-17 10:28:31,096 - ***** Epoch: 15: Eval results *****
2025-04-17 10:28:31,097 -   train_loss = 3.359354087284633
2025-04-17 10:28:48,072 - ***** Epoch: 16: Eval results *****
2025-04-17 10:28:48,072 -   train_loss = 3.1145884820393155
2025-04-17 10:29:05,014 - ***** Epoch: 17: Eval results *****
2025-04-17 10:29:05,014 -   train_loss = 2.9523240668433055
2025-04-17 10:29:22,038 - ***** Epoch: 18: Eval results *****
2025-04-17 10:29:22,038 -   train_loss = 2.779308761869158
2025-04-17 10:29:39,217 - ***** Epoch: 19: Eval results *****
2025-04-17 10:29:39,218 -   train_loss = 2.6757508516311646
2025-04-17 10:29:56,372 - ***** Epoch: 20: Eval results *****
2025-04-17 10:29:56,372 -   train_loss = 2.55076721736363
2025-04-17 10:30:13,265 - ***** Epoch: 21: Eval results *****
2025-04-17 10:30:13,265 -   train_loss = 2.470415013177054
2025-04-17 10:30:29,976 - ***** Epoch: 22: Eval results *****
2025-04-17 10:30:29,976 -   train_loss = 2.3861460515430997
2025-04-17 10:30:46,992 - ***** Epoch: 23: Eval results *****
2025-04-17 10:30:46,993 -   train_loss = 2.3333249943596974
2025-04-17 10:31:03,837 - ***** Epoch: 24: Eval results *****
2025-04-17 10:31:03,837 -   train_loss = 2.2593471663338796
2025-04-17 10:31:20,183 - ***** Epoch: 25: Eval results *****
2025-04-17 10:31:20,183 -   train_loss = 2.2129975727626254
2025-04-17 10:31:37,020 - ***** Epoch: 26: Eval results *****
2025-04-17 10:31:37,020 -   train_loss = 2.164110098566328
2025-04-17 10:31:53,790 - ***** Epoch: 27: Eval results *****
2025-04-17 10:31:53,790 -   train_loss = 2.120207258633205
2025-04-17 10:32:10,924 - ***** Epoch: 28: Eval results *****
2025-04-17 10:32:10,924 -   train_loss = 2.0649895668029785
2025-04-17 10:32:27,081 - ***** Epoch: 29: Eval results *****
2025-04-17 10:32:27,082 -   train_loss = 2.0416813577924455
2025-04-17 10:32:43,811 - ***** Epoch: 30: Eval results *****
2025-04-17 10:32:43,812 -   train_loss = 1.9979101164000375
2025-04-17 10:33:00,318 - ***** Epoch: 31: Eval results *****
2025-04-17 10:33:00,318 -   train_loss = 1.9680928673063005
2025-04-17 10:33:17,091 - ***** Epoch: 32: Eval results *****
2025-04-17 10:33:17,092 -   train_loss = 1.9471635563032967
2025-04-17 10:33:34,329 - ***** Epoch: 33: Eval results *****
2025-04-17 10:33:34,330 -   train_loss = 1.9144151210784912
2025-04-17 10:33:51,371 - ***** Epoch: 34: Eval results *****
2025-04-17 10:33:51,371 -   train_loss = 1.8907526135444641
2025-04-17 10:34:08,138 - ***** Epoch: 35: Eval results *****
2025-04-17 10:34:08,139 -   train_loss = 1.8836192403520857
2025-04-17 10:34:25,170 - ***** Epoch: 36: Eval results *****
2025-04-17 10:34:25,170 -   train_loss = 1.849606020109994
2025-04-17 10:34:41,645 - ***** Epoch: 37: Eval results *****
2025-04-17 10:34:41,646 -   train_loss = 1.8147066916738237
2025-04-17 10:34:58,657 - ***** Epoch: 38: Eval results *****
2025-04-17 10:34:58,658 -   train_loss = 1.7904383540153503
2025-04-17 10:35:15,043 - ***** Epoch: 39: Eval results *****
2025-04-17 10:35:15,043 -   train_loss = 1.7864476953233992
2025-04-17 10:35:31,806 - ***** Epoch: 40: Eval results *****
2025-04-17 10:35:31,806 -   train_loss = 1.7751130206244332
2025-04-17 10:35:48,187 - ***** Epoch: 41: Eval results *****
2025-04-17 10:35:48,188 -   train_loss = 1.7572949954441615
2025-04-17 10:36:05,437 - ***** Epoch: 42: Eval results *****
2025-04-17 10:36:05,438 -   train_loss = 1.7555459993226188
2025-04-17 10:36:22,244 - ***** Epoch: 43: Eval results *****
2025-04-17 10:36:22,244 -   train_loss = 1.725444495677948
2025-04-17 10:36:39,152 - ***** Epoch: 44: Eval results *****
2025-04-17 10:36:39,152 -   train_loss = 1.71990305185318
2025-04-17 10:36:55,603 - ***** Epoch: 45: Eval results *****
2025-04-17 10:36:55,603 -   train_loss = 1.7117591670581274
2025-04-17 10:37:12,290 - ***** Epoch: 46: Eval results *****
2025-04-17 10:37:12,291 -   train_loss = 1.6932952148573739
2025-04-17 10:37:28,328 - ***** Epoch: 47: Eval results *****
2025-04-17 10:37:28,328 -   train_loss = 1.6853409664971488
2025-04-17 10:37:45,155 - ***** Epoch: 48: Eval results *****
2025-04-17 10:37:45,155 -   train_loss = 1.6720904793058122
2025-04-17 10:38:01,904 - ***** Epoch: 49: Eval results *****
2025-04-17 10:38:01,905 -   train_loss = 1.6622984494481767
2025-04-17 10:38:19,450 - ***** Epoch: 50: Eval results *****
2025-04-17 10:38:19,451 -   train_loss = 1.6431356923920768
2025-04-17 10:38:36,804 - ***** Epoch: 51: Eval results *****
2025-04-17 10:38:36,805 -   train_loss = 1.6560724462781633
2025-04-17 10:38:53,504 - ***** Epoch: 52: Eval results *****
2025-04-17 10:38:53,504 -   train_loss = 1.6351646270070757
2025-04-17 10:39:10,618 - ***** Epoch: 53: Eval results *****
2025-04-17 10:39:10,618 -   train_loss = 1.6361470477921622
2025-04-17 10:39:26,856 - ***** Epoch: 54: Eval results *****
2025-04-17 10:39:26,857 -   train_loss = 1.6422176105635506
2025-04-17 10:39:43,832 - ***** Epoch: 55: Eval results *****
2025-04-17 10:39:43,833 -   train_loss = 1.618553408554622
2025-04-17 10:40:00,630 - ***** Epoch: 56: Eval results *****
2025-04-17 10:40:00,631 -   train_loss = 1.6022667969976152
2025-04-17 10:40:17,258 - ***** Epoch: 57: Eval results *****
2025-04-17 10:40:17,258 -   train_loss = 1.5885377952030726
2025-04-17 10:40:34,210 - ***** Epoch: 58: Eval results *****
2025-04-17 10:40:34,211 -   train_loss = 1.5988638060433524
2025-04-17 10:40:50,429 - ***** Epoch: 59: Eval results *****
2025-04-17 10:40:50,430 -   train_loss = 1.578799843788147
2025-04-17 10:41:07,124 - ***** Epoch: 60: Eval results *****
2025-04-17 10:41:07,124 -   train_loss = 1.5748631698744637
2025-04-17 10:41:23,400 - ***** Epoch: 61: Eval results *****
2025-04-17 10:41:23,400 -   train_loss = 1.5779412048203605
2025-04-17 10:41:40,321 - ***** Epoch: 62: Eval results *****
2025-04-17 10:41:40,321 -   train_loss = 1.5692865252494812
2025-04-17 10:41:55,431 - ***** Epoch: 63: Eval results *****
2025-04-17 10:41:55,431 -   train_loss = 1.5714731982776098
2025-04-17 10:42:11,601 - ***** Epoch: 64: Eval results *****
2025-04-17 10:42:11,602 -   train_loss = 1.5445379189082555
2025-04-17 10:42:27,879 - ***** Epoch: 65: Eval results *****
2025-04-17 10:42:27,880 -   train_loss = 1.5559247306415014
2025-04-17 10:42:44,144 - ***** Epoch: 66: Eval results *****
2025-04-17 10:42:44,145 -   train_loss = 1.5473199997629439
2025-04-17 10:43:00,384 - ***** Epoch: 67: Eval results *****
2025-04-17 10:43:00,384 -   train_loss = 1.5303492035184587
2025-04-17 10:43:16,782 - ***** Epoch: 68: Eval results *****
2025-04-17 10:43:16,782 -   train_loss = 1.5308520453316825
2025-04-17 10:43:33,384 - ***** Epoch: 69: Eval results *****
2025-04-17 10:43:33,384 -   train_loss = 1.5278252959251404
2025-04-17 10:43:49,963 - ***** Epoch: 70: Eval results *****
2025-04-17 10:43:49,963 -   train_loss = 1.5378225616046362
2025-04-17 10:44:06,473 - ***** Epoch: 71: Eval results *****
2025-04-17 10:44:06,473 -   train_loss = 1.5260800293513708
2025-04-17 10:44:22,241 - ***** Epoch: 72: Eval results *****
2025-04-17 10:44:22,241 -   train_loss = 1.5409446954727173
2025-04-17 10:44:38,461 - ***** Epoch: 73: Eval results *****
2025-04-17 10:44:38,461 -   train_loss = 1.5308823415211268
2025-04-17 10:44:54,401 - ***** Epoch: 74: Eval results *****
2025-04-17 10:44:54,401 -   train_loss = 1.527665138244629
2025-04-17 10:45:11,116 - ***** Epoch: 75: Eval results *****
2025-04-17 10:45:11,117 -   train_loss = 1.5288330912590027
2025-04-17 10:45:27,173 - ***** Epoch: 76: Eval results *****
2025-04-17 10:45:27,173 -   train_loss = 1.5208497898919242
2025-04-17 10:45:43,778 - ***** Epoch: 77: Eval results *****
2025-04-17 10:45:43,778 -   train_loss = 1.506390494959695
2025-04-17 10:45:59,829 - ***** Epoch: 78: Eval results *****
2025-04-17 10:45:59,829 -   train_loss = 1.5098134108952113
2025-04-17 10:46:16,457 - ***** Epoch: 79: Eval results *****
2025-04-17 10:46:16,457 -   train_loss = 1.5125635947499956
2025-04-17 10:46:32,472 - ***** Epoch: 80: Eval results *****
2025-04-17 10:46:32,472 -   train_loss = 1.5060618349484034
2025-04-17 10:46:49,054 - ***** Epoch: 81: Eval results *****
2025-04-17 10:46:49,055 -   train_loss = 1.507939807006291
2025-04-17 10:47:05,564 - ***** Epoch: 82: Eval results *****
2025-04-17 10:47:05,564 -   train_loss = 1.5039888279778617
2025-04-17 10:47:22,132 - ***** Epoch: 83: Eval results *****
2025-04-17 10:47:22,133 -   train_loss = 1.520085096359253
2025-04-17 10:47:38,244 - ***** Epoch: 84: Eval results *****
2025-04-17 10:47:38,245 -   train_loss = 1.5017468929290771
2025-04-17 10:47:54,573 - ***** Epoch: 85: Eval results *****
2025-04-17 10:47:54,573 -   train_loss = 1.5044848237718855
2025-04-17 10:48:11,240 - ***** Epoch: 86: Eval results *****
2025-04-17 10:48:11,241 -   train_loss = 1.5042651465960912
2025-04-17 10:48:28,038 - ***** Epoch: 87: Eval results *****
2025-04-17 10:48:28,039 -   train_loss = 1.4982344508171082
2025-04-17 10:48:44,393 - ***** Epoch: 88: Eval results *****
2025-04-17 10:48:44,393 -   train_loss = 1.4948718973568507
2025-04-17 10:49:01,139 - ***** Epoch: 89: Eval results *****
2025-04-17 10:49:01,139 -   train_loss = 1.4890625817435128
2025-04-17 10:49:17,514 - ***** Epoch: 90: Eval results *****
2025-04-17 10:49:17,515 -   train_loss = 1.5051015274865287
2025-04-17 10:49:34,117 - ***** Epoch: 91: Eval results *****
2025-04-17 10:49:34,117 -   train_loss = 1.4895317128726415
2025-04-17 10:49:50,403 - ***** Epoch: 92: Eval results *****
2025-04-17 10:49:50,403 -   train_loss = 1.4938311661992754
2025-04-17 10:50:07,162 - ***** Epoch: 93: Eval results *****
2025-04-17 10:50:07,162 -   train_loss = 1.494200885295868
2025-04-17 10:50:23,881 - ***** Epoch: 94: Eval results *****
2025-04-17 10:50:23,881 -   train_loss = 1.4933629291398185
2025-04-17 10:50:40,744 - ***** Epoch: 95: Eval results *****
2025-04-17 10:50:40,745 -   train_loss = 1.4904657091413225
2025-04-17 10:50:57,163 - ***** Epoch: 96: Eval results *****
2025-04-17 10:50:57,164 -   train_loss = 1.4846479637282235
2025-04-17 10:51:13,962 - ***** Epoch: 97: Eval results *****
2025-04-17 10:51:13,962 -   train_loss = 1.4852814418928963
2025-04-17 10:51:30,088 - ***** Epoch: 98: Eval results *****
2025-04-17 10:51:30,089 -   train_loss = 1.5040470446859087
2025-04-17 10:51:46,647 - ***** Epoch: 99: Eval results *****
2025-04-17 10:51:46,647 -   train_loss = 1.491354022707258
2025-04-17 10:52:03,532 - ***** Epoch: 100: Eval results *****
2025-04-17 10:52:03,533 -   train_loss = 1.4950302498681205
2025-04-17 10:52:05,229 - Pre-training finished...
2025-04-17 10:52:05,589 - Freeze all parameters but the last layer for efficiency
2025-04-17 10:52:05,598 - Multimodal Intent Recognition begins...
2025-04-17 10:52:05,598 - Training begins...
2025-04-17 10:52:20,166 - Initializing centroids with K-means++...
2025-04-17 10:52:20,246 - K-means++ used 0.08 s
2025-04-17 10:52:50,026 - K-means used 0.02 s
2025-04-17 10:52:51,294 - ***** Epoch: 1 *****
2025-04-17 10:52:51,294 - Supervised Training Loss: 4.356400
2025-04-17 10:52:51,296 - Unsupervised Training Loss: 5.533300
2025-04-17 10:53:19,780 - K-means used 0.04 s
2025-04-17 10:53:20,869 - ***** Epoch: 2 *****
2025-04-17 10:53:20,869 - Supervised Training Loss: 4.962440
2025-04-17 10:53:20,869 - Unsupervised Training Loss: 5.560350
2025-04-17 10:53:49,245 - K-means used 0.02 s
2025-04-17 10:53:50,350 - ***** Epoch: 3 *****
2025-04-17 10:53:50,351 - Supervised Training Loss: 4.819140
2025-04-17 10:53:50,351 - Unsupervised Training Loss: 5.424460
2025-04-17 10:54:18,436 - K-means used 0.02 s
2025-04-17 10:54:19,943 - ***** Epoch: 4 *****
2025-04-17 10:54:19,944 - Supervised Training Loss: 4.609830
2025-04-17 10:54:19,944 - Unsupervised Training Loss: 5.492130
2025-04-17 10:54:50,228 - K-means used 0.02 s
2025-04-17 10:54:51,317 - ***** Epoch: 5 *****
2025-04-17 10:54:51,317 - Supervised Training Loss: 4.324460
2025-04-17 10:54:51,317 - Unsupervised Training Loss: 5.531850
2025-04-17 10:55:20,316 - K-means used 0.02 s
2025-04-17 10:55:21,491 - ***** Epoch: 6 *****
2025-04-17 10:55:21,491 - Supervised Training Loss: 4.715850
2025-04-17 10:55:21,491 - Unsupervised Training Loss: 5.325060
2025-04-17 10:55:50,761 - K-means used 0.03 s
2025-04-17 10:55:51,950 - ***** Epoch: 7 *****
2025-04-17 10:55:51,951 - Supervised Training Loss: 4.610890
2025-04-17 10:55:51,951 - Unsupervised Training Loss: 5.444220
2025-04-17 10:56:21,071 - K-means used 0.02 s
2025-04-17 10:56:22,677 - ***** Epoch: 8 *****
2025-04-17 10:56:22,678 - Supervised Training Loss: 4.462200
2025-04-17 10:56:22,678 - Unsupervised Training Loss: 5.507420
2025-04-17 10:56:52,081 - K-means used 0.02 s
2025-04-17 10:56:53,459 - ***** Epoch: 9 *****
2025-04-17 10:56:53,459 - Supervised Training Loss: 4.689930
2025-04-17 10:56:53,460 - Unsupervised Training Loss: 5.544570
2025-04-17 10:57:22,206 - K-means used 0.02 s
2025-04-17 10:57:23,624 - ***** Epoch: 10 *****
2025-04-17 10:57:23,624 - Supervised Training Loss: 4.610640
2025-04-17 10:57:23,624 - Unsupervised Training Loss: 5.386780
2025-04-17 10:57:52,213 - K-means used 0.02 s
2025-04-17 10:57:53,598 - ***** Epoch: 11 *****
2025-04-17 10:57:53,598 - Supervised Training Loss: 4.525550
2025-04-17 10:57:53,598 - Unsupervised Training Loss: 5.471040
2025-04-17 10:58:21,992 - K-means used 0.02 s
2025-04-17 10:58:23,403 - ***** Epoch: 12 *****
2025-04-17 10:58:23,404 - Supervised Training Loss: 4.674680
2025-04-17 10:58:23,404 - Unsupervised Training Loss: 5.538110
2025-04-17 10:58:52,511 - K-means used 0.03 s
2025-04-17 10:58:54,004 - ***** Epoch: 13 *****
2025-04-17 10:58:54,004 - Supervised Training Loss: 4.649080
2025-04-17 10:58:54,004 - Unsupervised Training Loss: 5.249160
2025-04-17 10:59:22,332 - K-means used 0.02 s
2025-04-17 10:59:23,852 - ***** Epoch: 14 *****
2025-04-17 10:59:23,853 - Supervised Training Loss: 4.593790
2025-04-17 10:59:23,853 - Unsupervised Training Loss: 5.391160
2025-04-17 10:59:52,055 - K-means used 0.02 s
2025-04-17 10:59:53,625 - ***** Epoch: 15 *****
2025-04-17 10:59:53,625 - Supervised Training Loss: 4.493420
2025-04-17 10:59:53,625 - Unsupervised Training Loss: 5.492710
2025-04-17 11:00:21,472 - K-means used 0.05 s
2025-04-17 11:00:23,256 - ***** Epoch: 16 *****
2025-04-17 11:00:23,256 - Supervised Training Loss: 4.689870
2025-04-17 11:00:23,256 - Unsupervised Training Loss: 4.935770
2025-04-17 11:00:50,813 - K-means used 0.01 s
2025-04-17 11:00:52,581 - ***** Epoch: 17 *****
2025-04-17 11:00:52,582 - Supervised Training Loss: 4.680870
2025-04-17 11:00:52,582 - Unsupervised Training Loss: 5.182820
2025-04-17 11:01:12,540 - Training is finished...
2025-04-17 11:01:12,541 - Testing begins...
2025-04-17 11:01:19,094 - ***** Test results *****
2025-04-17 11:01:19,094 -   ACC = 39.1
2025-04-17 11:01:19,094 -   ARI = 19.57
2025-04-17 11:01:19,094 -   NMI = 44.83
2025-04-17 11:01:19,094 -   fmi = 24.66
2025-04-17 11:01:19,094 - Testing is finished...
2025-04-17 11:01:19,094 - Multimodal intent recognition is finished...
2025-04-17 11:01:19,094 - Results are saved in results/results_umc_pre.csv
2025-04-17 11:01:20,161 - Freeze all parameters but the last layer for efficiency
2025-04-17 11:01:20,197 - Pre-training start...
2025-04-17 11:01:21,037 - ***** Epoch: 1: Eval results *****
2025-04-17 11:01:21,037 -   train_loss = 5.669917583465576
2025-04-17 11:01:21,893 - ***** Epoch: 2: Eval results *****
2025-04-17 11:01:21,893 -   train_loss = 5.675268650054932
2025-04-17 11:01:22,739 - ***** Epoch: 3: Eval results *****
2025-04-17 11:01:22,739 -   train_loss = 5.671773910522461
2025-04-17 11:01:23,580 - ***** Epoch: 4: Eval results *****
2025-04-17 11:01:23,580 -   train_loss = 5.677586078643799
2025-04-17 11:01:24,425 - ***** Epoch: 5: Eval results *****
2025-04-17 11:01:24,425 -   train_loss = 5.665362358093262
2025-04-17 11:01:25,267 - ***** Epoch: 6: Eval results *****
2025-04-17 11:01:25,267 -   train_loss = 5.682164192199707
2025-04-17 11:01:26,116 - ***** Epoch: 7: Eval results *****
2025-04-17 11:01:26,116 -   train_loss = 5.673859119415283
2025-04-17 11:01:26,958 - ***** Epoch: 8: Eval results *****
2025-04-17 11:01:26,959 -   train_loss = 5.67146110534668
2025-04-17 11:01:27,796 - ***** Epoch: 9: Eval results *****
2025-04-17 11:01:27,796 -   train_loss = 5.680974006652832
2025-04-17 11:01:28,608 - ***** Epoch: 10: Eval results *****
2025-04-17 11:01:28,608 -   train_loss = 5.6844401359558105
2025-04-17 11:01:29,465 - ***** Epoch: 11: Eval results *****
2025-04-17 11:01:29,466 -   train_loss = 5.668063640594482
2025-04-17 11:01:30,329 - ***** Epoch: 12: Eval results *****
2025-04-17 11:01:30,329 -   train_loss = 5.66882848739624
2025-04-17 11:01:31,131 - ***** Epoch: 13: Eval results *****
2025-04-17 11:01:31,131 -   train_loss = 5.6689453125
2025-04-17 11:01:31,828 - ***** Epoch: 14: Eval results *****
2025-04-17 11:01:31,829 -   train_loss = 5.6772918701171875
2025-04-17 11:01:32,696 - ***** Epoch: 15: Eval results *****
2025-04-17 11:01:32,696 -   train_loss = 5.678562641143799
2025-04-17 11:01:33,411 - ***** Epoch: 16: Eval results *****
2025-04-17 11:01:33,411 -   train_loss = 5.696641445159912
2025-04-17 11:01:34,299 - ***** Epoch: 17: Eval results *****
2025-04-17 11:01:34,300 -   train_loss = 5.69077205657959
2025-04-17 11:01:35,150 - ***** Epoch: 18: Eval results *****
2025-04-17 11:01:35,150 -   train_loss = 5.6670732498168945
2025-04-17 11:01:36,005 - ***** Epoch: 19: Eval results *****
2025-04-17 11:01:36,005 -   train_loss = 5.676005840301514
2025-04-17 11:01:36,825 - ***** Epoch: 20: Eval results *****
2025-04-17 11:01:36,825 -   train_loss = 5.647857666015625
2025-04-17 11:01:37,526 - ***** Epoch: 21: Eval results *****
2025-04-17 11:01:37,527 -   train_loss = 5.657468318939209
2025-04-17 11:01:38,389 - ***** Epoch: 22: Eval results *****
2025-04-17 11:01:38,390 -   train_loss = 5.660557270050049
2025-04-17 11:01:39,294 - ***** Epoch: 23: Eval results *****
2025-04-17 11:01:39,295 -   train_loss = 5.662416458129883
2025-04-17 11:01:40,148 - ***** Epoch: 24: Eval results *****
2025-04-17 11:01:40,148 -   train_loss = 5.635446071624756
2025-04-17 11:01:40,991 - ***** Epoch: 25: Eval results *****
2025-04-17 11:01:40,991 -   train_loss = 5.6519951820373535
2025-04-17 11:01:41,826 - ***** Epoch: 26: Eval results *****
2025-04-17 11:01:41,826 -   train_loss = 5.659436225891113
2025-04-17 11:01:42,669 - ***** Epoch: 27: Eval results *****
2025-04-17 11:01:42,669 -   train_loss = 5.657155990600586
2025-04-17 11:01:43,547 - ***** Epoch: 28: Eval results *****
2025-04-17 11:01:43,547 -   train_loss = 5.638627052307129
2025-04-17 11:01:44,376 - ***** Epoch: 29: Eval results *****
2025-04-17 11:01:44,376 -   train_loss = 5.6236090660095215
2025-04-17 11:01:45,076 - ***** Epoch: 30: Eval results *****
2025-04-17 11:01:45,077 -   train_loss = 5.644278049468994
2025-04-17 11:01:45,782 - ***** Epoch: 31: Eval results *****
2025-04-17 11:01:45,782 -   train_loss = 5.639128684997559
2025-04-17 11:01:46,659 - ***** Epoch: 32: Eval results *****
2025-04-17 11:01:46,659 -   train_loss = 5.647702693939209
2025-04-17 11:01:47,528 - ***** Epoch: 33: Eval results *****
2025-04-17 11:01:47,529 -   train_loss = 5.6240925788879395
2025-04-17 11:01:48,241 - ***** Epoch: 34: Eval results *****
2025-04-17 11:01:48,241 -   train_loss = 5.629632949829102
2025-04-17 11:01:49,092 - ***** Epoch: 35: Eval results *****
2025-04-17 11:01:49,092 -   train_loss = 5.624047756195068
2025-04-17 11:01:49,797 - ***** Epoch: 36: Eval results *****
2025-04-17 11:01:49,797 -   train_loss = 5.620481491088867
2025-04-17 11:01:50,503 - ***** Epoch: 37: Eval results *****
2025-04-17 11:01:50,504 -   train_loss = 5.632373332977295
2025-04-17 11:01:51,209 - ***** Epoch: 38: Eval results *****
2025-04-17 11:01:51,209 -   train_loss = 5.614681243896484
2025-04-17 11:01:51,915 - ***** Epoch: 39: Eval results *****
2025-04-17 11:01:51,915 -   train_loss = 5.599794387817383
2025-04-17 11:01:52,625 - ***** Epoch: 40: Eval results *****
2025-04-17 11:01:52,625 -   train_loss = 5.602749347686768
2025-04-17 11:01:53,354 - ***** Epoch: 41: Eval results *****
2025-04-17 11:01:53,354 -   train_loss = 5.599615097045898
2025-04-17 11:01:54,068 - ***** Epoch: 42: Eval results *****
2025-04-17 11:01:54,069 -   train_loss = 5.613943099975586
2025-04-17 11:01:54,971 - ***** Epoch: 43: Eval results *****
2025-04-17 11:01:54,972 -   train_loss = 5.579607963562012
2025-04-17 11:01:55,835 - ***** Epoch: 44: Eval results *****
2025-04-17 11:01:55,835 -   train_loss = 5.580249786376953
2025-04-17 11:01:56,685 - ***** Epoch: 45: Eval results *****
2025-04-17 11:01:56,686 -   train_loss = 5.562154769897461
2025-04-17 11:01:57,504 - ***** Epoch: 46: Eval results *****
2025-04-17 11:01:57,505 -   train_loss = 5.5681352615356445
2025-04-17 11:01:58,359 - ***** Epoch: 47: Eval results *****
2025-04-17 11:01:58,359 -   train_loss = 5.546492576599121
2025-04-17 11:01:59,177 - ***** Epoch: 48: Eval results *****
2025-04-17 11:01:59,177 -   train_loss = 5.551332950592041
2025-04-17 11:01:59,879 - ***** Epoch: 49: Eval results *****
2025-04-17 11:01:59,879 -   train_loss = 5.546416282653809
2025-04-17 11:02:00,597 - ***** Epoch: 50: Eval results *****
2025-04-17 11:02:00,597 -   train_loss = 5.539791584014893
2025-04-17 11:02:01,310 - ***** Epoch: 51: Eval results *****
2025-04-17 11:02:01,311 -   train_loss = 5.516695976257324
2025-04-17 11:02:02,037 - ***** Epoch: 52: Eval results *****
2025-04-17 11:02:02,037 -   train_loss = 5.529239654541016
2025-04-17 11:02:02,749 - ***** Epoch: 53: Eval results *****
2025-04-17 11:02:02,750 -   train_loss = 5.512359142303467
2025-04-17 11:02:03,465 - ***** Epoch: 54: Eval results *****
2025-04-17 11:02:03,465 -   train_loss = 5.496636390686035
2025-04-17 11:02:04,205 - ***** Epoch: 55: Eval results *****
2025-04-17 11:02:04,205 -   train_loss = 5.481027126312256
2025-04-17 11:02:04,951 - ***** Epoch: 56: Eval results *****
2025-04-17 11:02:04,951 -   train_loss = 5.487554550170898
2025-04-17 11:02:05,669 - ***** Epoch: 57: Eval results *****
2025-04-17 11:02:05,669 -   train_loss = 5.482072830200195
2025-04-17 11:02:06,395 - ***** Epoch: 58: Eval results *****
2025-04-17 11:02:06,395 -   train_loss = 5.444706916809082
2025-04-17 11:02:07,104 - ***** Epoch: 59: Eval results *****
2025-04-17 11:02:07,104 -   train_loss = 5.447348594665527
2025-04-17 11:02:07,946 - ***** Epoch: 60: Eval results *****
2025-04-17 11:02:07,947 -   train_loss = 5.439218521118164
2025-04-17 11:02:08,658 - ***** Epoch: 61: Eval results *****
2025-04-17 11:02:08,658 -   train_loss = 5.441936492919922
2025-04-17 11:02:09,384 - ***** Epoch: 62: Eval results *****
2025-04-17 11:02:09,384 -   train_loss = 5.4478302001953125
2025-04-17 11:02:10,285 - ***** Epoch: 63: Eval results *****
2025-04-17 11:02:10,285 -   train_loss = 5.424896717071533
2025-04-17 11:02:11,140 - ***** Epoch: 64: Eval results *****
2025-04-17 11:02:11,140 -   train_loss = 5.371130466461182
2025-04-17 11:02:11,986 - ***** Epoch: 65: Eval results *****
2025-04-17 11:02:11,987 -   train_loss = 5.374485969543457
2025-04-17 11:02:12,841 - ***** Epoch: 66: Eval results *****
2025-04-17 11:02:12,841 -   train_loss = 5.347944736480713
2025-04-17 11:02:13,690 - ***** Epoch: 67: Eval results *****
2025-04-17 11:02:13,690 -   train_loss = 5.316446781158447
2025-04-17 11:02:14,550 - ***** Epoch: 68: Eval results *****
2025-04-17 11:02:14,550 -   train_loss = 5.347495079040527
2025-04-17 11:02:15,399 - ***** Epoch: 69: Eval results *****
2025-04-17 11:02:15,399 -   train_loss = 5.270148277282715
2025-04-17 11:02:16,246 - ***** Epoch: 70: Eval results *****
2025-04-17 11:02:16,247 -   train_loss = 5.27806282043457
2025-04-17 11:02:17,077 - ***** Epoch: 71: Eval results *****
2025-04-17 11:02:17,077 -   train_loss = 5.280452728271484
2025-04-17 11:02:17,948 - ***** Epoch: 72: Eval results *****
2025-04-17 11:02:17,948 -   train_loss = 5.23837423324585
2025-04-17 11:02:18,662 - ***** Epoch: 73: Eval results *****
2025-04-17 11:02:18,663 -   train_loss = 5.25958251953125
2025-04-17 11:02:19,373 - ***** Epoch: 74: Eval results *****
2025-04-17 11:02:19,374 -   train_loss = 5.232539653778076
2025-04-17 11:02:20,090 - ***** Epoch: 75: Eval results *****
2025-04-17 11:02:20,090 -   train_loss = 5.242489814758301
2025-04-17 11:02:20,801 - ***** Epoch: 76: Eval results *****
2025-04-17 11:02:20,802 -   train_loss = 5.2273077964782715
2025-04-17 11:02:21,702 - ***** Epoch: 77: Eval results *****
2025-04-17 11:02:21,702 -   train_loss = 5.223241329193115
2025-04-17 11:02:22,534 - ***** Epoch: 78: Eval results *****
2025-04-17 11:02:22,534 -   train_loss = 5.147313594818115
2025-04-17 11:02:23,436 - ***** Epoch: 79: Eval results *****
2025-04-17 11:02:23,436 -   train_loss = 5.17958927154541
2025-04-17 11:02:24,262 - ***** Epoch: 80: Eval results *****
2025-04-17 11:02:24,263 -   train_loss = 5.161207675933838
2025-04-17 11:02:24,976 - ***** Epoch: 81: Eval results *****
2025-04-17 11:02:24,976 -   train_loss = 5.117351055145264
2025-04-17 11:02:25,691 - ***** Epoch: 82: Eval results *****
2025-04-17 11:02:25,691 -   train_loss = 5.15433406829834
2025-04-17 11:02:26,604 - ***** Epoch: 83: Eval results *****
2025-04-17 11:02:26,604 -   train_loss = 5.114541053771973
2025-04-17 11:02:27,479 - ***** Epoch: 84: Eval results *****
2025-04-17 11:02:27,479 -   train_loss = 5.077511310577393
2025-04-17 11:02:28,329 - ***** Epoch: 85: Eval results *****
2025-04-17 11:02:28,329 -   train_loss = 5.077057361602783
2025-04-17 11:02:29,185 - ***** Epoch: 86: Eval results *****
2025-04-17 11:02:29,186 -   train_loss = 5.066667079925537
2025-04-17 11:02:30,049 - ***** Epoch: 87: Eval results *****
2025-04-17 11:02:30,049 -   train_loss = 5.0059990882873535
2025-04-17 11:02:30,925 - ***** Epoch: 88: Eval results *****
2025-04-17 11:02:30,926 -   train_loss = 5.0340046882629395
2025-04-17 11:02:31,753 - ***** Epoch: 89: Eval results *****
2025-04-17 11:02:31,753 -   train_loss = 4.977297306060791
2025-04-17 11:02:32,470 - ***** Epoch: 90: Eval results *****
2025-04-17 11:02:32,471 -   train_loss = 4.9835896492004395
2025-04-17 11:02:33,365 - ***** Epoch: 91: Eval results *****
2025-04-17 11:02:33,365 -   train_loss = 4.9392170906066895
2025-04-17 11:02:34,217 - ***** Epoch: 92: Eval results *****
2025-04-17 11:02:34,217 -   train_loss = 4.914980411529541
2025-04-17 11:02:35,058 - ***** Epoch: 93: Eval results *****
2025-04-17 11:02:35,058 -   train_loss = 4.9043803215026855
2025-04-17 11:02:35,900 - ***** Epoch: 94: Eval results *****
2025-04-17 11:02:35,900 -   train_loss = 4.919134140014648
2025-04-17 11:02:36,740 - ***** Epoch: 95: Eval results *****
2025-04-17 11:02:36,741 -   train_loss = 4.904653549194336
2025-04-17 11:02:37,575 - ***** Epoch: 96: Eval results *****
2025-04-17 11:02:37,575 -   train_loss = 4.875249862670898
2025-04-17 11:02:38,460 - ***** Epoch: 97: Eval results *****
2025-04-17 11:02:38,461 -   train_loss = 4.888803482055664
2025-04-17 11:02:39,180 - ***** Epoch: 98: Eval results *****
2025-04-17 11:02:39,181 -   train_loss = 4.850020408630371
2025-04-17 11:02:39,906 - ***** Epoch: 99: Eval results *****
2025-04-17 11:02:39,906 -   train_loss = 4.860918045043945
2025-04-17 11:02:40,617 - ***** Epoch: 100: Eval results *****
2025-04-17 11:02:40,617 -   train_loss = 4.800710678100586
2025-04-17 11:02:42,236 - Pre-training finished...
2025-04-17 11:02:42,435 - Freeze all parameters but the last layer for efficiency
2025-04-17 11:02:42,444 - Multimodal Intent Recognition begins...
2025-04-17 11:02:42,444 - Training begins...
2025-04-17 11:02:52,515 - Initializing centroids with K-means++...
2025-04-17 11:02:52,599 - K-means++ used 0.08 s
2025-04-17 11:03:22,514 - K-means used 0.03 s
2025-04-17 11:03:23,570 - ***** Epoch: 1 *****
2025-04-17 11:03:23,571 - Supervised Training Loss: 5.203670
2025-04-17 11:03:23,571 - Unsupervised Training Loss: 5.830620
2025-04-17 11:03:53,314 - K-means used 0.03 s
2025-04-17 11:03:54,563 - ***** Epoch: 2 *****
2025-04-17 11:03:54,563 - Supervised Training Loss: 4.216900
2025-04-17 11:03:54,564 - Unsupervised Training Loss: 5.819970
2025-04-17 11:04:24,551 - K-means used 0.03 s
2025-04-17 11:04:25,658 - ***** Epoch: 3 *****
2025-04-17 11:04:25,658 - Supervised Training Loss: 5.361510
2025-04-17 11:04:25,659 - Unsupervised Training Loss: 5.609650
2025-04-17 11:04:54,289 - K-means used 0.03 s
2025-04-17 11:04:55,486 - ***** Epoch: 4 *****
2025-04-17 11:04:55,486 - Supervised Training Loss: 5.073430
2025-04-17 11:04:55,486 - Unsupervised Training Loss: 5.613190
2025-04-17 11:05:24,029 - K-means used 0.04 s
2025-04-17 11:05:25,258 - ***** Epoch: 5 *****
2025-04-17 11:05:25,259 - Supervised Training Loss: 4.707140
2025-04-17 11:05:25,259 - Unsupervised Training Loss: 5.628150
2025-04-17 11:05:53,093 - K-means used 0.02 s
2025-04-17 11:05:54,286 - ***** Epoch: 6 *****
2025-04-17 11:05:54,286 - Supervised Training Loss: 5.009050
2025-04-17 11:05:54,286 - Unsupervised Training Loss: 5.404640
2025-04-17 11:06:22,653 - K-means used 0.03 s
2025-04-17 11:06:23,890 - ***** Epoch: 7 *****
2025-04-17 11:06:23,890 - Supervised Training Loss: 4.858280
2025-04-17 11:06:23,890 - Unsupervised Training Loss: 5.508980
2025-04-17 11:06:52,364 - K-means used 0.02 s
2025-04-17 11:06:53,824 - ***** Epoch: 8 *****
2025-04-17 11:06:53,824 - Supervised Training Loss: 4.679030
2025-04-17 11:06:53,824 - Unsupervised Training Loss: 5.554490
2025-04-17 11:07:24,980 - K-means used 0.03 s
2025-04-17 11:07:26,478 - ***** Epoch: 9 *****
2025-04-17 11:07:26,478 - Supervised Training Loss: 4.874900
2025-04-17 11:07:26,478 - Unsupervised Training Loss: 5.589500
2025-04-17 11:07:57,090 - K-means used 0.03 s
2025-04-17 11:07:58,449 - ***** Epoch: 10 *****
2025-04-17 11:07:58,449 - Supervised Training Loss: 4.799740
2025-04-17 11:07:58,450 - Unsupervised Training Loss: 5.434670
2025-04-17 11:08:26,986 - K-means used 0.02 s
2025-04-17 11:08:28,516 - ***** Epoch: 11 *****
2025-04-17 11:08:28,516 - Supervised Training Loss: 4.707710
2025-04-17 11:08:28,516 - Unsupervised Training Loss: 5.508000
2025-04-17 11:08:57,242 - K-means used 0.02 s
2025-04-17 11:08:58,810 - ***** Epoch: 12 *****
2025-04-17 11:08:58,811 - Supervised Training Loss: 4.829880
2025-04-17 11:08:58,811 - Unsupervised Training Loss: 5.577130
2025-04-17 11:09:27,360 - K-means used 0.01 s
2025-04-17 11:09:28,986 - ***** Epoch: 13 *****
2025-04-17 11:09:28,986 - Supervised Training Loss: 4.787160
2025-04-17 11:09:28,986 - Unsupervised Training Loss: 5.289770
2025-04-17 11:09:56,686 - K-means used 0.02 s
2025-04-17 11:09:58,326 - ***** Epoch: 14 *****
2025-04-17 11:09:58,326 - Supervised Training Loss: 4.731150
2025-04-17 11:09:58,327 - Unsupervised Training Loss: 5.424380
2025-04-17 11:10:26,848 - K-means used 0.01 s
2025-04-17 11:10:28,787 - ***** Epoch: 15 *****
2025-04-17 11:10:28,787 - Supervised Training Loss: 4.585710
2025-04-17 11:10:28,787 - Unsupervised Training Loss: 5.534050
2025-04-17 11:10:59,599 - K-means used 0.06 s
2025-04-17 11:11:01,415 - ***** Epoch: 16 *****
2025-04-17 11:11:01,416 - Supervised Training Loss: 4.801120
2025-04-17 11:11:01,416 - Unsupervised Training Loss: 4.990960
2025-04-17 11:11:32,826 - K-means used 0.02 s
2025-04-17 11:11:34,598 - ***** Epoch: 17 *****
2025-04-17 11:11:34,598 - Supervised Training Loss: 4.778240
2025-04-17 11:11:34,598 - Unsupervised Training Loss: 5.189230
2025-04-17 11:11:56,273 - Training is finished...
2025-04-17 11:11:56,273 - Testing begins...
2025-04-17 11:12:03,254 - ***** Test results *****
2025-04-17 11:12:03,254 -   ACC = 22.92
2025-04-17 11:12:03,254 -   ARI = 7.38
2025-04-17 11:12:03,254 -   NMI = 30.96
2025-04-17 11:12:03,254 -   fmi = 13.11
2025-04-17 11:12:03,255 - Testing is finished...
2025-04-17 11:12:03,255 - Multimodal intent recognition is finished...
2025-04-17 11:12:03,255 - Results are saved in results/results_umc_pre.csv
2025-04-17 11:12:04,320 - Freeze all parameters but the last layer for efficiency
2025-04-17 11:12:04,357 - Pre-training start...
2025-04-17 11:12:05,325 - ***** Epoch: 1: Eval results *****
2025-04-17 11:12:05,325 -   train_loss = 5.672309398651123
2025-04-17 11:12:06,211 - ***** Epoch: 2: Eval results *****
2025-04-17 11:12:06,211 -   train_loss = 5.67275333404541
2025-04-17 11:12:07,076 - ***** Epoch: 3: Eval results *****
2025-04-17 11:12:07,077 -   train_loss = 5.663555145263672
2025-04-17 11:12:07,949 - ***** Epoch: 4: Eval results *****
2025-04-17 11:12:07,949 -   train_loss = 5.670301914215088
2025-04-17 11:12:08,833 - ***** Epoch: 5: Eval results *****
2025-04-17 11:12:08,833 -   train_loss = 5.67001485824585
2025-04-17 11:12:09,767 - ***** Epoch: 6: Eval results *****
2025-04-17 11:12:09,767 -   train_loss = 5.673364639282227
2025-04-17 11:12:10,584 - ***** Epoch: 7: Eval results *****
2025-04-17 11:12:10,584 -   train_loss = 5.676059246063232
2025-04-17 11:12:11,440 - ***** Epoch: 8: Eval results *****
2025-04-17 11:12:11,440 -   train_loss = 5.665729999542236
2025-04-17 11:12:12,146 - ***** Epoch: 9: Eval results *****
2025-04-17 11:12:12,146 -   train_loss = 5.666774749755859
2025-04-17 11:12:13,001 - ***** Epoch: 10: Eval results *****
2025-04-17 11:12:13,002 -   train_loss = 5.673412322998047
2025-04-17 11:12:13,846 - ***** Epoch: 11: Eval results *****
2025-04-17 11:12:13,846 -   train_loss = 5.673698425292969
2025-04-17 11:12:14,682 - ***** Epoch: 12: Eval results *****
2025-04-17 11:12:14,682 -   train_loss = 5.67136812210083
2025-04-17 11:12:15,457 - ***** Epoch: 13: Eval results *****
2025-04-17 11:12:15,458 -   train_loss = 5.664313316345215
2025-04-17 11:12:16,307 - ***** Epoch: 14: Eval results *****
2025-04-17 11:12:16,307 -   train_loss = 5.672481536865234
2025-04-17 11:12:17,151 - ***** Epoch: 15: Eval results *****
2025-04-17 11:12:17,152 -   train_loss = 5.666848182678223
2025-04-17 11:12:18,003 - ***** Epoch: 16: Eval results *****
2025-04-17 11:12:18,003 -   train_loss = 5.659595012664795
2025-04-17 11:12:18,843 - ***** Epoch: 17: Eval results *****
2025-04-17 11:12:18,843 -   train_loss = 5.670828342437744
2025-04-17 11:12:19,667 - ***** Epoch: 18: Eval results *****
2025-04-17 11:12:19,667 -   train_loss = 5.666743278503418
2025-04-17 11:12:20,557 - ***** Epoch: 19: Eval results *****
2025-04-17 11:12:20,558 -   train_loss = 5.670398235321045
2025-04-17 11:12:21,284 - ***** Epoch: 20: Eval results *****
2025-04-17 11:12:21,285 -   train_loss = 5.663257598876953
2025-04-17 11:12:21,986 - ***** Epoch: 21: Eval results *****
2025-04-17 11:12:21,986 -   train_loss = 5.666425704956055
2025-04-17 11:12:22,690 - ***** Epoch: 22: Eval results *****
2025-04-17 11:12:22,690 -   train_loss = 5.669877052307129
2025-04-17 11:12:23,402 - ***** Epoch: 23: Eval results *****
2025-04-17 11:12:23,402 -   train_loss = 5.655277252197266
2025-04-17 11:12:24,101 - ***** Epoch: 24: Eval results *****
2025-04-17 11:12:24,101 -   train_loss = 5.666933059692383
2025-04-17 11:12:24,809 - ***** Epoch: 25: Eval results *****
2025-04-17 11:12:24,809 -   train_loss = 5.661780834197998
2025-04-17 11:12:25,527 - ***** Epoch: 26: Eval results *****
2025-04-17 11:12:25,527 -   train_loss = 5.662614345550537
2025-04-17 11:12:26,268 - ***** Epoch: 27: Eval results *****
2025-04-17 11:12:26,268 -   train_loss = 5.655368328094482
2025-04-17 11:12:27,133 - ***** Epoch: 28: Eval results *****
2025-04-17 11:12:27,134 -   train_loss = 5.659499645233154
2025-04-17 11:12:28,023 - ***** Epoch: 29: Eval results *****
2025-04-17 11:12:28,023 -   train_loss = 5.65627384185791
2025-04-17 11:12:28,832 - ***** Epoch: 30: Eval results *****
2025-04-17 11:12:28,832 -   train_loss = 5.65287971496582
2025-04-17 11:12:29,536 - ***** Epoch: 31: Eval results *****
2025-04-17 11:12:29,536 -   train_loss = 5.6500444412231445
2025-04-17 11:12:30,376 - ***** Epoch: 32: Eval results *****
2025-04-17 11:12:30,376 -   train_loss = 5.6567158699035645
2025-04-17 11:12:31,162 - ***** Epoch: 33: Eval results *****
2025-04-17 11:12:31,162 -   train_loss = 5.653555393218994
2025-04-17 11:12:31,869 - ***** Epoch: 34: Eval results *****
2025-04-17 11:12:31,869 -   train_loss = 5.654788017272949
2025-04-17 11:12:32,571 - ***** Epoch: 35: Eval results *****
2025-04-17 11:12:32,572 -   train_loss = 5.652501583099365
2025-04-17 11:12:33,277 - ***** Epoch: 36: Eval results *****
2025-04-17 11:12:33,278 -   train_loss = 5.64117956161499
2025-04-17 11:12:33,984 - ***** Epoch: 37: Eval results *****
2025-04-17 11:12:33,984 -   train_loss = 5.645105838775635
2025-04-17 11:12:34,880 - ***** Epoch: 38: Eval results *****
2025-04-17 11:12:34,880 -   train_loss = 5.6434197425842285
2025-04-17 11:12:35,730 - ***** Epoch: 39: Eval results *****
2025-04-17 11:12:35,730 -   train_loss = 5.637889385223389
2025-04-17 11:12:36,607 - ***** Epoch: 40: Eval results *****
2025-04-17 11:12:36,608 -   train_loss = 5.634591579437256
2025-04-17 11:12:37,428 - ***** Epoch: 41: Eval results *****
2025-04-17 11:12:37,428 -   train_loss = 5.626519203186035
2025-04-17 11:12:38,138 - ***** Epoch: 42: Eval results *****
2025-04-17 11:12:38,138 -   train_loss = 5.621558666229248
2025-04-17 11:12:39,028 - ***** Epoch: 43: Eval results *****
2025-04-17 11:12:39,029 -   train_loss = 5.622928619384766
2025-04-17 11:12:39,877 - ***** Epoch: 44: Eval results *****
2025-04-17 11:12:39,877 -   train_loss = 5.621773719787598
2025-04-17 11:12:40,690 - ***** Epoch: 45: Eval results *****
2025-04-17 11:12:40,690 -   train_loss = 5.617896556854248
2025-04-17 11:12:41,565 - ***** Epoch: 46: Eval results *****
2025-04-17 11:12:41,566 -   train_loss = 5.6034040451049805
2025-04-17 11:12:42,414 - ***** Epoch: 47: Eval results *****
2025-04-17 11:12:42,414 -   train_loss = 5.611633777618408
2025-04-17 11:12:43,235 - ***** Epoch: 48: Eval results *****
2025-04-17 11:12:43,235 -   train_loss = 5.615212440490723
2025-04-17 11:12:43,943 - ***** Epoch: 49: Eval results *****
2025-04-17 11:12:43,944 -   train_loss = 5.604969501495361
2025-04-17 11:12:44,657 - ***** Epoch: 50: Eval results *****
2025-04-17 11:12:44,657 -   train_loss = 5.599095344543457
2025-04-17 11:12:45,365 - ***** Epoch: 51: Eval results *****
2025-04-17 11:12:45,365 -   train_loss = 5.601094722747803
2025-04-17 11:12:46,254 - ***** Epoch: 52: Eval results *****
2025-04-17 11:12:46,254 -   train_loss = 5.59708833694458
2025-04-17 11:12:47,071 - ***** Epoch: 53: Eval results *****
2025-04-17 11:12:47,071 -   train_loss = 5.598765850067139
2025-04-17 11:12:47,777 - ***** Epoch: 54: Eval results *****
2025-04-17 11:12:47,778 -   train_loss = 5.5719475746154785
2025-04-17 11:12:48,493 - ***** Epoch: 55: Eval results *****
2025-04-17 11:12:48,493 -   train_loss = 5.57935905456543
2025-04-17 11:12:49,319 - ***** Epoch: 56: Eval results *****
2025-04-17 11:12:49,320 -   train_loss = 5.5738019943237305
2025-04-17 11:12:50,190 - ***** Epoch: 57: Eval results *****
2025-04-17 11:12:50,191 -   train_loss = 5.580545425415039
2025-04-17 11:12:50,890 - ***** Epoch: 58: Eval results *****
2025-04-17 11:12:50,890 -   train_loss = 5.547483444213867
2025-04-17 11:12:51,746 - ***** Epoch: 59: Eval results *****
2025-04-17 11:12:51,746 -   train_loss = 5.549315452575684
2025-04-17 11:12:52,438 - ***** Epoch: 60: Eval results *****
2025-04-17 11:12:52,439 -   train_loss = 5.552517890930176
2025-04-17 11:12:53,136 - ***** Epoch: 61: Eval results *****
2025-04-17 11:12:53,136 -   train_loss = 5.545973777770996
2025-04-17 11:12:53,832 - ***** Epoch: 62: Eval results *****
2025-04-17 11:12:53,832 -   train_loss = 5.530674457550049
2025-04-17 11:12:54,682 - ***** Epoch: 63: Eval results *****
2025-04-17 11:12:54,682 -   train_loss = 5.526963710784912
2025-04-17 11:12:55,392 - ***** Epoch: 64: Eval results *****
2025-04-17 11:12:55,393 -   train_loss = 5.508195400238037
2025-04-17 11:12:56,104 - ***** Epoch: 65: Eval results *****
2025-04-17 11:12:56,105 -   train_loss = 5.516971111297607
2025-04-17 11:12:56,810 - ***** Epoch: 66: Eval results *****
2025-04-17 11:12:56,810 -   train_loss = 5.487467288970947
2025-04-17 11:12:57,507 - ***** Epoch: 67: Eval results *****
2025-04-17 11:12:57,508 -   train_loss = 5.49884557723999
2025-04-17 11:12:58,208 - ***** Epoch: 68: Eval results *****
2025-04-17 11:12:58,208 -   train_loss = 5.4802775382995605
2025-04-17 11:12:58,913 - ***** Epoch: 69: Eval results *****
2025-04-17 11:12:58,913 -   train_loss = 5.4838714599609375
2025-04-17 11:12:59,610 - ***** Epoch: 70: Eval results *****
2025-04-17 11:12:59,611 -   train_loss = 5.484116554260254
2025-04-17 11:13:00,488 - ***** Epoch: 71: Eval results *****
2025-04-17 11:13:00,488 -   train_loss = 5.453020095825195
2025-04-17 11:13:01,325 - ***** Epoch: 72: Eval results *****
2025-04-17 11:13:01,325 -   train_loss = 5.4424638748168945
2025-04-17 11:13:02,170 - ***** Epoch: 73: Eval results *****
2025-04-17 11:13:02,171 -   train_loss = 5.426928997039795
2025-04-17 11:13:02,981 - ***** Epoch: 74: Eval results *****
2025-04-17 11:13:02,981 -   train_loss = 5.426605701446533
2025-04-17 11:13:03,686 - ***** Epoch: 75: Eval results *****
2025-04-17 11:13:03,687 -   train_loss = 5.4117751121521
2025-04-17 11:13:04,538 - ***** Epoch: 76: Eval results *****
2025-04-17 11:13:04,538 -   train_loss = 5.391742706298828
2025-04-17 11:13:05,387 - ***** Epoch: 77: Eval results *****
2025-04-17 11:13:05,387 -   train_loss = 5.412423133850098
2025-04-17 11:13:06,104 - ***** Epoch: 78: Eval results *****
2025-04-17 11:13:06,104 -   train_loss = 5.401223182678223
2025-04-17 11:13:06,814 - ***** Epoch: 79: Eval results *****
2025-04-17 11:13:06,814 -   train_loss = 5.387191295623779
2025-04-17 11:13:07,514 - ***** Epoch: 80: Eval results *****
2025-04-17 11:13:07,514 -   train_loss = 5.384153366088867
2025-04-17 11:13:08,208 - ***** Epoch: 81: Eval results *****
2025-04-17 11:13:08,208 -   train_loss = 5.392790794372559
2025-04-17 11:13:09,049 - ***** Epoch: 82: Eval results *****
2025-04-17 11:13:09,049 -   train_loss = 5.363919258117676
2025-04-17 11:13:09,882 - ***** Epoch: 83: Eval results *****
2025-04-17 11:13:09,883 -   train_loss = 5.346900463104248
2025-04-17 11:13:10,724 - ***** Epoch: 84: Eval results *****
2025-04-17 11:13:10,724 -   train_loss = 5.3417253494262695
2025-04-17 11:13:11,592 - ***** Epoch: 85: Eval results *****
2025-04-17 11:13:11,592 -   train_loss = 5.328564167022705
2025-04-17 11:13:12,397 - ***** Epoch: 86: Eval results *****
2025-04-17 11:13:12,398 -   train_loss = 5.326342582702637
2025-04-17 11:13:13,285 - ***** Epoch: 87: Eval results *****
2025-04-17 11:13:13,285 -   train_loss = 5.324619770050049
2025-04-17 11:13:14,133 - ***** Epoch: 88: Eval results *****
2025-04-17 11:13:14,133 -   train_loss = 5.291970252990723
2025-04-17 11:13:14,941 - ***** Epoch: 89: Eval results *****
2025-04-17 11:13:14,942 -   train_loss = 5.279888153076172
2025-04-17 11:13:15,789 - ***** Epoch: 90: Eval results *****
2025-04-17 11:13:15,789 -   train_loss = 5.272079944610596
2025-04-17 11:13:16,621 - ***** Epoch: 91: Eval results *****
2025-04-17 11:13:16,622 -   train_loss = 5.275430202484131
2025-04-17 11:13:17,452 - ***** Epoch: 92: Eval results *****
2025-04-17 11:13:17,452 -   train_loss = 5.281527042388916
2025-04-17 11:13:18,267 - ***** Epoch: 93: Eval results *****
2025-04-17 11:13:18,268 -   train_loss = 5.2698140144348145
2025-04-17 11:13:18,976 - ***** Epoch: 94: Eval results *****
2025-04-17 11:13:18,976 -   train_loss = 5.254870414733887
2025-04-17 11:13:19,856 - ***** Epoch: 95: Eval results *****
2025-04-17 11:13:19,856 -   train_loss = 5.254139423370361
2025-04-17 11:13:20,684 - ***** Epoch: 96: Eval results *****
2025-04-17 11:13:20,684 -   train_loss = 5.229580879211426
2025-04-17 11:13:21,513 - ***** Epoch: 97: Eval results *****
2025-04-17 11:13:21,513 -   train_loss = 5.216431617736816
2025-04-17 11:13:22,367 - ***** Epoch: 98: Eval results *****
2025-04-17 11:13:22,367 -   train_loss = 5.247365474700928
2025-04-17 11:13:23,192 - ***** Epoch: 99: Eval results *****
2025-04-17 11:13:23,192 -   train_loss = 5.19832181930542
2025-04-17 11:13:24,016 - ***** Epoch: 100: Eval results *****
2025-04-17 11:13:24,017 -   train_loss = 5.189342498779297
2025-04-17 11:13:25,695 - Pre-training finished...
2025-04-17 11:13:26,049 - Freeze all parameters but the last layer for efficiency
2025-04-17 11:13:26,059 - Multimodal Intent Recognition begins...
2025-04-17 11:13:26,059 - Training begins...
2025-04-17 11:13:36,789 - Initializing centroids with K-means++...
2025-04-17 11:13:36,844 - K-means++ used 0.05 s
2025-04-17 11:14:08,833 - K-means used 0.03 s
2025-04-17 11:14:09,846 - ***** Epoch: 1 *****
2025-04-17 11:14:09,847 - Supervised Training Loss: 5.236590
2025-04-17 11:14:09,847 - Unsupervised Training Loss: 5.825780
2025-04-17 11:14:37,394 - K-means used 0.02 s
2025-04-17 11:14:38,457 - ***** Epoch: 2 *****
2025-04-17 11:14:38,457 - Supervised Training Loss: 4.049280
2025-04-17 11:14:38,457 - Unsupervised Training Loss: 5.810210
2025-04-17 11:15:04,336 - K-means used 0.02 s
2025-04-17 11:15:05,699 - ***** Epoch: 3 *****
2025-04-17 11:15:05,699 - Supervised Training Loss: 5.357170
2025-04-17 11:15:05,699 - Unsupervised Training Loss: 5.589280
2025-04-17 11:15:33,201 - K-means used 0.03 s
2025-04-17 11:15:34,295 - ***** Epoch: 4 *****
2025-04-17 11:15:34,295 - Supervised Training Loss: 5.048590
2025-04-17 11:15:34,296 - Unsupervised Training Loss: 5.608090
2025-04-17 11:16:00,846 - K-means used 0.02 s
2025-04-17 11:16:02,034 - ***** Epoch: 5 *****
2025-04-17 11:16:02,034 - Supervised Training Loss: 4.682840
2025-04-17 11:16:02,035 - Unsupervised Training Loss: 5.611080
2025-04-17 11:16:29,584 - K-means used 0.02 s
2025-04-17 11:16:31,081 - ***** Epoch: 6 *****
2025-04-17 11:16:31,082 - Supervised Training Loss: 4.924130
2025-04-17 11:16:31,082 - Unsupervised Training Loss: 5.359920
2025-04-17 11:16:59,183 - K-means used 0.02 s
2025-04-17 11:17:00,404 - ***** Epoch: 7 *****
2025-04-17 11:17:00,404 - Supervised Training Loss: 4.818990
2025-04-17 11:17:00,404 - Unsupervised Training Loss: 5.488060
2025-04-17 11:17:29,063 - K-means used 0.02 s
2025-04-17 11:17:30,312 - ***** Epoch: 8 *****
2025-04-17 11:17:30,312 - Supervised Training Loss: 4.687540
2025-04-17 11:17:30,312 - Unsupervised Training Loss: 5.539960
2025-04-17 11:17:58,997 - K-means used 0.02 s
2025-04-17 11:18:00,286 - ***** Epoch: 9 *****
2025-04-17 11:18:00,286 - Supervised Training Loss: 4.893280
2025-04-17 11:18:00,286 - Unsupervised Training Loss: 5.581750
2025-04-17 11:18:27,599 - K-means used 0.02 s
2025-04-17 11:18:29,021 - ***** Epoch: 10 *****
2025-04-17 11:18:29,022 - Supervised Training Loss: 4.808040
2025-04-17 11:18:29,022 - Unsupervised Training Loss: 5.425750
2025-04-17 11:18:57,120 - K-means used 0.02 s
2025-04-17 11:18:58,479 - ***** Epoch: 11 *****
2025-04-17 11:18:58,480 - Supervised Training Loss: 4.728180
2025-04-17 11:18:58,480 - Unsupervised Training Loss: 5.505350
2025-04-17 11:19:26,971 - K-means used 0.02 s
2025-04-17 11:19:28,431 - ***** Epoch: 12 *****
2025-04-17 11:19:28,431 - Supervised Training Loss: 4.867850
2025-04-17 11:19:28,431 - Unsupervised Training Loss: 5.564100
2025-04-17 11:19:56,205 - K-means used 0.12 s
2025-04-17 11:19:57,702 - ***** Epoch: 13 *****
2025-04-17 11:19:57,702 - Supervised Training Loss: 4.818080
2025-04-17 11:19:57,702 - Unsupervised Training Loss: 5.308080
2025-04-17 11:20:23,730 - K-means used 0.02 s
2025-04-17 11:20:25,365 - ***** Epoch: 14 *****
2025-04-17 11:20:25,365 - Supervised Training Loss: 4.769950
2025-04-17 11:20:25,365 - Unsupervised Training Loss: 5.415180
2025-04-17 11:20:52,856 - K-means used 0.02 s
2025-04-17 11:20:54,557 - ***** Epoch: 15 *****
2025-04-17 11:20:54,558 - Supervised Training Loss: 4.640950
2025-04-17 11:20:54,558 - Unsupervised Training Loss: 5.516450
2025-04-17 11:21:23,201 - K-means used 0.01 s
2025-04-17 11:21:25,018 - ***** Epoch: 16 *****
2025-04-17 11:21:25,018 - Supervised Training Loss: 4.832760
2025-04-17 11:21:25,018 - Unsupervised Training Loss: 4.891320
2025-04-17 11:21:53,022 - K-means used 0.01 s
2025-04-17 11:21:54,848 - ***** Epoch: 17 *****
2025-04-17 11:21:54,848 - Supervised Training Loss: 4.807440
2025-04-17 11:21:54,848 - Unsupervised Training Loss: 5.202280
2025-04-17 11:22:13,710 - Training is finished...
2025-04-17 11:22:13,710 - Testing begins...
2025-04-17 11:22:20,023 - ***** Test results *****
2025-04-17 11:22:20,023 -   ACC = 22.92
2025-04-17 11:22:20,023 -   ARI = 7.29
2025-04-17 11:22:20,023 -   NMI = 30.79
2025-04-17 11:22:20,023 -   fmi = 13.09
2025-04-17 11:22:20,024 - Testing is finished...
2025-04-17 11:22:20,024 - Multimodal intent recognition is finished...
2025-04-17 11:22:20,024 - Results are saved in results/results_umc_pre.csv
2025-04-17 11:22:21,098 - Freeze all parameters but the last layer for efficiency
2025-04-17 11:22:21,139 - Pre-training start...
2025-04-17 11:22:21,983 - ***** Epoch: 1: Eval results *****
2025-04-17 11:22:21,983 -   train_loss = 5.6571269035339355
2025-04-17 11:22:22,818 - ***** Epoch: 2: Eval results *****
2025-04-17 11:22:22,818 -   train_loss = 5.659434795379639
2025-04-17 11:22:23,649 - ***** Epoch: 3: Eval results *****
2025-04-17 11:22:23,649 -   train_loss = 5.651946067810059
2025-04-17 11:22:24,470 - ***** Epoch: 4: Eval results *****
2025-04-17 11:22:24,470 -   train_loss = 5.65964412689209
2025-04-17 11:22:25,275 - ***** Epoch: 5: Eval results *****
2025-04-17 11:22:25,275 -   train_loss = 5.6529927253723145
2025-04-17 11:22:26,063 - ***** Epoch: 6: Eval results *****
2025-04-17 11:22:26,064 -   train_loss = 5.6491217613220215
2025-04-17 11:22:26,913 - ***** Epoch: 7: Eval results *****
2025-04-17 11:22:26,914 -   train_loss = 5.654989719390869
2025-04-17 11:22:27,740 - ***** Epoch: 8: Eval results *****
2025-04-17 11:22:27,740 -   train_loss = 5.662746429443359
2025-04-17 11:22:28,563 - ***** Epoch: 9: Eval results *****
2025-04-17 11:22:28,563 -   train_loss = 5.657382965087891
2025-04-17 11:22:29,382 - ***** Epoch: 10: Eval results *****
2025-04-17 11:22:29,382 -   train_loss = 5.659665584564209
2025-04-17 11:22:30,202 - ***** Epoch: 11: Eval results *****
2025-04-17 11:22:30,203 -   train_loss = 5.654342174530029
2025-04-17 11:22:31,040 - ***** Epoch: 12: Eval results *****
2025-04-17 11:22:31,040 -   train_loss = 5.655350685119629
2025-04-17 11:22:31,830 - ***** Epoch: 13: Eval results *****
2025-04-17 11:22:31,830 -   train_loss = 5.654000759124756
2025-04-17 11:22:32,682 - ***** Epoch: 14: Eval results *****
2025-04-17 11:22:32,682 -   train_loss = 5.651859760284424
2025-04-17 11:22:33,488 - ***** Epoch: 15: Eval results *****
2025-04-17 11:22:33,489 -   train_loss = 5.655356407165527
2025-04-17 11:22:34,290 - ***** Epoch: 16: Eval results *****
2025-04-17 11:22:34,290 -   train_loss = 5.649477958679199
2025-04-17 11:22:35,097 - ***** Epoch: 17: Eval results *****
2025-04-17 11:22:35,097 -   train_loss = 5.648185729980469
2025-04-17 11:22:35,891 - ***** Epoch: 18: Eval results *****
2025-04-17 11:22:35,891 -   train_loss = 5.652294635772705
2025-04-17 11:22:36,575 - ***** Epoch: 19: Eval results *****
2025-04-17 11:22:36,576 -   train_loss = 5.643340110778809
2025-04-17 11:22:37,398 - ***** Epoch: 20: Eval results *****
2025-04-17 11:22:37,398 -   train_loss = 5.64902925491333
2025-04-17 11:22:38,076 - ***** Epoch: 21: Eval results *****
2025-04-17 11:22:38,077 -   train_loss = 5.651147365570068
2025-04-17 11:22:38,762 - ***** Epoch: 22: Eval results *****
2025-04-17 11:22:38,762 -   train_loss = 5.646477222442627
2025-04-17 11:22:39,447 - ***** Epoch: 23: Eval results *****
2025-04-17 11:22:39,448 -   train_loss = 5.646996021270752
2025-04-17 11:22:40,144 - ***** Epoch: 24: Eval results *****
2025-04-17 11:22:40,144 -   train_loss = 5.646023750305176
2025-04-17 11:22:40,987 - ***** Epoch: 25: Eval results *****
2025-04-17 11:22:40,987 -   train_loss = 5.63762092590332
2025-04-17 11:22:41,802 - ***** Epoch: 26: Eval results *****
2025-04-17 11:22:41,803 -   train_loss = 5.6422576904296875
2025-04-17 11:22:42,578 - ***** Epoch: 27: Eval results *****
2025-04-17 11:22:42,578 -   train_loss = 5.635482311248779
2025-04-17 11:22:43,391 - ***** Epoch: 28: Eval results *****
2025-04-17 11:22:43,391 -   train_loss = 5.6387553215026855
2025-04-17 11:22:44,192 - ***** Epoch: 29: Eval results *****
2025-04-17 11:22:44,192 -   train_loss = 5.628870964050293
2025-04-17 11:22:45,021 - ***** Epoch: 30: Eval results *****
2025-04-17 11:22:45,022 -   train_loss = 5.6275315284729
2025-04-17 11:22:45,839 - ***** Epoch: 31: Eval results *****
2025-04-17 11:22:45,839 -   train_loss = 5.632128715515137
2025-04-17 11:22:46,662 - ***** Epoch: 32: Eval results *****
2025-04-17 11:22:46,663 -   train_loss = 5.6230878829956055
2025-04-17 11:22:47,461 - ***** Epoch: 33: Eval results *****
2025-04-17 11:22:47,461 -   train_loss = 5.623729705810547
2025-04-17 11:22:48,328 - ***** Epoch: 34: Eval results *****
2025-04-17 11:22:48,328 -   train_loss = 5.628900051116943
2025-04-17 11:22:49,128 - ***** Epoch: 35: Eval results *****
2025-04-17 11:22:49,129 -   train_loss = 5.611391067504883
2025-04-17 11:22:49,976 - ***** Epoch: 36: Eval results *****
2025-04-17 11:22:49,977 -   train_loss = 5.606020927429199
2025-04-17 11:22:50,765 - ***** Epoch: 37: Eval results *****
2025-04-17 11:22:50,766 -   train_loss = 5.604481220245361
2025-04-17 11:22:51,454 - ***** Epoch: 38: Eval results *****
2025-04-17 11:22:51,454 -   train_loss = 5.60474967956543
2025-04-17 11:22:52,154 - ***** Epoch: 39: Eval results *****
2025-04-17 11:22:52,154 -   train_loss = 5.597175121307373
2025-04-17 11:22:53,001 - ***** Epoch: 40: Eval results *****
2025-04-17 11:22:53,001 -   train_loss = 5.599037170410156
2025-04-17 11:22:53,771 - ***** Epoch: 41: Eval results *****
2025-04-17 11:22:53,771 -   train_loss = 5.599602222442627
2025-04-17 11:22:54,616 - ***** Epoch: 42: Eval results *****
2025-04-17 11:22:54,617 -   train_loss = 5.591963291168213
2025-04-17 11:22:55,433 - ***** Epoch: 43: Eval results *****
2025-04-17 11:22:55,433 -   train_loss = 5.579082489013672
2025-04-17 11:22:56,273 - ***** Epoch: 44: Eval results *****
2025-04-17 11:22:56,274 -   train_loss = 5.576801300048828
2025-04-17 11:22:57,072 - ***** Epoch: 45: Eval results *****
2025-04-17 11:22:57,072 -   train_loss = 5.5835089683532715
2025-04-17 11:22:57,756 - ***** Epoch: 46: Eval results *****
2025-04-17 11:22:57,756 -   train_loss = 5.576083660125732
2025-04-17 11:22:58,438 - ***** Epoch: 47: Eval results *****
2025-04-17 11:22:58,438 -   train_loss = 5.5675458908081055
2025-04-17 11:22:59,290 - ***** Epoch: 48: Eval results *****
2025-04-17 11:22:59,290 -   train_loss = 5.558106422424316
2025-04-17 11:23:00,105 - ***** Epoch: 49: Eval results *****
2025-04-17 11:23:00,106 -   train_loss = 5.556573390960693
2025-04-17 11:23:00,924 - ***** Epoch: 50: Eval results *****
2025-04-17 11:23:00,924 -   train_loss = 5.549458980560303
2025-04-17 11:23:01,726 - ***** Epoch: 51: Eval results *****
2025-04-17 11:23:01,726 -   train_loss = 5.539211750030518
2025-04-17 11:23:02,586 - ***** Epoch: 52: Eval results *****
2025-04-17 11:23:02,586 -   train_loss = 5.534213066101074
2025-04-17 11:23:03,384 - ***** Epoch: 53: Eval results *****
2025-04-17 11:23:03,384 -   train_loss = 5.523798942565918
2025-04-17 11:23:04,185 - ***** Epoch: 54: Eval results *****
2025-04-17 11:23:04,186 -   train_loss = 5.5317158699035645
2025-04-17 11:23:04,965 - ***** Epoch: 55: Eval results *****
2025-04-17 11:23:04,965 -   train_loss = 5.509167671203613
2025-04-17 11:23:05,814 - ***** Epoch: 56: Eval results *****
2025-04-17 11:23:05,814 -   train_loss = 5.515948295593262
2025-04-17 11:23:06,631 - ***** Epoch: 57: Eval results *****
2025-04-17 11:23:06,631 -   train_loss = 5.500900745391846
2025-04-17 11:23:07,444 - ***** Epoch: 58: Eval results *****
2025-04-17 11:23:07,444 -   train_loss = 5.4896745681762695
2025-04-17 11:23:08,256 - ***** Epoch: 59: Eval results *****
2025-04-17 11:23:08,257 -   train_loss = 5.491918087005615
2025-04-17 11:23:09,047 - ***** Epoch: 60: Eval results *****
2025-04-17 11:23:09,047 -   train_loss = 5.473762512207031
2025-04-17 11:23:09,906 - ***** Epoch: 61: Eval results *****
2025-04-17 11:23:09,906 -   train_loss = 5.468201160430908
2025-04-17 11:23:10,722 - ***** Epoch: 62: Eval results *****
2025-04-17 11:23:10,722 -   train_loss = 5.467742443084717
2025-04-17 11:23:11,539 - ***** Epoch: 63: Eval results *****
2025-04-17 11:23:11,540 -   train_loss = 5.462310314178467
2025-04-17 11:23:12,355 - ***** Epoch: 64: Eval results *****
2025-04-17 11:23:12,355 -   train_loss = 5.460247993469238
2025-04-17 11:23:13,134 - ***** Epoch: 65: Eval results *****
2025-04-17 11:23:13,134 -   train_loss = 5.438209056854248
2025-04-17 11:23:13,812 - ***** Epoch: 66: Eval results *****
2025-04-17 11:23:13,812 -   train_loss = 5.422358512878418
2025-04-17 11:23:14,486 - ***** Epoch: 67: Eval results *****
2025-04-17 11:23:14,486 -   train_loss = 5.421695232391357
2025-04-17 11:23:15,236 - ***** Epoch: 68: Eval results *****
2025-04-17 11:23:15,236 -   train_loss = 5.403068542480469
2025-04-17 11:23:16,077 - ***** Epoch: 69: Eval results *****
2025-04-17 11:23:16,077 -   train_loss = 5.408064842224121
2025-04-17 11:23:16,896 - ***** Epoch: 70: Eval results *****
2025-04-17 11:23:16,896 -   train_loss = 5.402956962585449
2025-04-17 11:23:17,674 - ***** Epoch: 71: Eval results *****
2025-04-17 11:23:17,674 -   train_loss = 5.388171672821045
2025-04-17 11:23:18,358 - ***** Epoch: 72: Eval results *****
2025-04-17 11:23:18,358 -   train_loss = 5.384737968444824
2025-04-17 11:23:19,205 - ***** Epoch: 73: Eval results *****
2025-04-17 11:23:19,205 -   train_loss = 5.363260269165039
2025-04-17 11:23:20,009 - ***** Epoch: 74: Eval results *****
2025-04-17 11:23:20,010 -   train_loss = 5.379769325256348
2025-04-17 11:23:20,817 - ***** Epoch: 75: Eval results *****
2025-04-17 11:23:20,818 -   train_loss = 5.351689338684082
2025-04-17 11:23:21,619 - ***** Epoch: 76: Eval results *****
2025-04-17 11:23:21,620 -   train_loss = 5.356407642364502
2025-04-17 11:23:22,318 - ***** Epoch: 77: Eval results *****
2025-04-17 11:23:22,318 -   train_loss = 5.3502631187438965
2025-04-17 11:23:23,012 - ***** Epoch: 78: Eval results *****
2025-04-17 11:23:23,012 -   train_loss = 5.339759826660156
2025-04-17 11:23:23,862 - ***** Epoch: 79: Eval results *****
2025-04-17 11:23:23,863 -   train_loss = 5.329223155975342
2025-04-17 11:23:24,666 - ***** Epoch: 80: Eval results *****
2025-04-17 11:23:24,666 -   train_loss = 5.325547218322754
2025-04-17 11:23:25,465 - ***** Epoch: 81: Eval results *****
2025-04-17 11:23:25,465 -   train_loss = 5.312453269958496
2025-04-17 11:23:26,242 - ***** Epoch: 82: Eval results *****
2025-04-17 11:23:26,242 -   train_loss = 5.320372104644775
2025-04-17 11:23:26,920 - ***** Epoch: 83: Eval results *****
2025-04-17 11:23:26,921 -   train_loss = 5.300292015075684
2025-04-17 11:23:27,764 - ***** Epoch: 84: Eval results *****
2025-04-17 11:23:27,764 -   train_loss = 5.295267105102539
2025-04-17 11:23:28,443 - ***** Epoch: 85: Eval results *****
2025-04-17 11:23:28,443 -   train_loss = 5.289042949676514
2025-04-17 11:23:29,144 - ***** Epoch: 86: Eval results *****
2025-04-17 11:23:29,145 -   train_loss = 5.272461414337158
2025-04-17 11:23:29,956 - ***** Epoch: 87: Eval results *****
2025-04-17 11:23:29,956 -   train_loss = 5.284658908843994
2025-04-17 11:23:30,769 - ***** Epoch: 88: Eval results *****
2025-04-17 11:23:30,769 -   train_loss = 5.250197887420654
2025-04-17 11:23:31,584 - ***** Epoch: 89: Eval results *****
2025-04-17 11:23:31,585 -   train_loss = 5.246439456939697
2025-04-17 11:23:32,401 - ***** Epoch: 90: Eval results *****
2025-04-17 11:23:32,402 -   train_loss = 5.242994785308838
2025-04-17 11:23:33,181 - ***** Epoch: 91: Eval results *****
2025-04-17 11:23:33,181 -   train_loss = 5.243057727813721
2025-04-17 11:23:33,857 - ***** Epoch: 92: Eval results *****
2025-04-17 11:23:33,857 -   train_loss = 5.2269978523254395
2025-04-17 11:23:34,705 - ***** Epoch: 93: Eval results *****
2025-04-17 11:23:34,705 -   train_loss = 5.238183975219727
2025-04-17 11:23:35,514 - ***** Epoch: 94: Eval results *****
2025-04-17 11:23:35,514 -   train_loss = 5.224828720092773
2025-04-17 11:23:36,326 - ***** Epoch: 95: Eval results *****
2025-04-17 11:23:36,326 -   train_loss = 5.2023539543151855
2025-04-17 11:23:37,145 - ***** Epoch: 96: Eval results *****
2025-04-17 11:23:37,145 -   train_loss = 5.216451168060303
2025-04-17 11:23:37,957 - ***** Epoch: 97: Eval results *****
2025-04-17 11:23:37,957 -   train_loss = 5.213382244110107
2025-04-17 11:23:38,761 - ***** Epoch: 98: Eval results *****
2025-04-17 11:23:38,761 -   train_loss = 5.170645236968994
2025-04-17 11:23:39,457 - ***** Epoch: 99: Eval results *****
2025-04-17 11:23:39,457 -   train_loss = 5.188669204711914
2025-04-17 11:23:40,136 - ***** Epoch: 100: Eval results *****
2025-04-17 11:23:40,136 -   train_loss = 5.176361560821533
2025-04-17 11:23:41,745 - Pre-training finished...
2025-04-17 11:23:41,945 - Freeze all parameters but the last layer for efficiency
2025-04-17 11:23:41,952 - Multimodal Intent Recognition begins...
2025-04-17 11:23:41,953 - Training begins...
2025-04-17 11:23:52,490 - Initializing centroids with K-means++...
2025-04-17 11:23:52,549 - K-means++ used 0.06 s
2025-04-17 11:24:22,441 - K-means used 0.03 s
2025-04-17 11:24:23,502 - ***** Epoch: 1 *****
2025-04-17 11:24:23,502 - Supervised Training Loss: 5.226230
2025-04-17 11:24:23,503 - Unsupervised Training Loss: 5.826910
2025-04-17 11:24:54,897 - K-means used 0.06 s
2025-04-17 11:24:55,972 - ***** Epoch: 2 *****
2025-04-17 11:24:55,972 - Supervised Training Loss: 4.319340
2025-04-17 11:24:55,972 - Unsupervised Training Loss: 5.813800
2025-04-17 11:25:24,748 - K-means used 0.03 s
2025-04-17 11:25:25,813 - ***** Epoch: 3 *****
2025-04-17 11:25:25,813 - Supervised Training Loss: 5.400910
2025-04-17 11:25:25,813 - Unsupervised Training Loss: 5.618030
2025-04-17 11:25:55,250 - K-means used 0.02 s
2025-04-17 11:25:56,472 - ***** Epoch: 4 *****
2025-04-17 11:25:56,473 - Supervised Training Loss: 5.052030
2025-04-17 11:25:56,473 - Unsupervised Training Loss: 5.617910
2025-04-17 11:26:25,194 - K-means used 0.02 s
2025-04-17 11:26:26,570 - ***** Epoch: 5 *****
2025-04-17 11:26:26,570 - Supervised Training Loss: 4.653550
2025-04-17 11:26:26,570 - Unsupervised Training Loss: 5.627620
2025-04-17 11:26:58,256 - K-means used 0.02 s
2025-04-17 11:26:59,514 - ***** Epoch: 6 *****
2025-04-17 11:26:59,514 - Supervised Training Loss: 4.982960
2025-04-17 11:26:59,514 - Unsupervised Training Loss: 5.397530
2025-04-17 11:27:30,417 - K-means used 0.02 s
2025-04-17 11:27:31,699 - ***** Epoch: 7 *****
2025-04-17 11:27:31,699 - Supervised Training Loss: 4.850830
2025-04-17 11:27:31,699 - Unsupervised Training Loss: 5.509670
2025-04-17 11:27:59,583 - K-means used 0.02 s
2025-04-17 11:28:01,081 - ***** Epoch: 8 *****
2025-04-17 11:28:01,081 - Supervised Training Loss: 4.694780
2025-04-17 11:28:01,081 - Unsupervised Training Loss: 5.558510
2025-04-17 11:28:29,778 - K-means used 0.03 s
2025-04-17 11:28:31,246 - ***** Epoch: 9 *****
2025-04-17 11:28:31,246 - Supervised Training Loss: 4.882150
2025-04-17 11:28:31,246 - Unsupervised Training Loss: 4.983850
2025-04-17 11:29:00,300 - K-means used 0.02 s
2025-04-17 11:29:01,937 - ***** Epoch: 10 *****
2025-04-17 11:29:01,938 - Supervised Training Loss: 4.808290
2025-04-17 11:29:01,938 - Unsupervised Training Loss: 5.433000
2025-04-17 11:29:29,636 - K-means used 0.02 s
2025-04-17 11:29:31,142 - ***** Epoch: 11 *****
2025-04-17 11:29:31,142 - Supervised Training Loss: 4.723440
2025-04-17 11:29:31,142 - Unsupervised Training Loss: 5.513740
2025-04-17 11:29:58,324 - K-means used 0.02 s
2025-04-17 11:29:59,870 - ***** Epoch: 12 *****
2025-04-17 11:29:59,870 - Supervised Training Loss: 4.853890
2025-04-17 11:29:59,870 - Unsupervised Training Loss: 5.572910
2025-04-17 11:30:28,492 - K-means used 0.02 s
2025-04-17 11:30:30,238 - ***** Epoch: 13 *****
2025-04-17 11:30:30,238 - Supervised Training Loss: 4.791440
2025-04-17 11:30:30,238 - Unsupervised Training Loss: 5.298720
2025-04-17 11:30:58,652 - K-means used 0.02 s
2025-04-17 11:31:00,680 - ***** Epoch: 14 *****
2025-04-17 11:31:00,680 - Supervised Training Loss: 4.754350
2025-04-17 11:31:00,680 - Unsupervised Training Loss: 5.432390
2025-04-17 11:31:27,333 - K-means used 0.02 s
2025-04-17 11:31:29,306 - ***** Epoch: 15 *****
2025-04-17 11:31:29,307 - Supervised Training Loss: 4.591820
2025-04-17 11:31:29,307 - Unsupervised Training Loss: 5.540070
2025-04-17 11:31:56,992 - K-means used 0.02 s
2025-04-17 11:31:58,963 - ***** Epoch: 16 *****
2025-04-17 11:31:58,963 - Supervised Training Loss: 4.821070
2025-04-17 11:31:58,964 - Unsupervised Training Loss: 4.973630
2025-04-17 11:32:26,381 - K-means used 0.02 s
2025-04-17 11:32:28,453 - ***** Epoch: 17 *****
2025-04-17 11:32:28,453 - Supervised Training Loss: 4.797680
2025-04-17 11:32:28,453 - Unsupervised Training Loss: 5.201020
2025-04-17 11:32:45,448 - Training is finished...
2025-04-17 11:32:45,449 - Testing begins...
2025-04-17 11:32:52,941 - ***** Test results *****
2025-04-17 11:32:52,942 -   ACC = 21.57
2025-04-17 11:32:52,942 -   ARI = 5.89
2025-04-17 11:32:52,942 -   NMI = 27.51
2025-04-17 11:32:52,942 -   fmi = 12.14
2025-04-17 11:32:52,942 - Testing is finished...
2025-04-17 11:32:52,942 - Multimodal intent recognition is finished...
2025-04-17 11:32:52,942 - Results are saved in results/results_umc_pre.csv
